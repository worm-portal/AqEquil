<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>AqEquil.AqSpeciation API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>AqEquil.AqSpeciation</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">DEBUGGING_R = True
FIXED_SPECIES = [&#34;H2O&#34;, &#34;H+&#34;, &#34;O2(g)&#34;, &#34;water&#34;, &#34;Cl-&#34;, &#34;e-&#34;, &#34;OH-&#34;, &#34;O2&#34;, &#34;H2O(g)&#34;]

import os
import re
import sys
import shutil
import copy
import collections
import dill
import math
from itertools import groupby

from urllib.request import urlopen
from io import StringIO

import warnings
import subprocess
import pkg_resources
import pandas as pd
import numpy as np
from chemparse import parse_formula
from IPython.core.display import display, HTML
import periodictable

from ._HKF_cgl import OBIGT2eos, calc_logK

# matplotlib for static plots
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import plotly.express as px
import plotly.io as pio

from plotly.subplots import make_subplots
import plotly.graph_objects as go

# rpy2 for Python and R integration
import rpy2.rinterface_lib.callbacks
import logging
rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR) # will display errors, but not warnings

import rpy2.robjects as ro
from rpy2.robjects import pandas2ri
pandas2ri.activate()


def load(filename, messages=True, hide_traceback=True):
    
    &#34;&#34;&#34;
    Load a speciation file.

    Parameters
    ----------
    filename : str
        Name of the speciation file.

    messages : bool, default True
        Print messages produced by this function?

    hide_traceback : bool, default True
        Hide traceback message when encountering errors handled by this function?
        When True, error messages handled by this class will be short and to
        the point.

    Returns
    ----------
    An object of class `Speciation`.
    &#34;&#34;&#34;

    err_handler = Error_Handler(clean=hide_traceback)
    
    if len(filename) &lt;= 12:
        print(&#34;Attempting to load &#34;+str(filename)+&#34;.speciation ...&#34;)
        filename = filename+&#34;.speciation&#34;
    
    if &#39;speciation&#39; in filename[-11:]:
        if os.path.exists(filename) and os.path.isfile(filename):
            pass
        else:
            err = &#34;Cannot locate input file {}/{}&#34;.format(os.getcwd(), filename)
            err_handler.raise_exception(err)
    else:
        err = (&#34;Input file {}&#34;.format(filename) + &#34; &#34;
            &#34;must be in {} format.&#34;.format(ext_dict[ext]))
        err_handler.raise_exception(err)
    
    if os.path.getsize(filename) &gt; 0:
        with open(filename, &#39;rb&#39;) as handle:
            speciation = dill.load(handle)
            if messages:
                print(&#34;Loaded &#39;{}&#39;&#34;.format(filename))
            return speciation
    else:
        msg = &#34;Cannot open &#34; + str(filename) + &#34; because the file is empty.&#34;
        err_handler.raise_exception(msg)


def _float_to_fraction (x, error=0.000001):
    
    &#34;&#34;&#34;
    Convert a float into a fraction. Works with floats like 2.66666666.
    Solution from https://stackoverflow.com/a/5128558/8406195
    &#34;&#34;&#34;
    n = int(math.floor(x))
    x -= n
    if x &lt; error:
        return (n, 1)
    elif 1 - error &lt; x:
        return (n+1, 1)

    # The lower fraction is 0/1
    lower_n = 0
    lower_d = 1
    # The upper fraction is 1/1
    upper_n = 1
    upper_d = 1
    while True:
        # The middle fraction is (lower_n + upper_n) / (lower_d + upper_d)
        middle_n = lower_n + upper_n
        middle_d = lower_d + upper_d
        # If x + error &lt; middle
        if middle_d * (x + error) &lt; middle_n:
            # middle is our new upper
            upper_n = middle_n
            upper_d = middle_d
        # Else If middle &lt; x - error
        elif middle_n &lt; (x - error) * middle_d:
            # middle is our new lower
            lower_n = middle_n
            lower_d = middle_d
        # Else middle is our best fraction
        else:
            return (n * middle_d + middle_n, middle_d)

    
def _float_to_formatted_fraction(x, error=0.000001):
    
    &#34;&#34;&#34;
    Format a fraction for html.
    &#34;&#34;&#34;
    f = _float_to_fraction(x, error=error)
    
    whole_number_float = int((f[0]-(f[0]%f[1]))/f[1])
    remainder_tuple = (f[0]%f[1], f[1])
    
    if remainder_tuple[0] == 0:
        return str(whole_number_float)
    else:
        if whole_number_float == 0:
            whole_number_float = &#34;&#34;
        return &#34;{0}&lt;sup&gt;{1}&lt;/sup&gt;&amp;frasl;&lt;sub&gt;{2}&lt;/sub&gt;&#34;.format(
                whole_number_float, remainder_tuple[0], remainder_tuple[1])


def _format_coeff(coeff):
    
    &#34;&#34;&#34;
    Format a reaction coefficient for html.
    &#34;&#34;&#34;
    if coeff == 1 or coeff == -1:
        coeff = &#34;&#34;
    elif coeff.is_integer() and coeff &lt; 0:
        coeff = str(-int(coeff))
    elif coeff.is_integer() and coeff &gt; 0:
        coeff = str(int(coeff))
    else:
        if coeff &lt; 0:
            coeff = _float_to_formatted_fraction(-coeff)
        else:
            coeff = _float_to_formatted_fraction(coeff)

    if coeff != &#34;&#34;:
        coeff = coeff + &#34; &#34;

    return coeff


def _convert_to_RVector(value, force_Rvec=True):
    
    &#34;&#34;&#34;
    Convert a value or list into an R vector of the appropriate type.
    
    Parameters
    ----------
    value : numeric or str, or list of numeric or str
        Value to be converted.
    
    force_Rvec : bool, default True
        If `value` is not a list, force conversion into a R vector?
        False will return an int, float, or str if value is non-list.
        True will always return an R vector.
    
    Returns
    -------
    int, float, str, or an rpy2 R vector
        A value or R vector of an appropriate data type.
    &#34;&#34;&#34;

    if not isinstance(value, list) and not force_Rvec:
        return value
    elif not isinstance(value, list) and force_Rvec:
        value = [value]
    else:
        pass

    if all(isinstance(x, bool) for x in value):
        return ro.BoolVector(value)
    elif all(isinstance(x, int) for x in value):
        return ro.IntVector(value)
    elif all(isinstance(x, float) or isinstance(x, int) for x in value):
        return ro.FloatVector(value)
    else:
        return ro.StrVector([str(v) for v in value])

    
def _clean_rpy2_pandas_conversion(
        df,
        float_cols=[&#34;G&#34;, &#34;H&#34;, &#34;S&#34;, &#34;Cp&#34;,
                    &#34;V&#34;, &#34;a1.a&#34;, &#34;a2.b&#34;,
                    &#34;a3.c&#34;, &#34;a4.d&#34;, &#34;c1.e&#34;,
                    &#34;c2.f&#34;, &#34;omega.lambda&#34;, &#34;z.T&#34;,
                    &#34;azero&#34;, &#34;neutral_ion_type&#34;,
                    &#34;logK1&#34;, &#34;logK2&#34;, &#34;logK3&#34;, &#34;logK4&#34;,
                    &#34;logK5&#34;, &#34;logK6&#34;, &#34;logK7&#34;, &#34;logK8&#34;,
                    &#34;T1&#34;, &#34;T2&#34;, &#34;T3&#34;, &#34;T4&#34;, &#34;T5&#34;, &#34;T6&#34;,
                    &#34;T7&#34;, &#34;T8&#34;],
        str_cols=[&#34;name&#34;, &#34;abbrv&#34;, &#34;state&#34;, &#34;formula&#34;,
                  &#34;ref1&#34;, &#34;ref2&#34;, &#34;date&#34;,
                  &#34;E_units&#34;, &#34;tag&#34;, &#34;dissrxn&#34;, &#34;formula_ox&#34;,
                  &#34;P1&#34;, &#34;P2&#34;, &#34;P3&#34;, &#34;P4&#34;, &#34;P5&#34;, &#34;P6&#34;,
                  &#34;P7&#34;, &#34;P8&#34;],
        NA_string=&#34;&#34;):

    df.replace(NA_string, np.nan, inplace=True)
    for col in float_cols:
        if col in df.columns:
            df[col] = df[col].astype(float)
    for col in str_cols:
        if col in df.columns:
            df[col] = df[col].astype(str)
    return df
    

def _get_colors(colormap, ncol, alpha=1.0, hide_traceback=True):

    &#34;&#34;&#34;
    Get a list of rgb values for a matplotlib colormap
    
    Parameters
    ----------
    colormap : str
        Name of the colormap to color the scatterpoints. Accepts &#34;WORM&#34;,
        &#34;colorblind&#34;, or matplotlib colormaps.
        See https://matplotlib.org/stable/tutorials/colors/colormaps.html
        The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
        Color blindness. Nat Methods 8, 441 (2011).
        https://doi.org/10.1038/nmeth.1618
    
    ncol : int
        Number of colors to return in the list.
    
    alpha : float, default 1.0
        An alpha value between 0.0 (transparent) and 1.0 (opaque).

    hide_traceback : bool, default True
        Hide traceback message when encountering errors handled by this function?
        When True, error messages handled by this class will be short and to
        the point.
    
    Returns
    -------
    colors : list
        A list of rgb color tuples
    &#34;&#34;&#34;
    
    err_handler = Error_Handler(clean=hide_traceback)
    
    qualitative_cmaps = [&#39;Pastel1&#39;, &#39;Pastel2&#39;, &#39;Paired&#39;, &#39;Accent&#39;,
                         &#39;Dark2&#39;, &#39;Set1&#39;, &#39;Set2&#39;, &#39;Set3&#39;,
                         &#39;tab10&#39;, &#39;tab20&#39;, &#39;tab20b&#39;, &#39;tab20c&#39;]
    
    if colormap == &#34;colorblind&#34;:
        # colors from Wong B. 2011, https://doi.org/10.1038/nmeth.1618
        colors = [(0, 0, 0, alpha), # black
                  (230/255, 159/255, 0, alpha), # orange
                  (86/255, 180/255, 233/255, alpha), # sky blue
                  (0, 158/255, 115/255, alpha), # bluish green
                  (240/255, 228/255, 66/255, alpha), # yellow
                  (0, 114/255, 178/255, alpha), # blue
                  (213/255, 94/255, 0, alpha), # vermillion
                  (204/255, 121/255, 167/255, alpha)] # reddish purple
        if ncol &lt;= len(colors):
            return colors[:ncol]
        else:
            print(&#34;Switching from &#39;colorblind&#39; colormap to &#39;viridis&#39; because there are {} variables to plot.&#34;.format(ncol))
            colormap = &#34;viridis&#34;
    elif colormap == &#34;WORM&#34;:
        colors = [(0, 0, 0, alpha), # black
                  (22/255, 153/255, 211/255, alpha), # blue
                  (232/255, 86/255, 66/255, alpha), # red
                  (245/255, 171/255, 80/255, alpha), # orange
                  (115/255, 108/255, 168/255, alpha), # purple
                  (151/255, 208/255, 119/255, alpha), # green
                  (47/255, 91/255, 124/255, alpha), # dark blue
                  (119/255, 119/255, 119/255, alpha)] # gray
        if ncol &lt;= len(colors):
            return colors[:ncol]
        else:
            print(&#34;Switching from &#39;WORM&#39; colormap to &#39;viridis&#39; because there are {} variables to plot.&#34;.format(ncol))
            colormap = &#34;viridis&#34;
            
    if colormap in qualitative_cmaps:
        # handle qualitative (non-continuous) colormaps
        colors = [plt.cm.__getattribute__(colormap).colors[i] for i in range(ncol)]
        colors = [(c[0], c[1], c[2], alpha) for c in colors]
    else:
        # handle sequential (continuous) colormaps
        norm = matplotlib.colors.Normalize(vmin=0, vmax=ncol-1)
        try:
            cmap = cm.__getattribute__(colormap)
        except:
            valid_colormaps = [cmap for cmap in dir(cm) if &#34;_&#34; not in cmap and cmap not in [&#34;LUTSIZE&#34;, &#34;MutableMapping&#34;, &#34;ScalarMappable&#34;, &#34;functools&#34;, &#34;datad&#34;, &#34;revcmap&#34;]]
            err_handler.raise_exception(&#34;&#39;{}&#39;&#34;.format(colormap)+&#34; is not a recognized matplotlib colormap. &#34;
                    &#34;Try one of these: {}&#34;.format(valid_colormaps))
        m = cm.ScalarMappable(norm=norm, cmap=cmap)
        colors = [m.to_rgba(i) for i in range(ncol)]
        colors = [(c[0], c[1], c[2], alpha) for c in colors]
    
    return colors


def _all_equal(iterable):
    # check that all elements of a list are equal
    g = groupby(iterable)
    return next(g, True) and not next(g, False)


def chemlabel(name, charge_sign_at_end=False):
    
    &#34;&#34;&#34;
    Format a chemical formula to display subscripts and superscripts in HTML
    (e.g., Plotly plots)
    Example, &#34;CH3COO-&#34; becomes &#34;CH&lt;sub&gt;3&lt;/sub&gt;COO&lt;sup&gt;-&lt;/sup&gt;&#34;
    
    Parameters
    ----------
    name : str
        A chemical formula.
    
    charge_sign_at_end : bool, default False
        Display charge with sign after the number (e.g. SO4 2-)?
        
    
    Returns
    -------
    A formatted chemical formula string.
    &#34;&#34;&#34;
    
    # format only the first part of the name if it has &#34;_(input)&#34;
    if len(name.split(&#34;_(input)&#34;))==2:
        if name.split(&#34;_(input)&#34;)[1] == &#39;&#39;:
            name = name.split(&#34;_(input)&#34;)[0]
            input_flag=True
    else:
        input_flag = False
    
    name = _html_chemname_format(name, charge_sign_at_end=charge_sign_at_end)
    
    # add &#34; (input)&#34; to the end of the name
    if input_flag:
        name = name+&#34; (input)&#34;
    
    return(name)


def _html_chemname_format(name, charge_sign_at_end=False):
    
    &#34;&#34;&#34;
    Function duplicated from pyCHNOSZ
    &#34;&#34;&#34;
    
    p = re.compile(r&#39;(?P&lt;sp&gt;[-+]\d*?$)&#39;)
    name = p.sub(r&#39;&lt;sup&gt;\g&lt;sp&gt;&lt;/sup&gt;&#39;, name)
    charge = re.search(r&#39;&lt;.*$&#39;, name)

    name_no_charge = re.match(r&#39;(?:(?!&lt;|$).)*&#39;, name).group(0)
    mapping = {&#34;0&#34;: &#34;&lt;sub&gt;0&lt;/sub&gt;&#34;, &#34;1&#34;: &#34;&lt;sub&gt;1&lt;/sub&gt;&#34;, &#34;2&#34;: &#34;&lt;sub&gt;2&lt;/sub&gt;&#34;,
               &#34;3&#34;: &#34;&lt;sub&gt;3&lt;/sub&gt;&#34;, &#34;4&#34;: &#34;&lt;sub&gt;4&lt;/sub&gt;&#34;, &#34;5&#34;: &#34;&lt;sub&gt;5&lt;/sub&gt;&#34;,
               &#34;6&#34;: &#34;&lt;sub&gt;6&lt;/sub&gt;&#34;, &#34;7&#34;: &#34;&lt;sub&gt;7&lt;/sub&gt;&#34;, &#34;8&#34;: &#34;&lt;sub&gt;8&lt;/sub&gt;&#34;,
               &#34;9&#34;: &#34;&lt;sub&gt;9&lt;/sub&gt;&#34;, &#34;.&#34;:&#34;&lt;sub&gt;.&lt;/sub&gt;&#34;}
    name_no_charge_formatted = &#34;&#34;.join([mapping.get(x) or x
                                        for x in list(name_no_charge)])

    if charge != None:
        name = name_no_charge_formatted + charge.group(0)
    else:
        name = name_no_charge_formatted

    if charge_sign_at_end:
        if &#34;&lt;sup&gt;-&#34; in name:
            name = name.replace(&#34;&lt;sup&gt;-&#34;, &#34;&lt;sup&gt;&#34;)
            name = name.replace(&#34;&lt;/sup&gt;&#34;, &#34;-&lt;/sup&gt;&#34;)
        if &#34;&lt;sup&gt;+&#34; in name:
            name = name.replace(&#34;&lt;sup&gt;+&#34;, &#34;&lt;sup&gt;&#34;)
            name = name.replace(&#34;&lt;/sup&gt;&#34;, &#34;+&lt;/sup&gt;&#34;)

    return(name)
    

def _isnotebook():
    
    &#34;&#34;&#34;
    Check if this code is running in a Jupyter notebook
    &#34;&#34;&#34;
    try:
        shell = get_ipython().__class__.__name__
        if shell == &#39;ZMQInteractiveShell&#39;:
            return True   # Jupyter notebook or qtconsole
        elif shell == &#39;TerminalInteractiveShell&#39;:
            return False  # Terminal running IPython
        else:
            return False  # Other type (?)
    except NameError:
        return False      # Probably standard Python interpreter


class Error_Handler:
    
    &#34;&#34;&#34;
    Handles how errors are printed in Jupyter notebooks. By default, errors that
    are handled by AqEquil are printed with an error message, but no traceback.
    Errors that are not handled by AqEquil, such as those thrown if the user
    encounters a bug, will display a full traceback.
    
    If the error handler prints an error message without traceback, all future
    errors regardless of origin will be shown without traceback until the
    notebook kernel is restarted.
    
    Parameters
    ----------
    clean : bool
        Report exceptions without traceback? If True, only the error message is
        shown. If False, the entire error message, including traceback, is
        shown. Ignored if AqEquil is not being run in a Jupyter notebook.
    
    &#34;&#34;&#34;
    def __init__(self, clean=True):
        self.clean = clean # bool: hide traceback?
        pass
    
    
    @staticmethod
    def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,
                       exception_only=False, running_compiled_code=False):
        
        &#34;&#34;&#34;
        Return a modified ipython showtraceback function that does not display
        traceback when encountering an error.
        &#34;&#34;&#34;
        
        ipython = get_ipython()
        etype, value, tb = sys.exc_info()
        value.__cause__ = None  # suppress chained exceptions
        return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))
        

    def raise_exception(self, msg):
        
        &#34;&#34;&#34;
        Raise an exception that displays the error message without traceback. This
        happens only when the exception is predicted by the AqEquil package
        (e.g., for common user errors).
        &#34;&#34;&#34;
        if self.clean and _isnotebook():
            ipython = get_ipython()
            ipython.showtraceback = self.hide_traceback
            
        raise Exception(msg)
        
    
class AqEquil(object):

    &#34;&#34;&#34;
    Class containing functions to speciate aqueous water chemistry data using
    existing or custom thermodynamic datasets.
    
    Parameters
    ----------
    eq36da : str, defaults to path given by the environment variable EQ36DA
        Path to directory where data1 files are stored. 
        
    eq36co : str, defaults to path given by the environment variable EQ36CO
        Path to directory where EQ3 executables are stored.
    
    db : str, default &#34;WORM&#34;
        Determines which thermodynamic database is used in the speciation
        calculation. There are several options available:
        - &#34;WORM&#34; will load the default WORM thermodynamic database,
        solid solution database, and logK database. These files are retrieved
        from https://github.com/worm-portal/WORM-db to ensure they are
        up-to-date.
        - Three letter file extension for the desired data1 database, e.g.,
        &#34;wrm&#34;. This will use a data1 file with this file extension, e.g.,
        &#34;data1.wrm&#34; located in the path stored in the &#39;EQ36DA&#39; environment
        variable used by EQ3NR.
        - The name of a data0 file located in the current working directory,
        e.g., &#34;data0.wrm&#34;. This data0 file will be compiled by EQPT
        automatically during the speciation calculation.
        - The name of a CSV file containing thermodynamic data located in
        the current working directory, e.g., &#34;wrm_data.csv&#34;. The CSV file
        will be used to generate a data0 file for each sample (using
        additional arguments from `db_args` if desired).
        - The URL of a data0 file, e.g.,
        &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#34;
        - The URL of a CSV file containing thermodynamic data, e.g.,
        &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
        
    solid_solutions : str
        Filepath of a CSV file containing parameters for solid solutions, e.g.,
        &#34;my_solid_solutions.csv&#34;. If `db` is set to &#34;WORM&#34; and `solid_solutions`
        is not defined, then parameters for solid solutions will be retrieved
        from &#34;Solid_solutions.csv&#34; at https://github.com/worm-portal/WORM-db
    
    logK : str
        Filepath of a CSV file containing equilibrium constants for chemical
        species, e.g., &#34;my_logK_entries.csv&#34;. If `db` is set to &#34;WORM&#34; and `logK`
        is not defined, then equilibrium constants will be retrieved from
        &#34;wrm_data_logK.csv&#34; at https://github.com/worm-portal/WORM-db
    
    logK_S : str
        Filepath of a CSV file containing equilibrium constants for chemical
        species, e.g., &#34;my_logK_S_entries.csv&#34;. If `db` is set to &#34;WORM&#34; and `logK_S`
        is not defined, then equilibrium constants will be retrieved from
        &#34;wrm_data_logK_S.csv&#34; at https://github.com/worm-portal/WORM-db
    
    logK_extrapolate : str, default &#34;none&#34;
        What method should be used to extrapolate equilibrium constants in the
        logK database (defined by parameter `logK`) as a function of
        temperature? Can be either &#34;none&#34;, &#34;flat&#34;, &#34;poly&#34;, or &#34;linear&#34;.
    
    download_csv_files : bool, default False
        Download copies of database CSV files to your current working directory?
    
    exclude_category : dict
        Exclude species from thermodynamic databases based on column values.
        For instance,
        `exclude_category={&#39;category_1&#39;:[&#34;organic_aq&#34;, &#34;organic_cr&#34;]}`
        will exclude all species that have &#34;organic_aq&#34; or &#34;organic_cr&#34; in
        the column &#34;category_1&#34;.
        Species are excluded from the main thermodynamic database CSV and the
        equilibrium constant (logK) CSV database. This parameter has no effect
        if the thermodynamic database is a data0 or data1 file.
        
    suppress_redox : list of str, default []
        Suppress equilibrium between oxidation states of listed elements
        (Cl, H, and O cannot be included).
        
    input_template : str, default &#34;none&#34;
        Can be either &#34;strict&#34;, &#34;basis&#34;, &#34;all&#34;, or &#34;none&#34; (default). If any
        option other than &#34;none&#34; is chosen, a sample input file template CSV
        file customized to this thermodynamic dataset called
        &#34;sample_input_template.csv&#34; will be generated in the current directory.
        This template can be populated with water sample data to be speciated by
        the `speciate` function. The &#34;strict&#34; option is highly recommended for
        most users. This is because strict basis species speciate into auxiliary
        and non-basis species, but not the other way around.
        Columns in the template include &#39;Sample&#39;, &#39;Temperature&#39;, &#39;logfO2&#39;, and
        others, depending on the chosen option. If &#34;strict&#34;, columns for strict
        basis species will be included. If &#34;basis&#34;, columns for both strict and
        auxiliary basis species will be included. If &#34;all&#34;, then columns for all
        aqueous species will be included.
        
    water_model : str, default &#34;SUPCRT92&#34;
        This is an experimental feature that is not yet fully supported.
        Desired water model. Can be either &#34;SUPCRT92&#34;, &#34;IAPWS95&#34;, or &#34;DEW&#34;.
        These models are described here: http://chnosz.net/manual/water.html
        
    exceed_Ttr : bool, default True
        Calculate Gibbs energies of mineral phases and other species
        beyond their transition temperatures?
        
    verbose : int, 0, 1, or 2, default 1
        Level determining how many messages are returned during a
        calculation. 2 for all messages, 1 for errors or warnings only,
        0 for silent.

    load_thermo : bool, default True
        Load thermodynamic database(s) when instantiating this class?

    hide_traceback : bool, default True
        Hide traceback message when encountering errors handled by this class?
        When True, error messages handled by this class will be short and to
        the point.
    
    Attributes
    ----------
    eq36da : str
        Path to directory where data1 files are stored.
        
    eq36co : str
        Path to directory where EQ3 executables are stored.
        
    df_input_processed : pd.DataFrame
        Pandas dataframe containing user-supplied sample chemistry data that has
        been processed by `speciate`.
    
    half_cell_reactions : pd.DataFrame
        Pandas dataframe containing half cell reactions that can be combined
        into redox reactions for calculating chemical affinity and energy supply
        values during speciation.
        
    redox_pairs : list of int
        List of indices of half reactions in the `half_cell_reactions` table
        to be combined when generating full redox reactions.
            
    affinity_energy_reactions_raw : str
        A formatted TSV string of redox reactions for calculating chemical
        affinities and energy supplies during speciation.

    affinity_energy_reactions_table : pd.DataFrame
        A table of redox reactions for calculating chemical affinities and
        energy supplies during speciation.
    
    affinity_energy_formatted_reactions : pd.DataFrame
        A pandas dataframe containing balanced redox reactions written in full.
        
    &#34;&#34;&#34;

    def __init__(self,
                 eq36da=os.environ.get(&#39;EQ36DA&#39;),
                 eq36co=os.environ.get(&#39;EQ36CO&#39;),
                 db=&#34;WORM&#34;,
                 elements=None,
                 solid_solutions=None,
                 logK=None,
                 logK_S=None,
                 logK_extrapolate=&#34;none&#34;,
                 download_csv_files=False,
                 exclude_category={},
                 suppress_redox=[],
                 input_template=&#34;none&#34;,
                 water_model=&#34;SUPCRT92&#34;,
                 exceed_Ttr=True,
                 verbose=1,
                 load_thermo=True,
                 hide_traceback=True):

        self.eq36da = eq36da
        self.eq36co = eq36co
        self.df_input_processed = None
        self.water_model = water_model
        
        half_rxn_data = pkg_resources.resource_stream(__name__, &#34;half_cell_reactions.csv&#34;)
        self.half_cell_reactions = pd.read_csv(half_rxn_data) #define the input file (dataframe of redox pairs)
        self.redox_pairs = None
        self.affinity_energy_reactions_raw = None
        self.affinity_energy_reactions_table = None
        self.affinity_energy_formatted_reactions = None
        
        self.verbose = verbose
        self.hide_traceback = hide_traceback
        self.err_handler = Error_Handler(clean=self.hide_traceback)
        
        self.raw_3_input_dict = {}
        self.raw_3_output_dict = {}
        self.raw_3_pickup_dict_bottom = {}
        self.raw_3_pickup_dict_top = {}
        
        self.batch_T = []
        self.batch_P = []
        
        self.logK_models = {}

        
        
        if load_thermo:
            
            # attributes to add to AqEquil class
            self.db = db
            self.elements = elements
            self.solid_solutions = solid_solutions
            self.exclude_category = exclude_category
            self.logK = logK
            self.logK_S = logK_S
            self.logK_extrapolate = logK_extrapolate
            self.download_csv_files = download_csv_files
            self.exclude_category = exclude_category
            self.suppress_redox = suppress_redox
            self.exceed_Ttr = exceed_Ttr
            self.input_template = input_template
            
            self.thermo = AqEquil.Thermodata(AqEquil_instance=self) # outer instance passed to inner instance
        
            self.data1 = self.thermo.data1

    def _capture_r_output(self):
        &#34;&#34;&#34;
        Capture and create a list of R console messages
        &#34;&#34;&#34;
        
        # Record output #
        self.stdout = []
        self.stderr = []
        
        # If DEBUGGING_R==False, uses python to print R lines after executing an R block 
        # If DEBUGGING_R==True, will ugly print from R directly. Allows printing from R to troubleshoot errors.
        if DEBUGGING_R:
        
            # Dummy functions #
            def add_to_stdout(line): self.stdout.append(line)
            def add_to_stderr(line): self.stderr.append(line)

            # Keep the old functions #
            self.stdout_orig = rpy2.rinterface_lib.callbacks.consolewrite_print
            self.stderr_orig = rpy2.rinterface_lib.callbacks.consolewrite_warnerror

            # Set the call backs #
            rpy2.rinterface_lib.callbacks.consolewrite_print     = add_to_stdout
            rpy2.rinterface_lib.callbacks.consolewrite_warnerror = add_to_stderr

    def _print_captured_r_output(self):
        printable_lines = [line for line in self.stdout if line not in [&#39;[1]&#39;, &#39;\n&#39;]]
        printable_lines = [line for line in printable_lines if re.search(&#34;^\s*\[[0-9]+\]$&#34;, line) is None]
        printable_lines = [re.sub(r&#39; \\n\&#34;&#39;, &#34;&#34;, line) for line in printable_lines]
        [print(line[2:-1]) for line in printable_lines]

    def __file_exists(self, filename, ext=&#39;.csv&#39;):
        &#34;&#34;&#34;
        Check that a file exists and that it has the correct extension.
        Returns True if so, raises exception if not.
        &#34;&#34;&#34;
        
        ext_dict = {
            &#34;.csv&#34; : &#34;comma separated values (.csv)&#34;,
            &#34;.txt&#34; : &#34;standard text (.txt)&#34;,
            &#34;.rds&#34; : &#34;R Data (.rds)&#34;,
        }

        if ext in filename[-4:]:
            
            if os.path.exists(filename) and os.path.isfile(filename):
                return True
            else:
                err = &#34;Cannot locate input file {}/{}&#34;.format(os.getcwd(), filename)
                self.err_handler.raise_exception(err)
        else:
            err = (&#34;Input file {}&#34;.format(filename) + &#34; &#34;
                &#34;must be in {} format.&#34;.format(ext_dict[ext]))
            self.err_handler.raise_exception(err)
        
        return False

    
    def _check_sample_input_file(self, input_filename, exclude, db,
                                       dynamic_db, charge_balance_on,
                                       suppress_missing,
                                       redox_suppression):
        &#34;&#34;&#34;
        Check for problems in sample input file.
        &#34;&#34;&#34;
        
        # does the input file exist? Is it a CSV?
        if self.__file_exists(input_filename):
            df_in = pd.read_csv(input_filename, header=None) # no headers for now so colname dupes can be checked
        else:
            self.err_handler.raise_exception(&#34;_check_sample_input() error!&#34;)
        
        # are there any samples?
        if df_in.shape[0] &lt;= 2:
            err_no_samples = (&#34;The file {}&#34;.format(input_filename) + &#34; &#34;
                &#34;must contain at least three rows: the &#34;
                &#34;first for column names, the second for column subheaders, &#34;
                &#34;followed by one or more rows for sample data.&#34;)
            self.err_handler.raise_exception(err_no_samples)
        
        err_list = [] # for appending errors found in the sample input file
        
        # get header list
        col_list = list(df_in.iloc[0, 1:])
        
        # are there blank headers?
        if True in [isinstance(x, float) and x != x for x in col_list]:
            # isinstance(x, float) and x != x is a typesafe way to check for nan
            err_blank_header = (&#34;One or more columns in the sample input &#34;
                &#34;file have blank headers. These might be empty columns. &#34;
                &#34;Only the first column may have a blank header. Remove any &#34;
                &#34;empty columns and/or give each header a name.&#34;)
            self.err_handler.raise_exception(err_blank_header)
        
        # are there duplicate headers?
        dupe_cols = list(set([x for x in col_list if col_list.count(x) &gt; 1]))
        if len(dupe_cols) &gt; 0:
            err_dupe_cols = (&#34;Duplicate column names are not allowed. &#34;
                &#34;Duplicate column names were found for:\n&#34;
                &#34;{}&#34;.format(str(dupe_cols)))
            err_list.append(err_dupe_cols)
        
        df_in.columns = df_in.iloc[0] # set column names
        df_in = df_in.drop(df_in.index[0], axis=0) # drop column name row
        df_in_headercheck = copy.deepcopy(df_in.iloc[:,1:]) # drop first column. Deepcopy slice because drop() doesn&#39;t work well with unnamed columns.
        
        # drop excluded headers
        for exc in exclude:
            if exc == df_in.columns[0]: # skip if &#39;sample&#39; column is excluded
                continue
            try:
                df_in_headercheck = df_in_headercheck.drop(exc, axis=1) # drop excluded columns
            except:
                err_bad_exclude = (
                        &#34;Could not exclude the header &#39;{}&#39;&#34;.format(exc)+&#34;. &#34;
                        &#34;This header could not be found in &#34;
                        &#34;{}&#34;.format(input_filename)+&#34;&#34;)
                err_list.append(err_bad_exclude)
        
        # get row list
        row_list = list(df_in.iloc[1:, 0])
        
        # are there blank rows?
        if True in [isinstance(x, float) and x != x for x in row_list]:
            # isinstance(x, float) and x != x is a typesafe way to check for nan
            err_blank_row = (&#34;One or more rows in the sample input &#34;
                &#34;file have blank sample names. These might be empty rows. &#34;
                &#34;Remove any empty rows and/or give each sample a name. Sample &#34;
                &#34;names go in the first column.&#34;)
            self.err_handler.raise_exception(err_blank_row)
            
        # are there duplicate rows?
        dupe_rows = list(set([x for x in row_list if row_list.count(x) &gt; 1]))
        if len(dupe_rows) &gt; 0:
            err_dupe_rows = (&#34;Duplicate sample names are not allowed. &#34;
                &#34;Duplicate sample names were found for:\n&#34;
                &#34;{}&#34;.format(str(dupe_rows)))
            err_list.append(err_dupe_rows)
        
        # are there any leading or trailing spaces in sample names?
        invalid_sample_names = [n for n in list(df_in.iloc[1:, 0])
                                if str(n[0])==&#34; &#34; or str(n[-1])==&#34; &#34;]
        if len(invalid_sample_names) &gt; 0:
            err_sample_leading_trailing_spaces = (&#34;The following sample names &#34;
                &#34;have leading or trailing spaces. Remove spaces and try again: &#34;
                &#34;{}&#34;.format(invalid_sample_names))
            self.err_handler.raise_exception(err_sample_leading_trailing_spaces)
        
        # are column names valid entries in the database?
        if self.thermo.custom_data0:
            if &#34;data0&#34; in db:
                data_path = db
            else:
                data_path = &#34;data0.&#34; + db
        elif self.thermo.dynamic_db:
            data_path = self.thermo.thermo_db_filename
        else:
            data_path = self.eq36da + &#34;/data0.&#34; + db
        
        if self.thermo.thermo_db_type == &#34;data0&#34; and self.thermo.thermo_db_source == &#34;URL&#34;:
            data_path = &#34;data0.&#34; + self.thermo.data0_lettercode
        
        if not (os.path.exists(data_path) or os.path.isfile(data_path)) and self.thermo.thermo_db_source==&#34;file&#34;:
            warn_no_data0 = (&#34;Warning: Could not locate {}.&#34;.format(data_path) + &#34; &#34;
                &#34;Unable to determine if column headers included in &#34;
                &#34;{} &#34;.format(input_filename) + &#34;match entries for species &#34;
                &#34;in the requested thermodynamic database &#39;{}&#39;.&#34;.format(db))
            if self.verbose &gt; 0:
                print(warn_no_data0)
            
        if self.thermo.thermo_db_type == &#34;data0&#34;:
            data0_lines = self.thermo.thermo_db.split(&#34;\n&#34;)
            start_index = [i+1 for i, s in enumerate(data0_lines) if &#39;*  species name&#39; in s]
            end_index = [i-1 for i, s in enumerate(data0_lines) if &#39;elements&#39; in s]
            db_species = [i.split()[0] for i in data0_lines[start_index[0]:end_index[0]]]
        elif self.thermo.thermo_db_type == &#34;CSV&#34;:
            df_OBIGT = self.thermo.thermo_db
            db_species = list(df_OBIGT[&#34;name&#34;])

        if charge_balance_on == &#39;pH&#39;:
            err_charge_balance_on_pH = (&#34;To balance charge on pH, use &#34;
                &#34;charge_balance_on=&#39;H+&#39;&#34;)
            err_list.append(err_charge_balance_on_pH)
        elif charge_balance_on in [&#39;Temperature&#39;, &#39;logfO2&#39;]:
            err_charge_balance_invalid_type = (&#34;Cannot balance charge &#34;
                &#34;on {}.&#34;.format(charge_balance_on))
            err_list.append(err_charge_balance_invalid_type)
        elif charge_balance_on != &#34;none&#34; and charge_balance_on not in list(set(df_in_headercheck.columns)):
            err_charge_balance_invalid_sp = (&#34;The species chosen for charge balance&#34;
                &#34; &#39;{}&#39;&#34;.format(charge_balance_on)+&#34;&#34;
                &#34; was not found among the headers of the sample input file.&#34;)
            err_list.append(err_charge_balance_invalid_sp)

        if self.thermo.thermo_db_type in [&#34;data0&#34;, &#34;CSV&#34;]:
            
            for species in list(dict.fromkeys(df_in_headercheck.columns)):
                if species not in db_species and species not in [&#39;Temperature&#39;, &#39;logfO2&#39;, &#39;pH&#39;, &#39;Pressure&#39;, &#39;Eh&#39;, &#39;pe&#39;]+FIXED_SPECIES:
                    err_species_not_in_db = (&#34;The species &#39;{}&#39;&#34;.format(species) + &#34; &#34;
                        &#34;was not found in {}&#34;.format(data_path) + &#34;. &#34;
                        &#34;If the column contains data that should not be &#34;
                        &#34;included in the speciation calculation, add the &#34;
                        &#34;column name to the &#39;exclude&#39; argument. Try &#34;
                        &#34;help(AqEquil.AqEquil.speciate) &#34;
                        &#34;for more information about &#39;exclude&#39;.&#34;)
                    err_list.append(err_species_not_in_db)
                elif species == &#39;pH&#39;:
                    err_species_pH = (&#34;Please rename the &#39;pH&#39; column in &#34;
                        &#34;the sample input file to &#39;H+&#39; with the subheader &#34;
                        &#34;unit &#39;pH&#39;.&#34;)
                    err_list.append(err_species_pH)

        
        
        # are subheader units valid?
        subheaders = df_in_headercheck.iloc[0,]
        valid_subheaders = [&#34;degC&#34;, &#34;ppm&#34;, &#34;ppb&#34;, &#34;Suppressed&#34;, &#34;Molality&#34;,
                            &#34;Molarity&#34;, &#34;mg/L&#34;, &#34;mg/kg.sol&#34;, &#34;Alk., eq/kg.H2O&#34;,
                            &#34;Alk., eq/L&#34;, &#34;Alk., eq/kg.sol&#34;, &#34;Alk., mg/L CaCO3&#34;,
                            &#34;Alk., mg/L HCO3-&#34;, &#34;Log activity&#34;, &#34;Log act combo&#34;,
                            &#34;Log mean act&#34;, &#34;pX&#34;, &#34;pH&#34;, &#34;pHCl&#34;, &#34;pmH&#34;, &#34;pmX&#34;,
                            &#34;Hetero. equil.&#34;, &#34;Homo. equil.&#34;, &#34;Make non-basis&#34;,
                            &#34;logfO2&#34;, &#34;Mineral&#34;, &#34;bar&#34;, &#34;volts&#34;]
        for i, subheader in enumerate(subheaders):
            if subheader not in valid_subheaders:
                err_valid_sub = (&#34;The subheader &#39;{}&#39;&#34;.format(subheader) + &#34; &#34;
                    &#34;for the column &#39;{}&#39;&#34;.format(df_in_headercheck.columns[i]) + &#34; &#34;
                    &#34;is not recognized. Valid subheaders are {}&#34;.format(str(valid_subheaders)) + &#34;. &#34;
                    &#34;If the column {}&#34;.format(df_in_headercheck.columns[i]) + &#34; &#34;
                    &#34;contains data that is not meant for the &#34;
                    &#34;speciation calculation, add the column name &#34;
                    &#34;to the &#39;exclude&#39; argument. Try help(AqEquil.AqEquil.speciate) &#34;
                    &#34;for more information about &#39;exclude&#39;.&#34;)
                err_list.append(err_valid_sub)
            
        # is a &#39;Temperature&#39; column present?
        if &#34;Temperature&#34; not in df_in_headercheck.columns and &#34;Temperature&#34; not in exclude:
            err_temp = (&#34;The column &#39;Temperature&#39; was not found in the input file. &#34;
                &#34;Please include a column with &#39;Temperature&#39; in the first row, &#34;
                &#34;&#39;degC&#39; in the second row, and a temperature value for each &#34;
                &#34;sample in degrees Celsius.&#34;)
            err_list.append(err_temp)

        # raise an exception that summarizes all errors found
        if len(err_list) &gt; 0:
            errs = &#34;\n\n*&#34;.join(err_list)
            errs = (&#34;The input file {}&#34;.format(input_filename)+&#34; encountered&#34;
                &#34; errors:\n\n*&#34; + errs)
            self.err_handler.raise_exception(errs)
        
        # warn about &#34;suppress_redox&#34; in db_args if &#34;Hetero. equil.&#34; among subheaders.
        # Redox suppression won&#39;t work for an element constrained by heterogeneous equilibrium
        if redox_suppression and &#34;Hetero. equil.&#34; in list(subheaders):
            if self.verbose &gt; 0:
                print(&#34;Warning: &#39;suppress_redox&#39; does not currently work with the &#34;
                      &#34;heterogeneous equilibrium option if the mineral or gas &#34;
                      &#34;contains a redox-suppressed element.&#34;)
        
        sample_temps = [float(t) for t in list(df_in[&#34;Temperature&#34;])[1:]]
        if &#34;Pressure&#34; in df_in.columns:
            sample_press = [float(p) if p.lower() != &#39;psat&#39; else &#39;psat&#39; for p in list(df_in[&#34;Pressure&#34;])[1:]]
        else:
            sample_press = [&#39;psat&#39;]*len(sample_temps)
        
        
        return sample_temps, sample_press
        

    def __move_eqpt_extra_output(self):
        &#34;&#34;&#34;
        Moves all EQPT output and data0 into the eqpt_files folder
        &#34;&#34;&#34;
        
        self.__mk_check_del_directory(&#34;eqpt_files&#34;)
        if os.path.exists(&#34;eqpt_log.txt&#34;) and os.path.isfile(&#34;eqpt_log.txt&#34;):
            shutil.move(&#34;eqpt_log.txt&#34;, &#34;eqpt_files/eqpt_log.txt&#34;)
        if os.path.exists(&#34;data1f.txt&#34;) and os.path.isfile(&#34;data1f.txt&#34;):
            shutil.move(&#34;data1f.txt&#34;, &#34;eqpt_files/data1f.txt&#34;)
        if os.path.exists(&#34;slist.txt&#34;) and os.path.isfile(&#34;slist.txt&#34;):
            shutil.move(&#34;slist.txt&#34;, &#34;eqpt_files/slist.txt&#34;)

            
    def runeqpt(self, db, dynamic_db=False):
        
        &#34;&#34;&#34;
        Convert a data0 into a data1 file with EQPT.
        
        Parameters
        ----------
        db : str
            Three letter code of database.
        &#34;&#34;&#34;

        if os.path.exists(&#34;data0.&#34;+db) and os.path.isfile(&#34;data0.&#34;+db):
            pass
        else:
            self.err_handler.raise_exception(&#34; &#34;.join([&#34;Error: could not locate custom database&#34;,
                            &#34;data0.{} in {}.&#34;.format(db, os.getcwd())]))

        if os.path.exists(&#34;data1.&#34;+db) and os.path.isfile(&#34;data1.&#34;+db):
            os.remove(&#34;data1.&#34;+db)

        self.__move_eqpt_extra_output()
        
        args = [&#34;cd&#34;, os.getcwd(), &#34;;&#34;, self.eq36co+&#39;/eqpt&#39;, &#34;&#39;&#34;+os.getcwd()+&#34;/data0.&#34;+db+&#34;&#39;&#34;]
        args = &#34; &#34;.join(args)

        try:
            self.__run_script_and_wait(args) # run EQPT
        except:
            self.err_handler.raise_exception(
                &#34;Error: EQPT failed to run on {}.&#34;.format(&#34;data0.&#34;+db))

        if os.path.exists(&#34;data1&#34;) and os.path.isfile(&#34;data1&#34;):
            os.rename(&#34;data1&#34;, &#34;data1.&#34;+db)
        if os.path.exists(&#34;data0.d1&#34;) and os.path.isfile(&#34;data0.d1&#34;):
            os.rename(&#34;data0.d1&#34;, &#34;data1.&#34;+db)
        if os.path.exists(&#34;data0.po&#34;) and os.path.isfile(&#34;data0.po&#34;):
            os.rename(&#34;data0.po&#34;, &#34;eqpt_log.txt&#34;)
        if os.path.exists(&#34;data0.d1f&#34;) and os.path.isfile(&#34;data0.d1f&#34;):
            os.rename(&#34;data0.d1f&#34;, &#34;data1f.txt&#34;)
        if os.path.exists(&#34;data0.s&#34;) and os.path.isfile(&#34;data0.s&#34;):
            os.rename(&#34;data0.s&#34;, &#34;slist.txt&#34;)

        if os.path.exists(&#34;data1.&#34;+db) and os.path.isfile(&#34;data1.&#34;+db):
            if self.verbose &gt; 0:
                if not dynamic_db:
                    print(&#34;Successfully created a data1.&#34;+db+&#34; from data0.&#34;+db)
        else:
            if dynamic_db:
                msg = (&#34;EQPT has encounted a problem processing the database &#34;
                       &#34;for this sample. Check eqpt_log.txt for details.&#34;)
            else:
                msg = (&#34;EQPT could not create data1.&#34;+db+&#34; from &#34;
                       &#34;data0.&#34;+db+&#34;. Check eqpt_log.txt for details.&#34;)
            self.err_handler.raise_exception(msg)
        
        self.__move_eqpt_extra_output()

    
    def runeq3(self,
               filename_3i,
               db,
               samplename=None,
               path_3i=&#34;&#34;,
               path_3o=&#34;&#34;,
               path_3p=&#34;&#34;,
               data1_path=&#34;&#34;,
               dynamic_db_name=None):
        
        &#34;&#34;&#34;
        Call EQ3 on a .3i input file.
        
        Parameters
        ----------
        filename_3i : str
            Name of 3i input file.
        
        db : str
            Three letter code of database.
        
        path_3i : path str, default current working directory
            Path of .3i input files.
            
        path_3o : path str, default current working directory
            Path of .3o output files.
        
        path_3p : path str, default current working directory
            Path of .3p pickup files.
        
        data1_path : str, default None
            File path of data1 file.
            
        dynamic_db_name : str
            Database name to be printed if dynamic databases are being used.
            This parameter is for internal use.
        &#34;&#34;&#34;

        # get current working dir
        cwd = os.getcwd()
        cwdd = cwd + &#34;/&#34;
        
        if samplename == None:
            samplename = filename_3i[:-3]
        
        if self.verbose &gt; 0 and dynamic_db_name == None:
            print(&#39;Using &#39; + db + &#39; to speciate &#39; + samplename)
        elif self.verbose &gt; 0 and isinstance(dynamic_db_name, str):
            print(&#39;Using &#39; + dynamic_db_name + &#39; to speciate &#39; + samplename)
            
        args = [&#34;cd&#34;, &#34;&#39;&#34; + cwdd+path_3i+&#34;&#39;&#34;, &#34;;&#34;, # change directory to where 3i files are stored
                self.eq36co + &#39;/eq3nr&#39;, # path to EQ3NR executable
                &#34;&#39;&#34; + data1_path + &#34;/data1.&#34; + db+&#34;&#39;&#34;, # path to data1 file
                &#34;&#39;&#34;+cwdd + path_3i +&#34;/&#34;+ filename_3i+&#34;&#39;&#34;] # path to 3i file
        
        args = &#34; &#34;.join(args)
        
        self.__run_script_and_wait(args) # run EQ3
        
        filename_3o = filename_3i[:-1] + &#39;o&#39;
        filename_3p = filename_3i[:-1] + &#39;p&#39;
        
        # The new eq36 build truncates names, e.g., MLS.Source.3i creates MLS.3o
        # Correct for this here:
        files_3o = [file for file in os.listdir(cwdd + path_3i) if &#34;.3o&#34; in file]
        files_3p = [file for file in os.listdir(cwdd + path_3i) if &#34;.3p&#34; in file]
        
        if len(files_3o) == 0:
            if self.verbose &gt; 0:
                print(&#39;Error: EQ3 failed to produce output for &#39; + filename_3i)
        elif len(files_3o) == 1:
            file_3o = files_3o[0]
            try:
                # move output
                shutil.move(cwdd + path_3i+&#34;/&#34;+file_3o, cwdd + path_3o+&#34;/&#34;+filename_3o)
            except:
                self.err_handler.raise_exception(&#34;Error: could not move&#34;, path_3i+&#34;/&#34;+file_3o, &#34;to&#34;, path_3o+&#34;/&#34;+filename_3o)
        else:
            self.err_handler.raise_exception(&#34;Error: multiple output files detected for one speciation calculation.&#34;)
            
        if len(files_3p) == 0:
            if self.verbose &gt; 0:
                print(&#39;Error: EQ3 failed to produce output for &#39; + filename_3i)
        elif len(files_3p) == 1:
            file_3p = files_3p[0]
            try:
                # move output
                shutil.move(cwdd + path_3i+&#34;/&#34;+file_3p, cwdd + path_3p+&#34;/&#34;+filename_3p)
            except:
                self.err_handler.raise_exception(&#34;Error: could not move&#34;, path_3i+&#34;/&#34;+file_3p, &#34;to&#34;, path_3p+&#34;/&#34;+filename_3p)
        else:
            self.err_handler.raise_exception(&#34;Error: multiple pickup files detected for one speciation calculation.&#34;)

                    
    def runeq6(self,
               filename_6i,
               db,
               samplename=None,
               path_6i=&#34;&#34;,
               data1_path=None,
               dynamic_db_name=None):
        
        &#34;&#34;&#34;
        Call EQ6 on a .6i input file.
        
        Parameters
        ----------
        filename_6i : str
            Name of 6i input file.
        
        db : str
            Three letter code of database.
        
        samplename : str
            The name of the sample, used to announce which sample is being run.
        
        path_6i : path str, default current working directory
            Path of directory containing .6i input files.
            
        data1_path : path str, default current working directory
            Path of directory where the data1 thermodynamic database file is
            stored. The data1 file will be called from this location to
            perform the speciation. The data1 file must be named
            data1.xyz, where xyz matches `db`, the three letter code of your
            chosen database.
            
        dynamic_db_name : str
            Database name to be printed if dynamic databases are being used.
            This parameter is for internal use.
        &#34;&#34;&#34;

        if data1_path == None:
            data1_path = self.eq36da
        
        # get current working dir
        cwd = os.getcwd()
        cwdd = cwd + &#34;/&#34;
        
        if samplename == None:
            samplename = filename_6i[:-3]
        
        if self.verbose &gt; 0 and dynamic_db_name == None:
            print(&#39;Using &#39; + db + &#39; to react &#39; + samplename)
        elif self.verbose &gt; 0 and isinstance(dynamic_db_name, str):
            print(&#39;Using &#39; + dynamic_db_name + &#39; to react &#39; + samplename)

        args = [&#34;cd&#34;, &#34;&#39;&#34; + cwdd+path_6i+&#34;&#39;&#34;, &#34;;&#34;, # change directory to 6i folder
                self.eq36co+&#39;/eq6&#39;, # path of EQ6 executable
                &#34;&#39;&#34; + data1_path + &#34;/data1.&#34; + db+&#34;&#39;&#34;, # path to data1 file
                &#34;&#39;&#34;+cwdd+path_6i + filename_6i+&#34;&#39;&#34;] # path of 6i file
        
        args = &#34; &#34;.join(args)
        
        self.__run_script_and_wait(args) # run EQ6
        
                
    def __mk_check_del_directory(self, path):
        
        &#34;&#34;&#34;
        Checks for the dir being created. If it is already present, delete it
        before recreating it.
        &#34;&#34;&#34;
        
        if not os.path.exists(path):
            os.makedirs(path)
        else:
            shutil.rmtree(path)
            os.makedirs(path)

    
    def __run_script_and_wait(self, args):
        
        &#34;&#34;&#34;
        Runs shell commands.
        &#34;&#34;&#34;
        
        # DEVNULL and STDOUT needed to suppress all warnings
        subprocess.Popen(args, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT, shell=True).wait()

            
    def _delete_rxn_folders(self):
        
        &#34;&#34;&#34;
        Deletes folders storing raw EQ3/6 input and output.
        &#34;&#34;&#34;
        
        if os.path.exists(&#39;rxn_3i&#39;) and os.path.isdir(&#39;rxn_3i&#39;):
            shutil.rmtree(&#39;rxn_3i&#39;)
        if os.path.exists(&#39;rxn_3o&#39;) and os.path.isdir(&#39;rxn_3o&#39;):
            shutil.rmtree(&#39;rxn_3o&#39;)
        if os.path.exists(&#39;rxn_3p&#39;) and os.path.isdir(&#39;rxn_3p&#39;):
            shutil.rmtree(&#39;rxn_3p&#39;)
        if os.path.exists(&#39;rxn_6i&#39;) and os.path.isdir(&#39;rxn_6i&#39;):
            shutil.rmtree(&#39;rxn_6i&#39;)
        if os.path.exists(&#39;rxn_6o&#39;) and os.path.isdir(&#39;rxn_6o&#39;):
            shutil.rmtree(&#39;rxn_6o&#39;)
        if os.path.exists(&#39;rxn_6p&#39;) and os.path.isdir(&#39;rxn_6p&#39;):
            shutil.rmtree(&#39;rxn_6p&#39;)
        if os.path.exists(&#39;eqpt_files&#39;) and os.path.isdir(&#39;eqpt_files&#39;):
            shutil.rmtree(&#39;eqpt_files&#39;)
        if os.path.exists(&#39;rxn_data0&#39;) and os.path.isdir(&#39;rxn_data0&#39;):
            shutil.rmtree(&#39;rxn_data0&#39;)


    @staticmethod
    def __f(x, poly_coeffs):
        # return values from a polynomial fit
        value = 0
        for i in range(0,len(poly_coeffs)):
            value += poly_coeffs[i]*x**i
        return value


    def __plot_TP_grid_polyfit(self, xvals, yvals, poly_coeffs_1, poly_coeffs_2,
                               res=500, width=600, height=300):

        print(&#34;R COEFFS&#34;)
        print(poly_coeffs_1)
        print(poly_coeffs_2)
        
        
        f1_x = np.linspace(xvals[0], xvals[3], num=res)
        f2_x = np.linspace(xvals[3], xvals[7], num=res)
        f1_y = [self.__f(x, poly_coeffs_1) for x in f1_x]
        f2_y = [self.__f(x, poly_coeffs_2) for x in f2_x]

        fig = go.Figure()

        fig.add_trace(go.Scatter(x=f1_x, y=f1_y,
                            mode=&#39;lines&#39;,
                            name=&#39;f1&#39;))
        fig.add_trace(go.Scatter(x=f2_x, y=f2_y,
                            mode=&#39;lines&#39;,
                            name=&#39;f2&#39;))
        fig.add_trace(go.Scatter(x=xvals, y=yvals,
                            mode=&#39;markers&#39;,
                            name=&#39;TP points&#39;))
        
        fig.update_layout(legend_title=None,
                          title={&#39;text&#39;:&#34;TP grid polyfit&#34;}, autosize=False,
                          width=width, height=height,
                          margin={&#34;t&#34;: 40}, xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True}, template=&#34;simple_white&#34;)

        fig[&#39;layout&#39;][&#39;xaxis&#39;][&#39;title&#39;]=&#39;Temperature, C&#39;
        fig[&#39;layout&#39;][&#39;yaxis&#39;][&#39;title&#39;]=&#39;Pressure, bar&#39;
            
        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [],
                  &#39;toImageButtonOptions&#39;: {
                                           &#39;format&#39;: &#39;png&#39;, # one of png, svg, jpeg, webp
                                           &#39;filename&#39;: &#34;TP_grid_fit&#34;,
                                           &#39;height&#39;: height,
                                           &#39;width&#39;: width,
                                           &#39;scale&#39;: 1,
                                           },
                 }

        fig.show(config=config)

    
    def _interpolate_logK(self, T, logK_grid, T_grid, logK_extrapolate=&#34;none&#34;):
        
        logK_grid_trunc = [t for t in logK_grid if not math.isnan(t)]
        grid_len = len(logK_grid_trunc)
        logK_grid = logK_grid_trunc
        T_grid = T_grid[0:grid_len]
        
        if logK_extrapolate==&#34;none&#34; and (T &gt; max(T_grid) or T &lt; min(T_grid)):
            return np.nan, &#34;no fit&#34;
        elif logK_extrapolate==&#34;no fit&#34;:
            return np.nan, &#34;no fit&#34;
        
        # turns off poor polyfit warning
        # TODO: restore polyfit warning setting afterward
        warnings.simplefilter(&#39;ignore&#39;, np.RankWarning)
        
        if len(T_grid) &gt;= 4:
            if (len(T_grid) % 2) == 0:
                # if T_grid has an even length
                n_mid1 = math.floor(len(T_grid)/2)-1
                n_mid2 = n_mid1+1
            else:
                # if T_grid has an odd length
                n_mid1 = math.floor(len(T_grid)/2)
                n_mid2 = n_mid1+1

            poly_coeffs_1 = np.polyfit(T_grid[:n_mid2], logK_grid[:n_mid2], len(T_grid[:n_mid2])-1)
            poly_coeffs_2 = np.polyfit(T_grid[n_mid1:], logK_grid[n_mid1:], len(T_grid[n_mid1:])-1)

            model_1 = np.poly1d(poly_coeffs_1)
            model_2 = np.poly1d(poly_coeffs_2)

            if T &gt;= T_grid[0] and T &lt;= T_grid[n_mid1]:
                logK = model_1(T)
                model = &#34;model 1&#34;
            elif T &gt; T_grid[n_mid1] and T &lt;= T_grid[-1]:
                logK = model_2(T)
                model = &#34;model 2&#34;
            else:
                # dependent on extrapolation option
                if logK_extrapolate==&#34;none&#34;:
                    logK = np.nan
                    model = &#34;no fit&#34;
                elif logK_extrapolate==&#34;poly&#34;:
                    if T &lt; T_grid[0]:
                        logK = model_1(T)
                        model = &#34;model 1&#34;
                    elif T &gt; T_grid[-1]:
                        logK = model_2(T)
                        model = &#34;model 2&#34;
                    else:
                        logK = np.nan
                        model = &#34;no fit&#34;
                elif logK_extrapolate==&#34;linear&#34;:
                    poly_coeffs_1 = np.polyfit(T_grid[0:2], logK_grid[0:2], 1)
                    linear_model_1 = np.poly1d(poly_coeffs_1)
                    poly_coeffs_2 = np.polyfit(T_grid[-2:], logK_grid[-2:], 1)
                    linear_model_2 = np.poly1d(poly_coeffs_2)
                    if T &lt; T_grid[0]:
                        logK = linear_model_1(T)
                        model = &#34;linear model 1&#34;
                    elif T &gt; T_grid[-1]:
                        logK = linear_model_2(T)
                        model = &#34;linear model 2&#34;
                    else:
                        logK = np.nan
                        model = &#34;no fit&#34;
                elif logK_extrapolate==&#34;flat&#34;:
                    if T &lt; T_grid[0]:
                        logK = logK_grid[0]
                        model = &#34;flat extrap. 1&#34;
                    elif T &gt; T_grid[-1]:
                        logK = logK_grid[-1]
                        model = &#34;flat extrap. 2&#34;
                    else:
                        logK = np.nan
                        model = &#34;no fit&#34;
        elif len(T_grid) &gt;= 2:
            poly_coeffs = np.polyfit(T_grid, logK_grid, len(T_grid)-1)
            model_fit = np.poly1d(poly_coeffs)
            if T &gt;= T_grid[0] and T &lt;= T_grid[-1]:
                logK = model_fit(T)
                model = &#34;model 1&#34;
            else:
                # dependent on extrapolation option
                if logK_extrapolate==&#34;none&#34;:
                    logK = np.nan
                    model = &#34;no fit&#34;
                elif logK_extrapolate in [&#34;poly&#34;, &#34;linear&#34;]:
                    logK = model_fit(T)
                    model = &#34;model 1&#34;
                elif logK_extrapolate==&#34;flat&#34;:
                    if T &lt; T_grid[0]:
                        logK = logK_grid[0]
                        model = &#34;flat extrap.&#34;
                    elif T &gt; T_grid[-1]:
                        logK = logK_grid[-1]
                        model = &#34;flat extrap.&#34;
                    else:
                        logK = np.nan
                        model = &#34;no fit&#34;
        else:
            # only one T_grid value
            if T == T_grid[0]:
                logK = logK_grid[0]
                model = &#34;single point extrap.&#34;
            else:
                # dependent on extrapolation option
                if logK_extrapolate==&#34;none&#34;:
                    logK = np.nan
                    model = &#34;no fit&#34;
                elif logK_extrapolate!=&#34;none&#34;:
                    logK = logK_grid[0]
                    model = &#34;single point extrap.&#34;
            
#         ### TEST
#         from matplotlib import pyplot as plt
#         plt.plot(T_grid, logK_grid, &#39;o&#39;)
#         T_m1 = np.linspace(min(T_grid[:n_mid2]), max(T_grid[:n_mid2]), 100)
#         T_m2 = np.linspace(min(T_grid[n_mid1:]), max(T_grid[n_mid1:]), 100)
#         plt.plot(T_m1, model_1(T_m1))
#         plt.plot(T_m2, model_2(T_m2))
#         ###
        
        return logK, model
        
        
    def speciate(self,
                 input_filename,
                 db=None,
                 db_solid_solution=None,
                 db_logK=None,
                 logK_extrapolate=None,
                 activity_model=&#34;b-dot&#34;,
                 redox_flag=&#34;logfO2&#34;,
                 redox_aux=&#34;Fe+3&#34;,
                 default_logfO2=-6,
                 exclude=[],
                 suppress=[],
                 alter_options=[],
                 charge_balance_on=&#34;none&#34;,
                 suppress_missing=True,
                 blanks_are_0=False,
                 strict_minimum_pressure=True,
                 aq_scale=1,
                 verbose=1,
                 report_filename=None,
                 get_aq_dist=True,
                 aq_dist_type=&#34;log_activity&#34;,
                 get_mass_contribution=True,
                 mass_contribution_other=True,
                 get_mineral_sat=True,
                 mineral_sat_type=&#34;affinity&#34;,
                 get_redox=True,
                 redox_type=&#34;Eh&#34;,
                 get_ion_activity_ratios=True,
                 get_fugacity=True,
                 get_basis_totals=True,
                 get_solid_solutions=True,
                 get_affinity_energy=False,
                 negative_energy_supplies=False,
                 rxn_filename=None,
                 not_limiting=[&#34;H+&#34;, &#34;OH-&#34;, &#34;H2O&#34;],
                 get_charge_balance=True,
                 custom_db=False, # deprecated
                 batch_3o_filename=None,
                 delete_generated_folders=False,
                 db_args={}):
        
        &#34;&#34;&#34;
        Calculate the equilibrium distribution of chemical species in solution.
        Additionally, calculate chemical affinities and energy supplies for
        user-specified reactions.
        
        Parameters
        ----------
        input_filename : str
            User-supplied utf8-encoded comma separated value (csv) file
            containing sample data intended for speciation. The file must
            follow this format:
            
            - the first row is a header row that must contain the names of the
              species to be included in the speciation calculation. There
              cannot be duplicate headers.
            - the second row must contain subheaders for each species in the
              header row. These subheaders must be taken from the following:
              
                    degC
                    ppm
                    ppb
                    Suppressed
                    Molality
                    Molarity
                    mg/L
                    mg/kg.sol
                    Alk., eq/kg.H2O
                    Alk., eq/L
                    Alk., eq/kg.sol
                    Alk., mg/L CaCO3
                    Alk., mg/L HCO3-
                    Log activity
                    Log act combo
                    Log mean act
                    pX
                    pH
                    pHCl
                    pmH
                    pmX
                    Hetero. equil.
                    Homo. equil.
                    Make non-basis
                    
            - &#39;Temperature&#39; must be included as a header, with &#39;degC&#39; as its
              subheader.
            - The first column must contain sample names. There cannot be
              duplicate sample names.
        
        db : str, default &#34;wrm&#34;
            Determines which thermodynamic database is used in the speciation
            calculation. There are several options available:
            - Three letter file extension for the desired data1 database, e.g.,
            &#34;wrm&#34;. This will use a data1 file with this file extension, e.g.,
            &#34;data1.wrm&#34; located in the path stored in the &#39;EQ36DA&#39; environment
            variable used by EQ3NR.
            - The name of a data0 file located in the current working directory,
            e.g., &#34;data0.wrm&#34;. This data0 file will be compiled by EQPT
            automatically during the speciation calculation.
            - The name of a CSV file containing thermodynamic data located in
            the current working directory, e.g., &#34;wrm_data.csv&#34;. The CSV file
            will be used to generate a data0 file for each sample (using
            additional arguments from `db_args` if desired).
            - The URL of a data0 file, e.g.,
            &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#34;
            - The URL of a CSV file containing thermodynamic data, e.g.,
            &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
        
        db_solid_solution : str, optional
            Used only if `db` points to a thermodynamic data CSV file (or the
            URL of a CSV hosted online). Determines which thermodynamic database
            is used for idealized solid solutions in the speciation calculation.
            There are two options:
            - The name of a CSV file containing solid solution parameters
            located in the current working directory, e.g.,
            &#34;wrm_solid_solutions.csv&#34;
            - The URL of a CSV file containing solid solution parameters, e.g.,
            &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/solid_solutions.csv&#34;
        
        db_logK : str, optional
            The name of the CSV file containing species with dissociation
            constants but no other properties or parameters. Used only if `db`
            points to a thermodynamic data CSV file (or the URL of a CSV hosted
            online).
        
        activity_model : str, default &#34;b-dot&#34;
            Activity model to use for speciation. Can be either &#34;b-dot&#34;,
            or &#34;davies&#34;. NOTE: the &#34;pitzer&#34; model is not yet implemented.
        
        redox_flag : str, default &#34;O2(g)&#34;
            Determines which column in the sample input file sets the overall
            redox state of the samples. Options for redox_flag include &#39;O2(g)&#39;,
            &#39;pe&#39;, &#39;Eh&#39;, &#39;logfO2&#39;, and &#39;redox aux&#39;. The code will search your
            sample spreadsheet file (see `filename`) for a column corresponding
            to the option you chose:
            
            * &#39;O2(g)&#39; with a valid subheader for a gas
            * &#39;pe&#39; with subheader pe
            * &#39;Eh&#39; with subheader volts
            * &#39;logfO2&#39; with subheader logfO2
            * &#39;redox aux&#39; will search for a column corresponding to the
              auxilliary basis species selected to form a redox couple with its
              linked strict basis species (see `redox_aux`). For example, the
              redox couple Fe+2/Fe+3 would require a column named Fe+3
            
            If an appropriate header or redox data cannot be found to define
            redox state, `default_logfO2` is used to set sample logfO2.
            
            There is a special case where dissolved oxygen can be used to impose
            sample redox state if `redox_flag` is set to logfO2 and a column named
            logfO2 does not appear in your sample spreadsheet. If there is a
            column corresponding to dissolved oxygen measurements, logfO2 is
            calculated from the equilibrium reaction O2(aq) = O2(g) at the
            temperature and pressure of the sample using the revised Helgeson-
            Kirkham-Flowers (HKF) equation of state (JC Tanger IV and HC
            Helgeson, Am. J. Sci., 1988, 288, 19).
        
        redox_aux : default &#34;Fe+3&#34;, optional
            Ignored unless `redox_flag` equals 1. Name of the auxilliary species
            whose reaction links it to a basis species (or another auxilliary
            species) such that they form a redox couple that controls sample
            fO2. For instance, Fe+3 is linked to Fe+2 in many supporting data
            files, so selecting `redox_flag` = 1 and `redox_aux` = &#34;Fe+3&#34; will
            set sample fO2 based on the Fe+2/Fe+3 redox couple.
        
        default_logfO2 : float, default -6
            Default value for sample logfO2 in case redox data cannot be found
            in the user-supplied sample spreadsheet.
        
        exclude : list of str, default []
            Names of columns in the user-supplied sample spreadsheet that should
            not be considered aqueous species. Useful for excluding columns
            containing sample metatadata, such as &#34;Year&#34; and &#34;Location&#34;.
            
        suppress : list of str, default []
            Names of chemical species that will be prevented from forming in the
            speciation calculation.
        
        alter_options : list, default []
            A list of lists, e.g.,
            [[&#34;CaOH+&#34;, &#34;Suppress&#34;], [&#34;CaCl+&#34;, &#34;AugmentLogK&#34;, -1]]
            The first element of each interior list is the name of a species.
            The second element is an option to alter the species, and can be:
            - Suppress : suppress the formation of the species. (See also:
            `suppress`).
            - Replace : replace the species&#39; log K value with a desired value.
            - AugmentLogK : augment the value of the species&#39; log K.
            - AugmentG : augment the Gibbs free energy of the species by a
            desired value, in kcal/mol.
            The third element is a numeric value corresponding to the chosen
            option. A third element is not required for Suppress.
            
        charge_balance_on : str, default &#34;none&#34;
            If &#34;none&#34;, will not balance electrical charge between cations and
            anions in the speciation calculation. If a name of a species is
            supplied instead, the activity of that species will be allowed to
            change until charge balance is obtained. For example,
            charge_balance_on = &#34;H+&#34; will calculate what pH a sample must have
            to have zero net charge.
        
        suppress_missing : bool, default True
            Suppress the formation of an aqueous species if it is missing a
            value in the user-supplied sample spreadsheet?

        blanks_are_0 : bool, default False
            Assume all blank values in the water chemistry input file are 0?
            
        strict_minimum_pressure : bool, default True
            Ensure that the minimum pressure in the speciation calculation does
            not go below the minimum pressure in the TP grid of the data0 file?
        
        aq_scale : float, default 1
            Scale factor for the mass of the aqueous phase. By default, the
            aqueous phase is 1 kg of solvent.
        
        verbose : int, 0, 1, or 2, default 1
            Level determining how many messages are returned during a
            calculation. 2 for all messages, 1 for errors or warnings only,
            0 for silent.
            
        report_filename : str, optional
            Name of the comma separated values (csv) report file generated when
            the calculation is complete. If this argument is not defined, a
            report file is not generated.
            
        get_aq_dist : bool, default True
            Calculate distributions of aqueous species?
        
        aq_dist_type : str, default &#34;log_activity&#34;
            Desired units of measurement for reported distributions of aqueous
            species. Can be &#34;molality&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, or
            &#34;log_activity&#34;. Ignored if `get_aq_dist` is False.
        
        get_mass_contribution : bool, default True
            Calculate basis species contributions to mass balance of aqueous
            species?
        
        mass_contribution_other : bool, default True
            Include an &#34;other&#34; species for the sake of summing percents of basis
            species contributions to 100%? Ignored if `get_mass_contribution` is
            False.
        
        get_mineral_sat : bool, default True
            Calculate saturation states of pure solids?
        
        mineral_sat_type : str, default &#34;affinity&#34;
            Desired units of measurement for reported saturation states of pure
            solids. Can be &#34;logQoverK&#34; or &#34;affinity&#34;. Ignored if
            `get_mineral_sat` is False.
        
        get_redox : bool, default True
            Calculate potentials of redox couples?
            
        redox_type : str, default &#34;Eh&#34;
            Desired units of measurement for reported redox potentials. Can be
            &#34;Eh&#34;, &#34;pe&#34;, &#34;logfO2&#34;, or &#34;Ah&#34;. Ignored if `get_redox` is False.
        
        get_ion_activity_ratios : bool, default True
            Calculate ion/H+ activity ratios and neutral species activities?
        
        get_fugacity : bool, default True
            Calculate gas fugacities?

        get_basis_totals : bool, default True
            Report total compositions of basis aqueous species?

        get_solid_solutions : bool, default True
            Permit the calculation of solid solutions and include them in the
            speciation report?
        
        get_affinity_energy : bool, default False
            Calculate affinities and energy supplies of reactions listed in a
            separate user-supplied file?
        
        negative_energy_supplies : bool, default False
            Report negative energy supplies? If False, negative energy supplies
            are reported as 0 cal/kg H2O. If True, negative energy supplies are
            reported. A &#39;negative energy supply&#39; represents the energy cost of
            depleting the limiting reactant of a reaction. This metric is not
            always helpful when examing energy supply results, so this option is
            set to False by default.
        
        rxn_filename : str, optional
            Name of .txt file containing reactions used to calculate affinities
            and energy supplies. Ignored if `get_affinity_energy` is False.
        
        not_limiting : list, default [&#34;H+&#34;, &#34;OH-&#34;, &#34;H2O&#34;]
            List containing names of species that are not considered limiting
            when calculating energy supplies. Ignored if `get_affinity_energy`
            is False.
        
        get_charge_balance : bool, default True
            Calculate charge balance and ionic strength?
        
        batch_3o_filename : str, optional
            Name of rds (R object) file exported after the speciation
            calculation? No file will be generated if this argument is not
            defined.
            
        delete_generated_folders : bool, default False
            Delete the &#39;rxn_3i&#39;, &#39;rxn_3o&#39;, &#39;rxn_3p&#39;, and &#39;eqpt_files&#39; folders
            containing raw EQ3NR input, output, pickup, and EQPT files once the
            speciation calculation is complete?
           
        db_args : dict, default {}
            Dictionary of arguments to modify how the thermodynamic database is
            processed. Only used when `db` points to thermodynamic data in a CSV
            file. Ignored if `db` points to a data0 file (because a data0 file
            is already ready for a speciation calculation). Options for
            `db_args` are passed to the `create_data0` function, so refer to
            `create_data0` for more information about what options are possible.
            
            - Example of `db_args` where organics are excluded and redox is
            suppressed for Fe and S:
            db_args = {
               &#34;exclude_category&#34;:{&#34;category_1&#34;:[&#34;organic_aq&#34;]},
               &#34;suppress_redox&#34;:[&#34;Fe&#34;, &#34;S&#34;],
            }
            
        
        Returns
        -------
        speciation : object of class Speciation
            Contains the results of the speciation calculation.
        
        &#34;&#34;&#34;
        
        self.batch_T = []
        self.batch_P = []
        
        self.verbose = verbose
        
        if db != None:
            # load new thermodynamic database
            self.thermo._set_active_db(db)
        else:
            db = self.thermo.db
            
        if self.thermo.thermo_db_type == &#34;CSV&#34;:
            db_args[&#34;db&#34;] = &#34;dyn&#34;
            
        dynamic_db = self.thermo.dynamic_db
        data0_lettercode = self.thermo.data0_lettercode # needs to be this way
        
        
        if (self.thermo.thermo_db_type == &#34;data0&#34; or self.thermo.thermo_db_type == &#34;data1&#34;) and len(db_args) &gt; 0:
            if self.verbose &gt; 0:
                print(&#34;Warning: Ignoring db_args because a premade data0 or data1 file is being used: &#39;&#34; + db + &#34;&#39;&#34;)
            
        redox_suppression = False
        if &#34;suppress_redox&#34; in db_args.keys() and self.thermo.thermo_db_type != &#34;data0&#34; and self.thermo.thermo_db_type != &#34;data1&#34;:
            if len(db_args[&#34;suppress_redox&#34;]) &gt; 0:
                redox_suppression = True
        
        # check input sample file for errors
        if activity_model != &#39;pitzer&#39;: # TODO: allow check_sample_input_file() to handle pitzer
            sample_temps, sample_press = self._check_sample_input_file(
                                          input_filename, exclude, db,
                                          dynamic_db, charge_balance_on, suppress_missing,
                                          redox_suppression)
        
        if aq_dist_type not in [&#34;molality&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, &#34;log_activity&#34;]:
            self.err_handler.raise_exception(&#34;Unrecognized aq_dist_type. Valid &#34;
                &#34;options are &#39;molality&#39;, &#39;log_molality&#39;, &#39;log_gamma&#39;, &#39;log_activity&#39;&#34;)
        if mineral_sat_type not in [&#34;logQoverK&#34;, &#34;affinity&#34;]:
            self.err_handler.raise_exception(&#34;Unrecognized mineral_sat_type. Valid &#34;
                &#34;options are &#39;logQoverK&#39; or &#39;affinity&#39;&#34;)
        if redox_type not in [&#34;Eh&#34;, &#34;pe&#34;, &#34;logfO2&#34;, &#34;Ah&#34;]:
            self.err_handler.raise_exception(&#34;Unrecognized redox_type. Valid &#34;
                &#34;options are &#39;Eh&#39;, &#39;pe&#39;, &#39;logfO2&#39;, or &#39;Ah&#39;&#34;)
        
        if redox_flag == &#34;O2(g)&#34; or redox_flag == -3:
            redox_flag = -3
        elif redox_flag == &#34;pe&#34; or redox_flag == -2:
            redox_flag = -2
        elif redox_flag == &#34;Eh&#34; or redox_flag == -1:
            redox_flag = -1
        elif redox_flag == &#34;logfO2&#34; or redox_flag == 0:
            redox_flag = 0
        elif redox_flag == &#34;redox aux&#34; or redox_flag == 1:
            redox_flag = 1
        else:
            self.err_handler.raise_exception(&#34;Unrecognized redox flag. Valid options are &#39;O2(g)&#39;&#34;
                                             &#34;, &#39;pe&#39;, &#39;Eh&#39;, &#39;logfO2&#39;, &#39;redox aux&#39;&#34;)
            
        # handle batch_3o naming
        if batch_3o_filename != None:
            if &#34;.rds&#34; in batch_3o_filename[-4:]:
                batch_3o_filename = batch_3o_filename
            else:
                batch_3o_filename = &#34;batch_3o_{}.rds&#34;.format(data0_lettercode)
        else:
            batch_3o_filename = ro.r(&#34;NULL&#34;)
        
        # reset logK_models whenever speciate() is called
        # (prevents errors when speciations are run back-to-back)
        self.logK_models = {}
        
        # dynamic data0 creation per sample
        if dynamic_db:
            db_args[&#34;fill_data0&#34;] = False
            db_args[&#34;dynamic_db&#34;] = True
            db_args[&#34;verbose&#34;] = self.verbose
            db_args[&#34;dynamic_db_sample_temps&#34;] = sample_temps
            db_args[&#34;dynamic_db_sample_press&#34;] = sample_press
            
            if db_logK != None:
                self.thermo._load_logK(db_logK, source=&#34;file&#34;)
            
            if logK_extrapolate != None:
                db_args[&#34;logK_extrapolate&#34;] = logK_extrapolate
            elif self.thermo.logK_active:
                db_args[&#34;logK_extrapolate&#34;] = self.thermo.logK_extrapolate
                logK_extrapolate = self.thermo.logK_extrapolate
            else:
                logK_extrapolate = &#34;none&#34;

            if db_solid_solution != None:
                if not (db_solid_solution[0:8].lower() == &#34;https://&#34; or db_solid_solution[0:7].lower() == &#34;http://&#34; or db_solid_solution[0:4].lower() == &#34;www.&#34;):
                    if os.path.exists(db_solid_solution) and os.path.isfile(db_solid_solution):
                        db_args[&#34;filename_ss&#34;] = db_solid_solution
                    else:
                        self.err_handler.raise_exception(&#34;Error: could not locate &#34; + str(db_solid_solution))
                else:
                    db_solid_solution_csv_name = db_solid_solution.split(&#34;/&#34;)[-1].lower()
            
                    # Download from URL and decode as UTF-8 text.
                    with urlopen(db_solid_solution) as webpage:
                        content = webpage.read().decode()
                        
                    # Save to CSV file.
                    with open(db_solid_solution_csv_name, &#39;w&#39;) as output:
                        output.write(content)
                        
                    db_args[&#34;filename_ss&#34;] = db_solid_solution_csv_name
                    
            if self.verbose &gt; 0:
                print(&#34;Getting&#34;, self.thermo.thermo_db_filename, &#34;ready. This will take a moment...&#34;)
    
            thermo_df, data0_file_lines, grid_temps, grid_press, data0_lettercode, water_model, P1, plot_poly_fit = self.create_data0(**db_args)
            
        if self.thermo.custom_data0 and not dynamic_db:
            self.__mk_check_del_directory(&#39;eqpt_files&#39;)
            if self.thermo.thermo_db_type != &#34;data1&#34;:
                self.runeqpt(data0_lettercode)
            
            if os.path.exists(&#34;data1.&#34;+data0_lettercode) and os.path.isfile(&#34;data1.&#34;+data0_lettercode):
                try:
                    # store contents of data1 file in AqEquil object
                    with open(&#34;data1.&#34;+data0_lettercode, mode=&#39;rb&#39;) as data1:
                        self.data1[&#34;all_samples&#34;] = data1.read()
                    # move or copy data1
                    if self.thermo.thermo_db_type != &#34;data1&#34;:
                        shutil.move(&#34;data1.&#34;+data0_lettercode, &#34;eqpt_files/data1.&#34;+data0_lettercode)
                    else:
                        shutil.copyfile(&#34;data1.&#34;+data0_lettercode, &#34;eqpt_files/data1.&#34;+data0_lettercode)
                        
                except:
                    if self.verbose &gt; 0:
                        print(&#39;Error: Could not move&#39;, &#34;data1.&#34;+data0_lettercode, &#34;to eqpt_files&#34;)
            
            data1_path = os.getcwd()+&#34;/eqpt_files&#34; # creating a folder name without spaces to store the data1 overcomes the problem where environment variables with spaces do not work properly when assigned to EQ36DA
            
            data0_path = &#34;data0.&#34; + data0_lettercode
            
        elif dynamic_db:
            self.__mk_check_del_directory(&#39;eqpt_files&#39;)
            
        else:
            data0_path = self.eq36da + &#34;/data0.&#34; + data0_lettercode
        
        # gather information from data0 file and perform checks
        if not dynamic_db:
            if os.path.exists(data0_path) and os.path.isfile(data0_path):
                with open(data0_path) as data0:
                    data0_lines = data0.readlines()
                    start_index = [i+1 for i, s in enumerate(data0_lines) if s == &#39;temperatures\n&#39;]
                    if activity_model == &#39;davies&#39; or activity_model == &#39;b-dot&#39;:
                        end_index = [i for i, s in enumerate(data0_lines) if s == &#39;debye huckel a (adh)\n&#39;]
                    elif activity_model == &#39;pitzer&#39;:
                        end_index = [i for i, s in enumerate(data0_lines) if s == &#39;debye huckel aphi\n&#39;]
                    db_grids_unformatted = [i.split(&#34;pressures&#34;)[0] for i in data0_lines[start_index[0]:end_index[0]]]
                    db_grids = [&#34; &#34;.join(i.split()) for i in db_grids_unformatted if i != &#39;&#39;]
                    grid_temps = db_grids[0] + &#34; &#34; + db_grids[1]
                    grid_press = db_grids[2] + &#34; &#34; + db_grids[3]
                    grid_temps = grid_temps.split(&#34; &#34;)
                    grid_press = grid_press.split(&#34; &#34;)

                    try:
                        n_TP_points = data0_lines[2].split(&#34;points: &#34;)[1] # extract number of TP points from the third line of data0 file
                        n_TP_points = n_TP_points.replace(&#34;\n&#34;, &#34;&#34;)
                        n_TP_points = int(n_TP_points)
                    except:
                        n_TP_points = 8
                    if n_TP_points == 1:
                        grid_temps = grid_temps[0]
                        grid_press = grid_press[0]

                    try:
                        water_model = data0_lines[1].split(&#34;model: &#34;)[1] # extract water model from the second line of data0 file
                        water_model = water_model.replace(&#34;\n&#34;, &#34;&#34;)
                    except:
                        water_model = &#34;SUPCRT92&#34;
    #                     print(&#34;Water model could not be referenced from {}&#34;.format(data0_path)+&#34;&#34;
    #                           &#34;. Defaulting to SUPCRT92 water model...&#34;)


                    if(water_model not in [&#34;SUPCRT92&#34;, &#34;IAPWS95&#34;, &#34;DEW&#34;]):
                        water_model = &#34;SUPCRT92&#34; # the default for EQ3/6
                        print(&#34;Water model given in {}&#34;.format(data0_path)+&#34; was not &#34;
                              &#34;recognized. Defaulting to SUPCRT92 water model...&#34;)
                    
            else: # if a data0 file can&#39;t be found, assume default water model, 0-350 C and PSAT
                water_model = &#34;SUPCRT92&#34;
                grid_temps = [&#34;0.0100&#34;, &#34;50.0000&#34;, &#34;100.0000&#34;, &#34;150.0000&#34;,
                             &#34;200.0000&#34;, &#34;250.0000&#34;, &#34;300.0000&#34;, &#34;350.0000&#34;]
                grid_press = [&#34;1.0000&#34;, &#34;1.0000&#34;, &#34;1.0132&#34;, &#34;4.7572&#34;,
                              &#34;15.5365&#34;, &#34;39.7365&#34;, &#34;85.8378&#34;, &#34;165.2113&#34;]
                
            grid_press_numeric = [float(n) for n in grid_press]
            if min(grid_press_numeric) == 1:
                P1=True
            else:
                P1=False
                
            self._capture_r_output()
        
            r_check_TP_grid = pkg_resources.resource_string(__name__, &#39;check_TP_grid.r&#39;).decode(&#34;utf-8&#34;)
        
            ro.r(r_check_TP_grid)
        
            list_tp = ro.r.check_TP_grid(grid_temps=_convert_to_RVector(grid_temps),
                                         grid_press=_convert_to_RVector(grid_press),
                                         P1=P1,
                                         water_model=water_model,
                                         check_for_errors=False,
                                         verbose=self.verbose)
        
            self._print_captured_r_output()
            
            grid_temps = list(list_tp.rx2(&#34;grid_temps&#34;))
            grid_press = list(list_tp.rx2(&#34;grid_press&#34;))
            poly_coeffs_1 = list_tp.rx2(&#34;poly_coeffs_1&#34;)
            poly_coeffs_2 = list_tp.rx2(&#34;poly_coeffs_2&#34;)
            
            
        else:
            grid_temps = ro.r(&#34;NULL&#34;)
            grid_press = ro.r(&#34;NULL&#34;)
            poly_coeffs_1 = ro.r(&#34;NULL&#34;)
            poly_coeffs_2 = ro.r(&#34;NULL&#34;)
            
            
        if get_affinity_energy:
            if rxn_filename == None and self.affinity_energy_reactions_raw==None:
                err = (&#34;get_affinity_energy is set to True but a reaction TXT &#34;
                       &#34;file is not specified or redox reactions have not yet &#34;
                       &#34;been generated with make_redox_reactions()&#34;)
                self.err_handler.raise_exception(err)
            elif rxn_filename != None:
                self.__file_exists(rxn_filename, &#39;.txt&#39;)
                
                self.affinity_energy_reactions_raw = pd.read_csv(rxn_filename, sep=&#34;\t&#34;, header=None, names=[&#34;col&#34;+str(i) for i in range(1,50)])
                load_rxn_file = True
            else:
                if self.thermo.thermo_db_type != &#34;CSV&#34;:
                    if self.verbose &gt; 0:
                        warn_msg = (&#34;Warning: get_affinity_energy is set to True but &#34;
                            &#34;the active thermodynamic database (&#34;+self.thermo.db+&#34;) is not &#34;
                            &#34;in CSV format. This indicates a possible mismatch between &#34;
                            &#34;the thermodynamic database used to generate redox reactions &#34;
                            &#34;and the one used in this speciation calculation. Continuing anyway...&#34;)
                        print(warn_msg)
                rxn_filename = self.affinity_energy_reactions_raw
                load_rxn_file = False
            

            
        else:
            rxn_filename = &#34;&#34;
            load_rxn_file=False

        
        # handle Alter/Suppress options
        # e.g. [[&#34;CaCl+&#34;, &#34;AugmentLogK&#34;, -1], [&#34;CaOH+&#34;, &#34;Suppress&#34;]]
        alter_options_dict = {}
        if len(alter_options) &gt; 0:
            for ao in alter_options:
                if not isinstance(ao, list):
                    err = (&#34;alter_options must be a list of lists, e.g.,\n&#34;
                          &#34;[[&#39;CaCl+&#39;, &#39;AugmentLogK&#39;, -1], [&#39;CaOH+&#39;, &#39;Suppress&#39;]]&#34;
                          &#34;\nor\n[[&#39;CaHCO3+&#39;, &#39;Suppress&#39;]]&#34;)
                    self.err_handler.raise_exception(err)
                key = ao[0]
                if ao[1] == &#34;Suppress&#34; and len(ao) == 2:
                    ao += [&#34;0&#34;]
                alter_options_dict[key] = _convert_to_RVector(list(ao[1:]))
        alter_options = ro.ListVector(alter_options_dict)
        
        input_dir = &#34;rxn_3i&#34;
        output_dir = &#34;rxn_3o&#34;
        pickup_dir = &#34;rxn_3p&#34;
            
        # preprocess for EQ3 using R scripts
        self._capture_r_output()
        
        r_prescript = pkg_resources.resource_string(
            __name__, &#39;preprocess_for_EQ3.r&#39;).decode(&#34;utf-8&#34;)
        ro.r(r_prescript)
        
        input_processed_list = ro.r.preprocess(input_filename=input_filename,
                                               exclude=_convert_to_RVector(exclude),
                                               grid_temps=_convert_to_RVector(grid_temps),
                                               grid_press=_convert_to_RVector(grid_press),
                                               strict_minimum_pressure=strict_minimum_pressure,
                                               dynamic_db=dynamic_db,
                                               poly_coeffs_1=poly_coeffs_1,
                                               poly_coeffs_2=poly_coeffs_2,
                                               water_model=water_model,
                                               verbose=self.verbose)
        
        
        self._print_captured_r_output()
        
        self.df_input_processed = ro.conversion.rpy2py(input_processed_list.rx2(&#34;df&#34;))
        
        
        if blanks_are_0:
            self.df_input_processed = self.df_input_processed.fillna(1E-18)
        
        self.__mk_check_del_directory(&#39;rxn_3i&#39;)
        self.__mk_check_del_directory(&#39;rxn_3o&#39;)
        self.__mk_check_del_directory(&#39;rxn_3p&#39;)
        if dynamic_db:
            self.__mk_check_del_directory(&#39;rxn_data0&#39;)
        
        # Has the user been warned about redox column during write_3i_file()?
        # Prevents repeated warnings.
        warned_about_redox_column = False
        
        self.batch_T = list(input_processed_list.rx2(&#34;temp_degC&#34;))
        self.batch_P = list(input_processed_list.rx2(&#34;pressure_bar&#34;))
        
        # create and run a 3i file for each sample
        for sample_row_index in range(0, self.df_input_processed.shape[0]):
            
            temp_degC = list(input_processed_list.rx2(&#34;temp_degC&#34;))[sample_row_index]
            pressure_bar = list(input_processed_list.rx2(&#34;pressure_bar&#34;))[sample_row_index]
            
            df = self.df_input_processed.iloc[[sample_row_index]] # double brackets to keep as df row instead of series
            
            samplename = str(df.index[0])
            
            # handle dynamic data0 creation
            if dynamic_db:
                
                self.__fill_data0(thermo_df=ro.conversion.rpy2py(thermo_df),
                                  data0_file_lines=copy.deepcopy(data0_file_lines),
                                  grid_temps=[temp_degC],
                                  grid_press=[pressure_bar],
                                  db=data0_lettercode,
                                  water_model=water_model,
                                  activity_model=activity_model,
                                  P1=P1,
                                  plot_poly_fit=plot_poly_fit,
                                  logK_extrapolate=logK_extrapolate,
                                  dynamic_db=dynamic_db,
                                  verbose=verbose)
                
                if self.thermo.thermo_db_type != &#34;data1&#34;:
                    self.runeqpt(data0_lettercode, dynamic_db=True)
                
                if os.path.exists(&#34;data1.&#34;+data0_lettercode) and os.path.isfile(&#34;data1.&#34;+data0_lettercode):
                    # store contents of data1 file in AqEquil object
                    with open(&#34;data1.&#34;+data0_lettercode, mode=&#39;rb&#39;) as data1:
                        self.data1[samplename] = data1.read()
                    try:
                        # move data1
                        shutil.move(&#34;data1.&#34;+data0_lettercode, &#34;eqpt_files/data1.&#34;+data0_lettercode)
                    except:
                        if self.verbose &gt; 0:
                            print(&#39;Error: Could not move&#39;, &#34;data1.&#34;+data0_lettercode, &#34;to eqpt_files&#34;)

                data1_path = os.getcwd()+&#34;/eqpt_files&#34; # creating a folder name without spaces to store the data1 overcomes the problem where environment variables with spaces do not work properly when assigned to EQ36DA

                data0_path = &#34;data0.&#34; + data0_lettercode
                
            else:
                pressure_bar = list(input_processed_list.rx2(&#34;pressure_bar&#34;))[sample_row_index]
                data1_path = self.thermo.eq36da
            
            # allowed aq block species are left after any category exclusion in db_args
            allowed_aq_block_species = [&#34;all&#34;]
            if dynamic_db:
                allowed_aq_block_species = list(thermo_df[&#34;name&#34;]) + FIXED_SPECIES
            
            # write 3i files
            self._capture_r_output()

            warned_about_redox_column = ro.r.write_3i_file(df=ro.conversion.py2rpy(df),
                               temp_degC=temp_degC,
                               pressure_bar=pressure_bar,
                               minimum_pressure=input_processed_list.rx2(&#34;minimum_pressure&#34;),
                               strict_minimum_pressure=strict_minimum_pressure,
                               pressure_override=dynamic_db,
                               suppress_missing=suppress_missing,
                               exclude=input_processed_list.rx2(&#34;exclude&#34;),
                               allowed_aq_block_species=_convert_to_RVector(allowed_aq_block_species),
                               charge_balance_on=charge_balance_on,
                               suppress=_convert_to_RVector(suppress),
                               alter_options=alter_options,
                               aq_scale=aq_scale,
                               get_solid_solutions=get_solid_solutions,
                               input_dir=input_dir,
                               redox_flag=redox_flag,
                               redox_aux=redox_aux,
                               default_logfO2=default_logfO2,
                               water_model=water_model,
                               warned_about_redox_column=warned_about_redox_column,
                               activity_model=activity_model,
                               verbose=self.verbose)

            self._print_captured_r_output()
        
            # run EQ3 on each 3i file
            samplename = self.df_input_processed.iloc[sample_row_index, self.df_input_processed.columns.get_loc(&#34;Sample&#34;)]
            filename_3i = self.df_input_processed.index[sample_row_index]+&#34;.3i&#34;
            filename_3o = filename_3i[:-1] + &#39;o&#39;
            filename_3p = filename_3i[:-1] + &#39;p&#39;
            
            
            if dynamic_db:
                dynamic_db_name = self.thermo.thermo_db_filename
            else:
                dynamic_db_name = None
            
            self.runeq3(filename_3i=filename_3i,
                        db=data0_lettercode,
                        samplename=samplename,
                        path_3i=input_dir,
                        path_3o=output_dir,
                        path_3p=pickup_dir,
                        data1_path=data1_path,
                        dynamic_db_name=dynamic_db_name)
            
            # store input, output, and pickup as dicts in AqEquil object
            try:
                with open(input_dir + &#34;/&#34; + filename_3i, &#34;r&#34;) as f:
                    lines=f.readlines()
                self.raw_3_input_dict[samplename] = lines
            except:
                pass
            try:
                with open(output_dir + &#34;/&#34; + filename_3o, &#34;r&#34;) as f:
                    lines=f.readlines()
                self.raw_3_output_dict[samplename] = lines
            except:
                pass
            try:
                with open(pickup_dir + &#34;/&#34; + filename_3p, &#34;r&#34;) as f:
                    lines=f.readlines()
                    
                # capture everything after &#34;start of the bottom half&#34;
                top_half = []
                bottom_half = []
                capture = False
                for line in lines:
                    if &#34;Start of the bottom half of the input file&#34; in line:
                        capture = True
                    if capture:
                        bottom_half.append(line)
                    else:
                        top_half.append(line)
                        
                self.raw_3_pickup_dict_top[samplename] = top_half # top half of the 3p file, including header for mixing calcs
                self.raw_3_pickup_dict_bottom[samplename] = bottom_half # the bottom half
                
            except:
                pass
            
            if dynamic_db:
                shutil.move(&#34;data0.dyn&#34;, &#34;rxn_data0/&#34;+filename_3i[0:-3]+&#34;_data0.dat&#34;)

        if self.thermo.custom_data0:
            # delete straggling data1 files generated after running eq3
            if os.path.exists(&#34;data1&#34;) and os.path.isfile(&#34;data1&#34;):
                os.remove(&#34;data1&#34;)

        files_3o = [file+&#34;.3o&#34; for file in self.df_input_processed.index]
        
        df_input_processed_names = _convert_to_RVector(list(self.df_input_processed.columns))
        
        if self.thermo.thermo_db_type == &#34;CSV&#34;:
            custom_obigt = self.thermo.thermo_db
        else:
            custom_obigt = ro.r(&#34;NULL&#34;)
        
        # mine output
        self._capture_r_output()
        
        r_3o_mine = pkg_resources.resource_string(
            __name__, &#39;3o_mine.r&#39;).decode(&#34;utf-8&#34;)
        ro.r(r_3o_mine)
        
        batch_3o = ro.r.main_3o_mine(
            files_3o=_convert_to_RVector(files_3o),
            input_filename=input_filename,
            input_pressures=_convert_to_RVector(list(input_processed_list.rx2(&#34;pressure_bar&#34;))),
            rxn_filename=rxn_filename,
            get_aq_dist=get_aq_dist,
            aq_dist_type=aq_dist_type,
            get_mass_contribution=get_mass_contribution,
            mass_contribution_other=mass_contribution_other,
            get_mineral_sat=get_mineral_sat,
            mineral_sat_type=mineral_sat_type,
            get_redox=get_redox,
            redox_type=redox_type,
            get_charge_balance=get_charge_balance,
            get_ion_activity_ratios=get_ion_activity_ratios,
            get_fugacity=get_fugacity,
            get_basis_totals=get_basis_totals,
            get_solid_solutions=get_solid_solutions,
            get_affinity_energy=get_affinity_energy,
            negative_energy_supplies=negative_energy_supplies,
            load_rxn_file=load_rxn_file,
            not_limiting=_convert_to_RVector(not_limiting),
            batch_3o_filename=batch_3o_filename,
            df_input_processed=ro.conversion.py2rpy(self.df_input_processed),
            # New rpy2 py2rpy2 conversion might not need the workaround below.
            # The old note regarding deprecated pandas2ri is shown below...
            # OLD NOTE:
            # Needed for keeping symbols in column names after porting
            #   df_input_processed in the line above. Some kind of check.names
            #   option for pandas2ri.py2ri would be nice. Workaround:
            df_input_processed_names=df_input_processed_names,
            custom_obigt=custom_obigt,
            water_model=water_model,
            fixed_species=_convert_to_RVector(FIXED_SPECIES),
            verbose=self.verbose,
        )

        self._print_captured_r_output()
        
        if len(batch_3o) == 0:
            self.err_handler.raise_exception(&#34;Could not compile a speciation report. This is &#34;
                            &#34;likely because errors occurred during &#34;
                            &#34;the speciation calculation.&#34;)
            return
        
        if get_mass_contribution:
            mass_contribution = ro.conversion.rpy2py(batch_3o.rx2(&#39;mass_contribution&#39;))
        df_report = ro.conversion.rpy2py(batch_3o.rx2(&#39;report&#39;))
        
        #df_input = ro.conversion.rpy2py(batch_3o.rx2(&#39;input&#39;))
        report_divs = batch_3o.rx2(&#39;report_divs&#39;)

        input_cols = list(report_divs.rx2(&#39;input&#39;))
        df_input = df_report[input_cols].copy()
        
        # add a pressure column to df_input
        df_input[&#34;Pressure_bar&#34;] = pd.Series(dtype=&#39;float&#39;)
        sample_data = batch_3o.rx2(&#39;sample_data&#39;)
        for sample in sample_data:
            df_input.loc[str(sample.rx2(&#39;name&#39;)[0]), &#34;Pressure_bar&#34;] = float(sample.rx2(&#39;pressure&#39;)[0])
        report_divs[0] = _convert_to_RVector(input_cols + [&#34;Pressure_bar&#34;])
            
        # handle headers and subheaders of input section
        headers = [col.split(&#34;_&#34;)[0] for col in list(df_input.columns)]
        headers = [&#34;pH&#34; if header == &#34;H+&#34; else header for header in headers]
        headers = [header+&#34;_(input)&#34; if header not in [&#34;Temperature&#34;, &#34;logfO2&#34;, &#34;Pressure&#34;]+exclude else header for header in headers]
        report_divs[0] = _convert_to_RVector(headers) # modify headers in the &#39;input&#39; section, report_divs[0]
        subheaders = [subheader[1] if len(subheader) &gt; 1 else &#34;&#34; for subheader in [
            col.split(&#34;_&#34;) for col in list(df_input.columns)]]
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        
        df_input.columns = multicolumns

        df_join = df_input

        if get_aq_dist:
            aq_distribution_cols = list(report_divs.rx2(&#39;aq_distribution&#39;))
            df_aq_distribution = df_report[aq_distribution_cols]
            df_aq_distribution = df_aq_distribution.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            
            # create a pH column from H+
            df_aq_distribution[&#34;pH&#34;] = np.nan # pH values are assigned when sample data is assembled later
            
            # handle headers of aq_distribution section
            headers = df_aq_distribution.columns
            subheaders = [aq_dist_type]*(len(headers)-1) # -1 because the last column will have subheader pH (see next line)
            subheaders = subheaders + [&#34;pH&#34;]
            
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_aq_distribution.columns = multicolumns
            
            # ensure final pH column is included in report_divs aq_distribution section
            aq_dist_indx = list(report_divs.names).index(&#34;aq_distribution&#34;)
            report_divs[aq_dist_indx] = _convert_to_RVector(list(headers))
            
            df_join = df_join.join(df_aq_distribution)

        if get_mineral_sat:
            mineral_sat_cols = list(report_divs.rx2(&#39;mineral_sat&#39;))
            mineral_sat_cols = [col for col in mineral_sat_cols if col != &#34;df&#34;] # TO DO: why is df appearing in mineral sat cols and redox sections?
            df_mineral_sat = df_report[mineral_sat_cols]
            df_mineral_sat = df_mineral_sat.apply(pd.to_numeric, errors=&#39;coerce&#39;)

            # handle headers of df_mineral_sat section
            if mineral_sat_type == &#34;affinity&#34;:
                mineral_sat_unit = &#34;affinity_kcal&#34;
            elif mineral_sat_type == &#34;logQoverK&#34;:
                mineral_sat_unit = &#34;logQ/K&#34;
            else:
                self.err_handler.raise_exception(
                    &#34;mineral_sat_type must be either &#39;affinity&#39; or &#39;logQoverK&#39;&#34;)

            headers = df_mineral_sat.columns
            subheaders = [mineral_sat_unit]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_mineral_sat.columns = multicolumns
            df_join = df_join.join(df_mineral_sat)

        if get_redox:
            redox_cols = list(report_divs.rx2(&#39;redox&#39;))
            redox_cols = [col for col in redox_cols if col != &#34;df&#34;] # TO DO: why is df appearing in mineral sat cols and redox sections?
            df_redox = df_report[redox_cols]
            df_redox = df_redox.apply(pd.to_numeric, errors=&#39;coerce&#39;)

            # handle headers of df_redox section
            if redox_type == &#34;Eh&#34;:
                redox_unit = &#34;Eh_volts&#34;
            elif redox_type == &#34;pe&#34;:
                redox_unit = &#34;pe&#34;
            elif redox_type == &#34;logfO2&#34;:
                redox_unit = &#34;logfO2&#34;
            elif redox_type == &#34;Ah&#34;:
                redox_unit = &#34;Ah_kcal&#34;
            else:
                self.err_handler.raise_exception(
                    &#34;redox_type must be either &#39;Eh&#39;, &#39;pe&#39;, &#39;logfO2&#39;, or &#39;Ah&#39;&#34;)

            headers = df_redox.columns
            subheaders = [redox_unit]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_redox.columns = multicolumns
            df_join = df_join.join(df_redox)

        if get_charge_balance:
            charge_balance_cols = list(report_divs.rx2(&#39;charge_balance&#39;))
            df_charge_balance = df_report[charge_balance_cols]
            df_charge_balance = df_charge_balance.apply(pd.to_numeric, errors=&#39;coerce&#39;)

            # handle headers of df_charge_balance section
            headers = df_charge_balance.columns
            subheaders = [&#34;%&#34;]*2 + [&#39;eq/kg.H2O&#39;, &#39;molality&#39;] + \
                [&#39;eq/kg.H2O&#39;]*4 + [&#39;molality&#39;]
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_charge_balance.columns = multicolumns
            df_join = df_join.join(df_charge_balance)
            
        if get_ion_activity_ratios:
            if type(report_divs.rx2(&#39;ion_activity_ratios&#39;)) != rpy2.rinterface_lib.sexp.NULLType:
                ion_activity_ratio_cols = list(report_divs.rx2(&#39;ion_activity_ratios&#39;))

                df_ion_activity_ratios = df_report[ion_activity_ratio_cols]
                df_ion_activity_ratios = df_ion_activity_ratios.apply(pd.to_numeric, errors=&#39;coerce&#39;)

                # handle headers of df_ion_activity_ratios section
                headers = df_ion_activity_ratios.columns
                subheaders = [&#34;Log ion-H+ activity ratio&#34;]*len(headers)
                multicolumns = pd.MultiIndex.from_arrays(
                    [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
                df_ion_activity_ratios.columns = multicolumns
                df_join = df_join.join(df_ion_activity_ratios)
            
        if get_fugacity:
            fugacity_cols = list(report_divs.rx2(&#39;fugacity&#39;))
            df_fugacity = df_report[fugacity_cols]
            df_fugacity = df_fugacity.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            
            # handle headers of fugacity section
            headers = df_fugacity.columns
            subheaders = [&#34;log_fugacity&#34;]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_fugacity.columns = multicolumns
            df_join = df_join.join(df_fugacity)

        if get_basis_totals:
            sc_cols = list(report_divs.rx2(&#39;basis_totals&#39;))
            df_sc = df_report[sc_cols]
            df_sc = df_sc.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            
            # handle headers of basis_totals section
            headers = df_sc.columns
            subheaders = [&#34;molality&#34;]*(len(headers))
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_sc.columns = multicolumns
            df_join = df_join.join(df_sc)
            
        if get_affinity_energy:
            affinity_cols = list(report_divs.rx2(&#39;affinity&#39;))
            energy_cols = list(report_divs.rx2(&#39;energy&#39;))
            
            df_affinity = df_report[affinity_cols]
            df_energy = df_report[energy_cols]
            
            df_affinity = df_affinity.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            df_energy = df_energy.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            
            # handle headers of df_affinity section
            headers = df_affinity.columns
            subheaders = [&#39;cal/mol e-&#39;]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_affinity.columns = multicolumns

            # handle headers of df_energy section
            headers = df_energy.columns
            subheaders = [&#39;cal/kg.H2O&#39;]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_energy.columns = multicolumns
            df_join = df_join.join(df_affinity)
            df_join = df_join.join(df_energy)

        out_dict = {&#39;sample_data&#39;: {},
                    &#39;report&#39;: df_join,
                    &#39;input&#39;: df_input, &#39;report_divs&#39;: report_divs}
        
        if get_mass_contribution:
            out_dict[&#39;mass_contribution&#39;] = mass_contribution

        sample_data = batch_3o.rx2(&#39;sample_data&#39;)

        # assemble sample data
        for i, sample in enumerate(sample_data):
            dict_sample_data = {
                &#34;filename&#34;: str(sample.rx2(&#39;filename&#39;)[0]),
                &#34;name&#34;: str(sample.rx2(&#39;name&#39;)[0]),
                &#34;temperature&#34;: float(sample.rx2(&#39;temperature&#39;)[0]),
                &#34;pressure&#34;: float(sample.rx2(&#39;pressure&#39;)[0]),
                &#34;logact_H2O&#34;: float(sample.rx2(&#39;logact_H2O&#39;)[0]),
                &#34;H2O_density&#34;: float(sample.rx2(&#39;H2O_density&#39;)[0]),
                &#34;H2O_molality&#34;: float(sample.rx2(&#39;H2O_molality&#39;)[0]),
                &#34;H2O_log_molality&#34;: float(sample.rx2(&#39;H2O_log_molality&#39;)[0]),
                }

            if get_aq_dist:
                sample_aq_dist = ro.conversion.rpy2py(sample.rx2(&#39;aq_distribution&#39;))
                sample_aq_dist = sample_aq_dist.apply(pd.to_numeric, errors=&#39;coerce&#39;)
                
                sample_pH = -sample_aq_dist.loc[&#34;H+&#34;, &#34;log_activity&#34;]
                out_dict[&#34;report&#34;].loc[str(sample.rx2(&#39;name&#39;)[0]), &#34;pH&#34;] = sample_pH
                
                dict_sample_data.update({&#34;aq_distribution&#34;: sample_aq_dist})

            if get_mass_contribution:
                sample_mass_contribution = mass_contribution[mass_contribution[&#34;sample&#34;] == sample.rx2(&#39;name&#39;)[0]]
                dict_sample_data.update(
                    {&#34;mass_contribution&#34;: sample_mass_contribution})

            if get_mineral_sat:
                dict_sample_data.update(
                    {&#34;mineral_sat&#34;: ro.conversion.rpy2py(sample.rx2(&#39;mineral_sat&#39;)).apply(pd.to_numeric, errors=&#39;coerce&#39;)})
                # replace sample mineral_sat entry with None if there is no mineral saturation data.
                if(len(dict_sample_data[&#39;mineral_sat&#39;].index) == 1 and dict_sample_data[&#39;mineral_sat&#39;].index[0] == &#39;None&#39;):
                    dict_sample_data[&#39;mineral_sat&#39;] = None

            if get_redox:
                dict_sample_data.update(
                    {&#34;redox&#34;: ro.conversion.rpy2py(sample.rx2(&#39;redox&#39;)).apply(pd.to_numeric, errors=&#39;coerce&#39;)})

            if get_charge_balance:
                dict_sample_data.update({&#34;charge_balance&#34;: df_charge_balance.loc[sample.rx2(&#39;name&#39;)[0], :]})
            
            if get_ion_activity_ratios:
                
                try:
                    dict_sample_data.update(
                        {&#34;ion_activity_ratios&#34;: ro.conversion.rpy2py(sample.rx2(&#39;ion_activity_ratios&#39;))})
                except:
                    dict_sample_data[&#39;ion_activity_ratios&#39;] = None
            
            if get_fugacity:
                dict_sample_data.update(
                    {&#34;fugacity&#34;: ro.conversion.rpy2py(sample.rx2(&#39;fugacity&#39;)).apply(pd.to_numeric, errors=&#39;coerce&#39;)})
                # replace sample fugacity entry with None if there is no fugacity data.
                if(len(dict_sample_data[&#39;fugacity&#39;].index) == 1 and dict_sample_data[&#39;fugacity&#39;].index[0] == &#39;None&#39;):
                    dict_sample_data[&#39;fugacity&#39;] = None
                else:
                    dict_sample_data[&#34;fugacity&#34;][&#34;fugacity&#34;] = 10**dict_sample_data[&#34;fugacity&#34;][&#34;log_fugacity&#34;]
                    
            if get_basis_totals:
                sc_dist = ro.conversion.rpy2py(sample.rx2(&#39;basis_totals&#39;))
                sc_dist = sc_dist.apply(pd.to_numeric, errors=&#39;coerce&#39;)
                dict_sample_data.update({&#34;basis_totals&#34;: sc_dist})

            if get_solid_solutions:
                sample_solid_solutions = batch_3o.rx2[&#34;sample_data&#34;].rx2[str(sample.rx2(&#39;name&#39;)[0])].rx2[&#34;solid_solutions&#34;]

                if not type(sample_solid_solutions.names) == rpy2.rinterface_lib.sexp.NULLType:

                    ss_df_list = []
                    for ss in list(sample_solid_solutions.names):
                        df_ss_ideal = ro.conversion.rpy2py(sample_solid_solutions.rx2[str(ss)].rx2[&#34;ideal solution&#34;])
                        df_ss_mineral = ro.conversion.rpy2py(sample_solid_solutions.rx2[str(ss)].rx2[&#34;mineral&#34;])
                        df_merged = pd.merge(df_ss_mineral, df_ss_ideal, left_on=&#39;mineral&#39;, right_on=&#39;component&#39;, how=&#39;left&#39;)
                        df_merged.insert(0, &#39;solid solution&#39;, ss)
                        del df_merged[&#39;component&#39;]
                        ss_df_list.append(df_merged)
                
                    dict_sample_data.update(
                        {&#34;solid_solutions&#34;: pd.concat(ss_df_list)})
            
            if get_affinity_energy:
                dict_sample_data.update({&#34;affinity_energy_raw&#34;: ro.conversion.rpy2py(
                    sample.rx2(&#39;affinity_energy_raw&#39;))})
                dict_sample_data.update(
                    {&#34;affinity_energy&#34;: ro.conversion.rpy2py(sample.rx2(&#39;affinity_energy&#39;))})

            out_dict[&#34;sample_data&#34;].update(
                {sample_data.names[i]: dict_sample_data})

        out_dict.update({&#34;batch_3o&#34;: batch_3o})
        
        out_dict.update({&#34;water_model&#34;:water_model, &#34;grid_temps&#34;:grid_temps, &#34;grid_press&#34;:grid_press})
        
        speciation = Speciation(out_dict, hide_traceback=self.hide_traceback)
        
        if get_affinity_energy:
            speciation.half_cell_reactions = self.half_cell_reactions
            speciation.affinity_energy_reactions_table = self.affinity_energy_reactions_table
            speciation.affinity_energy_formatted_reactions = self.affinity_energy_formatted_reactions
            speciation.show_redox_reactions = self.show_redox_reactions
        
        if report_filename != None:
            if &#34;.csv&#34; in report_filename[-4:]:
                out_dict[&#34;report&#34;].to_csv(report_filename)
            else:
                out_dict[&#34;report&#34;].to_csv(report_filename+&#34;.csv&#34;)

        if delete_generated_folders:
            self._delete_rxn_folders()
            try:
                # delete straggler data1 file
                os.remove(&#34;data1&#34;)
            except:
                pass
        
        if self.verbose &gt; 0:
            print(&#34;Finished!&#34;)
        
        speciation.raw_3_input_dict = self.raw_3_input_dict
        speciation.raw_3_output_dict = self.raw_3_output_dict
        speciation.raw_3_pickup_dict_top = self.raw_3_pickup_dict_top
        speciation.raw_3_pickup_dict_bottom = self.raw_3_pickup_dict_bottom
        speciation.raw_6_input_dict = {}
        speciation.raw_6_output_dict = {}
        speciation.raw_6_pickup_dict = {}
        speciation.thermo = self.thermo
        speciation.data1 = self.data1
        
        speciation.logK_models = self.logK_models
        speciation.batch_T = self.batch_T
        speciation.batch_P = self.batch_P
        
        return speciation
    

    @staticmethod
    def __s_d(x, k):
        # specify how many decimals are printed
        # e.g. 12.433 becomes &#34;12.4330&#34; if k=4
        kstr = &#39;{:.&#39;+str(k)+&#39;f}&#39;
        return kstr.format(round(x, k)).strip()
    
    
    def __fill_data0(self, thermo_df, data0_file_lines, grid_temps, grid_press, db,
                   water_model, activity_model, P1, plot_poly_fit, logK_extrapolate,
                   dynamic_db, verbose):
        
        
        self._capture_r_output()
        
        r_check_TP_grid = pkg_resources.resource_string(
            __name__, &#39;check_TP_grid.r&#39;).decode(&#34;utf-8&#34;)
        
        ro.r(r_check_TP_grid)
        
        list_tp = ro.r.check_TP_grid(grid_temps=_convert_to_RVector(grid_temps),
                                     grid_press=_convert_to_RVector(grid_press),
                                     P1=P1,
                                     water_model=water_model,
                                     check_for_errors=True,
                                     verbose=self.verbose)
        
        self._print_captured_r_output()
        
        grid_temps = list(list_tp.rx2(&#34;grid_temps&#34;))
        grid_press = list(list_tp.rx2(&#34;grid_press&#34;))
        
        if plot_poly_fit and len(grid_temps) == 8:
            self.__plot_TP_grid_polyfit(xvals=grid_temps,
                                        yvals=grid_press,
                                        poly_coeffs_1=list(list_tp.rx2(&#34;poly_coeffs_1&#34;)),
                                        poly_coeffs_2=list(list_tp.rx2(&#34;poly_coeffs_2&#34;)),
                                        res=500)

        self._print_captured_r_output()
        
        # calculate logK at each T and P for every species
        out_dfs = []
        for i,Tc in enumerate(grid_temps):
            out_dfs.append(calc_logK(thermo_df, Tc=Tc, P=grid_press[i], TP_i=i, water_model=water_model))
        
        dissrxn_logK_dict = {&#39;name&#39;: out_dfs[0][&#34;name&#34;],
                             &#39;logK_0&#39;: out_dfs[0][&#34;dissrxn_logK_0&#34;]}
        
        if len(grid_temps) == 8:
            for i in range(1, len(grid_temps)):
                dissrxn_logK_dict[&#39;logK_&#39;+str(i)] = out_dfs[i][&#34;dissrxn_logK_&#34;+str(i)]
                
        if len(grid_temps) == 1:
            dissrxn_logK_dict[&#39;logK_1&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_2&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_3&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_4&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_5&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_6&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_7&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
    
        dissrxn_logK = pd.DataFrame(dissrxn_logK_dict)
        
        # remove duplicate rows (e.g., for mineral polymorphs)
        dissrxn_logK = dissrxn_logK.drop_duplicates(&#34;name&#34;)
        
        # handle free logK values
        free_logK_names = []
        if &#34;logK1&#34; in thermo_df.columns:
            
            free_logK_df = thermo_df.dropna(subset=[&#39;logK1&#39;])
            free_logK_names = list(free_logK_df[&#34;name&#34;])
    
            sp_dupes = []
            for i,sp in enumerate(free_logK_names):
                logK_grid = list(free_logK_df[[&#34;logK1&#34;, &#34;logK2&#34;, &#34;logK3&#34;,
                                               &#34;logK4&#34;, &#34;logK5&#34;, &#34;logK6&#34;,
                                               &#34;logK7&#34;, &#34;logK8&#34;]].iloc[i]) # logK at T and P in datasheet
                
                T_grid = list(free_logK_df[[&#34;T1&#34;, &#34;T2&#34;, &#34;T3&#34;,
                                            &#34;T4&#34;, &#34;T5&#34;, &#34;T6&#34;,
                                            &#34;T7&#34;, &#34;T8&#34;]].iloc[i]) # T for free logK grid
                
                P_grid = list(free_logK_df[[&#34;P1&#34;, &#34;P2&#34;, &#34;P3&#34;,
                                            &#34;P4&#34;, &#34;P5&#34;, &#34;P6&#34;,
                                            &#34;P7&#34;, &#34;P8&#34;]].iloc[i]) # P for free logK grid
                
                
                for ii,T in enumerate(grid_temps):
                    
                    logK, model = self._interpolate_logK(T, logK_grid, T_grid, logK_extrapolate)
                    
                    dissrxn_logK.loc[(dissrxn_logK.name == sp), &#34;logK_&#34;+str(ii)] = logK
                
                
                self.logK_models[sp] = {&#34;logK_grid&#34;:logK_grid,
                                        &#34;T_grid&#34;:T_grid,
                                        &#34;P_grid&#34;:P_grid,
                                        &#34;logK_extrapolate&#34;:logK_extrapolate,
                                        &#34;type&#34;:&#34;free logK values&#34;,
                                        }
        
                # check that there aren&#39;t duplicates between OBIGT-style datasheet and
                # the &#39;free logK&#39; datasheet
                if sp in dissrxn_logK[&#34;name&#34;]:
                    sp_errs.append(sp)
                    
            if len(sp_dupes) &gt; 0:
                msg = (&#34;The following species are duplicated between the &#34;
                       &#34;thermodynamic datafiles used: &#34; + &#34;,&#34;.join(sp_errs))
                self.err_handler.raise_exception(msg)
        
        # calculate and process logK values of species in the OBIGT-style datasheet
        for idx in range(0, dissrxn_logK.shape[0]):

            name = dissrxn_logK.iloc[idx, dissrxn_logK.columns.get_loc(&#39;name&#39;)]

            # format the logK reaction block of this species&#39; data0 entry
            logK_grid = list(dissrxn_logK.iloc[idx, 1:9])
            
            if not dynamic_db:
                if name not in self.logK_models.keys() and name not in free_logK_names:
                    self.logK_models[name] = {&#34;logK_grid&#34;:logK_grid,
                                  &#34;T_grid&#34;:grid_temps,
                                  &#34;P_grid&#34;:grid_press,
                                  &#34;logK_extrapolate&#34;:logK_extrapolate,
                                  &#34;type&#34;:&#34;calculated logK values&#34;,
                                  }
            elif dynamic_db:
                if name not in self.logK_models.keys() and name not in free_logK_names:
                    self.logK_models[name] = {&#34;logK_grid&#34;:[logK_grid[0]],
                                              &#34;T_grid&#34;:[grid_temps[0]],
                                              &#34;P_grid&#34;:[grid_press[0]],
                                              &#34;logK_extrapolate&#34;:&#34;no fit&#34;,
                                              &#34;type&#34;:&#34;calculated logK values&#34;,
                                              }
                    
                elif name not in free_logK_names:
                    self.logK_models[name][&#34;logK_grid&#34;] += [logK_grid[0]]
                    self.logK_models[name][&#34;T_grid&#34;] += [grid_temps[0]]
                    self.logK_models[name][&#34;P_grid&#34;] += [grid_press[0]]

            # filter out strict basis species
            # TODO: do this by species tag, not just whether it has a logK grid of all 0s
            if len(set(logK_grid)) == 1:
                if set(logK_grid) == set([0]):
                    continue

            # loop through logK values and format for data0
            logK_list = []
            for i in range(0, len(logK_grid)):
                logK_val = self.__s_d(logK_grid[i], 4)
                
                # conditional formatting based on position
                if (i+1) == 1 or (i+1) % 5 == 0: # first entry of a line
                    max_length = 11
                    end_char = &#34;&#34;
                elif (i+1) % 4 == 0 and (i+1) != len(logK_grid): # last entry of a line
                    max_length = 6
                    end_char = &#34;\n&#34;
                else:
                    max_length = 6
                    end_char = &#34;&#34;

                # get decimal position and format spaces accordingly
                decimal_position = logK_val.find(&#34;.&#34;)
                logK_val = &#34;&#34;.join([&#34; &#34;]*(max_length-decimal_position)) + logK_val + end_char
                # append to logk list
                logK_list.append(logK_val)

            logK_list = &#34;&#34;.join(logK_list)
            
            # todo: make this more robust to catch any potential logK_grid skips
            if &#34;logK_grid_&#34;+name in data0_file_lines:
                data0_file_lines[data0_file_lines.index(&#34;logK_grid_&#34;+name)] = logK_list

        # handle data0 header section
        self._capture_r_output()
        
        r_fill_data0_header = pkg_resources.resource_string(
            __name__, &#39;fill_data0_header.r&#39;).decode(&#34;utf-8&#34;)
        
        ro.r(r_fill_data0_header)
        
        data0_file_lines = ro.r.fill_data0_head(data0_template=data0_file_lines,
                                       db=db,
                                       grid_temps=_convert_to_RVector(grid_temps),
                                       grid_press=_convert_to_RVector(grid_press),
                                       water_model=water_model,
                                       activity_model=activity_model)
        
        self._print_captured_r_output()
        
        with open(&#34;data0.&#34;+db, &#39;w&#39;) as f:
            for item in data0_file_lines:
                f.write(&#34;%s&#34; % item)

                
    def plot_logK_fit(self, name, plot_out=False, res=200, internal=True, logK_extrapolate=None, T_vals=[]):
        &#34;&#34;&#34;
        Plot the fit of logK values used in the speciation.

        Parameters
        ----------
        name : str
            Name of the chemical species.
        
        plot_out : bool, default False
            Return a Plotly figure object? If False, a figure is simply shown.
            If True, the function returns a Plotly figure object and does
            not show the plot.
        
        res : int
            Resolution of the fit line. Higher resolutions will be smoother.
            
        internal : bool, default True
            Reuse calculated fits if they already exist?
        
        logK_extrapolate : str, optional
            Option for extrapolating logK values in the plot. Possible values
            for this parameter include &#39;poly&#39;, &#39;linear&#39;, &#39;flat&#39;, or &#39;none&#39;.
            This is for planning and visualization only and does not affect
            results in `speciate()` or `create_data0()`. Those functions have
            their own parameters for setting logK extrapolation options.
        
        T_vals : list, optional
            Option for visualizing how the fit of logK values will be
            used to estimate the logK values at the temperatures specified in
            the list given to this parameter. This is useful for visualizing
            logK extrapolation options defined by `logK_extrapolate`.
        
        Returns
        ----------
        fig : a Plotly figure object
            Returned if `plot_out` is True.

        &#34;&#34;&#34;
        
        if internal and len(self.logK_models.keys()) &gt; 0:
            # use internally calculated logK models already stored...
            if name not in self.logK_models.keys():
                if name not in list(self.thermo.df_rejected_species[&#34;name&#34;]):
                    msg = &#34;The chemical species &#34; + str(name) + &#34; is not recognized.&#34;
                    self.err_handler.raise_exception(msg)
                else:
                    reject_reason = list(self.thermo.df_rejected_species.loc[self.thermo.df_rejected_species[&#39;name&#39;] == name, &#39;reason for rejection&#39;])[0]
                    
                    msg = (&#34;The chemical species &#34; + str(name) + &#34; cannot be &#34;
                           &#34;plotted because it was rejected from the &#34;
                           &#34;speciation:\n&#34; + str(reject_reason))
                    self.err_handler.raise_exception(msg)

            logK_grid = self.logK_models[name][&#34;logK_grid&#34;]
            T_grid = self.logK_models[name][&#34;T_grid&#34;]
            P_grid = self.logK_models[name][&#34;P_grid&#34;]
        
        else:
            # load logK models from Thermodata class&#39;s logK_db
            df_logK = self.thermo.logK_db
            
            i = list(df_logK[&#34;name&#34;]).index(name)
            
            logK_grid = list(df_logK[[&#34;logK1&#34;, &#34;logK2&#34;, &#34;logK3&#34;,
                                      &#34;logK4&#34;, &#34;logK5&#34;, &#34;logK6&#34;,
                                      &#34;logK7&#34;, &#34;logK8&#34;]].iloc[i]) # logK at T and P in datasheet

            T_grid = list(df_logK[[&#34;T1&#34;, &#34;T2&#34;, &#34;T3&#34;,
                                   &#34;T4&#34;, &#34;T5&#34;, &#34;T6&#34;,
                                   &#34;T7&#34;, &#34;T8&#34;]].iloc[i]) # T for free logK grid

            P_grid = list(df_logK[[&#34;P1&#34;, &#34;P2&#34;, &#34;P3&#34;,
                                   &#34;P4&#34;, &#34;P5&#34;, &#34;P6&#34;,
                                   &#34;P7&#34;, &#34;P8&#34;]].iloc[i]) # P for free logK grid
            
            if not isinstance(logK_extrapolate, str):
                logK_extrapolate = self.thermo.logK_extrapolate
            
        
        if not isinstance(logK_extrapolate, str):
            logK_extrapolate = self.logK_models[name][&#34;logK_extrapolate&#34;]
        
        if len(T_vals) == 0:
            grid_temps = self.batch_T
        else:
            grid_temps = T_vals
        
        grid_press = self.batch_P
        
        T_grid = [t for t in T_grid if not pd.isna(t)]
        P_grid = [p for p in P_grid if not pd.isna(p)]
        logK_grid = [k for k in logK_grid if not pd.isna(k)]
        
        fig = px.scatter(x=T_grid, y=logK_grid)
        
        if len(grid_temps) &gt; 0:
            if min(grid_temps) &lt;= min(T_grid):
                plot_T_min = min(grid_temps)
            else:
                plot_T_min = min(T_grid)
            if max(grid_temps) &gt;= max(T_grid):
                plot_T_max = max(grid_temps)
            else:
                plot_T_max = max(T_grid)
        else:
            plot_T_min = min(T_grid)
            plot_T_max = max(T_grid)
        
        plot_temps = np.linspace(plot_T_min, plot_T_max, res)

        pred_logK = []
        pred_model = []
        for t in plot_temps:
            logK, model = self._interpolate_logK(t, logK_grid, T_grid, logK_extrapolate)
            pred_logK.append(logK)
            pred_model.append(model)
        
        df_plot = pd.DataFrame({&#34;T&#34;:plot_temps, &#34;logK&#34;:pred_logK, &#34;model&#34;:pred_model})
        
        if logK_extrapolate != &#34;no fit&#34;:
            fig = px.line(df_plot, x=&#39;T&#39;, y=&#39;logK&#39;, color=&#39;model&#39;, title=name, template=&#34;simple_white&#34;)
        else:
            fig = px.line(x=[0], y=[0], title=name, template=&#34;simple_white&#34;) # dummy figure
            
        fig.update_traces(hovertemplate=&#34;T = %{x} C&lt;br&gt;Predicted logK = %{y}&lt;extra&gt;&lt;/extra&gt;&#34;)
        fig.update_layout(xaxis_range=[min(plot_temps) - 0.15*(max(plot_temps) - min(plot_temps)),
                                       max(plot_temps) + 0.15*(max(plot_temps) - min(plot_temps))],
                          xaxis_title=&#34;T,C&#34;, yaxis_title=&#34;logK&#34;)
        
        logK_label = &#34;fitted logK value(s)&#34;
        annotation = &#34;&#34;
        
        if len(grid_temps) &gt; 0:
            for i,gt in enumerate(grid_temps):
                # make vertical lines representing batch temperatures

                if i==0:
                    showlegend=True
                else:
                    showlegend=False

                if isinstance(grid_press, str):
                    ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;br&gt;P = PSAT&lt;extra&gt;&lt;/extra&gt;&#34;
                else:
                    if len(grid_press) &gt; 0:
                        ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;br&gt;P = &#34; + str(grid_press[i]) + &#34; bar(s)&lt;extra&gt;&lt;/extra&gt;&#34;
                    else:
                        ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;extra&gt;&lt;/extra&gt;&#34;
                        
                if len(T_grid) &gt; 1:
                    
                    if logK_extrapolate == &#34;none&#34; and (gt &gt; max(T_grid) or gt &lt; min(T_grid)):
                        viz_logK = max(logK_grid)
                    else:
                        viz_logK, _ = self._interpolate_logK(gt, logK_grid, T_grid, logK_extrapolate)
                    
                    vline_y_vals = [min(logK_grid)-0.15*(max(logK_grid)-min(logK_grid)), viz_logK]
                    
                    
                if logK_extrapolate == &#34;no fit&#34;:
                    vline_y_vals = [min(logK_grid)-0.15*(max(logK_grid)-min(logK_grid)), logK_grid[i]]
                    logK_label = &#34;calculated LogK value(s)&#34;
                    annotation = (&#34;LogK values are calculated from&lt;br&gt;G of dissociation into basis species&#34;
                                  &#34;&lt;br&gt;at the T and P of the speciated samples&lt;br&gt;and do not require a fit.&#34;)

                if _all_equal(logK_grid):
                    # if a flat horizontal logK fit line...
                    # then fix the y-axis range to prevent zoomed-in steppy wierdness
                    fig.update_layout(yaxis_range=[logK_grid[0]-1,logK_grid[0]+1])
                    vline_y_vals = [logK_grid[0]-1, logK_grid[0]]

                fig.add_trace(
                    go.Scatter(x=[gt, gt],
                               y=vline_y_vals,
                               mode=&#34;lines&#34;,
                               line=dict(color=&#39;rgba(255, 0, 0, 0.75)&#39;, width=3, dash=&#34;dot&#34;),
                               legendgroup=&#39;batch temperatures&#39;,
                               name=&#39;batch temperatures&#39;,
                               showlegend=showlegend,
                               hovertemplate=ht_samples,
                              ),
                )
        
        # add fitted logK points
        fig.add_trace(go.Scatter(x=T_grid, y=logK_grid, name=logK_label,
                                 mode=&#39;markers&#39;, marker=dict(color=&#34;black&#34;),
                                 text = P_grid,
                                 hovertemplate=&#34;T = %{x} C&lt;br&gt;P = %{text} bar(s)&lt;br&gt;logK = %{y}&lt;extra&gt;&lt;/extra&gt;&#34;,
                                 ),
                      )
        
        fig.add_annotation(x=0, y=0, xref=&#34;paper&#34;, yref=&#34;paper&#34;, align=&#39;left&#39;,
                           text=annotation, bgcolor=&#34;rgba(255, 255, 255, 0.5)&#34;,
                           showarrow=False)
        
        if plot_out:
            return fig
        else:
            fig.show()

        
    def __get_i_of_valid_free_logK_sp(self, free_logK_df, grid_temps,
                                      grid_press, dynamic_db,
                                      logK_extrapolate, db_sp_names):
            &#34;&#34;&#34;
            Check for species in the free logK database with pressure values that
            are permitted in the context of grid_temps and grid_press, then
            return their indices.
            &#34;&#34;&#34;
            
            if not isinstance(grid_press, list):
                # &#34;Psat&#34; to [&#34;psat&#34;]
                grid_press_list = [grid_press.lower()]
            else:
                grid_press_list = grid_press

            valid_sp_i = []
            rejected_sp_i_dict = {}
            
            for i,sp in enumerate(list(free_logK_df[&#34;name&#34;])):
                
                sp_temps_grid = [free_logK_df.iloc[i][&#34;T&#34;+str(ii)] for ii in range(1,9) if not math.isnan(free_logK_df.iloc[i][&#34;T&#34;+str(ii)])]
                sp_press_grid_init = [float(free_logK_df.iloc[i][&#34;P&#34;+str(ii)]) if free_logK_df.iloc[i][&#34;P&#34;+str(ii)] not in [&#34;Psat&#34;, &#34;psat&#34;] else &#39;psat&#39; for ii in range(1,9)]

                sp_grid_len = len(sp_temps_grid)
                
                sp_press_grid = []
                for p in sp_press_grid_init:
                    if isinstance(p, str):
                        sp_press_grid.append(p)
                    elif not math.isnan(p):
                        sp_press_grid.append(p)

                if sp_press_grid == grid_press_list and sp_temps_grid == grid_temps:
                    # If pressures and temperature grid exactly matches that of the sp...
                    # need to test this!
                    valid_sp_i.append(i)
                elif (logK_extrapolate != &#34;none&#34; or (min(grid_temps) &gt;= min(sp_temps_grid) and max(grid_temps) &lt;= max(sp_temps_grid))) and _all_equal(sp_press_grid + grid_press_list):
                    # If all grid temperatures are within minimum and maximum file temperatures,
                    # and all pressures in file for the sp are equal, and all grid pressures match
                    # file pressure, then the species is valid
                    valid_sp_i.append(i)
                
                else:
                    # species is invalid. Define reasons.
                    
                    reject_reason_list = []
                    

                    
                    if min(grid_temps) &lt; min(sp_temps_grid) and _all_equal(sp_press_grid + grid_press_list) and logK_extrapolate == &#34;none&#34;:
                        print(sp)
                        print(logK_extrapolate)
                        
                        min_sp = str(min(sp_temps_grid))
                        min_grid = str(min(grid_temps))
                        if dynamic_db:
                            reject_reason_list.append(&#34;Minimum temperature in this batch of samples is &#34;+min_grid+&#34;C, which is below the minimum applicability temperature of this species is &#34;+min_sp+&#34;C.&#34;)
                        else:
                            reject_reason_list.append(&#34;Minimum temperature in this data0 file is &#34;+min_grid+&#34;C, which is below the minimum applicability temperature of this species is &#34;+min_sp+&#34;C.&#34;)
                    
                    if max(grid_temps) &gt; max(sp_temps_grid) and _all_equal(sp_press_grid + grid_press_list) and logK_extrapolate == &#34;none&#34;:
                        max_sp = str(max(sp_temps_grid))
                        max_grid = str(max(grid_temps))
                        if dynamic_db:
                            reject_reason_list.append(&#34;Maximum temperature in this batch of samples is &#34;+max_grid+&#34;C, which is above the maximum applicability temperature of this species is &#34;+max_sp+&#34;C.&#34;)
                        else:
                            reject_reason_list.append(&#34;Maximum temperature in this data0 file is &#34;+max_grid+&#34;C, which is above the maximum applicability temperature of this species is &#34;+max_sp+&#34;C.&#34;)
                    
                    if not _all_equal(sp_press_grid + grid_press_list):
                        if dynamic_db:
                            reject_reason_list.append(&#34;Mismatch between pressures of samples in this batch and the applicable pressures for &#34;+str(sp)+&#34; given in the logK thermodynamic database.&#34;)
                        else:
                            reject_reason_list.append(&#34;Mismatch between desired pressure grid of data0 file and the applicable pressures for &#34;+str(sp)+&#34; given in the logK thermodynamic database.&#34;)
                    
                    if len(reject_reason_list) == 0:
                        reject_reason_list.append(&#34;Unknown&#34;)
                    
                    rejected_sp_i_dict[i] = &#34;\n&#34;.join(reject_reason_list)

            # loop through valid species and reject them if their dissociation reactions
            # contain species that have been rejected.
            
            valid_sp_i = list(dict.fromkeys(valid_sp_i))
            while True:
                valid_sp_i_before = copy.deepcopy(valid_sp_i)
                valid_sp_i, rejected_sp_i_dict = self._check_valid_free_logK_sp_dissrxn(valid_sp_i, rejected_sp_i_dict, free_logK_df, db_sp_names)
                if valid_sp_i_before == valid_sp_i:
                    break
            
            reject_indices = list(rejected_sp_i_dict.keys())
            reject_names = list(free_logK_df.iloc[reject_indices][&#34;name&#34;])
            reject_reasons =list(rejected_sp_i_dict.values())
            
            self.thermo.df_rejected_species = pd.concat([self.thermo.df_rejected_species, pd.DataFrame({&#39;database name&#39;:[self.thermo.logK_db_filename]*len(reject_indices), &#39;database index&#39;:reject_indices, &#34;name&#34;:reject_names, &#34;reason for rejection&#34;:reject_reasons})], ignore_index=True)
                        
            return valid_sp_i
            
            
    def _check_valid_free_logK_sp_dissrxn(self, valid_sp_i, rejected_sp_i_dict, free_logK_df, db_sp_names):
        
        valid_sp_names = list(free_logK_df.iloc[valid_sp_i][&#34;name&#34;])
        
        rejected_sp_names = list(free_logK_df.iloc[list(rejected_sp_i_dict.keys())][&#34;name&#34;])

        for i in valid_sp_i:
            dissrxn_i = free_logK_df.iloc[i][&#34;dissrxn&#34;]
            dissrxn_sp = dissrxn_i.split(&#34; &#34;)[1::2] # get species names from dissrxn
            dissrxn_sp = dissrxn_sp[1:] # ignore the species itself
            
            for sp in dissrxn_sp:
                if sp in rejected_sp_names and sp not in valid_sp_names and sp not in db_sp_names:
                    valid_sp_i.remove(i)
                    rejected_sp_i_dict[i] = &#34;Dissociation reaction contains the species &#34; + sp + &#34;, which has been rejected.&#34;
                    return valid_sp_i, rejected_sp_i_dict
                    
        return valid_sp_i, rejected_sp_i_dict
            
        
    def create_data0(self,
                     db,
                     filename_ss=None,
                     activity_model=&#34;b-dot&#34;,
                     exceed_Ttr=True,
                     grid_temps=[0.0100, 50.0000, 100.0000, 150.0000,
                                 200.0000, 250.0000, 300.0000, 350.0000],
                     grid_press=&#34;Psat&#34;,
                     P1=True,
                     plot_poly_fit=False,
                     logK_extrapolate=&#34;none&#34;,
                     fill_data0=True,
                     dynamic_db=False,
                     dynamic_db_sample_temps=[],
                     dynamic_db_sample_press=[],
                     verbose=1):
        &#34;&#34;&#34;
        Create a data0 file from a custom thermodynamic dataset.
        
        Parameters
        ----------
        db : str
            Desired three letter code of data0 output.
            
        filename_ss : str, optional
            Name of file containing solid solution parameters.

        grid_temps : list of eight float, default [0.0100, 50.0000, 100.0000, 150.0000, 200.0000, 250.0000, 300.0000, 350.0000]
            Eight temperature values that make up the T-P grid.
        
        grid_press : list of float, default &#34;Psat&#34;
            Eight pressure values that make up the T-P grid. &#34;Psat&#34; for
            calculations along the liquid-vapor saturation curve.
        
        P1 : bool, default True,
            Use pressure of 1 bar below 100 degrees C instead of calculated
            values of Psat? Ignored if `grid_press` is not &#34;Psat&#34;.
        
        plot_poly_fit : bool, default False
            Plot the polynomial fit of the temperature pressure grid?
        
        dynamic_db : bool, default False
            Are data0 files being created dynamically? If unsure, use False.
            Used by `speciate` to display valid messages.
        
        verbose : int, 0, 1, or 2, default 1
            Level determining how many messages are returned during a
            calculation. 2 for all messages, 1 for errors or warnings only,
            0 for silent.
        &#34;&#34;&#34;
        
        thermo_df = self.thermo.thermo_db
        db_logK = self.thermo.logK_db
        water_model = self.thermo.water_model
        
        self.verbose = verbose
        
        self.batch_T = grid_temps
        self.batch_P = grid_press
        
        if not dynamic_db:
            if self.verbose &gt;= 1:
                print(&#34;Creating data0.{}...&#34;.format(db), flush=True)
        
        if len(grid_temps) not in [1, 8]:
            self.err_handler.raise_exception(&#34;&#39;grid_temps&#39; must have either one or eight values.&#34;)
        if isinstance(grid_press, list):
            if len(grid_press) not in [1, 8]:
                self.err_handler.raise_exception(&#34;&#39;grid_press&#39; must have either one or eight values.&#34;)
        
        if sum([T &gt;= 10000 for T in grid_temps]):
            self.err_handler.raise_exception(&#34;Grid temperatures must be below 10k C.&#34;)
        
        if isinstance(grid_press, list):
            if sum([P &gt;= 10000 for P in grid_press]) and water_model != &#34;DEW&#34;:
                self.err_handler.raise_exception(&#34;Grid pressures must be below 10 kilobars.&#34;)
                
        if water_model == &#34;SUPCRT92&#34;:
            min_T = 0
            max_T = 2250
            min_P = 0
            max_P = 30000
        elif water_model == &#34;IAPWS95&#34;:
            min_T = 0
            max_T = 1000
            min_P = 0
            max_P = 10000
        elif water_model == &#34;DEW&#34;:
            min_T = 0
            max_T = 1000
            min_P = 1000
            max_P = 60000
        else:
            self.err_handler.raise_exception(&#34;The water model &#39;{}&#39; &#34;.format(water_model)+&#34;is not &#34;
                &#34;recognized. Try &#39;SUPCRT92&#39;, &#39;IAPWS95&#39;, or &#39;DEW&#39;.&#34;)
        
        # check that T and P are above minimum values
        if sum([T &lt;= min_T for T in grid_temps]):
            print(&#34;WARNING: one or more temperatures in &#39;grid_temps&#39; is below &#34;
                  &#34;or equal to {} C&#34;.format(min_T)+&#34; and is outside the valid &#34;
                  &#34;temperature range for the {} water model.&#34;.format(water_model))
        if isinstance(grid_press, list):
            if sum([P &lt; min_P for P in grid_press]):
                print(&#34;WARNING: one or more pressures in &#39;grid_press&#39; is below &#34;
                      &#34;{} bar&#34;.format(min_P)+&#34;, the minimum valid &#34;
                      &#34;pressure for the {} water model.&#34;.format(water_model))
        
        # check that T and P are below maximum values
        if sum([T &gt; max_T for T in grid_temps]):
            print(&#34;WARNING: one or more temperatures in &#39;grid_temps&#39; is above &#34;
                  &#34;{} C&#34;.format(max_T)+&#34;, the maximum valid &#34;
                  &#34;temperature for the {} water model.&#34;.format(water_model))
        if isinstance(grid_press, list):
            if sum([P &gt; max_P for P in grid_press]):
                print(&#34;WARNING: one or more pressures in &#39;grid_press&#39; is above &#34;
                      &#34;{} bar&#34;.format(max_P)+&#34;, the maximum valid &#34;
                      &#34;pressure for the {} water model.&#34;.format(water_model))
            
        if water_model != &#34;SUPCRT92&#34;:
            print(&#34;WARNING: water models other than SUPCRT92 are not yet fully supported.&#34;)
        
        # reset logK_models whenever create_data0() is called
        # (prevents errors when create_data0() functions are run back-to-back)
        self.logK_models = {}
        
        # interpolate logK values from &#34;free logK&#34; datasheet at T and P
        if isinstance(db_logK, pd.DataFrame):

            if len(dynamic_db_sample_temps) &gt; 0:
                grid_or_sample_temps = dynamic_db_sample_temps
            else:
                grid_or_sample_temps = grid_temps
                
            if len(dynamic_db_sample_press) &gt; 0:
                grid_or_sample_press = dynamic_db_sample_press
            else:
                grid_or_sample_press = grid_press
            
            free_logK_df = _clean_rpy2_pandas_conversion(self.thermo.logK_db)

            valid_i = self.__get_i_of_valid_free_logK_sp(
                free_logK_df,
                grid_or_sample_temps,
                grid_or_sample_press,
                dynamic_db,
                logK_extrapolate,
                db_sp_names=thermo_df[&#34;name&#34;],
                )
            free_logK_df_valid = copy.deepcopy(free_logK_df.iloc[valid_i])
            thermo_df = pd.concat([thermo_df, free_logK_df_valid], ignore_index=True)
            
            thermo_df = _clean_rpy2_pandas_conversion(thermo_df)
        
        if self.thermo.solid_solutions_active:
            solid_solution_df = ro.conversion.py2rpy(self.thermo.solid_solution_db)
        else:
            solid_solution_df = ro.r(&#34;NULL&#34;)
        
        template = pkg_resources.resource_string(
            __name__, &#39;data0.min&#39;).decode(&#34;utf-8&#34;)
        
        out_list = self.thermo.out_list
    
        self._capture_r_output()
    
        r_create_data0 = pkg_resources.resource_string(
            __name__, &#39;create_data0.r&#39;).decode(&#34;utf-8&#34;)
        
        ro.r(r_create_data0)
        
        # assemble data0 file
        data0_file_lines = ro.r.create_data0(thermo_df=ro.conversion.py2rpy(thermo_df),
                          solid_solution_df=solid_solution_df,
                          db=db,
                          water_model=water_model,
                          template=template,
                          dissrxns=out_list.rx2(&#34;dissrxns&#34;),
                          basis_pref=out_list.rx2(&#34;basis_pref&#34;),
                          exceed_Ttr=exceed_Ttr,
                          fixed_species=_convert_to_RVector(FIXED_SPECIES),
                          verbose=self.verbose)
        
        self._print_captured_r_output()
        
        data0_file_lines = data0_file_lines[0].split(&#34;\n&#34;)
        
        if fill_data0:
            
            # begin TP-dependent processes
            self.__fill_data0(thermo_df=ro.conversion.rpy2py(thermo_df),
                              data0_file_lines=copy.deepcopy(data0_file_lines),
                              grid_temps=grid_temps,
                              grid_press=grid_press,
                              db=db,
                              water_model=water_model,
                              activity_model=activity_model,
                              P1=P1,
                              plot_poly_fit=plot_poly_fit,
                              logK_extrapolate=logK_extrapolate,
                              dynamic_db=dynamic_db,
                              verbose=self.verbose)
    
        else:
            return thermo_df, data0_file_lines, grid_temps, grid_press, db, water_model, P1, plot_poly_fit

        if self.verbose &gt; 0:
            print(&#34;Finished creating data0.{}.&#34;.format(db))
            

    def make_redox_reactions(self, db=None, redox_pairs=&#34;all&#34;, auto_load_db=True):
        
        &#34;&#34;&#34;
        Generate an organized collection of redox reactions for calculating
        chemical affinity and energy supply values during speciation.
        
        Parameters
        ----------
        db : str
            Determines which thermodynamic database is used in the speciation
            calculation. The database must be a CSV file (not a data0file)
            because the code must look up properties of chemical species to
            calculate affinities and energy supplies of reactions.
            The `db` parameter can either be:
            - The name of a CSV file containing thermodynamic data located in
            the current working directory, e.g., &#34;wrm_data.csv&#34;. The CSV file
            will be used to generate a data0 file for each sample (using
            additional arguments from `db_args` if desired).
            - The URL of a CSV file containing thermodynamic data, e.g.,
            &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
        
        redox_pairs : list of int or &#34;all&#34;, default &#34;all&#34;
            List of indices of half reactions in the half cell reaction table
            to be combined when generating full redox reactions.
            E.g. [0, 1, 4] will combine half reactions with indices 0, 1, and 4
            in the table stored in the `half_cell_reactions` attribute of the
            `AqEquil` class.
            If &#34;all&#34;, generate all possible redox reactions from available half
            cell reactions.
        
        auto_load_db : bool, default True
            Automatically download and use a WORM-styled CSV if the currently
            active thermodynamic database does not support affinity and energy
            supply calculations? If True, the most up-to-date copy of the
            wrm_data.csv will be downloaded from the URL
            https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv
            and set as the active thermodynamic database.
        
        Returns
        ----------
        Output is stored in the `affinity_energy_reactions_raw` and
        `affinity_energy_reactions_table` attributes of the `AqEquil` class.
        &#34;&#34;&#34;
        
        if db != None:
            self.thermo._set_active_db(db)
            
        if self.thermo.thermo_db_type != &#34;CSV&#34;:
            if self.verbose &gt; 0:
                if auto_load_db:
                    print(&#34;Warning: Redox reactions require a WORM-styled thermodynamic database CSV file.&#34;)
                else:
                    self.err_handler.raise_exception(&#34;Error: Redox reactions require a WORM-styled CSV file as the active thermodynamic database.&#34;)
            
            if auto_load_db:
                if self.verbose &gt; 0:
                    print(&#34;Warning: switching thermodynamic database from&#34;, str(self.thermo.thermo_db_filename), &#34;to wrm_data.csv...&#34;)
                self.thermo._set_active_db(db=&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;)
            
        db = self.thermo.db
        
        # reset all redox variables stored in the AqEquil class
        self.affinity_energy_reactions_raw = None
        self.affinity_energy_reactions_table = None
        self.affinity_energy_formatted_reactions = None
        
        if self.verbose &gt; 1:
            print(&#34;Generating redox reactions...&#34;)

        err_msg = (&#34;redox_pairs can either be &#39;all&#39; or a list of integers &#34;
               &#34;indicating the indices of half cell reactions in &#34;
               &#34;the half_cell_reactions table that should be combined into &#34;
               &#34;full redox reactions. For example, redox_pairs=[0, 1, 2, 6] &#34;
               &#34;will combine half cell reactions with indices 0, 1, 2, and 6 in &#34;
               &#34;the half_cell_reactions table. This table is an attribute in the &#34;
               &#34;class AqEquil.&#34;)
        if isinstance(redox_pairs, str):
            if redox_pairs == &#34;all&#34;:
                redox_pairs = list(range(0, self.half_cell_reactions.shape[0]))
            else:
                self.err_handler.raise_exception(err_msg)
        elif isinstance(redox_pairs, list):
            if not all([isinstance(i, int) for i in redox_pairs]):
                self.err_handler.raise_exception(err_msg)
        else:
            self.err_handler.raise_exception(err_msg)
        
        self.redox_pairs = redox_pairs
        
        df = self.half_cell_reactions.iloc[redox_pairs].reset_index(drop=True)
        
        wrm_data = self.thermo.thermo_db
        basis_df = wrm_data.loc[wrm_data[&#39;tag&#39;] == &#39;basis&#39;]
        
        db_names = []
        formulas = []
        for column in list(df.columns)[1:]:
            for item in list(df[column]):
                if item != &#39;nan&#39;:
                    if item in list(wrm_data.name) and isinstance(item, str):
                        index = wrm_data.loc[wrm_data[&#39;name&#39;] == item].index[0]
                        formula = wrm_data.loc[wrm_data[&#39;name&#39;] == item][&#39;formula&#39;][index]
                        df.replace(item, formula, inplace=True)
                        if item not in db_names:
                            db_names.append(item)
                            formulas.append(formula)
                    elif item in list(wrm_data.abbrv) and isinstance(item, str):
                        index = wrm_data.loc[wrm_data[&#39;abbrv&#39;] == item].index[0]
                        formula = wrm_data.loc[wrm_data[&#39;abbrv&#39;] == item][&#39;formula&#39;][index]
                        df.replace(item, formula, inplace=True)
                        if item not in db_names:
                            db_names.append(item)
                            formulas.append(formula)
                            
        df.replace(&#39;sulfur&#39;, &#39;S&#39;, inplace = True) ### remove this eventually
        db_names.append(&#39;sulfur&#39;) ### remove this eventually
        formulas.append(&#39;S&#39;) ### remove this eventually

        # append H+ and H2O to db for balancing
        if not &#39;H+&#39; in db_names:
            db_names.append(&#39;H+&#39;)
            formulas.append(&#39;H+&#39;)
        if not &#39;H2O&#39; in db_names:
            db_names.append(&#39;H2O&#39;)
            formulas.append(&#39;H2O&#39;)
        
        Oxidant_1 = df[&#39;Oxidant_1&#39;]
        Oxidant_2 = df[&#39;Oxidant_2&#39;]
        Oxidant_3 = df[&#39;Oxidant_3&#39;]
        Reductant_1 = df[&#39;Reductant_1&#39;]
        Reductant_2 = df[&#39;Reductant_2&#39;]
        
        #CREATING A LIST OF ALL SPECIES AND THEIR ELEMENT DICTIONARIES
        elements = [str(e) for e in list(periodictable.elements)[1:]]+[&#39;+&#39;,&#39;-&#39;]
        element_dictionary = dict()
        for i in formulas:
                parsed_formula = parse_formula(i)
                element_dictionary[i] = parsed_formula
                for e in elements:
                    if element_dictionary[i].get(e, 0) == 0:
                        element_dictionary[i][e] = 0
                        
        df_reax = pd.DataFrame() # empty df of reactions
        df_reax[&#39;rO_coeff&#39;] = &#39;&#39;
        df_reax[&#39;rO&#39;] = &#39;&#39;
        df_reax[&#39;rR_coeff&#39;] = &#39;&#39;
        df_reax[&#39;rR&#39;] = &#39;&#39;
        df_reax[&#39;pO_coeff&#39;] = &#39;&#39;
        df_reax[&#39;pO&#39;] = &#39;&#39;
        df_reax[&#39;pR_coeff&#39;] = &#39;&#39;
        df_reax[&#39;pR&#39;] = &#39;&#39;
        df_reax[&#39;Reaction&#39;] = &#39;&#39;
        df_reax[&#39;redox_pair&#39;] = &#39;&#39;
        index = 0

        reaction = [] 
        indices = np.arange(0, len(Oxidant_1), 1).tolist()*2 # how to loop back through the redox pairs to not run into out-of-range index
        rxn_num = 0 # counting unique reactions
        rxn_list = [] # list of unique reactions
        rxn_names = []
        rxn_pairs = [] # list of paired half reactions

        for i in range(0, len(Oxidant_1),1): # length of redox pairs - columns
            for n in range(0, len(Oxidant_1), 1):
                if Reductant_1[i] == Reductant_1[indices[i+n]] or Reductant_1[i] == Reductant_2[indices[i+n]]: # if both reductants are the same thing, skip
                    continue
                if Oxidant_1[i] == Oxidant_1[indices[i+n]] or Oxidant_1[i] == Oxidant_2[indices[i+n]] or Oxidant_1[i] == Oxidant_3[indices[i+n]]:
                    continue
#                 if Oxidant_1[i] == &#39;H2O&#39; and Reductant_1[indices[i+n]] == &#39;H2O&#39;: #suppress the splitting of water
#                     continue
                else:

                    # GENERATING REACTIONS BETWEEN OXIDANT_1 AND REDUCTANT_1
                    reaction.append(Oxidant_1[i]+&#39; \t &#39; + Reductant_1[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_num+=1
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_1[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_1[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index+=1

                # REACTIONS INVOLVING OTHER PH-DEPENDENT SPECIES
                if pd.isnull(Oxidant_2[i]) != True and Oxidant_2[i] != Reductant_2[indices[i+n]]:
                    reaction.append(Oxidant_2[i] + &#39; \t &#39; + Reductant_1[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_2[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_1[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                    if pd.isnull(Reductant_2[indices[i+n]]) != True:
                        reaction.append(Oxidant_2[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                        rxn_list.append(rxn_num)
                        rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                        df_reax.loc[index, &#39;rO&#39;] = Oxidant_2[i]
                        df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                        df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                        df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                        rxn_pairs.append([i, indices[i+n]])
                        index +=1
                        
                if pd.isnull(Oxidant_2[i]) != True and Oxidant_2[i] == Reductant_2[indices[i+n]]:
                    reaction.append(Oxidant_2[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_2[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                if pd.isnull(Reductant_2[indices[i+n]]) != True and Oxidant_2[i] != Reductant_2[indices[i+n]]:
                    reaction.append(Oxidant_1[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_1[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                if pd.isnull(Oxidant_3[i]) != True:
                    reaction.append(Oxidant_3[i] + &#39; \t &#39; + Reductant_1[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_3[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_1[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                    if pd.isnull(Reductant_2[indices[i+n]]) != True:
                        reaction.append(Oxidant_3[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                        rxn_list.append(rxn_num)
                        rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                        df_reax.loc[index, &#39;rO&#39;] = Oxidant_3[i]
                        df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                        df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                        df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                        rxn_pairs.append([i, indices[i+n]])
                        index +=1
        
        df_reax[&#39;Reaction&#39;] = rxn_list
        df_reax[&#39;Names&#39;] = rxn_names
        df_reax[&#39;Temp_Pairs&#39;] = rxn_pairs
        
        # if there are no reactions, return nothing
        if df_reax.shape[0] == 0:
            incompatible_half_reactions = pd.Series(self.half_cell_reactions[&#34;Redox Couple&#34;], index=redox_pairs).tolist()
            redundant_reductant_or_oxidant = []
            for col in [&#34;Oxidant_1&#34;, &#34;Oxidant_2&#34;, &#34;Oxidant_3&#34;, &#34;Reductant_1&#34;, &#34;Reductant_2&#34;]:
                redox_col = pd.Series(self.half_cell_reactions[col], index=[0,1])
                if redox_col.eq(redox_col[0]).all():
                    redundant_reductant_or_oxidant.append(redox_col[0])
            err_no_rxns = (&#34;Valid reactions could not be written between the half &#34;
                &#34;reactions {} &#34;.format(incompatible_half_reactions)+&#34;because &#34;
                &#34;{}&#34;.format(redundant_reductant_or_oxidant)+&#34; is on both sides &#34;
                &#34;of all reactions.&#34;)
            print(err_no_rxns)
            return
        
        ### BALANCING NON-O, H ELEMENTS
        for r in range(0, len(df_reax[&#39;rO&#39;])):
            count = 0 #to restart the loop through the elements
            temp_rO_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -
            temp_rR_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -
            temp_pO_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -
            temp_pR_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -

            
            for e in elements:
                if e in [&#39;O&#39;,&#39;H&#39;,&#39;+&#39;,&#39;-&#39;]:
                    continue
                else:
            
                    temp1 = int(element_dictionary[df_reax[&#39;rO&#39;][r]][e]) #count for the element in the list for rO at index r
                    temp2 = int(element_dictionary[df_reax[&#39;pR&#39;][r]][e])
                    temp3 = int(element_dictionary[df_reax[&#39;rR&#39;][r]][e])
                    temp4 = int(element_dictionary[df_reax[&#39;pO&#39;][r]][e])
                    if temp1 == temp2:
                        temp_rO_coeff[count] = 1
                        temp_pR_coeff[count] = 1
                    if temp1 != temp2:
                        if temp1 ==0:
                            temp_rO_coeff[count] = 1
                        if temp1 != 0:
                            temp_rO_coeff[count] = np.lcm(temp1,temp2)/temp1
                        if temp2 == 0:
                            temp_pR_coeff[count] = 1
                        if temp2 != 0:
                            temp_pR_coeff[count] = np.lcm(temp1,temp2)/temp2
                    if temp3 == temp4:
                        temp_rR_coeff[count] = 1
                        temp_pO_coeff[count] = 1
                    if temp4 != temp3:
                        if temp3 == 0:
                            temp_rR_coeff[count] = 1
                        if temp3 != 0:
                            temp_rR_coeff[count] = np.lcm(temp3,temp4)/temp3
                        if temp4 == 0.0:
                            temp_pO_coeff[count] = 1
                        if temp4 !=0.0:
                            temp_pO_coeff[count] = np.lcm(temp3,temp4)/temp4
                    count +=1
            df_reax.loc[r, &#39;rO_coeff&#39;] = -max(temp_rO_coeff)
            df_reax.loc[r, &#39;rR_coeff&#39;] = -max(temp_rR_coeff)
            df_reax.loc[r, &#39;pR_coeff&#39;] = max(temp_pR_coeff)
            df_reax.loc[r, &#39;pO_coeff&#39;] = max(temp_pO_coeff)
        
        all_reax = df_reax.copy(deep=True)
        all_reax[&#39;rO_2_coeff&#39;] = &#39;&#39;
        all_reax[&#39;rO_2&#39;] = &#39;&#39;
        all_reax[&#39;rO_3_coeff&#39;] = &#39;&#39;
        all_reax[&#39;rO_3&#39;] = &#39;&#39;
        all_reax[&#39;rR_2_coeff&#39;] = &#39;&#39;
        all_reax[&#39;rR_2&#39;] = &#39;&#39;
        
        ### MAIN REACTION
        for r in range(1, max(all_reax[&#39;Reaction&#39;]+1)): # each reaction number once, 1 to 305
            if len(all_reax[all_reax[&#39;Reaction&#39;]==r].index.values) == 1: # if nothing to combine, skip
                continue
            else:
                temp = all_reax[all_reax[&#39;Reaction&#39;]==r].index.values[0] #index of first instance of this reaction which has multiple subreactions
                lst2 = []
                all_reax.loc[temp-0.5] = all_reax.loc[temp] # replicating the row to build on
                all_reax = all_reax.sort_index() # putting the replicated row above the first instance
                for i in all_reax[all_reax[&#39;Reaction&#39;]==r].index.values[2:]: #all but the first instance in the reactions (since that&#39;s copied already)
                    if all_reax.loc[i, &#39;rO&#39;] != all_reax.loc[temp, &#39;rO&#39;] and all_reax.loc[i, &#39;rO&#39;] not in lst2: # if rO is new (and not the same as the first)
                        lst2.append(all_reax.loc[i, &#39;rO&#39;]) # list unique rO besides the first
                        for l in range(0, len(lst2)): # looping through unique rO
                            temp2 = &#39;rO_&#39;+str(2+int(l)) # adding 0 or 1 to the rO number
                            all_reax.loc[temp-0.5,str(temp2)] = lst2[l] # add the unique rO to rO_2 or 3
                    if all_reax.loc[i, &#39;rR&#39;] != all_reax.loc[temp, &#39;rR&#39;]: # if rR is new
                            all_reax.loc[temp-0.5,&#39;rR_2&#39;] = all_reax.loc[i, &#39;rR&#39;] # add it to rR_2

                ##CHANGING COEFFICIENTS
                rO = all_reax.loc[temp-0.5,&#39;rO&#39;] #assigning easy variables
                rO_2 = all_reax.loc[temp-0.5,&#39;rO_2&#39;]
                rO_3 = all_reax.loc[temp-0.5,&#39;rO_3&#39;]
                rR = all_reax.loc[temp-0.5,&#39;rR&#39;]
                rR_2 = all_reax.loc[temp-0.5,&#39;rR_2&#39;]
                rO_coeff = all_reax.loc[temp-0.5,&#39;rO_coeff&#39;] #these are empty at the moment
                rO_2_coeff = all_reax.loc[temp-0.5,&#39;rO_2_coeff&#39;]
                rO_3_coeff = all_reax.loc[temp-0.5,&#39;rO_3_coeff&#39;]
                rR_2_coeff = all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;]
                rR_coeff = all_reax.loc[temp-0.5,&#39;rR_coeff&#39;]
                if rO_3 != &#39;&#39; and rO_2 != &#39;&#39;: #if DIC is the oxidant
                    all_reax.loc[temp-0.5,&#39;rO_coeff&#39;] = rO_coeff/3 #this works fine
                    all_reax.loc[temp-0.5,&#39;rO_2_coeff&#39;] = rO_coeff/3
                    all_reax.loc[temp-0.5,&#39;rO_3_coeff&#39;] = rO_coeff/3

                    if rR_2 != &#39;&#39;:
                        all_reax.loc[temp-0.5,&#39;rR_coeff&#39;] = rR_coeff/2 #this works fine
                        all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;] = rR_coeff/2

                        all_reax.loc[temp-0.4] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR - this works fine : line 4
                        all_reax.loc[temp-0.4, &#39;rR_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.4, &#39;rR_coeff&#39;] = rR_coeff

                        all_reax.loc[temp-0.3] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR_2 - this works fine: line 5
                        all_reax.loc[temp-0.3, &#39;rR_2_coeff&#39;] = rR_coeff
                        all_reax.loc[temp-0.3, &#39;rR_coeff&#39;] = 0

                        #NEW ROWS WITH TWO DIC AND BOTH rR
                        all_reax.loc[temp-0.25] = all_reax.loc[temp-0.5] #eliminate CO2
                        all_reax.loc[temp-0.25, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.25, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.25, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.24] = all_reax.loc[temp-0.5] #eliminate HCO3-
                        all_reax.loc[temp-0.24, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.24, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.24, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.23] = all_reax.loc[temp-0.5] #eliminate CO3-2
                        all_reax.loc[temp-0.23, &#39;rO_3_coeff&#39;] = 0                
                        all_reax.loc[temp-0.23, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.23, &#39;rO_coeff&#39;] = rO_coeff/2

                        all_reax.loc[temp-0.2] = all_reax.loc[temp-0.4] #NEW ROW WITH ONLY rR ELIMINATING CO2: line 6
                        all_reax.loc[temp-0.2, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.2, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.2, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1] = all_reax.loc[temp-0.4] #NEW ROW WITH ONLY rR ELIMINATING HCO3-: line 7
                        all_reax.loc[temp-0.1, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.1, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05] = all_reax.loc[temp-0.4] #NEW ROW WITH ONLY rR ELIMINATING CO3-2: line 8
                        all_reax.loc[temp-0.05, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.04] = all_reax.loc[temp-0.3] #NEW ROW WITH ONLY rR_2 ELIMINATING CO2: line 9
                        all_reax.loc[temp-0.04, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.04, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.04, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.03] = all_reax.loc[temp-0.3] #NEW ROW WITH ONLY rR_2 ELIMINATING HCO3-: line 10
                        all_reax.loc[temp-0.03, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.03, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.03, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.02] = all_reax.loc[temp-0.3] #NEW ROW WITH ONLY rR_2 ELIMINATING CO3-2: line 11
                        all_reax.loc[temp-0.02, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.02, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.02, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.01] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY CO2 and both RR
                        all_reax.loc[temp-0.01, &#39;rO_coeff&#39;] = rO_coeff
                        all_reax.loc[temp-0.01, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.01, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.009] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY HCO3- and both RR
                        all_reax.loc[temp-0.009, &#39;rO_coeff&#39;] = 0 ###
                        all_reax.loc[temp-0.009, &#39;rO_2_coeff&#39;] = rO_coeff
                        all_reax.loc[temp-0.009, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.008] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY CO2 and both RR
                        all_reax.loc[temp-0.008, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.008, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.008, &#39;rO_3_coeff&#39;] = rO_coeff

                    if rR_2 == &#39;&#39;:
                        all_reax.loc[temp-0.2] = all_reax.loc[temp-0.5] #NEW ROW ELIMINATING CO2
                        all_reax.loc[temp-0.2, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.2, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.2, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1] = all_reax.loc[temp-0.5] #NEW ROW ELIMINATING HCO3-
                        all_reax.loc[temp-0.1, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.1, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05] = all_reax.loc[temp-0.5] #NEW ROW ELIMINATING CO3-2
                        all_reax.loc[temp-0.05, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_3_coeff&#39;] = 0

                if rO_2 != &#39;&#39; and rO_3 == &#39;&#39;: # IF THERE ARE TWO OXIDANT OPTIONS
                    all_reax.loc[temp-0.5,&#39;rO_coeff&#39;] = rO_coeff/2
                    all_reax.loc[temp-0.5,&#39;rO_2_coeff&#39;] = rO_coeff/2

                    if rR_2 != &#39;&#39;: #IF THERE ARE TWO REDUCTANT OPTIONS
                        all_reax.loc[temp-0.5,&#39;rR_coeff&#39;] = rR_coeff/2
                        all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;] = rR_coeff/2
                        
                        if rR_2 == rO_2:
                            continue
                        else:

                            all_reax.loc[temp-0.4] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR
                            all_reax.loc[temp-0.4, &#39;rR_2_coeff&#39;] = 0
                            all_reax.loc[temp-0.4, &#39;rR_coeff&#39;] = rR_coeff

                            all_reax.loc[temp-0.3] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR_2
                            all_reax.loc[temp-0.3, &#39;rR_2_coeff&#39;] = rR_coeff
                            all_reax.loc[temp-0.3, &#39;rR_coeff&#39;] = 0

                            all_reax.loc[temp-0.2] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rO_2
                            all_reax.loc[temp-0.2, &#39;rO_2_coeff&#39;] = rO_coeff
                            all_reax.loc[temp-0.2, &#39;rO_coeff&#39;] = 0

                            all_reax.loc[temp-0.1] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rO
                            all_reax.loc[temp-0.1, &#39;rO_2_coeff&#39;] = 0
                            all_reax.loc[temp-0.1, &#39;rO_coeff&#39;] = rO_coeff

                if rO_2 == &#39;&#39; and rO_3 == &#39;&#39; and rR_2 != &#39;&#39;: # IF THERE IS ONLY ONE OXIDANT BUT TWO REDUCTANTS
                    all_reax.loc[temp-0.5,&#39;rR_coeff&#39;] = rR_coeff/2
                    all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;] = rR_coeff/2

        all_reax = all_reax.sort_index().reset_index(drop=True)
        
        pair_list = []
        for i in range(0, len(all_reax[&#39;Temp_Pairs&#39;])):
            pair_list.append([redox_pairs[all_reax.loc[i, &#39;Temp_Pairs&#39;][0]], redox_pairs[all_reax.loc[i, &#39;Temp_Pairs&#39;][1]]])
        all_reax[&#39;pairs&#39;] = pair_list

        new_elements = []
        for r in range(0, len(all_reax[&#39;rO&#39;])):
            for e in elements:
                if e in [&#39;O&#39;,&#39;H&#39;,&#39;+&#39;,&#39;-&#39;]:
                    continue
                else:
                    temp1 = int(element_dictionary[all_reax[&#39;rO&#39;][r]][e]) #count for the element in the list for rO at index r
                    temp2 = int(element_dictionary[all_reax[&#39;pR&#39;][r]][e])
                    temp3 = int(element_dictionary[all_reax[&#39;rR&#39;][r]][e])
                    temp4 = int(element_dictionary[all_reax[&#39;pO&#39;][r]][e])
                    if temp1 != temp2:
                        if temp1 ==0:
                            all_reax.loc[r, &#39;red_&#39;+e+&#39;_coeff&#39;] = -temp2
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;red_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)
                        if temp2 == 0:
                            all_reax.loc[r, &#39;red_&#39;+e+&#39;_coeff&#39;] = temp1
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;red_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)
                    if temp4 != temp3:
                        if temp3 == 0:
                            all_reax.loc[r, &#39;ox_&#39;+e+&#39;_coeff&#39;] = -temp4
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;ox_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)
                        if temp4 == 0.0:
                            all_reax.loc[r, &#39;ox_&#39;+e+&#39;_coeff&#39;] = temp3
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;ox_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)


        for i in new_elements:
            if i not in db_names:
                db_names.append(i)
            if i not in formulas:
                formulas.append(i)
            parsed_formula = parse_formula(i)
            element_dictionary[i] = parsed_formula
            for e in elements:
                if element_dictionary[i].get(e, 0) == 0:
                    element_dictionary[i][e] = 0

        reax = all_reax.copy(deep=True)
        reax.drop(&#39;Temp_Pairs&#39;, axis=1, inplace=True)
        reax.drop(&#39;pairs&#39;, axis=1, inplace=True)
        reax.reset_index(drop=True, inplace=True)
        for s in [&#39;O&#39;, &#39;H&#39;,&#39;-&#39;,&#39;+&#39;]:
            for i in range(0,len(reax[&#39;rO&#39;])):
                red = 0
                ox=0
                for j in reax.columns.tolist():
                    if &#39;_coeff&#39; in j:
                        if &#39;rO_&#39; in j or &#39;pR_&#39; in j or &#39;red_&#39; in j:
                            if str(reax[j][i]) != &#39;nan&#39; and str(reax[j][i]) != &#39;&#39;:
                                red_temp_coeff = reax[j][i]
                                red_temp = element_dictionary[reax[j.split(&#39;_coeff&#39;)[0]][i]][s]
                                red -= red_temp_coeff*red_temp

                        if &#39;rR_&#39; in j or &#39;pO_&#39; in j or &#39;ox_&#39; in j:
                            if str(reax[j][i]) != &#39;nan&#39; and str(reax[j][i]) != &#39;&#39;:
                                ox_temp_coeff = reax[j][i]
                                ox_temp = element_dictionary[reax[j.split(&#39;_coeff&#39;)[0]][i]][s]
                                ox -= ox_temp_coeff*ox_temp      

                reax.loc[i, &#39;r_&#39;+s] = red
                reax.loc[i, &#39;o_&#39;+s] = ox

        reax[&#39;r_H&#39;] = reax[&#39;r_H&#39;] - 2*reax[&#39;r_O&#39;]
        reax[&#39;o_H&#39;] = reax[&#39;o_H&#39;] - 2*reax[&#39;o_O&#39;]
        reax[&#39;r_+&#39;] = reax[&#39;r_+&#39;] - reax[&#39;r_H&#39;]
        reax[&#39;o_+&#39;] = reax[&#39;o_+&#39;] - reax[&#39;o_H&#39;]
        reax[&#39;r_e-&#39;] = reax[&#39;r_+&#39;] - reax[&#39;r_-&#39;] 
        reax[&#39;o_e-&#39;] = reax[&#39;o_+&#39;] - reax[&#39;o_-&#39;] 
        reax.rename({&#39;r_O&#39;: &#39;r_H2O&#39;, &#39;r_H&#39;: &#39;r_H+&#39;, &#39;o_O&#39;: &#39;o_H2O&#39;, &#39;o_H&#39;: &#39;o_H+&#39;}, axis=1, inplace = True)
        
        ### MULTIPLYING SUB-REACTIONS
        lcm_charge = []
        electrons = []
        for i in range(0, len(reax[&#39;rO&#39;])):
        # for i in range(0, 1):
            lcm_charge = np.lcm(round(reax[&#39;r_e-&#39;][i]), round(reax[&#39;o_e-&#39;][i]))
            electrons.append(str(lcm_charge)+&#39;e&#39;)
            r_multiplier = abs(lcm_charge/int(reax[&#39;r_e-&#39;][i]))
            o_multiplier = abs(lcm_charge/int(reax[&#39;o_e-&#39;][i]))
            for s in list(reax.columns):
                if (&#39;red_&#39; in s and &#39;coeff&#39; in s) or (&#39;rO_&#39; in s and &#39;coeff&#39; in s) or (&#39;pR_&#39; in s and &#39;coeff&#39; in s) or &#39;r_H2O&#39; in s or &#39;r_H+&#39; in s:
                    reax.loc[i, s] = reax.loc[i, s]*int(r_multiplier )
                if (&#39;ox_&#39; in s and &#39;coeff&#39; in s) or (&#39;rR_&#39; in s and &#39;coeff&#39; in s) or (&#39;pO_&#39; in s and &#39;coeff&#39; in s) or &#39;o_H2O&#39; in s or &#39;o_H+&#39; in s:
                    reax.loc[i, s] = reax.loc[i, s]*int(o_multiplier)
        reax[&#39;H+&#39;] = reax[&#39;r_H+&#39;] + reax[&#39;o_H+&#39;]
        reax[&#39;protons&#39;] = &#39;H+&#39;
        reax[&#39;H2O&#39;] = reax[&#39;r_H2O&#39;] + reax[&#39;o_H2O&#39;]
        reax[&#39;water&#39;] = &#39;H2O&#39;
        reax.drop(columns = [&#39;r_H2O&#39;, &#39;r_H+&#39;, &#39;r_-&#39;, &#39;r_+&#39;, &#39;r_e-&#39;, &#39;o_H2O&#39;, &#39;o_H+&#39;, &#39;o_-&#39;, &#39;o_+&#39;, &#39;o_e-&#39;],axis = 1, inplace = True)

        count = 0
        for i in db_names:
            db_names[count] = &#39;start&#39;+i+&#39;end&#39;
            count += 1

        real_reax = reax.replace(formulas,db_names)
        real_reax[&#39;rO_coeff&#39;] = real_reax[&#39;rO_coeff&#39;].astype(&#39;float&#39;) 
        real_reax[&#39;rR_coeff&#39;] = real_reax[&#39;rR_coeff&#39;].astype(&#39;float&#39;) 
        real_reax[&#39;pO_coeff&#39;] = real_reax[&#39;pO_coeff&#39;].astype(&#39;float&#39;) 
        real_reax[&#39;pR_coeff&#39;] = real_reax[&#39;pR_coeff&#39;].astype(&#39;float&#39;) 
        
        count = 0
        rxn_count = []
        rxn_number = []

        for i in real_reax[&#39;Reaction&#39;]:
            if i not in rxn_count:
                rxn_count.append(i)
                rxn_number.append(real_reax[&#39;Names&#39;][count]+ &#39;_&#39;+str(count))
            else:
                rxn_number.append(real_reax[&#39;Names&#39;][count]+ &#39;_&#39;+str(count)+&#39;_sub&#39;)
            count += 1
        real_reax.insert(0, &#39;Reaction Number&#39;, rxn_number)
        real_reax.insert(1, &#39;electrons&#39;, electrons)

        lst3 = [] #list of reaction numbers
        lst4 = [] #list of reactions with issues
        for i in range(0, len(real_reax[&#39;Reaction&#39;])):
            if real_reax[&#39;Reaction&#39;][i] not in lst3:
                lst3.append(real_reax[&#39;Reaction&#39;][i])
        for j in lst3: #looping through reaction numbers
            first_e = real_reax.loc[real_reax[&#39;Reaction&#39;] == j][&#39;electrons&#39;].reset_index(drop=True)[0]
            for k in real_reax.loc[real_reax[&#39;Reaction&#39;] == j][&#39;electrons&#39;].reset_index(drop=True):
                if k != first_e:
                    if j not in lst4:
                        lst4.append(j)
        for l in lst4:
            print(real_reax.loc[real_reax[&#39;Reaction&#39;] ==  l])

        real_reax.drop(labels=&#39;Reaction&#39;, axis=1, inplace = True)
        real_reax.drop(columns = &#39;Names&#39;, inplace = True)
        pairs = real_reax[&#39;redox_pair&#39;]
        real_reax.drop(columns = &#39;redox_pair&#39;, inplace = True)
        
        # 2-16-2022 CHANGES START HERE
        for i in range(0, len(real_reax[&#39;Reaction Number&#39;])):
            for j in range(2, len(real_reax.columns)):
                if str(real_reax.iloc[i, j]) == &#39;nan&#39;:
                    real_reax.iloc[i, j] = &#39;&#39;
        
        test_df = real_reax.copy(deep=True)
        count = 0
        for i in range(0, len(test_df[&#39;Reaction Number&#39;])):
            coefficients = []
            species = []
            for j in range(2, len(test_df.columns)):
                if count % 2 == 0: 
                    if test_df.iloc[i, j] != &#39;&#39;:
                        test_df.iloc[i, j] = round(test_df.iloc[i, j], 14)
                    if test_df.iloc[i, j] == 0 or test_df.iloc[i, j] == 0.0:
                        test_df.iloc[i, j] = &#39;&#39;
                        test_df.iloc[i, j+1] = &#39;&#39;
                    coefficient = test_df.iloc[i, j]
                    coefficients.append(test_df.iloc[i, j])
                if count % 2 != 0:
                    if test_df.iloc[i, j] != &#39;&#39;:
                        test_df.iloc[i, j] = str(test_df.iloc[i, j]).split(&#39;start&#39;)[1].split(&#39;end&#39;)[0]
                    compound = test_df.iloc[i, j]
                    if compound in species:
                        og_location = species.index(compound) 
                        df_location = 3+og_location*2 
                        df_location_coeff = df_location - 1
                        old_coeff = coefficients[og_location] 
                        new_coeff = coefficient + old_coeff 
                        test_df.iloc[i, j] = &#39;&#39;
                        test_df.iloc[i, j-1] = &#39;&#39;
                        df_value = test_df.iloc[i, df_location] #values from first occurence remaining
                        test_df.iloc[i, df_location_coeff] = new_coeff
                    species.append(compound)
                count+=1
        for m in range(0, 7):
            for i in range(0, len(test_df[&#39;Reaction Number&#39;])):
                line = []
                for j in range(2, len(test_df.columns)):
                    line.append(test_df.iloc[i, j])
                    if test_df.iloc[i, j] != &#39;&#39; and test_df.iloc[i, j-2] ==&#39;&#39;:
                        test_df.iloc[i, j-2] = test_df.iloc[i, j]
                        test_df.iloc[i, j] = &#39;&#39;

        file = test_df.to_csv(sep=&#39;\t&#39;, header=False, index=False, lineterminator=&#39;\n&#39;)

        file = file.split(&#34;\n&#34;) #not sure if I should keep this
        
        newlines = []
        for line in file:   
            line = line.strip()
            newlines.append(line)

        self.affinity_energy_reactions_raw = &#34;\n&#34;.join(newlines)
        df_rxn = pd.DataFrame([x.split(&#39;\t&#39;) for x in self.affinity_energy_reactions_raw.split(&#39;\n&#39;)])
        df_rxn.columns = df_rxn.columns.map(str)
        df_rxn = df_rxn.rename(columns={&#34;0&#34;: &#34;reaction_name&#34;, &#34;1&#34;: &#34;mol_e-_transferred_per_mol_rxn&#34;})
        df_rxn.insert(1, &#39;redox_pairs&#39;, all_reax[&#39;pairs&#39;])
        df_rxn = df_rxn.set_index(&#34;reaction_name&#34;)
        df_rxn = df_rxn[df_rxn[&#39;mol_e-_transferred_per_mol_rxn&#39;].notna()]
        self.affinity_energy_reactions_table = df_rxn
        
        prev_was_coeff = False
        n = 1
        for col in self.affinity_energy_reactions_table.iloc[:, 2:].columns:
            if not prev_was_coeff:
                new_col_name = &#34;coeff_&#34;+str(n)
                prev_was_coeff = True
            else:
                new_col_name = &#34;species_&#34;+str(n)
                prev_was_coeff = False
                n += 1
            self.affinity_energy_reactions_table = self.affinity_energy_reactions_table.rename(columns={col: new_col_name})
        
        nonsub_reaction_names = [name for name in self.affinity_energy_reactions_table.index if &#34;_sub&#34; not in name[-4:]]
        if self.verbose != 0:
            print(&#34;{} redox reactions have been generated.&#34;.format(len(nonsub_reaction_names)))

        
    def show_redox_reactions(self, formatted=True, charge_sign_at_end=False,
                                  hide_subreactions=True, simplify=True,
                                  show=True):
        
        &#34;&#34;&#34;
        Show a table of redox reactions generated with the function
        `make_redox_reactions`.
        
        Parameters
        ----------
        formatted : bool, default True
            Should reactions be formatted for html output?
            
        charge_sign_at_end : bool, default False
            Display charge with sign after the number (e.g. SO4 2-)? Ignored if
            `formatted` is False.
        
        hide_subreactions : bool, default True
            Hide subreactions?
        
        show : bool, default False
            Show the table of reactions? Ignored if not run in a Jupyter
            notebook.
        
        Returns
        ----------
        A pandas dataframe containing balanced redox reactions written in full.
        &#34;&#34;&#34;
        
        self.affinity_energy_formatted_reactions = copy.copy(self.affinity_energy_reactions_table.iloc[:, 0:1])
        
        df = copy.copy(self.affinity_energy_reactions_table)
        
        if simplify:
            main_rxn_names = df.loc[[ind for ind in df.index if &#34;_sub&#34; not in ind[-4:]]].index
            df = df.iloc[[i-1 for i in range(0, len(df.index)) if &#34;_sub&#34; not in df.index[i][-4:]]]
            
            self.affinity_energy_formatted_reactions = copy.copy(df.iloc[:, 0:1])
            
            reactions = []
            for irow in range(0, df.shape[0]):
                redox_pair = df.loc[df.index[irow], &#34;redox_pairs&#34;]

                oxidant_1 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[0]], &#34;Oxidant_1&#34;]
                oxidant_2 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[0]], &#34;Oxidant_2&#34;]
                oxidant_3 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[0]], &#34;Oxidant_3&#34;]
                reductant_1 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[1]], &#34;Reductant_1&#34;]
                reductant_2 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[1]], &#34;Reductant_2&#34;]
                
                oxidants = [ox for ox in [oxidant_1, oxidant_2, oxidant_3] if str(ox) != &#39;nan&#39;]
                reductants = [rd for rd in [reductant_1, reductant_2] if str(rd) != &#39;nan&#39;]
                
                if len(oxidants) &gt; 1:
                    oxidant_sigma_needed = True
                else:
                    oxidant_sigma_needed = False
                if len(reductants) &gt; 1:
                    reductant_sigma_needed = True
                else:
                    reductant_sigma_needed = False
                    
                rxn_row = df.iloc[irow, 2:]
                rxn = rxn_row[rxn_row.notna()]
                coeffs = copy.copy(rxn[::2]).tolist()
                names = copy.copy(rxn[1::2]).tolist()
                
                if oxidant_sigma_needed or reductant_sigma_needed:

                    reactant_names = [names[i] for i in range(0, len(names)) if float(coeffs[i]) &lt; 0]
                    for sp in reactant_names:
                        if sp in oxidants and oxidant_sigma_needed:
                            i = names.index(sp)
                            names[i] = u&#34;\u03A3&#34;+sp
                        if sp in reductants and reductant_sigma_needed:
                            if u&#34;\u03A3&#34;+sp not in names:
                                i = names.index(sp)
                                names[i] = u&#34;\u03A3&#34;+sp
                    
                react_grid = pd.DataFrame({&#34;coeff&#34;:coeffs, &#34;name&#34;:names})
                react_grid[&#34;coeff&#34;] = pd.to_numeric(react_grid[&#34;coeff&#34;])
                react_grid = react_grid.astype({&#39;coeff&#39;: &#39;float&#39;})

                reactants = &#34; + &#34;.join([(str(-int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else -react_grid[&#34;coeff&#34;][i])+&#34; &#34; if -react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                products = &#34; + &#34;.join([(str(int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else react_grid[&#34;coeff&#34;][i])+&#34; &#34; if react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
                if formatted:
                    reactants = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                    products = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
                reaction = reactants + &#34; = &#34; + products
                reactions.append(reaction)

            self.affinity_energy_formatted_reactions[&#34;reaction&#34;] = reactions[1:] + reactions[:1] # because reactions got rotated with respect to reaction names, rotate the other way
            self.affinity_energy_formatted_reactions.index = main_rxn_names
            
        else:
            reactions = []
            for irow in range(0, df.shape[0]):
                redox_pair = df.loc[self.affinity_energy_reactions_table.index[irow], &#34;redox_pairs&#34;]

                oxidant = redox_pair[0]
                reductant = redox_pair[1]

                rxn_row = df.iloc[irow, 2:]
                rxn = rxn_row[rxn_row.notna()]
                coeffs = copy.copy(rxn[::2]).tolist()
                names = copy.copy(rxn[1::2]).tolist()
                react_grid = pd.DataFrame({&#34;coeff&#34;:coeffs, &#34;name&#34;:names})
                react_grid[&#34;coeff&#34;] = pd.to_numeric(react_grid[&#34;coeff&#34;])
                react_grid = react_grid.astype({&#39;coeff&#39;: &#39;float&#39;})

                reactants = &#34; + &#34;.join([(str(-int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else -react_grid[&#34;coeff&#34;][i])+&#34; &#34; if -react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                products = &#34; + &#34;.join([(str(int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else react_grid[&#34;coeff&#34;][i])+&#34; &#34; if react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
                if formatted:
                    reactants = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                    products = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
                reaction = reactants + &#34; = &#34; + products
                reactions.append(reaction)
        
            self.affinity_energy_formatted_reactions[&#34;reaction&#34;] = reactions
        

        df_out = copy.copy(self.affinity_energy_formatted_reactions)

        if hide_subreactions and not simplify:
            df_out = self.affinity_energy_formatted_reactions.loc[[ind for ind in self.affinity_energy_formatted_reactions.index if &#34;_sub&#34; not in ind[-4:]]]
        
        if _isnotebook() and show:
            display(HTML(df_out.to_html(escape=False)))
        
        return df_out


    class Thermodata(object):
        &#34;&#34;&#34;
        Metaclass to store and load thermodynamic databases.
        Inherits attributes from its outer class, AqEquil.
        
        &#34;&#34;&#34;

        def __init__(self, AqEquil_instance):

            self.AqEquil_instance = AqEquil_instance
            
            # attributes to add to AqEquil class
            self.db = self.AqEquil_instance.db
            self.elements = self.AqEquil_instance.elements
            solid_solutions = self.AqEquil_instance.solid_solutions
            self.exclude_category = self.AqEquil_instance.exclude_category
            self.water_model = self.AqEquil_instance.water_model
            logK = self.AqEquil_instance.logK
            logK_S = self.AqEquil_instance.logK_S
            download_csv_files = self.AqEquil_instance.download_csv_files
            #exclude_category = self.AqEquil_instance.exclude_category
            suppress_redox = self.AqEquil_instance.suppress_redox
            exceed_Ttr = self.AqEquil_instance.exceed_Ttr
            input_template = self.AqEquil_instance.input_template
            verbose = self.AqEquil_instance.verbose
            
            self.hide_traceback = self.AqEquil_instance.hide_traceback
            self.err_handler = Error_Handler(clean=self.hide_traceback)

            self.eq36da = self.AqEquil_instance.eq36da
            self.eq36co = self.AqEquil_instance.eq36co

            self.df_rejected_species = pd.DataFrame({&#39;database name&#39;:[],
                                                     &#39;database index&#39;:[],
                                                     &#34;name&#34;:[],
                                                     &#34;reason for rejection&#34;:[]})
            
            # active thermo db attributes
            self.thermo_db = None
            self.thermo_db_type = None
            self.thermo_db_source = None
            self.thermo_db_filename = None
            self.custom_data0 = None
            self.data0_lettercode = None
            self.dynamic_db = None
            self.custom_obigt = None
            self.db_csv_name = None

            # data1 attributes
            self.data1 = {}

            # data0 attributes
            self.data0_db = None
            self.data0_db_type = None
            self.data0_db_source = None
            self.data0_db_filename = None

            # csv attributes
            self.csv_db = None
            self.csv_db_type = None
            self.csv_db_source = None
            self.csv_db_filename = None

            # element attributes
            self.element_db = None
            self.element_db_source = None
            self.element_db_filename = None
            self.element_active = None

            # solid solution attributes
            self.solid_solutions_active = False
            self.solid_solution_db = None
            self.solid_solution_db_source = None
            self.solid_solution_db_filename = None

            # logK attributes
            self.logK_active = False
            self.logK_extrapolate = self.AqEquil_instance.logK_extrapolate
            self.logK_db = None
            self.logK_db_source = None
            self.logK_db_filename = None

            # logK attributes
            self.logK_S_active = False
            self.logK_S_db = None
            self.logK_S_db_source = None
            self.logK_S_db_filename = None

            self.verbose=verbose

            if self.db == &#34;WORM&#34;:
                if self.verbose &gt; 0:
                    print(&#34;Loading Water-Organic-Rock-Microbe (WORM) thermodynamic databases...&#34;)
                self.db = &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
                self._set_active_db(db=self.db, download_csv_files=download_csv_files)
                if self.elements == None:
                    self._load_elements(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/elements.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)
                if solid_solutions == None:
                    self._load_solid_solutions(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/solid_solutions.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)
                if logK == None:
                    self._load_logK(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data_logK.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)
                if logK_S == None:
                    self._load_logK_S(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data_logK_S.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)
            else:
                self._set_active_db(db=self.db, download_csv_files=download_csv_files)
                

            # elements must be loaded if thermo_db_type is a CSV
            if self.elements != None:
                self._load_elements(elements, source=&#34;file&#34;)
            if not self.element_active and self.thermo_db_type==&#34;CSV&#34;:
                self._load_elements(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/elements.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)

            if solid_solutions != None:
                self._load_solid_solutions(solid_solutions, source=&#34;file&#34;)

            if logK != None:
                self._load_logK(logK, source=&#34;file&#34;)

            # must be loaded after the logK database
            if logK_S != None:
                self._load_logK_S(logK_S, source=&#34;file&#34;)
                
            if self.logK_active:
                self.thermo_db = pd.concat([self.thermo_db, self.logK_db], ignore_index=True)
                
            # process dissociation reactions
            if self.thermo_db_type == &#34;CSV&#34;:
                self._suppress_redox_and_generate_dissrxns(
                    suppress_redox=suppress_redox,
                    exceed_Ttr=exceed_Ttr)
            elif len(suppress_redox) &gt; 0 and self.verbose &gt; 0:
                print(&#34;Warning: redox suppression option is not recognized if a data0 or data1 database is used.&#34;)
                
            if self.logK_active:
                self.logK_db = self.thermo_db[~self.thermo_db[&#34;logK1&#34;].isnull()]
                self.thermo_db = self.thermo_db[self.thermo_db[&#34;logK1&#34;].isnull()]
                
            # generate input file template
            # (after species have been excluded)
            if input_template != &#34;none&#34;:
                if input_template == &#39;strict&#39;:
                    template_names = list(self.thermo_db[self.thermo_db[&#34;tag&#34;]==&#34;basis&#34;][&#34;name&#34;])
                elif input_template == &#39;basis&#39;:
                    template_names = list(self.thermo_db[self.thermo_db[&#34;tag&#34;].isin([&#34;basis&#34;, &#34;aux&#34;])][&#34;name&#34;])
                elif input_template == &#39;all&#39;:
                    template_names = list(self.thermo_db[self.thermo_db[&#34;state&#34;]==&#34;aq&#34;][&#34;name&#34;])

                template_names = sorted(template_names)
                input_template = pd.DataFrame({&#34;Sample&#34;:[&#34;id&#34;], &#34;H+&#34;:[&#34;pH&#34;], &#34;Temperature&#34;:[&#34;degC&#34;], &#34;logfO2&#34;:[&#34;logfO2&#34;]})
                input_template_2 = pd.DataFrame({name:[&#34;Molality&#34;] for name in template_names})
                input_template = pd.concat([input_template, input_template_2], axis=1)

                input_template.to_csv(&#34;sample_input_template.csv&#34;, index=False)


        def _remove_missing_G_species(self):
            # remove species that are missing a gibbs free energy value.
            # handle minerals first. Reject any that have missing G in any polymorph.
            mineral_name_reject = list(set(self.csv_db[(self.csv_db[&#34;G&#34;].isnull()) &amp; (self.csv_db[&#39;state&#39;].str.contains(&#39;cr&#39;))][&#34;name&#34;]))
            
            idx = list(self.csv_db[self.csv_db[&#34;name&#34;].isin(mineral_name_reject)].index)

            names = self.csv_db[&#34;name&#34;].loc[idx]

            self.csv_db = self.csv_db[~self.csv_db[&#34;name&#34;].isin(mineral_name_reject)]

            for i,name in enumerate(names):
                d = pd.DataFrame({&#39;database name&#39;: [self.csv_db_filename], &#39;database index&#39;: [idx[i]], &#39;name&#39;: [name], &#39;reason for rejection&#39;: [&#34;missing Gibbs free energy in at least one polymorph&#34;]})
                self.df_rejected_species = pd.concat([self.df_rejected_species, d], ignore_index=True)
            
            # TODO: other states besides minerals
                
        def _set_active_db(self, db=None, download_csv_files=False):
            &#34;&#34;&#34;
            Set the main active thermodynamic database to a CSV file, a data0 file,
            or a data1 file on the server, a local file, or from a URL address.
            &#34;&#34;&#34;

            if len(db) == 3:
                # e.g., &#34;wrm&#34;

                self.data0_lettercode = db
                self.dynamic_db = False

                # search for a data1 file in the eq36da directory
                if os.path.exists(self.eq36da + &#34;/data1.&#34; + db) and os.path.isfile(self.eq36da + &#34;/data1.&#34; + db):
                    self.thermo_db = None
                    self.thermo_db_type = &#34;data1&#34;
                    self.thermo_db_source = &#34;file&#34;
                    self.thermo_db_filename = &#34;data1.&#34;+db

                    # store contents of data1 file in AqEquil object
                    with open(self.eq36da + &#34;/data1.&#34; + db, mode=&#39;rb&#39;) as data1_file:
                        self.data1[&#34;all_samples&#34;] = data1_file.read()

                elif os.path.exists(&#34;data0.&#34; + db) and os.path.isfile(&#34;data0.&#34; + db):

                    if self.verbose &gt; 0:
                        print(&#34;data1.&#34; + db + &#34; was not found in the EQ36DA directory &#34;
                              &#34;but a data0.&#34;+db+&#34; was found in the current working &#34;
                              &#34;directory. Using it...&#34;)

                    self._load_data0(&#34;data0.&#34; + db, source=&#34;file&#34;)

                    self.thermo_db = self.data0_db
                    self.thermo_db_filename = self.data0_db_filename
                    self.thermo_db_type = &#34;data0&#34;
                    self.thermo_db_source = &#34;file&#34;
                    self.custom_data0 = True
                    self.data0_lettercode = db[-3:].lower()
                    self.custom_obigt = None
                    self.eq36da = os.getcwd()+&#34;/eqpt_files&#34;

                elif os.path.exists(&#34;data1.&#34; + db) and os.path.isfile(&#34;data1.&#34; + db):
                    
                    if self.verbose &gt; 0:
                        print(&#34;data1.&#34; + db + &#34; was not found in the EQ36DA directory &#34;
                              &#34;but a data1.&#34;+db+&#34; was found in the current working &#34;
                              &#34;directory. Using it...&#34;)

                    self.custom_data0 = True
                    self.thermo_db = None
                    self.eq36da = os.getcwd()+&#34;/eqpt_files&#34;

                    # search for a data1 locally

                    # store contents of data1 file in AqEquil object
                    with open(&#34;data1.&#34; + db, mode=&#39;rb&#39;) as data1_file:
                        self.data1[&#34;all_samples&#34;] = data1_file.read()
                        self.thermo_db_type = &#34;data1&#34;
                        self.thermo_db_source = &#34;file&#34;
                        self.thermo_db_filename = &#34;data1.&#34;+db

                else:
                    msg = (&#34;Could not locate a &#39;data1.&#34;+db+&#34;&#39; file in the EQ36DA &#34;
                          &#34;directory, nor a &#39;data0.&#34;+db+&#34;&#39; or &#39;data1.&#34;+db+&#34;&#39; file in &#34;
                          &#34;the current working directory.&#34;)
                    self.err_handler.raise_exception(msg)

            elif &#34;data0.&#34; in db[-9:].lower() and db[-4:].lower() != &#34;.csv&#34; and (db[0:8].lower() == &#34;https://&#34; or db[0:7].lower() == &#34;http://&#34; or db[0:4].lower() == &#34;www.&#34;):
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#34;

                self._load_data0(db, source=&#34;URL&#34;)

                self.thermo_db = self.data0_db
                self.thermo_db_filename = self.data0_db_filename
                self.thermo_db_type = &#34;data0&#34;
                self.thermo_db_source = &#34;URL&#34;
                self.custom_data0 = True
                self.data0_lettercode = db[-3:]
                self.dynamic_db = False
                self.custom_obigt = None

            elif db[0:-4].lower() == &#34;data0&#34; and not (db[0:8].lower() == &#34;https://&#34; or db[0:7].lower() == &#34;http://&#34; or db[0:4].lower() == &#34;www.&#34;):
                # e.g., &#34;data0.wrm&#34;

                self._load_data0(db, source=&#34;file&#34;)

                self.thermo_db = self.data0_db
                self.thermo_db_filename = self.data0_db_filename
                self.thermo_db_type = &#34;data0&#34;
                self.thermo_db_source = &#34;file&#34;
                self.custom_data0 = True
                self.data0_lettercode = db[-3:].lower()
                self.dynamic_db = False
                self.custom_obigt = None

            elif db[-4:].lower() == &#34;.csv&#34; and not (db[0:8].lower() == &#34;https://&#34; or db[0:7].lower() == &#34;http://&#34; or db[0:4].lower() == &#34;www.&#34;):
                # e.g., &#34;wrm_data.csv&#34;

                self._load_csv(db, source=&#34;file&#34;)

                self.thermo_db = self.csv_db
                self.thermo_db_filename = self.csv_db_filename
                self.thermo_db_type = &#34;CSV&#34;
                self.thermo_db_source = &#34;file&#34;
                self.dynamic_db = True
                self.custom_data0 = False
                self.custom_obigt = self.csv_db_filename
                self.data0_lettercode = None

            elif db[-4:].lower() == &#34;.csv&#34; and (db[0:8].lower() == &#34;https://&#34; or db[0:7].lower() == &#34;http://&#34; or db[0:4].lower() == &#34;www.&#34;):
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;

                self._load_csv(db, source=&#34;URL&#34;, download_csv_files=download_csv_files)

                self.thermo_db = self.csv_db
                self.thermo_db_filename = self.csv_db_filename
                self.thermo_db_type = &#34;CSV&#34;
                self.thermo_db_source = &#34;URL&#34;
                self.dynamic_db = True
                self.custom_data0 = False
                self.custom_obigt = self.csv_db_filename
                self.data0_lettercode = None

            else:
                self.err_handler.raise_exception(&#34;Unrecognized thermodynamic &#34;
                    &#34;database &#39;{}&#39;&#34;.format(db)+&#34; specified for db. A database can specified as:&#34;
                    &#34;\n - a three letter code designating a data0 file. e.g., db=&#39;wrm&#39;&#34;
                    &#34;\n - a data0 file in your working directory. e.g., db=&#39;data0.wrm&#39;&#34;
                    &#34;\n - a csv file in your working directory. e.g., db=&#39;wrm_data.csv&#39;&#34;
                    &#34;\n - a URL directing to a data0 file. e.g.,&#34;
                    &#34;\n\t db=&#39;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#39;&#34;
                    &#34;\n\t (note the data0 file in the URL must have &#39;data0.&#39; followed by a three letter code)&#34;
                    &#34;\n - a URL directing to a valid csv file. e.g.,&#34;
                    &#34;\n\t db=&#39;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#39;&#34;)

            if self.verbose &gt; 0:
                print(self.thermo_db_filename, &#34;is now set as the active thermodynamic database.&#34;)

                if self.thermo_db_filename in [&#39;data0.wrm&#39;, &#39;data1.wrm&#39;]:
                    print(&#34;This database is meant for rapid calculations between 0 and 350 C at water saturation pressure.&#34;)
                elif self.thermo_db_filename == &#34;wrm_data.csv&#34;:
                    print(&#34;This database is meant for calculations between 0 and 1000 C and up to 5 kb pressure.&#34;)

            self.db = db


        def __df_from_url(self, url, download_csv_files=False):
            &#34;&#34;&#34;
            Get a filename and dataframe from a URL pointing to a CSV file.
            &#34;&#34;&#34;

            filename = url.split(&#34;/&#34;)[-1].lower()

            # Download from URL and decode as UTF-8 text.
            with urlopen(url) as webpage:
                content = webpage.read().decode()

            if download_csv_files:
                if self.verbose &gt; 0:
                    print(&#34;Downloading&#34;, filename, &#34;from&#34;, url)
                with open(filename, &#39;w&#39;) as output:
                    output.write(content)

            return filename, pd.read_csv(StringIO(content), sep=&#34;,&#34;)


        def __str_from_url(self, url):
            &#34;&#34;&#34;
            Get a filename and contents from a URL pointing to a txt file.
            &#34;&#34;&#34;

            filename = url.split(&#34;/&#34;)[-1].lower()

            # Download from URL and decode as UTF-8 text.
            with urlopen(url) as webpage:
                txt_content = webpage.read().decode()

            if self.verbose &gt; 0:
                print(&#34;Downloading&#34;, filename, &#34;from&#34;, url)
            with open(filename, &#39;w&#39;) as output:
                output.write(txt_content)

            return filename, txt_content


        def _load_elements(self, db, source=&#34;url&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load an element database CSV file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;elements.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.element_db = pd.read_csv(db)
                    self.element_db_source = &#34;file&#34;
                    self.element_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/elements.csv&#34;
                self.element_db_filename, self.element_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.element_db_source = &#34;URL&#34;
            else:
                if self.verbose &gt; 0:
                    print(&#34;No element database loaded.&#34;)

            if self.thermo_db_type == &#34;CSV&#34;:
                if self.verbose &gt; 0:
                    print(&#34;Element database&#34;, self.element_db_filename, &#34;is active.&#34;)
                self.element_active = True
            else:
                if self.verbose &gt; 0:
                    print(&#34;Element database is not active because the active thermodynamic database is a&#34;, self.thermo_db_type, &#34;and not a CSV.&#34;)


        def _load_solid_solutions(self, db, source=&#34;url&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load a solid solution database CSV file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;solid_solutions.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.solid_solution_db = pd.read_csv(db)
                    self.solid_solution_db_source = &#34;file&#34;
                    self.solid_solution_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/solid_solutions.csv&#34;
                self.solid_solution_db_filename, self.solid_solution_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.solid_solution_db_source = &#34;URL&#34;
            else:
                if self.verbose &gt; 0:
                    print(&#34;No solid solution database loaded.&#34;)

            if self.thermo_db_type == &#34;CSV&#34;:
                if self.verbose &gt; 0:
                    print(&#34;Solid solution database&#34;, self.solid_solution_db_filename, &#34;is active.&#34;)
                self.solid_solutions_active = True
            else:
                if self.verbose &gt; 0:
                    print(&#34;Solid solution database is not active because the active thermodynamic database is a&#34;, self.thermo_db_type, &#34;and not a CSV.&#34;)


        def _load_logK(self, db, source=&#34;URL&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load a logK database CSV file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;logK.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.logK_db = pd.read_csv(db)
                    self.logK_db_source = &#34;file&#34;
                    self.logK_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data_logK.csv&#34;
                self.logK_db_filename, self.logK_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.logK_db_source = &#34;URL&#34;

            else:
                if self.verbose &gt; 0:
                    print(&#34;No logK database loaded.&#34;)

            if self.thermo_db_type == &#34;CSV&#34;:
                if self.verbose &gt; 0:
                    print(&#34;LogK database&#34;, self.logK_db_filename, &#34;is active.&#34;)
                self.logK_active = True
            else:
                if self.verbose &gt; 0:
                    print(&#34;LogK database is not active because the active thermodynamic database is a&#34;, self.thermo_db_type, &#34;and not a CSV.&#34;)

            self.logK_db = self._exclude_category(df=self.logK_db, df_name=self.logK_db_filename)


        def _load_logK_S(self, db, source=&#34;URL&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load a logK_S database CSV file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;logK_S.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.logK_S_db = pd.read_csv(db)
                    self.logK_S_db_source = &#34;file&#34;
                    self.logK_S_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data_logK_S.csv&#34;
                self.logK_S_db_filename, self.logK_S_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.logK_S_db_source = &#34;URL&#34;

            else:
                if self.verbose &gt; 0:
                    print(&#34;No logK_S database loaded.&#34;)

            if self.logK_active and self.element_active:
                if self.verbose &gt; 0:
                    print(&#34;LogK_S database&#34;, self.logK_S_db_filename, &#34;is active.&#34;)
                self.logK_S_active = True
            else:
                if self.verbose &gt; 0:
                    print(&#34;LogK_S database is not active because there is no active logK database.&#34;)

            self.logK_S_db = self._exclude_category(df=self.logK_S_db, df_name=self.logK_S_db_filename)

            if self.logK_S_active:
                for i,sp in enumerate(self.logK_S_db[&#34;name&#34;]):
                    
                    logK_25C = float(self.logK_S_db[&#34;logK_25&#34;][i])
                    
                    IS_ref = float(self.logK_S_db[&#34;logK_25_IS&#34;][i])
                    
                    T_list = self.logK_S_db[&#34;T_vals&#34;][i].split(&#34; &#34;)
                    T_list = [float(T) for T in T_list]

                    Delta_S = float(self.logK_S_db[&#34;DeltaS&#34;][i])
                    
                    if IS_ref &gt; 0:
                        # extrapolate to ionic strength 0
                        
                        # collect azero values for metal, ligand, and complex
                        metal_name = self.logK_S_db[&#34;metal_name&#34;][i]
                        
                        if self.thermo_db[&#34;name&#34;].isin([metal_name]).any():
                            metal_azero = list(self.thermo_db[self.thermo_db[&#34;name&#34;] == metal_name][&#34;azero&#34;])[0]
                            metal_charge = float(list(self.thermo_db[self.thermo_db[&#34;name&#34;] == metal_name][&#34;z.T&#34;])[0])
#                         elif:
#                             # todo: get metal azero and charge from other databases, e.g., logK db
#                             pass
                        else:
                            # todo: throw error
                            pass
                        
                        ligand_name = self.logK_S_db[&#34;ligand_name&#34;][i]
                        if isinstance(self.logK_S_db[&#34;ligand_azero&#34;][i], float):
                            ligand_azero = float(self.logK_S_db[&#34;ligand_azero&#34;][i])
                        elif self.thermo_db[&#34;name&#34;].isin([ligand_name]).any():
                            ligand_azero = float(list(self.thermo_db[self.thermo_db[&#34;name&#34;] == ligand_name][&#34;azero&#34;])[0])
                        else:
                            # todo: elif ligand_name in logK database names, get azero from there...
                            # or maybe this is not necessary if logK is merged with thermo_db at this point
                            pass
                        
                        if isinstance(self.logK_S_db[&#34;ligand_charge&#34;][i], float):
                            ligand_charge = float(self.logK_S_db[&#34;ligand_charge&#34;][i])
                        elif self.thermo_db[&#34;name&#34;].isin([ligand_name]).any():
                            ligand_charge = float(list(self.thermo_db[self.thermo_db[&#34;name&#34;] == ligand_name][&#34;z.T&#34;])[0])
                        else:
                            # todo: elif ligand_name in logK database names, get charge from there...
                            # or maybe this is not necessary if logK is merged with thermo_db at this point
                            pass
                    
                        dissrxn = self.logK_S_db[&#34;dissrxn&#34;][i].split(&#34; &#34;)
                        n_metal = float(dissrxn[dissrxn.index(metal_name)-1])
                        n_ligand = float(dissrxn[dissrxn.index(ligand_name)-1])
                        n_complex = -float(dissrxn[dissrxn.index(sp)-1])
                        
                        complex_charge = n_metal*metal_charge + n_ligand*ligand_charge
                        complex_azero = self.logK_S_db[&#34;azero&#34;][i]
                        
                        A=0.5114
                        B=0.3288
                        Bdot=0.041
                        If = 0 # what ionic strength to extrapolate to
                        
                        ari=[metal_azero, ligand_azero]
                        api=[complex_azero]
                        vri=[n_metal, n_ligand]
                        vpi=[n_complex]
                        zri=[metal_charge, ligand_charge]
                        zpi=[complex_charge]
                        
                        def loggamma(vparam, zparam, aparam, I):
                            x=[v*((-1*A*z**2*I**0.5)/(1+a*B*I**0.5)+Bdot*I) for v,z,a in zip(vparam, zparam, aparam)]
                            return x
                        
                        def f(vparam, zparam, aparam, I):
                            return sum(loggamma(vparam, zparam, aparam, I))
                        
                        logK_25C = -(-logK_25C+(f(vpi,zpi,api,IS_ref)-f(vri,zri,ari,IS_ref))-(f(vpi,zpi,api,If)-f(vri,zri,ari,If)))
                        
                    logK_list = self._est_logK_S(T_list, logK_25C, Delta_S)
                    
                    
                    if isinstance(self.logK_S_db[&#34;ligand_element&#34;][i], str):
                        # modify element database with pseudoelements
                        pseudoelement = self.logK_S_db[&#34;ligand_element&#34;][i]
                        if pseudoelement not in self.element_db[&#34;element&#34;]:
                            e_df = pd.DataFrame(
                                {&#39;element&#39;:[self.logK_S_db[&#34;ligand_element&#34;][i]],
                                 &#39;state&#39;:[self.logK_S_db[&#34;state&#34;][i]],
                                 &#39;source&#39;:[self.logK_S_db[&#34;ligand_name&#34;][i]],
                                 &#39;mass&#39;:[self.logK_S_db[&#34;ligand_mass&#34;][i]],
                                 &#39;s&#39;:[self.logK_S_db[&#34;ligand_entropy&#34;][i]],
                                 &#39;n&#39;:[self.logK_S_db[&#34;ligand_n&#34;][i]],
                                })

                            self.element_db = pd.concat([self.element_db, e_df], ignore_index=True)

                    if isinstance(self.logK_S_db[&#34;ligand_basis&#34;][i], str):
                        # add a basis species representing the pseudoelement
                        basis = self.logK_S_db[&#34;ligand_basis&#34;][i]
                        if basis not in self.thermo_db[&#34;name&#34;]:
                            b_df = pd.DataFrame(
                                {&#39;name&#39;:[self.logK_S_db[&#34;ligand_basis&#34;][i]],
                                 &#39;abbrv&#39;:[&#34;&#34;],
                                 &#39;formula&#39;:[self.logK_S_db[&#34;ligand_formula&#34;][i]],
                                 &#39;state&#39;:[self.logK_S_db[&#34;state&#34;][i]],
                                 &#39;ref1&#39;:[self.logK_S_db[&#34;ref1&#34;][i]],
                                 &#39;ref2&#39;:[self.logK_S_db[&#34;ref2&#34;][i]],
                                 &#39;date&#39;:[self.logK_S_db[&#34;date&#34;][i]],
                                 &#39;E_units&#39;:[&#34;cal&#34;],
                                 &#39;G&#39;:[0], &#39;H&#39;:[0], &#39;S&#39;:[0],
                                 &#39;Cp&#39;:[0], &#39;V&#39;:[0], &#39;a1.a&#39;:[0],
                                 &#39;a2.b&#39;:[0], &#39;a3.c&#39;:[0], &#39;a4.d&#39;:[0],
                                 &#39;c1.e&#39;:[0], &#39;c2.f&#39;:[0],
                                 &#39;omega.lambda&#39;:[0],
                                 &#39;z.T&#39;:[self.logK_S_db[&#34;ligand_charge&#34;][i]],
                                 &#39;azero&#39;:[self.logK_S_db[&#34;ligand_azero&#34;][i]],
                                 &#39;neutral_ion_type&#39;:[0],
                                 &#39;dissrxn&#39;:[&#39;&#39;],
                                 &#39;tag&#39;:[&#39;basis&#39;],
                                 &#39;formula_ox&#39;:[self.logK_S_db[&#34;ligand_formula&#34;][i]],
                                 &#39;category_1&#39;:[self.logK_S_db[&#34;category_1&#34;][i]],
                                })

                            self.thermo_db = pd.concat([self.thermo_db, b_df], ignore_index=True)

                    if self.logK_S_db[&#34;name&#34;][i] not in self.thermo_db[&#34;name&#34;] and self.logK_S_db[&#34;name&#34;][i] not in self.logK_db[&#34;name&#34;]:
                        s_df = pd.DataFrame(
                                {&#39;name&#39;:[self.logK_S_db[&#34;name&#34;][i]],
                                 &#39;abbrv&#39;:[&#34;&#34;],
                                 &#39;formula&#39;:[self.logK_S_db[&#34;formula&#34;][i]],
                                 &#39;state&#39;:[self.logK_S_db[&#34;state&#34;][i]],
                                 &#39;ref1&#39;:[self.logK_S_db[&#34;ref1&#34;][i]],
                                 &#39;ref2&#39;:[self.logK_S_db[&#34;ref2&#34;][i]],
                                 &#39;date&#39;:[self.logK_S_db[&#34;date&#34;][i]],
                                 &#39;logK1&#39;:[np.nan],&#39;logK2&#39;:[np.nan],&#39;logK3&#39;:[np.nan],&#39;logK4&#39;:[np.nan],&#39;logK5&#39;:[np.nan],&#39;logK6&#39;:[np.nan],&#39;logK7&#39;:[np.nan],&#39;logK8&#39;:[np.nan],
                                 &#39;T1&#39;:[np.nan],&#39;T2&#39;:[np.nan],&#39;T3&#39;:[np.nan],&#39;T4&#39;:[np.nan],&#39;T5&#39;:[np.nan],&#39;T6&#39;:[np.nan],&#39;T7&#39;:[np.nan],&#39;T8&#39;:[np.nan],
                                 &#39;P1&#39;:[np.nan],&#39;P2&#39;:[np.nan],&#39;P3&#39;:[np.nan],&#39;P4&#39;:[np.nan],&#39;P5&#39;:[np.nan],&#39;P6&#39;:[np.nan],&#39;P7&#39;:[np.nan],&#39;P8&#39;:[np.nan],
                                 &#39;azero&#39;:[self.logK_S_db[&#34;azero&#34;][i]],
                                 &#39;dissrxn&#39;:[self.logK_S_db[&#34;dissrxn&#34;][i]],
                                 &#39;tag&#39;:[&#39;&#39;],
                                 &#39;formula_ox&#39;:[self.logK_S_db[&#34;formula_ox&#34;][i]],
                                 &#39;category_1&#39;:[self.logK_S_db[&#34;category_1&#34;][i]],
                                })
                        self.logK_db = pd.concat([self.logK_db, s_df], ignore_index=True)

                        for ti in range(0, len(T_list)):
                            if ti+1 &gt; 8:
                                self.err_handler.raise_exception(&#34;Species &#34;, sp, &#34;in&#34;,
                                    self.logK_S_db_filename, &#34;may only have up to&#34;,
                                    &#34;eight temperature values in column T_vals&#34;)

                            self.logK_db.loc[self.logK_db.index[-1], &#34;logK&#34;+str(ti+1)] = logK_list[ti]
                            self.logK_db.loc[self.logK_db.index[-1], &#34;T&#34;+str(ti+1)] = T_list[ti]
                            self.logK_db.loc[self.logK_db.index[-1], &#34;P&#34;+str(ti+1)] = &#39;psat&#39;

        def _est_logK_S(self, T_list, logK_25C, Delta_S):

            R = 8.31446261815324/4.184 # cal/(mol K)

            # solve for G of reaction:
            # _r G= -2.303RT logK
            G_25 = -2.303*R*298.15*logK_25C # in cal/mol

            # solve for H of reaction:
            # _r G= _r H-T_r S
            H = G_25 + 298.15*Delta_S # in cal/mol

            logK_list = []
            for T_C in T_list:

                T_K = T_C+273.15 # convert C to Kelvin

                # estimate G at temperature
                G_T = H - T_K*Delta_S

                # convert G to logK
                logK_T = G_T/(-2.303*R*T_K)
                logK_list.append(logK_T)

            return logK_list


        def _load_data0(self, db, source=&#34;URL&#34;):
            &#34;&#34;&#34;
            Load a data0 file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#34;
                self.data0_db_filename, self.data0_db = self.__str_from_url(db)
                self.data0_db_type = &#34;data0&#34;
                self.data0_db_source = &#34;URL&#34;

            elif source == &#34;file&#34;:
                # e.g., &#34;data0.wrm&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    with open(db) as data0_content:
                        self.data0_db = data0_content.read()
                        self.data0_db_type = &#34;data0&#34;
                        self.data0_db_source = &#34;file&#34;
                        self.data0_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the data0 file &#39;&#34;+db+&#34;&#39;&#34;)


        def _load_csv(self, db, source=&#34;URL&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load a WORM-styled thermodynamic database CSV from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;wrm_data.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.csv_db = pd.read_csv(db)
                    self.csv_db_type = &#34;CSV&#34;
                    self.csv_db_source = &#34;file&#34;
                    self.csv_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
                self.csv_db_filename, self.csv_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.csv_db_type = &#34;CSV&#34;
                self.csv_db_source = &#34;URL&#34;

            self.csv_db = self.csv_db.astype({&#39;name&#39;:&#39;str&#39;, &#39;abbrv&#39;:&#39;str&#39;, &#39;formula&#39;:&#39;str&#39;,
                                          &#39;state&#39;:&#39;str&#39;, &#39;ref1&#39;:&#39;str&#39;, &#39;ref2&#39;:&#39;str&#39;,
                                          &#39;date&#39;: &#39;str&#39;, &#39;E_units&#39;:&#39;str&#39;,
                                          &#39;G&#39;:&#39;float&#39;, &#39;H&#39;:&#39;float&#39;, &#39;S&#39;:&#39;float&#39;,
                                          &#39;Cp&#39;:&#39;float&#39;, &#39;V&#39;:&#39;float&#39;, &#39;a1.a&#39;:&#39;float&#39;,
                                          &#39;a2.b&#39;:&#39;float&#39;, &#39;a3.c&#39;:&#39;float&#39;, &#39;a4.d&#39;:&#39;float&#39;,
                                          &#39;c1.e&#39;:&#39;float&#39;, &#39;c2.f&#39;:&#39;float&#39;,
                                          &#39;omega.lambda&#39;:&#39;float&#39;, &#39;z.T&#39;:&#39;float&#39;,
                                          &#39;azero&#39;:&#39;float&#39;, &#39;neutral_ion_type&#39;:&#39;float&#39;,
                                          &#39;dissrxn&#39;:&#39;str&#39;, &#39;tag&#39;:&#39;str&#39;,
                                          &#39;formula_ox&#39;:&#39;str&#39;, &#39;category_1&#39;:&#39;str&#39;})

            # Check that thermodynamic database input files exist and are formatted correctly.
            self._check_csv_db()
            self._remove_missing_G_species()

            self.csv_db = self._exclude_category(df=self.csv_db, df_name=self.csv_db_filename)


        def _exclude_category(self, df, df_name):
            &#34;&#34;&#34;
            Exclude entries from a df based on values in columns.
            e.g., {&#34;category_1&#34;:[&#34;organic_aq&#34;, &#34;organic_cr&#34;]}
            &#34;&#34;&#34;
            
            exclude_keys = list(self.exclude_category.keys())
            if len(exclude_keys) &gt; 0:
                for key in exclude_keys:
                    if self.verbose &gt; 0:
                        print(&#34;Excluding&#34;, str(self.exclude_category[key]), &#34;from column&#34;, str(key), &#34;in&#34;, df_name)
                        
                    if isinstance(self.exclude_category[key], list):
                        
                        idx = list(df[df[key].isin(self.exclude_category[key])].index)
                        
                        names = df[&#34;name&#34;].loc[idx]
                        
                        df = df[~df[key].isin(self.exclude_category[key])]
                        
                        for i,name in enumerate(names):
                            d = pd.DataFrame({&#39;database name&#39;: [df_name], &#39;database index&#39;: [idx[i]], &#39;name&#39;: [name], &#39;reason for rejection&#39;: [&#34;excluded by user&#34;]})
                            self.df_rejected_species = pd.concat([self.df_rejected_species, d], ignore_index=True)
                        
                    elif isinstance(self.exclude_category[key], str):
                        
                        idx = list(df[df[key] != self.exclude_category[key]].index)
                        names = df[&#34;name&#34;].loc[idx]
                        
                        df = df[~df[key] != self.exclude_category[key]]
                        
                        for i,name in enumerate(names):
                            d = pd.DataFrame({&#39;database name&#39;: [df_name], &#39;database index&#39;: [idx[i]], &#39;name&#39;: [name], &#39;reason for rejection&#39;: [&#34;excluded by user&#34;]})
                            self.df_rejected_species = pd.concat([self.df_rejected_species, d], ignore_index=True)
                    else:
                        self.err_handler.raise_exception(&#34;The parameter exclude_category must either be a string or a list.&#34;)
            return df


        def _check_csv_db(self):
            &#34;&#34;&#34;
            Check for problems in the thermodynamic database CSV.
            &#34;&#34;&#34;

            thermo_df = self.csv_db

            # does this file have the proper headers?
            required_headers = [&#34;name&#34;, &#34;abbrv&#34;, &#34;formula&#34;, &#34;state&#34;,
                                &#34;ref1&#34;, &#34;ref2&#34;, &#34;date&#34;, &#34;E_units&#34;,
                                &#34;G&#34;, &#34;H&#34;, &#34;S&#34;, &#34;Cp&#34;, &#34;V&#34;,
                                &#34;a1.a&#34;, &#34;a2.b&#34;, &#34;a3.c&#34;, &#34;a4.d&#34;, &#34;c1.e&#34;, &#34;c2.f&#34;,
                                &#34;omega.lambda&#34;, &#34;z.T&#34;,
                                &#34;azero&#34;, &#34;neutral_ion_type&#34;,
                                &#34;dissrxn&#34;, &#34;tag&#34;, &#34;formula_ox&#34;]

            missing_headers = []
            for header in required_headers:
                if header not in thermo_df.columns:
                    missing_headers.append(header)
            if len(missing_headers) &gt; 0:
                msg = (&#34;The thermodynamic database file &#34;
                       &#34;is missing one or more required columns: &#34;
                       &#34;{}&#34;.format(&#34;, &#34;.join(missing_headers))+&#34;. &#34;
                       &#34;Are these headers spelled correctly in the file?&#34;)
                self.err_handler.raise_exception(msg)

            # does Cl-, O2(g), and O2 exist in the file?
            required_species = [&#34;Cl-&#34;, &#34;O2&#34;, &#34;O2(g)&#34;]
            missing_species = []
            for species in required_species:
                if species not in list(thermo_df[&#34;name&#34;]):
                    missing_species.append(species)
            if len(missing_species) &gt; 0:
                msg = (&#34;The thermodynamic database file &#34;
                       &#34;is missing required species:&#34;
                       &#34;{}&#34;.format(missing_species)+&#34;. Default thermodynamic values&#34;
                       &#34; will be used.&#34;)
                warnings.warn(msg)

            return


        def _suppress_redox_and_generate_dissrxns(self,
                                                  suppress_redox,
                                                  exceed_Ttr=True):

            thermo_df = self.thermo_db
            
            suppress_redox = _convert_to_RVector(suppress_redox)

            # if elements are being redox-suppressed, exclude all species with a
            # formula containing one or more of the redox-suppressed elements if the
            # species does not have a formula_ox.
            # e.g., if &#34;methionine&#34; does not have a formula_ox, ensure it is excluded
            #       if sulfur is redox-suppressed.
            if len(suppress_redox) &gt; 0:
                thermo_db_no_formula_ox = thermo_df[thermo_df[&#34;formula_ox&#34;].isnull()]
                if thermo_db_no_formula_ox.shape[0] &gt; 0:
                    sp_names_to_exclude = []
                    for i,sp in enumerate(thermo_db_no_formula_ox[&#34;name&#34;]):
                        f = thermo_db_no_formula_ox.iloc[i, thermo_db_no_formula_ox.columns.get_loc(&#34;formula&#34;)]
                        f_elems = list(parse_formula(f).keys())
                        for elem in suppress_redox:
                            if elem in f_elems:
                                sp_names_to_exclude.append(sp)
                    self.exclude_category[&#34;name&#34;] = sp_names_to_exclude
                    if self.verbose &gt; 0 and len(sp_names_to_exclude) &gt; 0:
                        print(&#34;Excluding the following chemical species because &#34;
                              &#34;they contain redox-suppressed elements but do not &#34;
                              &#34;have element oxidation states given in the &#34;
                              &#34;&#39;formula_ox&#39; column of the thermodynamic database: &#34;
                              &#34;&#34;+str(sp_names_to_exclude))

            if len(self.exclude_category) &gt; 0:
                exclude_category_R =  {k:_convert_to_RVector(l) for k,l in zip(self.exclude_category.keys(), self.exclude_category.values())}
            else:
                exclude_category_R = {}
            exclude_category_R = ro.ListVector(exclude_category_R)

            self.AqEquil_instance._capture_r_output()

            r_redox_dissrxns = pkg_resources.resource_string(
                __name__, &#39;redox_and_dissrxns.r&#39;).decode(&#34;utf-8&#34;)

            ro.r(r_redox_dissrxns)
            
            thermo_df = _clean_rpy2_pandas_conversion(thermo_df)

            ro.conversion.py2rpy(thermo_df)

            self.out_list = ro.r.suppress_redox_and_generate_dissrxns(
                                   thermo_df=ro.conversion.py2rpy(thermo_df),
                                   water_model=self.water_model,
                                   exceed_Ttr=exceed_Ttr,
                                   suppress_redox=suppress_redox,
                                   exclude_category=exclude_category_R,
                                   element_df=ro.conversion.py2rpy(self.element_db),
                                   fixed_species=_convert_to_RVector(FIXED_SPECIES),
                                   verbose=self.verbose)
            
            self.AqEquil_instance._print_captured_r_output()

            thermo_df = self.out_list.rx2(&#34;thermo_df&#34;)
            thermo_df=ro.conversion.rpy2py(thermo_df)

    #         regenerated_dissrxns = out_list.rx2(&#34;dissrxns&#34;)
    #         regenerated_dissrxn_dict = {}
    #         for name in regenerated_dissrxns.names:
    #             if name != &#34;basis_list&#34;:
    #                 regenerated_dissrxn_dict[name] = regenerated_dissrxns.rx2(name)[0]


            thermo_df = _clean_rpy2_pandas_conversion(thermo_df)

            # convert E units and calculate missing GHS values
            self.thermo_db = OBIGT2eos(thermo_df, fixGHS=True, tocal=True)


def compare(*args):
    
    &#34;&#34;&#34;
    Combine two or more speciations into a single speciation object for
    comparison. The speciation object returned by this function can produce
    scatterplots, barplots, and mass contribution plots, and contains a report
    that can be browsed with `lookup`. See documentation for the functions in
    the `Speciation` class for more detail.

    Parameters
    ----------
    *args : two or more objects of class `Speciation` to compare

    Returns
    ----------
    An object of class `Speciation`.
    &#34;&#34;&#34;
    
    if all([&#34;mass_contribution&#34; in a.__dict__.keys() for a in args]):
        allow_mass_contribution = True
        mass_contribution_breaks = []
    else:
        allow_mass_contribution = False
    
    for i,sp in enumerate(args):
        if i == 0:
            sp_total = copy.deepcopy(sp)
            sp_total.sample_data = None
            if allow_mass_contribution:
                mass_contribution_breaks.append(0)
        else:
            sp_i = copy.deepcopy(sp)
            if allow_mass_contribution:
                mass_contribution_breaks.append(sp_total.report.shape[0])
            sp_total.report = pd.concat([sp_total.report, sp_i.report], axis=0, sort=False)
        

    sp_total.report.index = sp_total.report.index + (&#34;_&#34;+sp_total.report.groupby(level=0).cumcount().astype(str)).replace(&#39;_0&#39;,&#39;&#39;)
    
    if allow_mass_contribution:
        mass_contribution_breaks.append(len(sp_total.report.index))
        mc_sample_names_with_suffixes = list(sp_total.report.index)
        for i,sp in enumerate(args):
            mc_i = copy.deepcopy(sp.mass_contribution)
            
            new_sample_names = copy.copy(mc_sample_names_with_suffixes[mass_contribution_breaks[i]:mass_contribution_breaks[i+1]])
            old_sample_names = list(args[i].sample_data.keys())
            
            old_new_sample_name_dict = {old:new for old,new in zip(old_sample_names, new_sample_names)}
                
            newsample = [old_new_sample_name_dict[old] for old in mc_i[&#34;sample&#34;]]

            mc_i[&#34;sample&#34;] = newsample
            
            if i == 0:
                mc_total = mc_i
            else:
                mc_total = pd.concat([mc_total, mc_i], axis=0, sort=False)
        
        sp_total.mass_contribution = mc_total
        
    else:
        def no_mass_contrib_message(*args, **kwargs):
            print(&#34;Mass contributions cannot be compared between these speciations &#34;
                  &#34;because one or more calculations lack mass contribution data.&#34;)
        sp_total.plot_mass_contribution = no_mass_contrib_message
                
    
    return sp_total


class Speciation(object):
    
    &#34;&#34;&#34;
    Stores the output of a speciation calculation.
    
    Parameters
    ----------
    args : dict
        Arguments inherited from class AqEquil.
    
    hide_traceback : bool, default True
        Hide traceback message when encountering errors handled by this class?
        When True, error messages handled by this class will be short and to
        the point.
    
    Attributes
    ----------
    input : pd.DataFrame
        Pandas dataframe containing user-supplied sample chemistry data.
    
    mass_contribution : pd.DataFrame
        Pandas dataframe containing basis species contributions to mass balance
        of aqueous species.
    
    batch_3o : rpy2 ListVector
        An rpy2 ListVector (R object) containing speciation results, in case
        analysis in R is preferred.
    
    report : pd.DataFrame
        Pandas dataframe reporting major results of speciation calculation in
        across all samples.
    
    report_divs : rpy2 ListVector
        An rpy2 ListVector of column names within the different sections of the
        speciation report.
    
    sample_data : dict
        Dictionary with sample names as keys and speciation results as values.
    
    &#34;&#34;&#34;
    
    # get functions from the AqEquil class
    _interpolate_logK = AqEquil._interpolate_logK 
    plot_logK_fit = AqEquil.plot_logK_fit
    
    def __init__(self, args, hide_traceback=True):
        self.err_handler = Error_Handler(clean=hide_traceback)
        
        self.reactions_for_plotting = None # stores formatted reactions for plotting results of affinity and energy supply calculations
        for k in args:
            setattr(self, k, args[k])

    def __getitem__(self, item):
         return getattr(self, item)
    
    @staticmethod
    def __unique(seq):
        &#34;&#34;&#34;
        Provide a sequence, get a list of non-repeating elements in the same order.
        &#34;&#34;&#34;
        seen = set()
        seen_add = seen.add
        return [x for x in seq if not (x in seen or seen_add(x))]

    
    def save(self, filename, messages=True):
        &#34;&#34;&#34;
        Save the speciation as a &#39;.speciation&#39; file to your current working
        directory. This file can be loaded with `AqEquil.load(filename)`.
        
        Parameters
        ----------
        filename : str
            The desired name of the file.
            
        messages : str
            Print a message confirming the save?
        &#34;&#34;&#34;
        
        if filename[-11:] != &#39;.speciation&#39;:
            filename = filename + &#39;.speciation&#39;
        
        with open(filename, &#39;wb&#39;) as handle:
            dill.dump(self, handle, protocol=dill.HIGHEST_PROTOCOL)
            if messages:
                print(&#34;Saved as &#39;{}&#39;&#34;.format(filename))

    
    @staticmethod
    def _save_figure(fig, save_as, save_format, save_scale, plot_width, plot_height, ppi):
        if isinstance(save_format, str) and save_format not in [&#39;png&#39;, &#39;jpg&#39;, &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, &#39;html&#39;]:
            self.err_handler.raise_exception(&#34;{}&#34;.format(save_format)+&#34; is an unrecognized &#34;
                            &#34;save format. Supported formats include &#39;png&#39;, &#34;
                            &#34;&#39;jpg&#39;, &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#34;
                            &#34;&#39;json&#39;, or &#39;html&#39;&#34;)
            
        if isinstance(save_format, str):
            if not isinstance(save_as, str):
                save_as = &#34;newplot&#34;
            if save_format==&#34;html&#34;:
                fig.write_html(save_as+&#34;.html&#34;)
                print(&#34;Saved figure as {}&#34;.format(save_as)+&#34;.html&#34;)
                save_format = &#39;png&#39;
            elif save_format in [&#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;]:
                pio.full_figure_for_development(fig, warn=False)
                pio.write_image(fig, save_as+&#34;.&#34;+save_format, format=save_format, scale=save_scale,
                                width=plot_width*ppi, height=plot_height*ppi)
                print(&#34;Saved figure as {}&#34;.format(save_as)+&#34;.&#34;+save_format)
                save_format = &#34;png&#34;
            else:
                pio.write_image(fig, save_as+&#34;.&#34;+save_format, format=save_format, scale=save_scale,
                                width=plot_width*ppi, height=plot_height*ppi)
                print(&#34;Saved figure as {}&#34;.format(save_as)+&#34;.&#34;+save_format)
        else:
            save_format = &#34;png&#34;
            
        return save_as, save_format
    
    
    @staticmethod
    def __get_unit_info(subheader):
        
        unit_name_dict = {
            &#34;pH&#34; : (&#34;&#34;, &#34;pH&#34;),
            &#34;ppm&#34; : (&#34;&#34;, &#34;ppm&#34;),
            &#34;ppb&#34; : (&#34;&#34;, &#34;ppb&#34;),
            &#34;mg/L&#34; : (&#34;&#34;, &#34;mg/L&#34;),
            &#34;degC&#34; : (&#34;temperature&#34;, &#34;C&#34;),
            &#34;log_molality&#34; : (&#34;log molality&#34;, &#34;log(mol/kg)&#34;),
            &#34;Molality&#34; : (&#34;molality&#34;, &#34;mol/kg&#34;),
            &#34;molality&#34; : (&#34;molality&#34;, &#34;mol/kg&#34;),
            &#34;molal&#34; : (&#34;molality&#34;, &#34;mol/kg&#34;),
            &#34;log_activity&#34; : (&#34;log activity&#34;, &#34;&#34;),
            &#34;Log activity&#34; : (&#34;log activity&#34;, &#34;&#34;),
            &#34;mg/kg.sol&#34; : (&#34;&#34;, &#34;mg solute per kg solution&#34;),
            &#34;Alk., eq/kg.H2O&#34; : (&#34;alkalinity&#34;, &#34;eq/kg&#34;),
            &#34;Alk., eq/L&#34; : (&#34;alkalinity&#34;, &#34;eq/L&#34;),
            &#34;Alk., eq/kg.sol&#34; : (&#34;alkalinity&#34;, &#34;eq/kg solution&#34;),
            &#34;Alk., mg/L CaCO3&#34; : (&#34;alkalinity&#34;, &#34;mg/L CaCO3&#34;),
            &#34;Alk., mg/L HCO3-&#34; : (&#34;alkalinity&#34;, &#34;mg/L HCO3-&#34;),
            &#34;pX&#34; : (&#34;-(log activity)&#34;, &#34;-log(mol/kg)&#34;),
            &#34;activity&#34; : (&#34;activity&#34;, &#34;&#34;),
            &#34;log_gamma&#34; : (&#34;log gamma&#34;, &#34;&#34;),
            &#34;gamma&#34; : (&#34;gamma&#34;, &#34;&#34;),
            &#34;affinity_kcal&#34; : (&#34;affinity&#34;, &#34;kcal/mol&#34;),
            &#34;%&#34; : (&#34;&#34;, &#34;%&#34;),
            &#34;Eh_volts&#34; : (&#34;Eh&#34;, &#34;volts&#34;),
            &#34;eq/kg.H2O&#34; : (&#34;charge&#34;, &#34;eq/kg&#34;),
            &#34;logfO2&#34; : (&#34;&#34;, &#34;&#34;),
            &#34;cal/mol e-&#34; : (&#34;affinity&#34;, &#34;cal/mol e-&#34;),
            &#34;cal/kg.H2O&#34; : (&#34;energy supply&#34;, &#34;cal/kg H2O&#34;),
            &#34;Log ion-H+ activity ratio&#34; : (&#34;Log ion-H+ activity ratio&#34;, &#34;&#34;),
            &#34;log_fugacity&#34; : (&#34;log fugacity&#34;, &#34;log(bar)&#34;),
            &#34;fugacity&#34; : (&#34;fugacity&#34;, &#34;bar&#34;),
            &#34;bar&#34; : (&#34;&#34;, &#34;bar&#34;),
        }
        
        out = unit_name_dict.get(subheader)
        
        return out[0], out[1]

    
    def lookup(self, col=None):
        
        &#34;&#34;&#34;
        Look up desired columns in the speciation report.
        
        Parameters
        ----------
        col : str or list of str
            Leave blank to get a list of section names in the report:
            ```speciation.lookup()```
            Provide the name of a section to look up the names of columns in
            that section of the report:
            ```speciation.lookup(&#34;aq_distribution&#34;)```
            Provide a column name (or a list of column names) to retrieve the
            column from the report:
            ```speciation.lookup([&#34;Temperature&#34;, &#34;O2&#34;])```
            
        Returns
        ----------
        Pandas dataframe or list of str
            If a column name (or list of column names) is provided, returns the
            speciation report with only the desired column(s). Otherwise returns
            a list of section names (if no arguments are provided), or a list of
            columns in a section (if a section name is provided).
        &#34;&#34;&#34;
        
        names_length = len(self.report_divs.names)
        
        if col==None and names_length&gt;0:
            return list(self.report_divs.names)
        
        if names_length&gt;0:
            if col in list(self.report_divs.names):
                return list(self.report_divs.rx2(col))
        
        if isinstance(col, str):
            col = [col]
        
        return self.report.iloc[:, self.report.columns.get_level_values(0).isin(set(col))]
    
    
    def __convert_aq_units_to_log_friendly(self, species, rows):

        col_data = self.lookup(species)
        
        col_data = col_data.loc[rows]
        
        if col_data.columns.get_level_values(1) == &#39;log_activity&#39;:
            y = [10**float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = &#39;activity&#39;
        elif col_data.columns.get_level_values(1) == &#39;log_molality&#39;:
            y = [10**float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = &#39;molality&#39;
        elif col_data.columns.get_level_values(1) == &#39;log_gamma&#39;:
            y = [10**float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = &#39;gamma&#39;
        elif col_data.columns.get_level_values(1) == &#39;log_fugacity&#39;:
            y = [10**float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = &#39;fugacity&#39;
        else:
            y = [float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = col_data.columns.get_level_values(1)[0]
        return y, out_unit
    
    
    def plot_mineral_saturation(self, sample_name, title=None,
                                mineral_sat_type=&#34;affinity&#34;,
                                plot_width=4, plot_height=3, ppi=122,
                                colors=[&#34;blue&#34;, &#34;orange&#34;],
                                save_as=None, save_format=None, save_scale=1,
                                interactive=True, plot_out=False):
        &#34;&#34;&#34;
        Vizualize mineral saturation states in a sample as a bar plot.
        
        Parameters
        ----------
        sample_name : str
            Name of the sample to plot.
            
        title : str, optional
            Title of the plot.
        
        mineral_sat_type : str, default &#34;affinity&#34;
            Metric for mineral saturation state to plot. Can be &#34;affinity&#34; or
            &#34;logQoverK&#34;.
        
        colors : list of two str, default [&#34;blue&#34;, &#34;orange&#34;]
            Sets the color of the bars representing supersaturated
            and undersaturated states, respectively.
            
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.

        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.

        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
        &#34;&#34;&#34;
        
        if sample_name not in self.report.index:
            msg = (&#34;Could not find &#39;{}&#39;&#34;.format(sample_name)+&#34; among sample &#34;
                   &#34;names in the speciation report. Sample names include &#34;
                   &#34;{}&#34;.format(list(self.report.index)))
            self.err_handler.raise_exception(msg)
        
        if isinstance(self.sample_data[sample_name].get(&#39;mineral_sat&#39;, None), pd.DataFrame):
            mineral_data = self.sample_data[sample_name][&#39;mineral_sat&#39;][mineral_sat_type].astype(float).sort_values(ascending=False)
            x = mineral_data.index
        else:
            msg = (&#34;This sample does not have mineral saturation state data.&#34;
                   &#34;To generate this data, ensure get_mineral_sat=True when &#34;
                   &#34;running speciate(), or ensure this sample has &#34;
                   &#34;mineral-forming basis species.&#34;)
            self.err_handler.raise_exception(msg)
        
        color_list = [colors[0] if m &gt;= 0 else colors[1] for m in mineral_data]
            
        if mineral_sat_type == &#34;affinity&#34;:
            ylabel = &#39;affinity, kcal/mol&#39;
        if mineral_sat_type == &#34;logQoverK&#34;:
            ylabel = &#39;logQ/K&#39;
        
        if title==None:
            title = sample_name + &#34; mineral saturation index&#34;
        
        df = pd.DataFrame(mineral_data)

        fig = px.bar(df, x=df.index, y=&#34;affinity&#34;,
            height=plot_height*ppi, width=plot_width*ppi,
            labels={&#39;affinity&#39;: ylabel}, template=&#34;simple_white&#34;)
        
        fig.update_traces(hovertemplate = &#34;%{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&#34;,
                          marker_color=color_list)
        
        fig.update_layout(xaxis_tickangle=-45, xaxis_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                          margin={&#34;t&#34;:40},
                          xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True, &#39;exponentformat&#39;:&#39;power&#39;})
        
        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)

        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                             &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                             &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                             &#39;toggleSpikelines&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                             &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                             &#39;filename&#39;: save_as,
                                             &#39;height&#39;: plot_height*ppi,
                                             &#39;width&#39;: plot_width*ppi,
                                             &#39;scale&#39;: save_scale,
                                          },
                 }
        if not interactive:
            config[&#39;staticPlot&#39;] = True

        if plot_out:
            return fig
        else:
            fig.show(config=config)

    

    def barplot(self, y=&#34;pH&#34;, title=None, convert_log=True, show_missing=True,
                plot_width=4, plot_height=3, ppi=122, colormap=&#34;WORM&#34;,
                save_as=None, save_format=None, save_scale=1,
                interactive=True, plot_out=False):
        
        &#34;&#34;&#34;
        Show a bar plot to vizualize one or more variables across all samples.
        
        Parameters
        ----------
        y : str or list of str, default &#34;pH&#34;
            Name (or list of names) of the variables to plot. Valid variables
            are columns in the speciation report.

        title : str, optional
            Title of the plot.
            
        convert_log : bool, default True
            Convert units &#34;log_activity&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, and
            &#34;log_fugacity&#34; to &#34;activity&#34;, &#34;molality&#34;, &#34;gamma&#34;, and &#34;fugacity&#34;,
            respectively?
        
        show_missing : bool, default True
            Show samples that do not have bars?
        
        plot_width, plot_height : numeric, default 4 by 3
            Width and height of the plot, in inches.

        ppi : numeric, default 122
            Pixels per inch. Along with `plot_width` and `plot_height`,
            determines the size of interactive plots.
        
        colormap : str, default &#34;WORM&#34;
            Name of the colormap to color plotted data. Accepts &#34;WORM&#34;,
            &#34;colorblind&#34;, or matplotlib colormaps.
            See https://matplotlib.org/stable/tutorials/colors/colormaps.html
            The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
            Color blindness. Nat Methods 8, 441 (2011).
            https://doi.org/10.1038/nmeth.1618
            
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.
        
        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.

        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
            
        Returns
        -------
        fig : Plotly figure object
            A figure object is returned if `plot_out` is true. Otherwise, a
            figure is simply displayed.
        &#34;&#34;&#34;

        if not isinstance(y, list):
            y = [y]

        colors = _get_colors(colormap, len(y))

        # convert rgba to hex
        colors = [matplotlib.colors.rgb2hex(c) for c in colors]

        # map each species to its color, e.g.,
        # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
        dict_species_color = {sp:color for sp,color in zip(y, colors)}
        
        # html format color dict key names
        dict_species_color = {chemlabel(k):v for k,v in dict_species_color.items()}
            
        y_cols = self.lookup(y)

        if not show_missing:
            y_cols = y_cols.dropna(how=&#39;all&#39;) # this df will keep subheaders
        x = y_cols.index # names of samples

        df = self.lookup([&#34;name&#34;]+y).copy()
        if not show_missing:
            df = df.dropna(how=&#39;all&#39;) # this df will lose subheaders (flattened)
        df.loc[:, &#34;name&#34;] = df.index
        df.columns = df.columns.get_level_values(0)

        
        for i, yi in enumerate(y):
            y_col = y_cols.iloc[:, y_cols.columns.get_level_values(0)==yi]

            try:
                subheader = y_col.columns.get_level_values(1)[0]
            except:
                msg = (&#34;Could not find &#39;{}&#39; &#34;.format(yi)+&#34;in the speciation &#34;
                       &#34;report. Available variables include &#34;
                      &#34;{}&#34;.format(list(set(self.report.columns.get_level_values(0)))))
                self.err_handler.raise_exception(msg)
            try:
                unit_type, unit = self.__get_unit_info(subheader)
            except:
                unit_type = &#34;&#34;
                unit = &#34;&#34;
                
            try:
                y_vals = [float(y0[0]) if y0[0] != &#39;NA&#39; else float(&#34;nan&#34;) for y0 in y_col.values.tolist()]
            except:
                msg = (&#34;One or more the values belonging to &#34;
                       &#34;&#39;{}&#39; are non-numeric and cannot be plotted.&#34;.format(y_col.columns.get_level_values(0)[0]))
                self.err_handler.raise_exception(msg)

            if convert_log and [abs(y0) for y0 in y_vals] != y_vals: # convert to bar-friendly units if possible
                if subheader in [&#34;log_activity&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, &#34;log_fugacity&#34;]:
                    y_plot, out_unit = self.__convert_aq_units_to_log_friendly(yi, rows=x)
                    unit_type, unit = self.__get_unit_info(out_unit)
                else:
                    y_plot = y_vals
            else:
                y_plot = y_vals

            if i == 0:
                subheader_previous = subheader
                unit_type_previous = unit_type
            if unit_type != unit_type_previous and i != 0:
                
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(unit, yi_previous, unit_type_previous)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
            elif &#34;activity&#34; in subheader.lower() and &#34;molality&#34; in subheader_previous.lower():
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(&#34;activity&#34;, yi_previous, &#34;molality&#34;)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
            elif &#34;molality&#34; in subheader.lower() and &#34;activity&#34; in subheader_previous.lower():
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(&#34;molality&#34;, yi_previous, &#34;activity&#34;)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)

            yi_previous = copy.deepcopy(yi)
            unit_type_previous = copy.deepcopy(unit_type)
            subheader_previous = copy.deepcopy(subheader)
            
            df.loc[:, yi] = y_plot


        if len(y) &gt; 1:
            if unit != &#34;&#34;:
                ylabel = &#34;{} [{}]&#34;.format(unit_type, unit)
            else:
                ylabel = unit_type

        else:
            if &#39;pH&#39; in y:
                ylabel = &#39;pH&#39;
            elif &#39;Temperature&#39; in y:
                ylabel = &#39;Temperature [C]&#39;
            else:
                if unit != &#34;&#34;:
                    ylabel = &#34;{} {} [{}]&#34;.format(chemlabel(y[0]), unit_type, unit)
                else:
                    ylabel = &#34;{} {}&#34;.format(chemlabel(y[0]), unit_type)

        
        df = pd.melt(df, id_vars=[&#34;name&#34;], value_vars=y)
        df = df.rename(columns={&#34;Sample&#34;: &#34;y_variable&#34;, &#34;value&#34;: &#34;y_value&#34;})

        df[&#39;y_variable&#39;] = df[&#39;y_variable&#39;].apply(chemlabel)
        
        
        if (unit_type == &#34;energy supply&#34; or unit_type == &#34;affinity&#34;) and isinstance(self.affinity_energy_formatted_reactions, pd.DataFrame):
            
            # get formatted reactions to display
            if not isinstance(self.reactions_for_plotting, pd.DataFrame):

                self.reactions_for_plotting = self.show_redox_reactions(formatted=True,
                                                                       charge_sign_at_end=False,
                                                                       show=False, simplify=True)

            y_find = [yi.replace(&#34;_energy&#34;, &#34;&#34;).replace(&#34;_affinity&#34;, &#34;&#34;) for yi in y]
            
            rxns = self.reactions_for_plotting.loc[y_find, :][&#34;reaction&#34;].tolist()
            
            # get the formatted reactions in the right order, then add as a
            # column in df
            formatted_rxn_list = []
            for rxn in rxns:
                for i in range(0,len(x)):
                    formatted_rxn_list.append(rxn)
            df[&#34;formatted_rxns&#34;] = formatted_rxn_list

            if len(y) == 1:
                ylabel = &#34;{}&lt;br&gt;{} [{}]&#34;.format(chemlabel(y_find[0]), unit_type, unit)
            
            # customdata for displaying reactions has to be here instead of in update_traces
            fig = px.bar(df, x=&#34;name&#34;, y=&#34;y_value&#34;,
                height=plot_height*ppi, width=plot_width*ppi,
                color=&#39;y_variable&#39;, barmode=&#39;group&#39;,
                labels={&#39;y_value&#39;: ylabel}, template=&#34;simple_white&#34;,
                color_discrete_map=dict_species_color, custom_data=[&#39;formatted_rxns&#39;])
            
            fig.update_traces(
                hovertemplate = &#34;%{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&lt;br&gt;%{customdata}&#34;)

        else:
            
            fig = px.bar(df, x=&#34;name&#34;, y=&#34;y_value&#34;,
                height=plot_height*ppi, width=plot_width*ppi,
                color=&#39;y_variable&#39;, barmode=&#39;group&#39;,
                labels={&#39;y_value&#39;: ylabel}, template=&#34;simple_white&#34;,
                color_discrete_map=dict_species_color)
            
            fig.update_traces(hovertemplate = &#34;%{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&#34;)

        fig.update_layout(xaxis_tickangle=-45, xaxis_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                          legend_title=None, margin={&#34;t&#34;: 40},
                          xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True, &#39;exponentformat&#39;:&#39;power&#39;})
        if len(y) == 1:
            fig.update_layout(showlegend=False)

        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)
            
        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                             &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                             &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                             &#39;toggleSpikelines&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                             &#39;format&#39;: save_format,
                                             &#39;filename&#39;: save_as,
                                             &#39;height&#39;: plot_height*ppi,
                                             &#39;width&#39;: plot_width*ppi,
                                             &#39;scale&#39;: save_scale,
                                           },
                  }
        if not interactive:
            config[&#39;staticPlot&#39;] = True

        if plot_out:
            return fig
        else:
            fig.show(config=config)

        
    def scatterplot(self, x=&#34;pH&#34;, y=&#34;Temperature&#34;, title=None,
                          plot_width=4, plot_height=3, ppi=122,
                          fill_alpha=0.7, point_size=10,
                          ylab=None, lineplot=False,
                          colormap=&#34;WORM&#34;, save_as=None, save_format=None,
                          save_scale=1, interactive=True, plot_out=False):
        
        &#34;&#34;&#34;
        Vizualize two or more sample variables with a scatterplot.
        
        Parameters
        ----------
        x, y : str, default for x is &#34;pH&#34;, default for y is &#34;Temperature&#34;
            Names of the variables to plot against each other. Valid variables
            are columns in the speciation report. `y` can be a list of
            of variable names for a multi-series scatterplot.

        title : str, optional
            Title of the plot.
        
        plot_width, plot_height : numeric, default 4 by 3
            Width and height of the plot, in inches. Size of interactive plots
            is also determined by pixels per inch, set by the parameter `ppi`.
        
        ppi : numeric, default 122
            Pixels per inch. Along with `plot_width` and `plot_height`,
            determines the size of interactive plots.
        
        fill_alpha : numeric, default 0.7
            Transparency of scatterpoint area fill.
        
        point_size : numeric, default 10
            Size of scatterpoints.
        
        colormap : str, default &#34;WORM&#34;
            Name of the colormap to color the plotted data. Accepts &#34;WORM&#34;,
            &#34;colorblind&#34;, or matplotlib colormaps.
            See https://matplotlib.org/stable/tutorials/colors/colormaps.html
            The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
            Color blindness. Nat Methods 8, 441 (2011).
            https://doi.org/10.1038/nmeth.1618
            
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.

        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.
    
        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
            
        Returns
        -------
        fig : Plotly figure object
            A figure object is returned if `plot_out` is true. Otherwise, a
            figure is simply displayed.
        &#34;&#34;&#34;

        if not isinstance(y, list):
            y = [y]
        
        if not isinstance(x, str):
            self.err_handler.raise_exception(&#34;x must be a string.&#34;)
        
        x_col = self.lookup(x)
        
        try:
            xsubheader = x_col.columns.get_level_values(1)[0]
        except:
            msg = (&#34;Could not find &#39;{}&#39; &#34;.format(x)+&#34;in the speciation &#34;
                   &#34;report. Available variables include &#34;
                   &#34;{}&#34;.format(list(set(self.report.columns.get_level_values(0)))))
            self.err_handler.raise_exception(msg)
            
        try:
            x_plot = [float(x0[0]) if x0[0] != &#39;NA&#39; else float(&#34;nan&#34;) for x0 in x_col.values.tolist()]
        except:
            msg = (&#34;One or more the values belonging to &#34;
                   &#34;&#39;{}&#39; are non-numeric and cannot be plotted.&#34;.format(x_col.columns.get_level_values(0)[0]))
            self.err_handler.raise_exception(msg)
        
        try:
            xunit_type, xunit = self.__get_unit_info(xsubheader)
        except:
            xunit_type = &#34;&#34;
            xunit = &#34;&#34;

        colors = _get_colors(colormap, len(y), alpha=fill_alpha)
        
        for i, yi in enumerate(y):
            y_col = self.lookup(yi)
            
            try:
                subheader = y_col.columns.get_level_values(1)[0]
            except:
                msg = (&#34;Could not find &#39;{}&#39; &#34;.format(yi)+&#34;in the speciation &#34;
                       &#34;report. Available variables include &#34;
                      &#34;{}&#34;.format(list(set(self.report.columns.get_level_values(0)))))
                self.err_handler.raise_exception(msg)
            try:
                unit_type, unit = self.__get_unit_info(subheader)
            except:
                unit_type = &#34;&#34;
                unit = &#34;&#34;
            
            try:
                y_plot = [float(y0[0]) if y0[0] != &#39;NA&#39; else float(&#34;nan&#34;) for y0 in y_col.values.tolist()]
            except:
                msg = (&#34;One or more the values belonging to &#34;
                       &#34;&#39;{}&#39; are non-numeric and cannot be plotted.&#34;.format(y_col.columns.get_level_values(0)[0]))
                self.err_handler.raise_exception(msg)
                
            if i == 0:
                subheader_previous = subheader
                unit_type_previous = unit_type
            if unit_type != unit_type_previous and i != 0:
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(unit_type, yi_previous, unit_type_previous)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
            elif &#34;activity&#34; in subheader.lower() and &#34;molality&#34; in subheader_previous.lower():
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(&#34;activity&#34;, yi_previous, &#34;molality&#34;)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
            elif &#34;molality&#34; in subheader.lower() and &#34;activity&#34; in subheader_previous.lower():
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(&#34;molality&#34;, yi_previous, &#34;activity&#34;)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
                
            yi_previous = copy.deepcopy(yi)
            unit_type_previous = copy.deepcopy(unit_type)
            subheader_previous = copy.deepcopy(subheader)

        if len(y) &gt; 1:
            if unit != &#34;&#34;:
                ylabel = &#34;{} [{}]&#34;.format(unit_type, unit)
            else:
                ylabel = unit_type
        else:
            if &#39;pH&#39; in y:
                ylabel = &#39;pH&#39;
            elif &#39;Temperature&#39; in y:
                ylabel = &#39;Temperature [C]&#39;
            else:
                y_formatted = chemlabel(y[0])
                if unit != &#34;&#34;:
                    ylabel = &#34;{} {} [{}]&#34;.format(y_formatted, unit_type, unit)
                else:
                    ylabel = &#34;{} {}&#34;.format(y_formatted, unit_type)
        
        if x == &#39;pH&#39;:
            xlabel = &#39;pH&#39;
        elif x == &#39;Temperature&#39;:
            xlabel = &#39;Temperature [C]&#39;
        else:
            x_formatted = chemlabel(x)
            if xunit != &#34;&#34;:
                xlabel = &#34;{} {} [{}]&#34;.format(x_formatted, xunit_type, xunit)
            else:
                xlabel = &#34;{} {}&#34;.format(x_formatted, xunit_type)

        # convert rgba to hex
        colors = [matplotlib.colors.rgb2hex(c) for c in colors]

        # map each species to its color, e.g.,
        # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
        dict_species_color = {sp:color for sp,color in zip(y, colors)}
        
        # html format color dict key names
        dict_species_color = {chemlabel(k):v for k,v in dict_species_color.items()}
        
        df = self.lookup([&#34;name&#34;, x]+y).copy()
        df.loc[:, &#34;name&#34;] = df.index
        df.columns = df.columns.get_level_values(0)
        df = pd.melt(df, id_vars=[&#34;name&#34;, x], value_vars=y)
        df = df.rename(columns={&#34;Sample&#34;: &#34;y_variable&#34;, &#34;value&#34;: &#34;y_value&#34;})
        
        if (unit_type == &#34;energy supply&#34; or unit_type == &#34;affinity&#34;) and isinstance(self.reactions_for_plotting, pd.DataFrame):
            
            # get formatted reactions to display
            if not isinstance(self.reactions_for_plotting, pd.DataFrame):
                self.reactions_for_plotting = self.show_redox_reactions(formatted=True,
                                                                       charge_sign_at_end=False,
                                                                       show=False, simplify=True)
            
            y_find = [yi.replace(&#34;_energy&#34;, &#34;&#34;).replace(&#34;_affinity&#34;, &#34;&#34;) for yi in y]
            
            
            rxns = self.reactions_for_plotting.loc[y_find, :][&#34;reaction&#34;].tolist()
            rxn_dict = {rxn_name:rxn for rxn_name,rxn in zip(y, rxns)}

            if len(y) == 1:
                ylabel = &#34;{}&lt;br&gt;{} [{}]&#34;.format(chemlabel(y_find[0]), unit_type, unit)
            
            df[&#34;formatted_rxn&#34;] = df[&#34;y_variable&#34;].map(rxn_dict)
        else:
            df[&#34;formatted_rxn&#34;] = &#34;&#34;
        
        df[&#39;y_variable&#39;] = df[&#39;y_variable&#39;].apply(chemlabel)
        
        if ylab != None:
            ylabel=ylab
        
        if lineplot:
            fig = px.line(df, x=x, y=&#34;y_value&#34;, color=&#34;y_variable&#34;,
                             hover_data=[x, &#34;y_value&#34;, &#34;y_variable&#34;, &#34;name&#34;, &#34;formatted_rxn&#34;],
                             width=plot_width*ppi, height=plot_height*ppi,
                             labels={x: xlabel,  &#34;y_value&#34;: ylabel},
                             category_orders={&#34;species&#34;: y},
                             color_discrete_map=dict_species_color,
                             custom_data=[&#39;name&#39;, &#39;formatted_rxn&#39;],
                             template=&#34;simple_white&#34;)
        else:
            fig = px.scatter(df, x=x, y=&#34;y_value&#34;, color=&#34;y_variable&#34;,
                             hover_data=[x, &#34;y_value&#34;, &#34;y_variable&#34;, &#34;name&#34;, &#34;formatted_rxn&#34;],
                             width=plot_width*ppi, height=plot_height*ppi,
                             labels={x: xlabel,  &#34;y_value&#34;: ylabel},
                             category_orders={&#34;species&#34;: y},
                             color_discrete_map=dict_species_color,
                             opacity=fill_alpha,
                             custom_data=[&#39;name&#39;, &#39;formatted_rxn&#39;],
                             template=&#34;simple_white&#34;)
        
        
        fig.update_traces(marker=dict(size=point_size),
                          hovertemplate = &#34;%{customdata[0]}&lt;br&gt;&#34;+xlabel+&#34;: %{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&lt;br&gt;%{customdata[1]}&#34;)
        fig.update_layout(legend_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                          margin={&#34;t&#34;: 40},
                          yaxis={&#39;exponentformat&#39;:&#39;power&#39;})
        if len(y) == 1:
            fig.update_layout(showlegend=False)
            
        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)

        config = {&#39;displaylogo&#39;: False, &#39;scrollZoom&#39;: True,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;select2d&#39;, &#39;lasso2d&#39;, &#39;toggleSpikelines&#39;, &#39;resetScale2d&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                           &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                           &#39;filename&#39;: save_as,
                                           &#39;height&#39;: plot_height*ppi,
                                           &#39;width&#39;: plot_width*ppi,
                                           &#39;scale&#39;: save_scale,
                                           },
                 }

        if not interactive:
            config[&#39;staticPlot&#39;] = True
        
        if plot_out:
            return fig
        else:
            fig.show(config=config)

            
    def plot_mass_contribution(self, basis, title=None, sort_by=None,
                                     ascending=True, sort_y_by=None, width=0.9,
                                     colormap=&#34;WORM&#34;, sample_label = &#34;sample&#34;,
                                     colors=None,
                                     plot_width=4, plot_height=3, ppi=122,
                                     save_as=None, save_format=None,
                                     save_scale=1, interactive=True,
                                     plot_out=False):
        
        &#34;&#34;&#34;
        Plot basis species contributions to mass balance of aqueous species
        across all samples.
        
        Parameters
        ----------
        basis : str
            Name of the basis species.

        title : str, optional
            Title of the plot.
            
        sort_by : str, optional
            Name of the variable used to sort samples. Variable names must be
            taken from the speciation report column names. No sorting is done by
            default.
        
        ascending : bool, default True
            Should sample sorting be in ascending order? Descending if False.
            Ignored unless `sort_by` is defined.
        
        sort_y_by : list of str or &#39;alphabetical&#39;, optional
            List of species names in the order that they should be stacked, from
            the bottom of the plot to the top. &#39;alphabetical&#39; will sort species
            alphabetically.
        
        width : float, default 0.9
            Width of bars. No space between bars if width=1.0.
        
        colormap : str, default &#34;WORM&#34;
            Name of the colormap to color the scatterpoints. Accepts &#34;WORM&#34;,
            &#34;colorblind&#34;, or matplotlib colormaps.
            See https://matplotlib.org/stable/tutorials/colors/colormaps.html
            The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
            Color blindness. Nat Methods 8, 441 (2011).
            https://doi.org/10.1038/nmeth.1618
        
        sample_label : str, default &#34;sample&#34;
            Name of the label that appears when hovering over an element in the
            interactive mass contribution plot. By default, this is &#34;sample&#34;.
            However, other words might be more appropriate to describe the
            calculations you are performing. For instance, if you are comparing
            reaction progress, `sample_label = &#34;Xi&#34;` might be more appropriate.
        
        plot_width, plot_height : numeric, default 4 by 3
            Width and height of the plot, in inches. Size of interactive plots
            is also determined by pixels per inch, set by the parameter `ppi`.
            
        ppi : numeric, default 122
            Pixels per inch. Along with `plot_width` and `plot_height`,
            determines the size of interactive plots.
        
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.

        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.
    
        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
            
        Returns
        -------
        fig : Plotly figure object
            A figure object is returned if `plot_out` is true. Otherwise, a
            figure is simply displayed.
        &#34;&#34;&#34;
        
        try:
            self.mass_contribution
        except:
            msg = (&#34;Results for basis species contributions to aqueous mass &#34;
                   &#34;balance could not be found. Ensure that &#34;
                   &#34;get_mass_contribution = True when running speciate().&#34;)
            self.err_handler.raise_exception(msg)
            
        if basis not in set(self.mass_contribution[&#39;basis&#39;]):
            msg = (&#34;The basis species {} &#34;.format(basis)+&#34;could not be found &#34;
                   &#34;among available basis species: &#34;
                   &#34;{}&#34;.format(str(list(set(self.mass_contribution[&#39;basis&#39;])))))
            self.err_handler.raise_exception(msg)
            
        df_sp = copy.deepcopy(self.mass_contribution.loc[self.mass_contribution[&#39;basis&#39;] == basis])
        
        if isinstance(sort_y_by, list):
            for species in sort_y_by:
                if species not in df_sp[&#34;species&#34;]:
                    for sample in set(df_sp[&#34;sample&#34;]):
                        df2 = pd.DataFrame({&#39;sample&#39;:[sample], &#39;basis&#39;:[basis], &#39;species&#39;:[species], &#39;factor&#39;:[None], &#39;molality&#39;:[None], &#39;percent&#39;:[0]})
                        df_sp = pd.concat([df_sp, df2], ignore_index=True)
    
        if sort_by != None:
            if sort_by in self.report.columns.get_level_values(0):
                sort_col = self.lookup(sort_by)
                sort_by_unit = sort_col.columns.get_level_values(1)[0]
                sort_index = sort_col.sort_values([(sort_by, sort_by_unit)], ascending=ascending).index
                
                df_list = []
                for i in sort_index:
                    df_list.append(df_sp[df_sp[&#39;sample&#39;]==i])

                df_sp = pd.concat(df_list)
                
            else:
                msg = (&#34;Could not find {}&#34;.format(sort_by)+&#34; in the &#34;
                       &#34;speciation report. Available variables include &#34;
                       &#34;{}&#34;.format(list(self.report.columns.get_level_values(0))))
                self.err_handler.raise_exception(msg)
        
        df_sp[&#39;percent&#39;] = df_sp[&#39;percent&#39;].astype(float)
        
        unique_species = self.__unique(df_sp[&#34;species&#34;])
        
        if &#34;Other&#34; in unique_species:

            unique_species.append(unique_species.pop(unique_species.index(&#34;Other&#34;)))
        
        labels = self.__unique(df_sp[&#34;sample&#34;])

        bottom = np.array([0]*len(labels))

        if sort_y_by != None:
            if isinstance(sort_y_by, list):
                if len(unique_species) == len(sort_y_by):
                    if len([s for s in unique_species if s in sort_y_by]) == len(unique_species) and len([s for s in sort_y_by if s in unique_species]) == len(unique_species):
                        unique_species = sort_y_by
                    else:
                        valid_needed = [s for s in unique_species if s not in sort_y_by]
                        invalid = [s for s in sort_y_by if s not in unique_species]
                        msg = (&#34;sort_y_by is missing the following species: &#34;
                               &#34;{}&#34;.format(valid_needed)+&#34; and was provided &#34;
                               &#34;these invalid species: {}&#34;.format(invalid))
                        self.err_handler.raise_exception(msg)
                        
                elif len(sort_y_by) &lt; len(unique_species):
                    msg = (&#34;sort_y_by must have of all of the &#34;
                           &#34;following species: {}&#34;.format(unique_species)+&#34;. &#34;
                           &#34;You are missing {}&#34;.format([s for s in unique_species if s not in sort_y_by]))
                    self.err_handler.raise_exception(msg)
#                 else:
#                     msg = (&#34;sort_y_by can only have the &#34;
#                            &#34;following species: {}&#34;.format(unique_species)+&#34;.&#34;)
#                     self.err_handler.raise_exception(msg)
            elif sort_y_by == &#34;alphabetical&#34;:
                if &#34;Other&#34; in unique_species:
                    unique_species_no_other = [sp for sp in unique_species if sp != &#34;Other&#34;]
                    unique_species_no_other = sorted(unique_species_no_other)
                    unique_species = unique_species_no_other + [&#34;Other&#34;]
                else:
                    unique_species = sorted(unique_species)
            else:
                self.err_handler.raise_exception(&#34;sort_y_by must be either None, &#39;alphabetical&#39;, &#34;
                                &#34;or a list of species names.&#34;)
        
        if isinstance(colors, list):
            pass
        else:
            # get colormap
            colors = _get_colors(colormap, len(unique_species))

            # convert rgba to hex
            colors = [matplotlib.colors.rgb2hex(c) for c in colors]

        df_sp[&#34;species&#34;] = df_sp[&#34;species&#34;].apply(chemlabel)
        unique_species = [chemlabel(sp) for sp in unique_species]
        
        if title == None:
            title = &#39;&lt;span style=&#34;font-size: 14px;&#34;&gt;Species accounting for mass balance of {}&lt;/span&gt;&#39;.format(chemlabel(basis))
        
        
        # map each species to its color, e.g.,
        # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
        dict_species_color = {sp:color for sp,color in zip(unique_species, colors)}
        
        category_orders = {&#34;species&#34;: unique_species, &#34;sample&#34;: labels}


        fig = px.bar(df_sp, x=&#34;sample&#34;, y=&#34;percent&#34;, color=&#34;species&#34;,
                     width=plot_width*ppi, height=plot_height*ppi,
                     labels={&#34;sample&#34;: sample_label,  &#34;percent&#34;: &#34;mole %&#34;, &#34;species&#34;: &#34;species&#34;},
                     category_orders=category_orders,
                     color_discrete_map=dict_species_color,
                     template=&#34;simple_white&#34;,
                    )
        fig.update_layout(xaxis_tickangle=-45, xaxis_title=None, legend_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                          margin={&#34;t&#34;: 40}, bargap=0, xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True})

        fig.update_traces(width=width, marker_line_width=0)
        
        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)
            
        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                             &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                             &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                             &#39;toggleSpikelines&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                           &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                           &#39;filename&#39;: save_as,
                                           &#39;height&#39;: plot_height*ppi,
                                           &#39;width&#39;: plot_width*ppi,
                                           &#39;scale&#39;: save_scale,
                                           },
                 }
        
        if not interactive:
            config[&#39;staticPlot&#39;] = True
        
        if plot_out:
            return fig
        else:
            fig.show(config=config)


    def plot_solid_solutions(self, sample, title=None,
                                   width=0.9, colormap=&#34;WORM&#34;,
                                   affinity_plot=True,
                                   affinity_plot_colors=[&#34;blue&#34;, &#34;orange&#34;],
                                   plot_width=4, plot_height=4, ppi=122,
                                   save_as=None, save_format=None,
                                   save_scale=1, interactive=True,
                                   plot_out=False):
        
        &#34;&#34;&#34;
        Plot fractions of minerals of hypothetical solid solutions in a sample.
        
        Parameters
        ----------
        sample : str
            Name of the sample.

        title : str, optional
            Title of the plot.
        
        width : float, default 0.9
            Width of bars. No space between bars if width=1.0.
        
        colormap : str, default &#34;WORM&#34;
            Name of the colormap to color the scatterpoints. Accepts &#34;WORM&#34;,
            &#34;colorblind&#34;, or matplotlib colormaps.
            See https://matplotlib.org/stable/tutorials/colors/colormaps.html
            The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
            Color blindness. Nat Methods 8, 441 (2011).
            https://doi.org/10.1038/nmeth.1618
            
        affinity_plot : bool, default True
            Include the affinity subplot?
        
        affinity_plot_colors : list of two str, default [&#34;blue&#34;, &#34;orange&#34;]
            Colors indicating positive and negative values in the affinity
            subplot, respectively.
            
        plot_width, plot_height : numeric, default 4 by 3
            Width and height of the plot, in inches. Size of interactive plots
            is also determined by pixels per inch, set by the parameter `ppi`.
            
        ppi : numeric, default 122
            Pixels per inch. Along with `plot_width` and `plot_height`,
            determines the size of interactive plots.
        
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.

        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.
    
        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
            
        Returns
        -------
        fig : Plotly figure object
            A figure object is returned if `plot_out` is true. Otherwise, a
            figure is simply displayed.
        &#34;&#34;&#34;

        if sample not in self.sample_data.keys():
            msg = (&#34;The sample &#34;+sample+&#34; was not found in this speciation dataset.&#34;
                   &#34; Samples with solid solutions in this dataset include:&#34;+str([s for s in self.sample_data.keys() if &#34;solid_solutions&#34; in self.sample_data[s].keys()]))
            self.err_handler.raise_exception(msg)
        
        try:
            self.sample_data[sample][&#34;solid_solutions&#34;]
        except:
            msg = (&#34;Results for solid solutions could not be found for this &#34;
                   &#34;sample. Samples with solid solutions in this speciation &#34;
                   &#34;dataset include:&#34;+str([s for s in self.sample_data.keys() if &#34;solid_solutions&#34; in self.sample_data[s].keys()]))
            self.err_handler.raise_exception(msg)
        
        if title == None:
            title = &#34;Hypothetical solid solutions in &#34; + sample
        
        df_full = copy.deepcopy(self.sample_data[sample][&#34;solid_solutions&#34;])

        df = copy.deepcopy(df_full.dropna(subset=[&#39;x&#39;]))
        df = df[df[&#39;x&#39;] != 0]

        unique_minerals = self.__unique(df[&#34;mineral&#34;])
        
        # get colormap
        colors = _get_colors(colormap, len(unique_minerals))
        
        # convert rgba to hex
        colors = [matplotlib.colors.rgb2hex(c) for c in colors]
        
        # map each species to its color, e.g.,
        # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
        dict_minerals_color = {sp:color for sp,color in zip(unique_minerals, colors)}

        solid_solutions = list(dict.fromkeys(df[&#34;solid solution&#34;]))
        
        df_ss_only = df_full[df_full[&#34;x&#34;].isnull()]
        
        mineral_dict = {m:[] for m in unique_minerals}
        for ss in solid_solutions:
            for m in unique_minerals:
                df_sub = df.loc[df[&#34;solid solution&#34;] == ss,]
                frac = df_sub.loc[df_sub[&#34;mineral&#34;] == m, &#34;x&#34;]
                if len(frac) &gt; 0:
                    mineral_dict[m] = mineral_dict[m] + list(frac)
                else:
                    mineral_dict[m].append(0)

        if affinity_plot:
            rows = 2
            specs = [[{&#34;type&#34;: &#34;bar&#34;}], [{&#34;type&#34;: &#34;bar&#34;}]]
        else:
            rows = 1
            specs = [[{&#34;type&#34;: &#34;bar&#34;}]]
                    
        fig = make_subplots(
            rows=rows, cols=1,
            specs=specs,
            vertical_spacing = 0.05
        )

        # subplot 1
        for m in unique_minerals[::-1]:
            fig.add_trace(go.Bar(name=m, x=solid_solutions, y=mineral_dict[m], marker_color=dict_minerals_color[m]), row=1, col=1)
        
        # subplot 2
        if affinity_plot:
            fig.add_trace(go.Bar(name=&#34;ss&#34;, x=solid_solutions, y=df_ss_only[&#34;Aff, kcal&#34;],
                                 marker_color=[affinity_plot_colors[0] if val &gt; 0 else affinity_plot_colors[1] for val in df_ss_only[&#34;Aff, kcal&#34;]],
                                 showlegend=False),
                          row=2, col=1)

        fig.update_layout(barmode=&#39;stack&#39;, xaxis_tickangle=-45, xaxis_title=None, legend_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;}, autosize=False,
                          width=plot_width*ppi, height=plot_height*ppi,
                          margin={&#34;t&#34;: 40}, bargap=0, xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True}, template=&#34;simple_white&#34;)


        fig.update_xaxes(tickangle=-45)
        fig[&#39;layout&#39;][&#39;yaxis&#39;][&#39;title&#39;]=&#39;Mole Fraction&#39;
        if affinity_plot:
            fig[&#39;layout&#39;][&#39;yaxis2&#39;][&#39;title&#39;]=&#39;Affinity, kcal/mol&#39;
            fig.update_xaxes(showticklabels=False) # hide all the xticks
            fig.update_xaxes(showticklabels=True, row=2, col=1)
            
        
        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)
            
        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                             &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                             &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                             &#39;toggleSpikelines&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                           &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                           &#39;filename&#39;: save_as,
                                           &#39;height&#39;: plot_height*ppi,
                                           &#39;width&#39;: plot_width*ppi,
                                           &#39;scale&#39;: save_scale,
                                           },
                 }
        
        if not interactive:
            config[&#39;staticPlot&#39;] = True

        if plot_out:
            return fig
        else:
            fig.show(config=config)
            
            
    def join_6i_p(self, filepath_6i, chain_mt):
        path=&#39;rxn_6i&#39;
        if not os.path.exists(path):
            os.makedirs(path)
        else:
            shutil.rmtree(path)
            os.makedirs(path)
            
        if chain_mt:
            raw_p_dict = self.raw_6_pickup_dict
        else:
            raw_p_dict_bottom = self.raw_3_pickup_dict_bottom
            
        for sample_name in raw_p_dict_bottom.keys():
            sample_filename = self.sample_data[sample_name][&#39;filename&#39;][:-3]
            
            if isinstance(filepath_6i, str):
                # if a string (filepath) is given
                with open(filepath_6i, &#34;r&#34;) as f6i:
                    lines_6i = f6i.readlines()
            else:
                # if a Prepare_Reaction object is given
                all_lines = filepath_6i.formatted_reaction.split(&#34;\n&#34;)
                lines_6i = [e+&#34;\n&#34; for e in all_lines if e]
            
            # trim away any extra newlines at end of pre.6i, then add one.
            while lines_6i[-1] == &#34;\n&#34;:
                lines_6i = lines_6i[:-1]
                
            if lines_6i[-1][-1:] != &#34;\n&#34;: # \n counts as 1 character, not 2
                lines_6i[-1] = lines_6i[-1]+&#34;\n&#34;
                
            lines_3p = raw_p_dict_bottom[sample_name]
            
            lines_to_keep = []
            for line in lines_6i:
                if &#34;Start of the bottom half of the input file&#34; in line:
                    break
                else:
                    lines_to_keep.append(line)
            lines_to_keep += lines_3p
            
            if &#34;{tval}&#34; in &#34;&#34;.join(lines_to_keep):
                # grab temperature
                for line in lines_3p:
                    if &#34;Original temperature&#34; in line:
                        o_t = line.split(&#34;|&#34;)[2]
                for i,line in enumerate(lines_to_keep):
                    if &#34;{tval}&#34; in line:
                        lines_to_keep[i] = line.format(tval=o_t)
                        
            if &#34;{pval}&#34; in &#34;&#34;.join(lines_to_keep):
                # grab temperature
                for line in lines_3p:
                    if &#34;Original pressure&#34; in line:
                        o_p = line.split(&#34;|&#34;)[2]
                for i,line in enumerate(lines_to_keep):
                    if &#34;{pval}&#34; in line:
                        lines_to_keep[i] = line.format(tval=o_p)
            
            with open(path + &#34;/&#34; + sample_filename+&#34;.6i&#34;, &#34;w&#34;) as f:
                f.writelines(lines_to_keep)


    def mt(self, sample):
        &#34;&#34;&#34;
        Retrieve mass transfer results for a sample.
        
        Parameters
        ----------
        sample : str
            Name of the sample for which to retrieve mass transfer results.
            
        Returns
        -------
        An object of class `AqEquil.MassTransfer.Mass_Transfer`.
        &#34;&#34;&#34;
        
        sample_data = getattr(self, &#34;sample_data&#34;)
        return sample_data[sample][&#34;mass_transfer&#34;]

    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="AqEquil.AqSpeciation.chemlabel"><code class="name flex">
<span>def <span class="ident">chemlabel</span></span>(<span>name, charge_sign_at_end=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Format a chemical formula to display subscripts and superscripts in HTML
(e.g., Plotly plots)
Example, "CH3COO-" becomes "CH<sub>3</sub>COO<sup>-</sup>"</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>A chemical formula.</dd>
<dt><strong><code>charge_sign_at_end</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Display charge with sign after the number (e.g. SO4 2-)?</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A formatted chemical formula string.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chemlabel(name, charge_sign_at_end=False):
    
    &#34;&#34;&#34;
    Format a chemical formula to display subscripts and superscripts in HTML
    (e.g., Plotly plots)
    Example, &#34;CH3COO-&#34; becomes &#34;CH&lt;sub&gt;3&lt;/sub&gt;COO&lt;sup&gt;-&lt;/sup&gt;&#34;
    
    Parameters
    ----------
    name : str
        A chemical formula.
    
    charge_sign_at_end : bool, default False
        Display charge with sign after the number (e.g. SO4 2-)?
        
    
    Returns
    -------
    A formatted chemical formula string.
    &#34;&#34;&#34;
    
    # format only the first part of the name if it has &#34;_(input)&#34;
    if len(name.split(&#34;_(input)&#34;))==2:
        if name.split(&#34;_(input)&#34;)[1] == &#39;&#39;:
            name = name.split(&#34;_(input)&#34;)[0]
            input_flag=True
    else:
        input_flag = False
    
    name = _html_chemname_format(name, charge_sign_at_end=charge_sign_at_end)
    
    # add &#34; (input)&#34; to the end of the name
    if input_flag:
        name = name+&#34; (input)&#34;
    
    return(name)</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.compare"><code class="name flex">
<span>def <span class="ident">compare</span></span>(<span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>Combine two or more speciations into a single speciation object for
comparison. The speciation object returned by this function can produce
scatterplots, barplots, and mass contribution plots, and contains a report
that can be browsed with <code>lookup</code>. See documentation for the functions in
the <code><a title="AqEquil.AqSpeciation.Speciation" href="#AqEquil.AqSpeciation.Speciation">Speciation</a></code> class for more detail.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>*args</code></strong> :&ensp;<code>two</code> or <code>more objects</code> of <code>class </code>Speciation<code> to <a title="AqEquil.AqSpeciation.compare" href="#AqEquil.AqSpeciation.compare">compare()</a></code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>An object of class <code><a title="AqEquil.AqSpeciation.Speciation" href="#AqEquil.AqSpeciation.Speciation">Speciation</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compare(*args):
    
    &#34;&#34;&#34;
    Combine two or more speciations into a single speciation object for
    comparison. The speciation object returned by this function can produce
    scatterplots, barplots, and mass contribution plots, and contains a report
    that can be browsed with `lookup`. See documentation for the functions in
    the `Speciation` class for more detail.

    Parameters
    ----------
    *args : two or more objects of class `Speciation` to compare

    Returns
    ----------
    An object of class `Speciation`.
    &#34;&#34;&#34;
    
    if all([&#34;mass_contribution&#34; in a.__dict__.keys() for a in args]):
        allow_mass_contribution = True
        mass_contribution_breaks = []
    else:
        allow_mass_contribution = False
    
    for i,sp in enumerate(args):
        if i == 0:
            sp_total = copy.deepcopy(sp)
            sp_total.sample_data = None
            if allow_mass_contribution:
                mass_contribution_breaks.append(0)
        else:
            sp_i = copy.deepcopy(sp)
            if allow_mass_contribution:
                mass_contribution_breaks.append(sp_total.report.shape[0])
            sp_total.report = pd.concat([sp_total.report, sp_i.report], axis=0, sort=False)
        

    sp_total.report.index = sp_total.report.index + (&#34;_&#34;+sp_total.report.groupby(level=0).cumcount().astype(str)).replace(&#39;_0&#39;,&#39;&#39;)
    
    if allow_mass_contribution:
        mass_contribution_breaks.append(len(sp_total.report.index))
        mc_sample_names_with_suffixes = list(sp_total.report.index)
        for i,sp in enumerate(args):
            mc_i = copy.deepcopy(sp.mass_contribution)
            
            new_sample_names = copy.copy(mc_sample_names_with_suffixes[mass_contribution_breaks[i]:mass_contribution_breaks[i+1]])
            old_sample_names = list(args[i].sample_data.keys())
            
            old_new_sample_name_dict = {old:new for old,new in zip(old_sample_names, new_sample_names)}
                
            newsample = [old_new_sample_name_dict[old] for old in mc_i[&#34;sample&#34;]]

            mc_i[&#34;sample&#34;] = newsample
            
            if i == 0:
                mc_total = mc_i
            else:
                mc_total = pd.concat([mc_total, mc_i], axis=0, sort=False)
        
        sp_total.mass_contribution = mc_total
        
    else:
        def no_mass_contrib_message(*args, **kwargs):
            print(&#34;Mass contributions cannot be compared between these speciations &#34;
                  &#34;because one or more calculations lack mass contribution data.&#34;)
        sp_total.plot_mass_contribution = no_mass_contrib_message
                
    
    return sp_total</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>filename, messages=True, hide_traceback=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a speciation file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the speciation file.</dd>
<dt><strong><code>messages</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Print messages produced by this function?</dd>
<dt><strong><code>hide_traceback</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Hide traceback message when encountering errors handled by this function?
When True, error messages handled by this class will be short and to
the point.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>An object of class <code><a title="AqEquil.AqSpeciation.Speciation" href="#AqEquil.AqSpeciation.Speciation">Speciation</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load(filename, messages=True, hide_traceback=True):
    
    &#34;&#34;&#34;
    Load a speciation file.

    Parameters
    ----------
    filename : str
        Name of the speciation file.

    messages : bool, default True
        Print messages produced by this function?

    hide_traceback : bool, default True
        Hide traceback message when encountering errors handled by this function?
        When True, error messages handled by this class will be short and to
        the point.

    Returns
    ----------
    An object of class `Speciation`.
    &#34;&#34;&#34;

    err_handler = Error_Handler(clean=hide_traceback)
    
    if len(filename) &lt;= 12:
        print(&#34;Attempting to load &#34;+str(filename)+&#34;.speciation ...&#34;)
        filename = filename+&#34;.speciation&#34;
    
    if &#39;speciation&#39; in filename[-11:]:
        if os.path.exists(filename) and os.path.isfile(filename):
            pass
        else:
            err = &#34;Cannot locate input file {}/{}&#34;.format(os.getcwd(), filename)
            err_handler.raise_exception(err)
    else:
        err = (&#34;Input file {}&#34;.format(filename) + &#34; &#34;
            &#34;must be in {} format.&#34;.format(ext_dict[ext]))
        err_handler.raise_exception(err)
    
    if os.path.getsize(filename) &gt; 0:
        with open(filename, &#39;rb&#39;) as handle:
            speciation = dill.load(handle)
            if messages:
                print(&#34;Loaded &#39;{}&#39;&#34;.format(filename))
            return speciation
    else:
        msg = &#34;Cannot open &#34; + str(filename) + &#34; because the file is empty.&#34;
        err_handler.raise_exception(msg)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="AqEquil.AqSpeciation.AqEquil"><code class="flex name class">
<span>class <span class="ident">AqEquil</span></span>
<span>(</span><span>eq36da='/home/shock/EQ3_6v8.0a/db', eq36co='/usr/local/bin', db='WORM', elements=None, solid_solutions=None, logK=None, logK_S=None, logK_extrapolate='none', download_csv_files=False, exclude_category={}, suppress_redox=[], input_template='none', water_model='SUPCRT92', exceed_Ttr=True, verbose=1, load_thermo=True, hide_traceback=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Class containing functions to speciate aqueous water chemistry data using
existing or custom thermodynamic datasets.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>eq36da</code></strong> :&ensp;<code>str, defaults to path given by the environment variable EQ36DA</code></dt>
<dd>Path to directory where data1 files are stored.</dd>
<dt><strong><code>eq36co</code></strong> :&ensp;<code>str, defaults to path given by the environment variable EQ36CO</code></dt>
<dd>Path to directory where EQ3 executables are stored.</dd>
<dt><strong><code>db</code></strong> :&ensp;<code>str</code>, default <code>"WORM"</code></dt>
<dd>Determines which thermodynamic database is used in the speciation
calculation. There are several options available:
- "WORM" will load the default WORM thermodynamic database,
solid solution database, and logK database. These files are retrieved
from <a href="https://github.com/worm-portal/WORM-db">https://github.com/worm-portal/WORM-db</a> to ensure they are
up-to-date.
- Three letter file extension for the desired data1 database, e.g.,
"wrm". This will use a data1 file with this file extension, e.g.,
"data1.wrm" located in the path stored in the 'EQ36DA' environment
variable used by EQ3NR.
- The name of a data0 file located in the current working directory,
e.g., "data0.wrm". This data0 file will be compiled by EQPT
automatically during the speciation calculation.
- The name of a CSV file containing thermodynamic data located in
the current working directory, e.g., "wrm_data.csv". The CSV file
will be used to generate a data0 file for each sample (using
additional arguments from <code>db_args</code> if desired).
- The URL of a data0 file, e.g.,
"https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm"
- The URL of a CSV file containing thermodynamic data, e.g.,
"https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv"</dd>
<dt><strong><code>solid_solutions</code></strong> :&ensp;<code>str</code></dt>
<dd>Filepath of a CSV file containing parameters for solid solutions, e.g.,
"my_solid_solutions.csv". If <code>db</code> is set to "WORM" and <code>solid_solutions</code>
is not defined, then parameters for solid solutions will be retrieved
from "Solid_solutions.csv" at <a href="https://github.com/worm-portal/WORM-db">https://github.com/worm-portal/WORM-db</a></dd>
<dt><strong><code>logK</code></strong> :&ensp;<code>str</code></dt>
<dd>Filepath of a CSV file containing equilibrium constants for chemical
species, e.g., "my_logK_entries.csv". If <code>db</code> is set to "WORM" and <code>logK</code>
is not defined, then equilibrium constants will be retrieved from
"wrm_data_logK.csv" at <a href="https://github.com/worm-portal/WORM-db">https://github.com/worm-portal/WORM-db</a></dd>
<dt><strong><code>logK_S</code></strong> :&ensp;<code>str</code></dt>
<dd>Filepath of a CSV file containing equilibrium constants for chemical
species, e.g., "my_logK_S_entries.csv". If <code>db</code> is set to "WORM" and <code>logK_S</code>
is not defined, then equilibrium constants will be retrieved from
"wrm_data_logK_S.csv" at <a href="https://github.com/worm-portal/WORM-db">https://github.com/worm-portal/WORM-db</a></dd>
<dt><strong><code>logK_extrapolate</code></strong> :&ensp;<code>str</code>, default <code>"none"</code></dt>
<dd>What method should be used to extrapolate equilibrium constants in the
logK database (defined by parameter <code>logK</code>) as a function of
temperature? Can be either "none", "flat", "poly", or "linear".</dd>
<dt><strong><code>download_csv_files</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Download copies of database CSV files to your current working directory?</dd>
<dt><strong><code>exclude_category</code></strong> :&ensp;<code>dict</code></dt>
<dd>Exclude species from thermodynamic databases based on column values.
For instance,
<code>exclude_category={'category_1':["organic_aq", "organic_cr"]}</code>
will exclude all species that have "organic_aq" or "organic_cr" in
the column "category_1".
Species are excluded from the main thermodynamic database CSV and the
equilibrium constant (logK) CSV database. This parameter has no effect
if the thermodynamic database is a data0 or data1 file.</dd>
<dt><strong><code>suppress_redox</code></strong> :&ensp;<code>list</code> of <code>str</code>, default <code>[]</code></dt>
<dd>Suppress equilibrium between oxidation states of listed elements
(Cl, H, and O cannot be included).</dd>
<dt><strong><code>input_template</code></strong> :&ensp;<code>str</code>, default <code>"none"</code></dt>
<dd>Can be either "strict", "basis", "all", or "none" (default). If any
option other than "none" is chosen, a sample input file template CSV
file customized to this thermodynamic dataset called
"sample_input_template.csv" will be generated in the current directory.
This template can be populated with water sample data to be speciated by
the <code>speciate</code> function. The "strict" option is highly recommended for
most users. This is because strict basis species speciate into auxiliary
and non-basis species, but not the other way around.
Columns in the template include 'Sample', 'Temperature', 'logfO2', and
others, depending on the chosen option. If "strict", columns for strict
basis species will be included. If "basis", columns for both strict and
auxiliary basis species will be included. If "all", then columns for all
aqueous species will be included.</dd>
<dt><strong><code>water_model</code></strong> :&ensp;<code>str</code>, default <code>"SUPCRT92"</code></dt>
<dd>This is an experimental feature that is not yet fully supported.
Desired water model. Can be either "SUPCRT92", "IAPWS95", or "DEW".
These models are described here: <a href="http://chnosz.net/manual/water.html">http://chnosz.net/manual/water.html</a></dd>
<dt><strong><code>exceed_Ttr</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Calculate Gibbs energies of mineral phases and other species
beyond their transition temperatures?</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int, 0, 1,</code> or <code>2</code>, default <code>1</code></dt>
<dd>Level determining how many messages are returned during a
calculation. 2 for all messages, 1 for errors or warnings only,
0 for silent.</dd>
<dt><strong><code>load_thermo</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Load thermodynamic database(s) when instantiating this class?</dd>
<dt><strong><code>hide_traceback</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Hide traceback message when encountering errors handled by this class?
When True, error messages handled by this class will be short and to
the point.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>eq36da</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to directory where data1 files are stored.</dd>
<dt><strong><code>eq36co</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to directory where EQ3 executables are stored.</dd>
<dt><strong><code>df_input_processed</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Pandas dataframe containing user-supplied sample chemistry data that has
been processed by <code>speciate</code>.</dd>
<dt><strong><code>half_cell_reactions</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Pandas dataframe containing half cell reactions that can be combined
into redox reactions for calculating chemical affinity and energy supply
values during speciation.</dd>
<dt><strong><code>redox_pairs</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>List of indices of half reactions in the <code>half_cell_reactions</code> table
to be combined when generating full redox reactions.</dd>
<dt><strong><code>affinity_energy_reactions_raw</code></strong> :&ensp;<code>str</code></dt>
<dd>A formatted TSV string of redox reactions for calculating chemical
affinities and energy supplies during speciation.</dd>
<dt><strong><code>affinity_energy_reactions_table</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>A table of redox reactions for calculating chemical affinities and
energy supplies during speciation.</dd>
<dt><strong><code>affinity_energy_formatted_reactions</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>A pandas dataframe containing balanced redox reactions written in full.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AqEquil(object):

    &#34;&#34;&#34;
    Class containing functions to speciate aqueous water chemistry data using
    existing or custom thermodynamic datasets.
    
    Parameters
    ----------
    eq36da : str, defaults to path given by the environment variable EQ36DA
        Path to directory where data1 files are stored. 
        
    eq36co : str, defaults to path given by the environment variable EQ36CO
        Path to directory where EQ3 executables are stored.
    
    db : str, default &#34;WORM&#34;
        Determines which thermodynamic database is used in the speciation
        calculation. There are several options available:
        - &#34;WORM&#34; will load the default WORM thermodynamic database,
        solid solution database, and logK database. These files are retrieved
        from https://github.com/worm-portal/WORM-db to ensure they are
        up-to-date.
        - Three letter file extension for the desired data1 database, e.g.,
        &#34;wrm&#34;. This will use a data1 file with this file extension, e.g.,
        &#34;data1.wrm&#34; located in the path stored in the &#39;EQ36DA&#39; environment
        variable used by EQ3NR.
        - The name of a data0 file located in the current working directory,
        e.g., &#34;data0.wrm&#34;. This data0 file will be compiled by EQPT
        automatically during the speciation calculation.
        - The name of a CSV file containing thermodynamic data located in
        the current working directory, e.g., &#34;wrm_data.csv&#34;. The CSV file
        will be used to generate a data0 file for each sample (using
        additional arguments from `db_args` if desired).
        - The URL of a data0 file, e.g.,
        &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#34;
        - The URL of a CSV file containing thermodynamic data, e.g.,
        &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
        
    solid_solutions : str
        Filepath of a CSV file containing parameters for solid solutions, e.g.,
        &#34;my_solid_solutions.csv&#34;. If `db` is set to &#34;WORM&#34; and `solid_solutions`
        is not defined, then parameters for solid solutions will be retrieved
        from &#34;Solid_solutions.csv&#34; at https://github.com/worm-portal/WORM-db
    
    logK : str
        Filepath of a CSV file containing equilibrium constants for chemical
        species, e.g., &#34;my_logK_entries.csv&#34;. If `db` is set to &#34;WORM&#34; and `logK`
        is not defined, then equilibrium constants will be retrieved from
        &#34;wrm_data_logK.csv&#34; at https://github.com/worm-portal/WORM-db
    
    logK_S : str
        Filepath of a CSV file containing equilibrium constants for chemical
        species, e.g., &#34;my_logK_S_entries.csv&#34;. If `db` is set to &#34;WORM&#34; and `logK_S`
        is not defined, then equilibrium constants will be retrieved from
        &#34;wrm_data_logK_S.csv&#34; at https://github.com/worm-portal/WORM-db
    
    logK_extrapolate : str, default &#34;none&#34;
        What method should be used to extrapolate equilibrium constants in the
        logK database (defined by parameter `logK`) as a function of
        temperature? Can be either &#34;none&#34;, &#34;flat&#34;, &#34;poly&#34;, or &#34;linear&#34;.
    
    download_csv_files : bool, default False
        Download copies of database CSV files to your current working directory?
    
    exclude_category : dict
        Exclude species from thermodynamic databases based on column values.
        For instance,
        `exclude_category={&#39;category_1&#39;:[&#34;organic_aq&#34;, &#34;organic_cr&#34;]}`
        will exclude all species that have &#34;organic_aq&#34; or &#34;organic_cr&#34; in
        the column &#34;category_1&#34;.
        Species are excluded from the main thermodynamic database CSV and the
        equilibrium constant (logK) CSV database. This parameter has no effect
        if the thermodynamic database is a data0 or data1 file.
        
    suppress_redox : list of str, default []
        Suppress equilibrium between oxidation states of listed elements
        (Cl, H, and O cannot be included).
        
    input_template : str, default &#34;none&#34;
        Can be either &#34;strict&#34;, &#34;basis&#34;, &#34;all&#34;, or &#34;none&#34; (default). If any
        option other than &#34;none&#34; is chosen, a sample input file template CSV
        file customized to this thermodynamic dataset called
        &#34;sample_input_template.csv&#34; will be generated in the current directory.
        This template can be populated with water sample data to be speciated by
        the `speciate` function. The &#34;strict&#34; option is highly recommended for
        most users. This is because strict basis species speciate into auxiliary
        and non-basis species, but not the other way around.
        Columns in the template include &#39;Sample&#39;, &#39;Temperature&#39;, &#39;logfO2&#39;, and
        others, depending on the chosen option. If &#34;strict&#34;, columns for strict
        basis species will be included. If &#34;basis&#34;, columns for both strict and
        auxiliary basis species will be included. If &#34;all&#34;, then columns for all
        aqueous species will be included.
        
    water_model : str, default &#34;SUPCRT92&#34;
        This is an experimental feature that is not yet fully supported.
        Desired water model. Can be either &#34;SUPCRT92&#34;, &#34;IAPWS95&#34;, or &#34;DEW&#34;.
        These models are described here: http://chnosz.net/manual/water.html
        
    exceed_Ttr : bool, default True
        Calculate Gibbs energies of mineral phases and other species
        beyond their transition temperatures?
        
    verbose : int, 0, 1, or 2, default 1
        Level determining how many messages are returned during a
        calculation. 2 for all messages, 1 for errors or warnings only,
        0 for silent.

    load_thermo : bool, default True
        Load thermodynamic database(s) when instantiating this class?

    hide_traceback : bool, default True
        Hide traceback message when encountering errors handled by this class?
        When True, error messages handled by this class will be short and to
        the point.
    
    Attributes
    ----------
    eq36da : str
        Path to directory where data1 files are stored.
        
    eq36co : str
        Path to directory where EQ3 executables are stored.
        
    df_input_processed : pd.DataFrame
        Pandas dataframe containing user-supplied sample chemistry data that has
        been processed by `speciate`.
    
    half_cell_reactions : pd.DataFrame
        Pandas dataframe containing half cell reactions that can be combined
        into redox reactions for calculating chemical affinity and energy supply
        values during speciation.
        
    redox_pairs : list of int
        List of indices of half reactions in the `half_cell_reactions` table
        to be combined when generating full redox reactions.
            
    affinity_energy_reactions_raw : str
        A formatted TSV string of redox reactions for calculating chemical
        affinities and energy supplies during speciation.

    affinity_energy_reactions_table : pd.DataFrame
        A table of redox reactions for calculating chemical affinities and
        energy supplies during speciation.
    
    affinity_energy_formatted_reactions : pd.DataFrame
        A pandas dataframe containing balanced redox reactions written in full.
        
    &#34;&#34;&#34;

    def __init__(self,
                 eq36da=os.environ.get(&#39;EQ36DA&#39;),
                 eq36co=os.environ.get(&#39;EQ36CO&#39;),
                 db=&#34;WORM&#34;,
                 elements=None,
                 solid_solutions=None,
                 logK=None,
                 logK_S=None,
                 logK_extrapolate=&#34;none&#34;,
                 download_csv_files=False,
                 exclude_category={},
                 suppress_redox=[],
                 input_template=&#34;none&#34;,
                 water_model=&#34;SUPCRT92&#34;,
                 exceed_Ttr=True,
                 verbose=1,
                 load_thermo=True,
                 hide_traceback=True):

        self.eq36da = eq36da
        self.eq36co = eq36co
        self.df_input_processed = None
        self.water_model = water_model
        
        half_rxn_data = pkg_resources.resource_stream(__name__, &#34;half_cell_reactions.csv&#34;)
        self.half_cell_reactions = pd.read_csv(half_rxn_data) #define the input file (dataframe of redox pairs)
        self.redox_pairs = None
        self.affinity_energy_reactions_raw = None
        self.affinity_energy_reactions_table = None
        self.affinity_energy_formatted_reactions = None
        
        self.verbose = verbose
        self.hide_traceback = hide_traceback
        self.err_handler = Error_Handler(clean=self.hide_traceback)
        
        self.raw_3_input_dict = {}
        self.raw_3_output_dict = {}
        self.raw_3_pickup_dict_bottom = {}
        self.raw_3_pickup_dict_top = {}
        
        self.batch_T = []
        self.batch_P = []
        
        self.logK_models = {}

        
        
        if load_thermo:
            
            # attributes to add to AqEquil class
            self.db = db
            self.elements = elements
            self.solid_solutions = solid_solutions
            self.exclude_category = exclude_category
            self.logK = logK
            self.logK_S = logK_S
            self.logK_extrapolate = logK_extrapolate
            self.download_csv_files = download_csv_files
            self.exclude_category = exclude_category
            self.suppress_redox = suppress_redox
            self.exceed_Ttr = exceed_Ttr
            self.input_template = input_template
            
            self.thermo = AqEquil.Thermodata(AqEquil_instance=self) # outer instance passed to inner instance
        
            self.data1 = self.thermo.data1

    def _capture_r_output(self):
        &#34;&#34;&#34;
        Capture and create a list of R console messages
        &#34;&#34;&#34;
        
        # Record output #
        self.stdout = []
        self.stderr = []
        
        # If DEBUGGING_R==False, uses python to print R lines after executing an R block 
        # If DEBUGGING_R==True, will ugly print from R directly. Allows printing from R to troubleshoot errors.
        if DEBUGGING_R:
        
            # Dummy functions #
            def add_to_stdout(line): self.stdout.append(line)
            def add_to_stderr(line): self.stderr.append(line)

            # Keep the old functions #
            self.stdout_orig = rpy2.rinterface_lib.callbacks.consolewrite_print
            self.stderr_orig = rpy2.rinterface_lib.callbacks.consolewrite_warnerror

            # Set the call backs #
            rpy2.rinterface_lib.callbacks.consolewrite_print     = add_to_stdout
            rpy2.rinterface_lib.callbacks.consolewrite_warnerror = add_to_stderr

    def _print_captured_r_output(self):
        printable_lines = [line for line in self.stdout if line not in [&#39;[1]&#39;, &#39;\n&#39;]]
        printable_lines = [line for line in printable_lines if re.search(&#34;^\s*\[[0-9]+\]$&#34;, line) is None]
        printable_lines = [re.sub(r&#39; \\n\&#34;&#39;, &#34;&#34;, line) for line in printable_lines]
        [print(line[2:-1]) for line in printable_lines]

    def __file_exists(self, filename, ext=&#39;.csv&#39;):
        &#34;&#34;&#34;
        Check that a file exists and that it has the correct extension.
        Returns True if so, raises exception if not.
        &#34;&#34;&#34;
        
        ext_dict = {
            &#34;.csv&#34; : &#34;comma separated values (.csv)&#34;,
            &#34;.txt&#34; : &#34;standard text (.txt)&#34;,
            &#34;.rds&#34; : &#34;R Data (.rds)&#34;,
        }

        if ext in filename[-4:]:
            
            if os.path.exists(filename) and os.path.isfile(filename):
                return True
            else:
                err = &#34;Cannot locate input file {}/{}&#34;.format(os.getcwd(), filename)
                self.err_handler.raise_exception(err)
        else:
            err = (&#34;Input file {}&#34;.format(filename) + &#34; &#34;
                &#34;must be in {} format.&#34;.format(ext_dict[ext]))
            self.err_handler.raise_exception(err)
        
        return False

    
    def _check_sample_input_file(self, input_filename, exclude, db,
                                       dynamic_db, charge_balance_on,
                                       suppress_missing,
                                       redox_suppression):
        &#34;&#34;&#34;
        Check for problems in sample input file.
        &#34;&#34;&#34;
        
        # does the input file exist? Is it a CSV?
        if self.__file_exists(input_filename):
            df_in = pd.read_csv(input_filename, header=None) # no headers for now so colname dupes can be checked
        else:
            self.err_handler.raise_exception(&#34;_check_sample_input() error!&#34;)
        
        # are there any samples?
        if df_in.shape[0] &lt;= 2:
            err_no_samples = (&#34;The file {}&#34;.format(input_filename) + &#34; &#34;
                &#34;must contain at least three rows: the &#34;
                &#34;first for column names, the second for column subheaders, &#34;
                &#34;followed by one or more rows for sample data.&#34;)
            self.err_handler.raise_exception(err_no_samples)
        
        err_list = [] # for appending errors found in the sample input file
        
        # get header list
        col_list = list(df_in.iloc[0, 1:])
        
        # are there blank headers?
        if True in [isinstance(x, float) and x != x for x in col_list]:
            # isinstance(x, float) and x != x is a typesafe way to check for nan
            err_blank_header = (&#34;One or more columns in the sample input &#34;
                &#34;file have blank headers. These might be empty columns. &#34;
                &#34;Only the first column may have a blank header. Remove any &#34;
                &#34;empty columns and/or give each header a name.&#34;)
            self.err_handler.raise_exception(err_blank_header)
        
        # are there duplicate headers?
        dupe_cols = list(set([x for x in col_list if col_list.count(x) &gt; 1]))
        if len(dupe_cols) &gt; 0:
            err_dupe_cols = (&#34;Duplicate column names are not allowed. &#34;
                &#34;Duplicate column names were found for:\n&#34;
                &#34;{}&#34;.format(str(dupe_cols)))
            err_list.append(err_dupe_cols)
        
        df_in.columns = df_in.iloc[0] # set column names
        df_in = df_in.drop(df_in.index[0], axis=0) # drop column name row
        df_in_headercheck = copy.deepcopy(df_in.iloc[:,1:]) # drop first column. Deepcopy slice because drop() doesn&#39;t work well with unnamed columns.
        
        # drop excluded headers
        for exc in exclude:
            if exc == df_in.columns[0]: # skip if &#39;sample&#39; column is excluded
                continue
            try:
                df_in_headercheck = df_in_headercheck.drop(exc, axis=1) # drop excluded columns
            except:
                err_bad_exclude = (
                        &#34;Could not exclude the header &#39;{}&#39;&#34;.format(exc)+&#34;. &#34;
                        &#34;This header could not be found in &#34;
                        &#34;{}&#34;.format(input_filename)+&#34;&#34;)
                err_list.append(err_bad_exclude)
        
        # get row list
        row_list = list(df_in.iloc[1:, 0])
        
        # are there blank rows?
        if True in [isinstance(x, float) and x != x for x in row_list]:
            # isinstance(x, float) and x != x is a typesafe way to check for nan
            err_blank_row = (&#34;One or more rows in the sample input &#34;
                &#34;file have blank sample names. These might be empty rows. &#34;
                &#34;Remove any empty rows and/or give each sample a name. Sample &#34;
                &#34;names go in the first column.&#34;)
            self.err_handler.raise_exception(err_blank_row)
            
        # are there duplicate rows?
        dupe_rows = list(set([x for x in row_list if row_list.count(x) &gt; 1]))
        if len(dupe_rows) &gt; 0:
            err_dupe_rows = (&#34;Duplicate sample names are not allowed. &#34;
                &#34;Duplicate sample names were found for:\n&#34;
                &#34;{}&#34;.format(str(dupe_rows)))
            err_list.append(err_dupe_rows)
        
        # are there any leading or trailing spaces in sample names?
        invalid_sample_names = [n for n in list(df_in.iloc[1:, 0])
                                if str(n[0])==&#34; &#34; or str(n[-1])==&#34; &#34;]
        if len(invalid_sample_names) &gt; 0:
            err_sample_leading_trailing_spaces = (&#34;The following sample names &#34;
                &#34;have leading or trailing spaces. Remove spaces and try again: &#34;
                &#34;{}&#34;.format(invalid_sample_names))
            self.err_handler.raise_exception(err_sample_leading_trailing_spaces)
        
        # are column names valid entries in the database?
        if self.thermo.custom_data0:
            if &#34;data0&#34; in db:
                data_path = db
            else:
                data_path = &#34;data0.&#34; + db
        elif self.thermo.dynamic_db:
            data_path = self.thermo.thermo_db_filename
        else:
            data_path = self.eq36da + &#34;/data0.&#34; + db
        
        if self.thermo.thermo_db_type == &#34;data0&#34; and self.thermo.thermo_db_source == &#34;URL&#34;:
            data_path = &#34;data0.&#34; + self.thermo.data0_lettercode
        
        if not (os.path.exists(data_path) or os.path.isfile(data_path)) and self.thermo.thermo_db_source==&#34;file&#34;:
            warn_no_data0 = (&#34;Warning: Could not locate {}.&#34;.format(data_path) + &#34; &#34;
                &#34;Unable to determine if column headers included in &#34;
                &#34;{} &#34;.format(input_filename) + &#34;match entries for species &#34;
                &#34;in the requested thermodynamic database &#39;{}&#39;.&#34;.format(db))
            if self.verbose &gt; 0:
                print(warn_no_data0)
            
        if self.thermo.thermo_db_type == &#34;data0&#34;:
            data0_lines = self.thermo.thermo_db.split(&#34;\n&#34;)
            start_index = [i+1 for i, s in enumerate(data0_lines) if &#39;*  species name&#39; in s]
            end_index = [i-1 for i, s in enumerate(data0_lines) if &#39;elements&#39; in s]
            db_species = [i.split()[0] for i in data0_lines[start_index[0]:end_index[0]]]
        elif self.thermo.thermo_db_type == &#34;CSV&#34;:
            df_OBIGT = self.thermo.thermo_db
            db_species = list(df_OBIGT[&#34;name&#34;])

        if charge_balance_on == &#39;pH&#39;:
            err_charge_balance_on_pH = (&#34;To balance charge on pH, use &#34;
                &#34;charge_balance_on=&#39;H+&#39;&#34;)
            err_list.append(err_charge_balance_on_pH)
        elif charge_balance_on in [&#39;Temperature&#39;, &#39;logfO2&#39;]:
            err_charge_balance_invalid_type = (&#34;Cannot balance charge &#34;
                &#34;on {}.&#34;.format(charge_balance_on))
            err_list.append(err_charge_balance_invalid_type)
        elif charge_balance_on != &#34;none&#34; and charge_balance_on not in list(set(df_in_headercheck.columns)):
            err_charge_balance_invalid_sp = (&#34;The species chosen for charge balance&#34;
                &#34; &#39;{}&#39;&#34;.format(charge_balance_on)+&#34;&#34;
                &#34; was not found among the headers of the sample input file.&#34;)
            err_list.append(err_charge_balance_invalid_sp)

        if self.thermo.thermo_db_type in [&#34;data0&#34;, &#34;CSV&#34;]:
            
            for species in list(dict.fromkeys(df_in_headercheck.columns)):
                if species not in db_species and species not in [&#39;Temperature&#39;, &#39;logfO2&#39;, &#39;pH&#39;, &#39;Pressure&#39;, &#39;Eh&#39;, &#39;pe&#39;]+FIXED_SPECIES:
                    err_species_not_in_db = (&#34;The species &#39;{}&#39;&#34;.format(species) + &#34; &#34;
                        &#34;was not found in {}&#34;.format(data_path) + &#34;. &#34;
                        &#34;If the column contains data that should not be &#34;
                        &#34;included in the speciation calculation, add the &#34;
                        &#34;column name to the &#39;exclude&#39; argument. Try &#34;
                        &#34;help(AqEquil.AqEquil.speciate) &#34;
                        &#34;for more information about &#39;exclude&#39;.&#34;)
                    err_list.append(err_species_not_in_db)
                elif species == &#39;pH&#39;:
                    err_species_pH = (&#34;Please rename the &#39;pH&#39; column in &#34;
                        &#34;the sample input file to &#39;H+&#39; with the subheader &#34;
                        &#34;unit &#39;pH&#39;.&#34;)
                    err_list.append(err_species_pH)

        
        
        # are subheader units valid?
        subheaders = df_in_headercheck.iloc[0,]
        valid_subheaders = [&#34;degC&#34;, &#34;ppm&#34;, &#34;ppb&#34;, &#34;Suppressed&#34;, &#34;Molality&#34;,
                            &#34;Molarity&#34;, &#34;mg/L&#34;, &#34;mg/kg.sol&#34;, &#34;Alk., eq/kg.H2O&#34;,
                            &#34;Alk., eq/L&#34;, &#34;Alk., eq/kg.sol&#34;, &#34;Alk., mg/L CaCO3&#34;,
                            &#34;Alk., mg/L HCO3-&#34;, &#34;Log activity&#34;, &#34;Log act combo&#34;,
                            &#34;Log mean act&#34;, &#34;pX&#34;, &#34;pH&#34;, &#34;pHCl&#34;, &#34;pmH&#34;, &#34;pmX&#34;,
                            &#34;Hetero. equil.&#34;, &#34;Homo. equil.&#34;, &#34;Make non-basis&#34;,
                            &#34;logfO2&#34;, &#34;Mineral&#34;, &#34;bar&#34;, &#34;volts&#34;]
        for i, subheader in enumerate(subheaders):
            if subheader not in valid_subheaders:
                err_valid_sub = (&#34;The subheader &#39;{}&#39;&#34;.format(subheader) + &#34; &#34;
                    &#34;for the column &#39;{}&#39;&#34;.format(df_in_headercheck.columns[i]) + &#34; &#34;
                    &#34;is not recognized. Valid subheaders are {}&#34;.format(str(valid_subheaders)) + &#34;. &#34;
                    &#34;If the column {}&#34;.format(df_in_headercheck.columns[i]) + &#34; &#34;
                    &#34;contains data that is not meant for the &#34;
                    &#34;speciation calculation, add the column name &#34;
                    &#34;to the &#39;exclude&#39; argument. Try help(AqEquil.AqEquil.speciate) &#34;
                    &#34;for more information about &#39;exclude&#39;.&#34;)
                err_list.append(err_valid_sub)
            
        # is a &#39;Temperature&#39; column present?
        if &#34;Temperature&#34; not in df_in_headercheck.columns and &#34;Temperature&#34; not in exclude:
            err_temp = (&#34;The column &#39;Temperature&#39; was not found in the input file. &#34;
                &#34;Please include a column with &#39;Temperature&#39; in the first row, &#34;
                &#34;&#39;degC&#39; in the second row, and a temperature value for each &#34;
                &#34;sample in degrees Celsius.&#34;)
            err_list.append(err_temp)

        # raise an exception that summarizes all errors found
        if len(err_list) &gt; 0:
            errs = &#34;\n\n*&#34;.join(err_list)
            errs = (&#34;The input file {}&#34;.format(input_filename)+&#34; encountered&#34;
                &#34; errors:\n\n*&#34; + errs)
            self.err_handler.raise_exception(errs)
        
        # warn about &#34;suppress_redox&#34; in db_args if &#34;Hetero. equil.&#34; among subheaders.
        # Redox suppression won&#39;t work for an element constrained by heterogeneous equilibrium
        if redox_suppression and &#34;Hetero. equil.&#34; in list(subheaders):
            if self.verbose &gt; 0:
                print(&#34;Warning: &#39;suppress_redox&#39; does not currently work with the &#34;
                      &#34;heterogeneous equilibrium option if the mineral or gas &#34;
                      &#34;contains a redox-suppressed element.&#34;)
        
        sample_temps = [float(t) for t in list(df_in[&#34;Temperature&#34;])[1:]]
        if &#34;Pressure&#34; in df_in.columns:
            sample_press = [float(p) if p.lower() != &#39;psat&#39; else &#39;psat&#39; for p in list(df_in[&#34;Pressure&#34;])[1:]]
        else:
            sample_press = [&#39;psat&#39;]*len(sample_temps)
        
        
        return sample_temps, sample_press
        

    def __move_eqpt_extra_output(self):
        &#34;&#34;&#34;
        Moves all EQPT output and data0 into the eqpt_files folder
        &#34;&#34;&#34;
        
        self.__mk_check_del_directory(&#34;eqpt_files&#34;)
        if os.path.exists(&#34;eqpt_log.txt&#34;) and os.path.isfile(&#34;eqpt_log.txt&#34;):
            shutil.move(&#34;eqpt_log.txt&#34;, &#34;eqpt_files/eqpt_log.txt&#34;)
        if os.path.exists(&#34;data1f.txt&#34;) and os.path.isfile(&#34;data1f.txt&#34;):
            shutil.move(&#34;data1f.txt&#34;, &#34;eqpt_files/data1f.txt&#34;)
        if os.path.exists(&#34;slist.txt&#34;) and os.path.isfile(&#34;slist.txt&#34;):
            shutil.move(&#34;slist.txt&#34;, &#34;eqpt_files/slist.txt&#34;)

            
    def runeqpt(self, db, dynamic_db=False):
        
        &#34;&#34;&#34;
        Convert a data0 into a data1 file with EQPT.
        
        Parameters
        ----------
        db : str
            Three letter code of database.
        &#34;&#34;&#34;

        if os.path.exists(&#34;data0.&#34;+db) and os.path.isfile(&#34;data0.&#34;+db):
            pass
        else:
            self.err_handler.raise_exception(&#34; &#34;.join([&#34;Error: could not locate custom database&#34;,
                            &#34;data0.{} in {}.&#34;.format(db, os.getcwd())]))

        if os.path.exists(&#34;data1.&#34;+db) and os.path.isfile(&#34;data1.&#34;+db):
            os.remove(&#34;data1.&#34;+db)

        self.__move_eqpt_extra_output()
        
        args = [&#34;cd&#34;, os.getcwd(), &#34;;&#34;, self.eq36co+&#39;/eqpt&#39;, &#34;&#39;&#34;+os.getcwd()+&#34;/data0.&#34;+db+&#34;&#39;&#34;]
        args = &#34; &#34;.join(args)

        try:
            self.__run_script_and_wait(args) # run EQPT
        except:
            self.err_handler.raise_exception(
                &#34;Error: EQPT failed to run on {}.&#34;.format(&#34;data0.&#34;+db))

        if os.path.exists(&#34;data1&#34;) and os.path.isfile(&#34;data1&#34;):
            os.rename(&#34;data1&#34;, &#34;data1.&#34;+db)
        if os.path.exists(&#34;data0.d1&#34;) and os.path.isfile(&#34;data0.d1&#34;):
            os.rename(&#34;data0.d1&#34;, &#34;data1.&#34;+db)
        if os.path.exists(&#34;data0.po&#34;) and os.path.isfile(&#34;data0.po&#34;):
            os.rename(&#34;data0.po&#34;, &#34;eqpt_log.txt&#34;)
        if os.path.exists(&#34;data0.d1f&#34;) and os.path.isfile(&#34;data0.d1f&#34;):
            os.rename(&#34;data0.d1f&#34;, &#34;data1f.txt&#34;)
        if os.path.exists(&#34;data0.s&#34;) and os.path.isfile(&#34;data0.s&#34;):
            os.rename(&#34;data0.s&#34;, &#34;slist.txt&#34;)

        if os.path.exists(&#34;data1.&#34;+db) and os.path.isfile(&#34;data1.&#34;+db):
            if self.verbose &gt; 0:
                if not dynamic_db:
                    print(&#34;Successfully created a data1.&#34;+db+&#34; from data0.&#34;+db)
        else:
            if dynamic_db:
                msg = (&#34;EQPT has encounted a problem processing the database &#34;
                       &#34;for this sample. Check eqpt_log.txt for details.&#34;)
            else:
                msg = (&#34;EQPT could not create data1.&#34;+db+&#34; from &#34;
                       &#34;data0.&#34;+db+&#34;. Check eqpt_log.txt for details.&#34;)
            self.err_handler.raise_exception(msg)
        
        self.__move_eqpt_extra_output()

    
    def runeq3(self,
               filename_3i,
               db,
               samplename=None,
               path_3i=&#34;&#34;,
               path_3o=&#34;&#34;,
               path_3p=&#34;&#34;,
               data1_path=&#34;&#34;,
               dynamic_db_name=None):
        
        &#34;&#34;&#34;
        Call EQ3 on a .3i input file.
        
        Parameters
        ----------
        filename_3i : str
            Name of 3i input file.
        
        db : str
            Three letter code of database.
        
        path_3i : path str, default current working directory
            Path of .3i input files.
            
        path_3o : path str, default current working directory
            Path of .3o output files.
        
        path_3p : path str, default current working directory
            Path of .3p pickup files.
        
        data1_path : str, default None
            File path of data1 file.
            
        dynamic_db_name : str
            Database name to be printed if dynamic databases are being used.
            This parameter is for internal use.
        &#34;&#34;&#34;

        # get current working dir
        cwd = os.getcwd()
        cwdd = cwd + &#34;/&#34;
        
        if samplename == None:
            samplename = filename_3i[:-3]
        
        if self.verbose &gt; 0 and dynamic_db_name == None:
            print(&#39;Using &#39; + db + &#39; to speciate &#39; + samplename)
        elif self.verbose &gt; 0 and isinstance(dynamic_db_name, str):
            print(&#39;Using &#39; + dynamic_db_name + &#39; to speciate &#39; + samplename)
            
        args = [&#34;cd&#34;, &#34;&#39;&#34; + cwdd+path_3i+&#34;&#39;&#34;, &#34;;&#34;, # change directory to where 3i files are stored
                self.eq36co + &#39;/eq3nr&#39;, # path to EQ3NR executable
                &#34;&#39;&#34; + data1_path + &#34;/data1.&#34; + db+&#34;&#39;&#34;, # path to data1 file
                &#34;&#39;&#34;+cwdd + path_3i +&#34;/&#34;+ filename_3i+&#34;&#39;&#34;] # path to 3i file
        
        args = &#34; &#34;.join(args)
        
        self.__run_script_and_wait(args) # run EQ3
        
        filename_3o = filename_3i[:-1] + &#39;o&#39;
        filename_3p = filename_3i[:-1] + &#39;p&#39;
        
        # The new eq36 build truncates names, e.g., MLS.Source.3i creates MLS.3o
        # Correct for this here:
        files_3o = [file for file in os.listdir(cwdd + path_3i) if &#34;.3o&#34; in file]
        files_3p = [file for file in os.listdir(cwdd + path_3i) if &#34;.3p&#34; in file]
        
        if len(files_3o) == 0:
            if self.verbose &gt; 0:
                print(&#39;Error: EQ3 failed to produce output for &#39; + filename_3i)
        elif len(files_3o) == 1:
            file_3o = files_3o[0]
            try:
                # move output
                shutil.move(cwdd + path_3i+&#34;/&#34;+file_3o, cwdd + path_3o+&#34;/&#34;+filename_3o)
            except:
                self.err_handler.raise_exception(&#34;Error: could not move&#34;, path_3i+&#34;/&#34;+file_3o, &#34;to&#34;, path_3o+&#34;/&#34;+filename_3o)
        else:
            self.err_handler.raise_exception(&#34;Error: multiple output files detected for one speciation calculation.&#34;)
            
        if len(files_3p) == 0:
            if self.verbose &gt; 0:
                print(&#39;Error: EQ3 failed to produce output for &#39; + filename_3i)
        elif len(files_3p) == 1:
            file_3p = files_3p[0]
            try:
                # move output
                shutil.move(cwdd + path_3i+&#34;/&#34;+file_3p, cwdd + path_3p+&#34;/&#34;+filename_3p)
            except:
                self.err_handler.raise_exception(&#34;Error: could not move&#34;, path_3i+&#34;/&#34;+file_3p, &#34;to&#34;, path_3p+&#34;/&#34;+filename_3p)
        else:
            self.err_handler.raise_exception(&#34;Error: multiple pickup files detected for one speciation calculation.&#34;)

                    
    def runeq6(self,
               filename_6i,
               db,
               samplename=None,
               path_6i=&#34;&#34;,
               data1_path=None,
               dynamic_db_name=None):
        
        &#34;&#34;&#34;
        Call EQ6 on a .6i input file.
        
        Parameters
        ----------
        filename_6i : str
            Name of 6i input file.
        
        db : str
            Three letter code of database.
        
        samplename : str
            The name of the sample, used to announce which sample is being run.
        
        path_6i : path str, default current working directory
            Path of directory containing .6i input files.
            
        data1_path : path str, default current working directory
            Path of directory where the data1 thermodynamic database file is
            stored. The data1 file will be called from this location to
            perform the speciation. The data1 file must be named
            data1.xyz, where xyz matches `db`, the three letter code of your
            chosen database.
            
        dynamic_db_name : str
            Database name to be printed if dynamic databases are being used.
            This parameter is for internal use.
        &#34;&#34;&#34;

        if data1_path == None:
            data1_path = self.eq36da
        
        # get current working dir
        cwd = os.getcwd()
        cwdd = cwd + &#34;/&#34;
        
        if samplename == None:
            samplename = filename_6i[:-3]
        
        if self.verbose &gt; 0 and dynamic_db_name == None:
            print(&#39;Using &#39; + db + &#39; to react &#39; + samplename)
        elif self.verbose &gt; 0 and isinstance(dynamic_db_name, str):
            print(&#39;Using &#39; + dynamic_db_name + &#39; to react &#39; + samplename)

        args = [&#34;cd&#34;, &#34;&#39;&#34; + cwdd+path_6i+&#34;&#39;&#34;, &#34;;&#34;, # change directory to 6i folder
                self.eq36co+&#39;/eq6&#39;, # path of EQ6 executable
                &#34;&#39;&#34; + data1_path + &#34;/data1.&#34; + db+&#34;&#39;&#34;, # path to data1 file
                &#34;&#39;&#34;+cwdd+path_6i + filename_6i+&#34;&#39;&#34;] # path of 6i file
        
        args = &#34; &#34;.join(args)
        
        self.__run_script_and_wait(args) # run EQ6
        
                
    def __mk_check_del_directory(self, path):
        
        &#34;&#34;&#34;
        Checks for the dir being created. If it is already present, delete it
        before recreating it.
        &#34;&#34;&#34;
        
        if not os.path.exists(path):
            os.makedirs(path)
        else:
            shutil.rmtree(path)
            os.makedirs(path)

    
    def __run_script_and_wait(self, args):
        
        &#34;&#34;&#34;
        Runs shell commands.
        &#34;&#34;&#34;
        
        # DEVNULL and STDOUT needed to suppress all warnings
        subprocess.Popen(args, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT, shell=True).wait()

            
    def _delete_rxn_folders(self):
        
        &#34;&#34;&#34;
        Deletes folders storing raw EQ3/6 input and output.
        &#34;&#34;&#34;
        
        if os.path.exists(&#39;rxn_3i&#39;) and os.path.isdir(&#39;rxn_3i&#39;):
            shutil.rmtree(&#39;rxn_3i&#39;)
        if os.path.exists(&#39;rxn_3o&#39;) and os.path.isdir(&#39;rxn_3o&#39;):
            shutil.rmtree(&#39;rxn_3o&#39;)
        if os.path.exists(&#39;rxn_3p&#39;) and os.path.isdir(&#39;rxn_3p&#39;):
            shutil.rmtree(&#39;rxn_3p&#39;)
        if os.path.exists(&#39;rxn_6i&#39;) and os.path.isdir(&#39;rxn_6i&#39;):
            shutil.rmtree(&#39;rxn_6i&#39;)
        if os.path.exists(&#39;rxn_6o&#39;) and os.path.isdir(&#39;rxn_6o&#39;):
            shutil.rmtree(&#39;rxn_6o&#39;)
        if os.path.exists(&#39;rxn_6p&#39;) and os.path.isdir(&#39;rxn_6p&#39;):
            shutil.rmtree(&#39;rxn_6p&#39;)
        if os.path.exists(&#39;eqpt_files&#39;) and os.path.isdir(&#39;eqpt_files&#39;):
            shutil.rmtree(&#39;eqpt_files&#39;)
        if os.path.exists(&#39;rxn_data0&#39;) and os.path.isdir(&#39;rxn_data0&#39;):
            shutil.rmtree(&#39;rxn_data0&#39;)


    @staticmethod
    def __f(x, poly_coeffs):
        # return values from a polynomial fit
        value = 0
        for i in range(0,len(poly_coeffs)):
            value += poly_coeffs[i]*x**i
        return value


    def __plot_TP_grid_polyfit(self, xvals, yvals, poly_coeffs_1, poly_coeffs_2,
                               res=500, width=600, height=300):

        print(&#34;R COEFFS&#34;)
        print(poly_coeffs_1)
        print(poly_coeffs_2)
        
        
        f1_x = np.linspace(xvals[0], xvals[3], num=res)
        f2_x = np.linspace(xvals[3], xvals[7], num=res)
        f1_y = [self.__f(x, poly_coeffs_1) for x in f1_x]
        f2_y = [self.__f(x, poly_coeffs_2) for x in f2_x]

        fig = go.Figure()

        fig.add_trace(go.Scatter(x=f1_x, y=f1_y,
                            mode=&#39;lines&#39;,
                            name=&#39;f1&#39;))
        fig.add_trace(go.Scatter(x=f2_x, y=f2_y,
                            mode=&#39;lines&#39;,
                            name=&#39;f2&#39;))
        fig.add_trace(go.Scatter(x=xvals, y=yvals,
                            mode=&#39;markers&#39;,
                            name=&#39;TP points&#39;))
        
        fig.update_layout(legend_title=None,
                          title={&#39;text&#39;:&#34;TP grid polyfit&#34;}, autosize=False,
                          width=width, height=height,
                          margin={&#34;t&#34;: 40}, xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True}, template=&#34;simple_white&#34;)

        fig[&#39;layout&#39;][&#39;xaxis&#39;][&#39;title&#39;]=&#39;Temperature, C&#39;
        fig[&#39;layout&#39;][&#39;yaxis&#39;][&#39;title&#39;]=&#39;Pressure, bar&#39;
            
        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [],
                  &#39;toImageButtonOptions&#39;: {
                                           &#39;format&#39;: &#39;png&#39;, # one of png, svg, jpeg, webp
                                           &#39;filename&#39;: &#34;TP_grid_fit&#34;,
                                           &#39;height&#39;: height,
                                           &#39;width&#39;: width,
                                           &#39;scale&#39;: 1,
                                           },
                 }

        fig.show(config=config)

    
    def _interpolate_logK(self, T, logK_grid, T_grid, logK_extrapolate=&#34;none&#34;):
        
        logK_grid_trunc = [t for t in logK_grid if not math.isnan(t)]
        grid_len = len(logK_grid_trunc)
        logK_grid = logK_grid_trunc
        T_grid = T_grid[0:grid_len]
        
        if logK_extrapolate==&#34;none&#34; and (T &gt; max(T_grid) or T &lt; min(T_grid)):
            return np.nan, &#34;no fit&#34;
        elif logK_extrapolate==&#34;no fit&#34;:
            return np.nan, &#34;no fit&#34;
        
        # turns off poor polyfit warning
        # TODO: restore polyfit warning setting afterward
        warnings.simplefilter(&#39;ignore&#39;, np.RankWarning)
        
        if len(T_grid) &gt;= 4:
            if (len(T_grid) % 2) == 0:
                # if T_grid has an even length
                n_mid1 = math.floor(len(T_grid)/2)-1
                n_mid2 = n_mid1+1
            else:
                # if T_grid has an odd length
                n_mid1 = math.floor(len(T_grid)/2)
                n_mid2 = n_mid1+1

            poly_coeffs_1 = np.polyfit(T_grid[:n_mid2], logK_grid[:n_mid2], len(T_grid[:n_mid2])-1)
            poly_coeffs_2 = np.polyfit(T_grid[n_mid1:], logK_grid[n_mid1:], len(T_grid[n_mid1:])-1)

            model_1 = np.poly1d(poly_coeffs_1)
            model_2 = np.poly1d(poly_coeffs_2)

            if T &gt;= T_grid[0] and T &lt;= T_grid[n_mid1]:
                logK = model_1(T)
                model = &#34;model 1&#34;
            elif T &gt; T_grid[n_mid1] and T &lt;= T_grid[-1]:
                logK = model_2(T)
                model = &#34;model 2&#34;
            else:
                # dependent on extrapolation option
                if logK_extrapolate==&#34;none&#34;:
                    logK = np.nan
                    model = &#34;no fit&#34;
                elif logK_extrapolate==&#34;poly&#34;:
                    if T &lt; T_grid[0]:
                        logK = model_1(T)
                        model = &#34;model 1&#34;
                    elif T &gt; T_grid[-1]:
                        logK = model_2(T)
                        model = &#34;model 2&#34;
                    else:
                        logK = np.nan
                        model = &#34;no fit&#34;
                elif logK_extrapolate==&#34;linear&#34;:
                    poly_coeffs_1 = np.polyfit(T_grid[0:2], logK_grid[0:2], 1)
                    linear_model_1 = np.poly1d(poly_coeffs_1)
                    poly_coeffs_2 = np.polyfit(T_grid[-2:], logK_grid[-2:], 1)
                    linear_model_2 = np.poly1d(poly_coeffs_2)
                    if T &lt; T_grid[0]:
                        logK = linear_model_1(T)
                        model = &#34;linear model 1&#34;
                    elif T &gt; T_grid[-1]:
                        logK = linear_model_2(T)
                        model = &#34;linear model 2&#34;
                    else:
                        logK = np.nan
                        model = &#34;no fit&#34;
                elif logK_extrapolate==&#34;flat&#34;:
                    if T &lt; T_grid[0]:
                        logK = logK_grid[0]
                        model = &#34;flat extrap. 1&#34;
                    elif T &gt; T_grid[-1]:
                        logK = logK_grid[-1]
                        model = &#34;flat extrap. 2&#34;
                    else:
                        logK = np.nan
                        model = &#34;no fit&#34;
        elif len(T_grid) &gt;= 2:
            poly_coeffs = np.polyfit(T_grid, logK_grid, len(T_grid)-1)
            model_fit = np.poly1d(poly_coeffs)
            if T &gt;= T_grid[0] and T &lt;= T_grid[-1]:
                logK = model_fit(T)
                model = &#34;model 1&#34;
            else:
                # dependent on extrapolation option
                if logK_extrapolate==&#34;none&#34;:
                    logK = np.nan
                    model = &#34;no fit&#34;
                elif logK_extrapolate in [&#34;poly&#34;, &#34;linear&#34;]:
                    logK = model_fit(T)
                    model = &#34;model 1&#34;
                elif logK_extrapolate==&#34;flat&#34;:
                    if T &lt; T_grid[0]:
                        logK = logK_grid[0]
                        model = &#34;flat extrap.&#34;
                    elif T &gt; T_grid[-1]:
                        logK = logK_grid[-1]
                        model = &#34;flat extrap.&#34;
                    else:
                        logK = np.nan
                        model = &#34;no fit&#34;
        else:
            # only one T_grid value
            if T == T_grid[0]:
                logK = logK_grid[0]
                model = &#34;single point extrap.&#34;
            else:
                # dependent on extrapolation option
                if logK_extrapolate==&#34;none&#34;:
                    logK = np.nan
                    model = &#34;no fit&#34;
                elif logK_extrapolate!=&#34;none&#34;:
                    logK = logK_grid[0]
                    model = &#34;single point extrap.&#34;
            
#         ### TEST
#         from matplotlib import pyplot as plt
#         plt.plot(T_grid, logK_grid, &#39;o&#39;)
#         T_m1 = np.linspace(min(T_grid[:n_mid2]), max(T_grid[:n_mid2]), 100)
#         T_m2 = np.linspace(min(T_grid[n_mid1:]), max(T_grid[n_mid1:]), 100)
#         plt.plot(T_m1, model_1(T_m1))
#         plt.plot(T_m2, model_2(T_m2))
#         ###
        
        return logK, model
        
        
    def speciate(self,
                 input_filename,
                 db=None,
                 db_solid_solution=None,
                 db_logK=None,
                 logK_extrapolate=None,
                 activity_model=&#34;b-dot&#34;,
                 redox_flag=&#34;logfO2&#34;,
                 redox_aux=&#34;Fe+3&#34;,
                 default_logfO2=-6,
                 exclude=[],
                 suppress=[],
                 alter_options=[],
                 charge_balance_on=&#34;none&#34;,
                 suppress_missing=True,
                 blanks_are_0=False,
                 strict_minimum_pressure=True,
                 aq_scale=1,
                 verbose=1,
                 report_filename=None,
                 get_aq_dist=True,
                 aq_dist_type=&#34;log_activity&#34;,
                 get_mass_contribution=True,
                 mass_contribution_other=True,
                 get_mineral_sat=True,
                 mineral_sat_type=&#34;affinity&#34;,
                 get_redox=True,
                 redox_type=&#34;Eh&#34;,
                 get_ion_activity_ratios=True,
                 get_fugacity=True,
                 get_basis_totals=True,
                 get_solid_solutions=True,
                 get_affinity_energy=False,
                 negative_energy_supplies=False,
                 rxn_filename=None,
                 not_limiting=[&#34;H+&#34;, &#34;OH-&#34;, &#34;H2O&#34;],
                 get_charge_balance=True,
                 custom_db=False, # deprecated
                 batch_3o_filename=None,
                 delete_generated_folders=False,
                 db_args={}):
        
        &#34;&#34;&#34;
        Calculate the equilibrium distribution of chemical species in solution.
        Additionally, calculate chemical affinities and energy supplies for
        user-specified reactions.
        
        Parameters
        ----------
        input_filename : str
            User-supplied utf8-encoded comma separated value (csv) file
            containing sample data intended for speciation. The file must
            follow this format:
            
            - the first row is a header row that must contain the names of the
              species to be included in the speciation calculation. There
              cannot be duplicate headers.
            - the second row must contain subheaders for each species in the
              header row. These subheaders must be taken from the following:
              
                    degC
                    ppm
                    ppb
                    Suppressed
                    Molality
                    Molarity
                    mg/L
                    mg/kg.sol
                    Alk., eq/kg.H2O
                    Alk., eq/L
                    Alk., eq/kg.sol
                    Alk., mg/L CaCO3
                    Alk., mg/L HCO3-
                    Log activity
                    Log act combo
                    Log mean act
                    pX
                    pH
                    pHCl
                    pmH
                    pmX
                    Hetero. equil.
                    Homo. equil.
                    Make non-basis
                    
            - &#39;Temperature&#39; must be included as a header, with &#39;degC&#39; as its
              subheader.
            - The first column must contain sample names. There cannot be
              duplicate sample names.
        
        db : str, default &#34;wrm&#34;
            Determines which thermodynamic database is used in the speciation
            calculation. There are several options available:
            - Three letter file extension for the desired data1 database, e.g.,
            &#34;wrm&#34;. This will use a data1 file with this file extension, e.g.,
            &#34;data1.wrm&#34; located in the path stored in the &#39;EQ36DA&#39; environment
            variable used by EQ3NR.
            - The name of a data0 file located in the current working directory,
            e.g., &#34;data0.wrm&#34;. This data0 file will be compiled by EQPT
            automatically during the speciation calculation.
            - The name of a CSV file containing thermodynamic data located in
            the current working directory, e.g., &#34;wrm_data.csv&#34;. The CSV file
            will be used to generate a data0 file for each sample (using
            additional arguments from `db_args` if desired).
            - The URL of a data0 file, e.g.,
            &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#34;
            - The URL of a CSV file containing thermodynamic data, e.g.,
            &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
        
        db_solid_solution : str, optional
            Used only if `db` points to a thermodynamic data CSV file (or the
            URL of a CSV hosted online). Determines which thermodynamic database
            is used for idealized solid solutions in the speciation calculation.
            There are two options:
            - The name of a CSV file containing solid solution parameters
            located in the current working directory, e.g.,
            &#34;wrm_solid_solutions.csv&#34;
            - The URL of a CSV file containing solid solution parameters, e.g.,
            &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/solid_solutions.csv&#34;
        
        db_logK : str, optional
            The name of the CSV file containing species with dissociation
            constants but no other properties or parameters. Used only if `db`
            points to a thermodynamic data CSV file (or the URL of a CSV hosted
            online).
        
        activity_model : str, default &#34;b-dot&#34;
            Activity model to use for speciation. Can be either &#34;b-dot&#34;,
            or &#34;davies&#34;. NOTE: the &#34;pitzer&#34; model is not yet implemented.
        
        redox_flag : str, default &#34;O2(g)&#34;
            Determines which column in the sample input file sets the overall
            redox state of the samples. Options for redox_flag include &#39;O2(g)&#39;,
            &#39;pe&#39;, &#39;Eh&#39;, &#39;logfO2&#39;, and &#39;redox aux&#39;. The code will search your
            sample spreadsheet file (see `filename`) for a column corresponding
            to the option you chose:
            
            * &#39;O2(g)&#39; with a valid subheader for a gas
            * &#39;pe&#39; with subheader pe
            * &#39;Eh&#39; with subheader volts
            * &#39;logfO2&#39; with subheader logfO2
            * &#39;redox aux&#39; will search for a column corresponding to the
              auxilliary basis species selected to form a redox couple with its
              linked strict basis species (see `redox_aux`). For example, the
              redox couple Fe+2/Fe+3 would require a column named Fe+3
            
            If an appropriate header or redox data cannot be found to define
            redox state, `default_logfO2` is used to set sample logfO2.
            
            There is a special case where dissolved oxygen can be used to impose
            sample redox state if `redox_flag` is set to logfO2 and a column named
            logfO2 does not appear in your sample spreadsheet. If there is a
            column corresponding to dissolved oxygen measurements, logfO2 is
            calculated from the equilibrium reaction O2(aq) = O2(g) at the
            temperature and pressure of the sample using the revised Helgeson-
            Kirkham-Flowers (HKF) equation of state (JC Tanger IV and HC
            Helgeson, Am. J. Sci., 1988, 288, 19).
        
        redox_aux : default &#34;Fe+3&#34;, optional
            Ignored unless `redox_flag` equals 1. Name of the auxilliary species
            whose reaction links it to a basis species (or another auxilliary
            species) such that they form a redox couple that controls sample
            fO2. For instance, Fe+3 is linked to Fe+2 in many supporting data
            files, so selecting `redox_flag` = 1 and `redox_aux` = &#34;Fe+3&#34; will
            set sample fO2 based on the Fe+2/Fe+3 redox couple.
        
        default_logfO2 : float, default -6
            Default value for sample logfO2 in case redox data cannot be found
            in the user-supplied sample spreadsheet.
        
        exclude : list of str, default []
            Names of columns in the user-supplied sample spreadsheet that should
            not be considered aqueous species. Useful for excluding columns
            containing sample metatadata, such as &#34;Year&#34; and &#34;Location&#34;.
            
        suppress : list of str, default []
            Names of chemical species that will be prevented from forming in the
            speciation calculation.
        
        alter_options : list, default []
            A list of lists, e.g.,
            [[&#34;CaOH+&#34;, &#34;Suppress&#34;], [&#34;CaCl+&#34;, &#34;AugmentLogK&#34;, -1]]
            The first element of each interior list is the name of a species.
            The second element is an option to alter the species, and can be:
            - Suppress : suppress the formation of the species. (See also:
            `suppress`).
            - Replace : replace the species&#39; log K value with a desired value.
            - AugmentLogK : augment the value of the species&#39; log K.
            - AugmentG : augment the Gibbs free energy of the species by a
            desired value, in kcal/mol.
            The third element is a numeric value corresponding to the chosen
            option. A third element is not required for Suppress.
            
        charge_balance_on : str, default &#34;none&#34;
            If &#34;none&#34;, will not balance electrical charge between cations and
            anions in the speciation calculation. If a name of a species is
            supplied instead, the activity of that species will be allowed to
            change until charge balance is obtained. For example,
            charge_balance_on = &#34;H+&#34; will calculate what pH a sample must have
            to have zero net charge.
        
        suppress_missing : bool, default True
            Suppress the formation of an aqueous species if it is missing a
            value in the user-supplied sample spreadsheet?

        blanks_are_0 : bool, default False
            Assume all blank values in the water chemistry input file are 0?
            
        strict_minimum_pressure : bool, default True
            Ensure that the minimum pressure in the speciation calculation does
            not go below the minimum pressure in the TP grid of the data0 file?
        
        aq_scale : float, default 1
            Scale factor for the mass of the aqueous phase. By default, the
            aqueous phase is 1 kg of solvent.
        
        verbose : int, 0, 1, or 2, default 1
            Level determining how many messages are returned during a
            calculation. 2 for all messages, 1 for errors or warnings only,
            0 for silent.
            
        report_filename : str, optional
            Name of the comma separated values (csv) report file generated when
            the calculation is complete. If this argument is not defined, a
            report file is not generated.
            
        get_aq_dist : bool, default True
            Calculate distributions of aqueous species?
        
        aq_dist_type : str, default &#34;log_activity&#34;
            Desired units of measurement for reported distributions of aqueous
            species. Can be &#34;molality&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, or
            &#34;log_activity&#34;. Ignored if `get_aq_dist` is False.
        
        get_mass_contribution : bool, default True
            Calculate basis species contributions to mass balance of aqueous
            species?
        
        mass_contribution_other : bool, default True
            Include an &#34;other&#34; species for the sake of summing percents of basis
            species contributions to 100%? Ignored if `get_mass_contribution` is
            False.
        
        get_mineral_sat : bool, default True
            Calculate saturation states of pure solids?
        
        mineral_sat_type : str, default &#34;affinity&#34;
            Desired units of measurement for reported saturation states of pure
            solids. Can be &#34;logQoverK&#34; or &#34;affinity&#34;. Ignored if
            `get_mineral_sat` is False.
        
        get_redox : bool, default True
            Calculate potentials of redox couples?
            
        redox_type : str, default &#34;Eh&#34;
            Desired units of measurement for reported redox potentials. Can be
            &#34;Eh&#34;, &#34;pe&#34;, &#34;logfO2&#34;, or &#34;Ah&#34;. Ignored if `get_redox` is False.
        
        get_ion_activity_ratios : bool, default True
            Calculate ion/H+ activity ratios and neutral species activities?
        
        get_fugacity : bool, default True
            Calculate gas fugacities?

        get_basis_totals : bool, default True
            Report total compositions of basis aqueous species?

        get_solid_solutions : bool, default True
            Permit the calculation of solid solutions and include them in the
            speciation report?
        
        get_affinity_energy : bool, default False
            Calculate affinities and energy supplies of reactions listed in a
            separate user-supplied file?
        
        negative_energy_supplies : bool, default False
            Report negative energy supplies? If False, negative energy supplies
            are reported as 0 cal/kg H2O. If True, negative energy supplies are
            reported. A &#39;negative energy supply&#39; represents the energy cost of
            depleting the limiting reactant of a reaction. This metric is not
            always helpful when examing energy supply results, so this option is
            set to False by default.
        
        rxn_filename : str, optional
            Name of .txt file containing reactions used to calculate affinities
            and energy supplies. Ignored if `get_affinity_energy` is False.
        
        not_limiting : list, default [&#34;H+&#34;, &#34;OH-&#34;, &#34;H2O&#34;]
            List containing names of species that are not considered limiting
            when calculating energy supplies. Ignored if `get_affinity_energy`
            is False.
        
        get_charge_balance : bool, default True
            Calculate charge balance and ionic strength?
        
        batch_3o_filename : str, optional
            Name of rds (R object) file exported after the speciation
            calculation? No file will be generated if this argument is not
            defined.
            
        delete_generated_folders : bool, default False
            Delete the &#39;rxn_3i&#39;, &#39;rxn_3o&#39;, &#39;rxn_3p&#39;, and &#39;eqpt_files&#39; folders
            containing raw EQ3NR input, output, pickup, and EQPT files once the
            speciation calculation is complete?
           
        db_args : dict, default {}
            Dictionary of arguments to modify how the thermodynamic database is
            processed. Only used when `db` points to thermodynamic data in a CSV
            file. Ignored if `db` points to a data0 file (because a data0 file
            is already ready for a speciation calculation). Options for
            `db_args` are passed to the `create_data0` function, so refer to
            `create_data0` for more information about what options are possible.
            
            - Example of `db_args` where organics are excluded and redox is
            suppressed for Fe and S:
            db_args = {
               &#34;exclude_category&#34;:{&#34;category_1&#34;:[&#34;organic_aq&#34;]},
               &#34;suppress_redox&#34;:[&#34;Fe&#34;, &#34;S&#34;],
            }
            
        
        Returns
        -------
        speciation : object of class Speciation
            Contains the results of the speciation calculation.
        
        &#34;&#34;&#34;
        
        self.batch_T = []
        self.batch_P = []
        
        self.verbose = verbose
        
        if db != None:
            # load new thermodynamic database
            self.thermo._set_active_db(db)
        else:
            db = self.thermo.db
            
        if self.thermo.thermo_db_type == &#34;CSV&#34;:
            db_args[&#34;db&#34;] = &#34;dyn&#34;
            
        dynamic_db = self.thermo.dynamic_db
        data0_lettercode = self.thermo.data0_lettercode # needs to be this way
        
        
        if (self.thermo.thermo_db_type == &#34;data0&#34; or self.thermo.thermo_db_type == &#34;data1&#34;) and len(db_args) &gt; 0:
            if self.verbose &gt; 0:
                print(&#34;Warning: Ignoring db_args because a premade data0 or data1 file is being used: &#39;&#34; + db + &#34;&#39;&#34;)
            
        redox_suppression = False
        if &#34;suppress_redox&#34; in db_args.keys() and self.thermo.thermo_db_type != &#34;data0&#34; and self.thermo.thermo_db_type != &#34;data1&#34;:
            if len(db_args[&#34;suppress_redox&#34;]) &gt; 0:
                redox_suppression = True
        
        # check input sample file for errors
        if activity_model != &#39;pitzer&#39;: # TODO: allow check_sample_input_file() to handle pitzer
            sample_temps, sample_press = self._check_sample_input_file(
                                          input_filename, exclude, db,
                                          dynamic_db, charge_balance_on, suppress_missing,
                                          redox_suppression)
        
        if aq_dist_type not in [&#34;molality&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, &#34;log_activity&#34;]:
            self.err_handler.raise_exception(&#34;Unrecognized aq_dist_type. Valid &#34;
                &#34;options are &#39;molality&#39;, &#39;log_molality&#39;, &#39;log_gamma&#39;, &#39;log_activity&#39;&#34;)
        if mineral_sat_type not in [&#34;logQoverK&#34;, &#34;affinity&#34;]:
            self.err_handler.raise_exception(&#34;Unrecognized mineral_sat_type. Valid &#34;
                &#34;options are &#39;logQoverK&#39; or &#39;affinity&#39;&#34;)
        if redox_type not in [&#34;Eh&#34;, &#34;pe&#34;, &#34;logfO2&#34;, &#34;Ah&#34;]:
            self.err_handler.raise_exception(&#34;Unrecognized redox_type. Valid &#34;
                &#34;options are &#39;Eh&#39;, &#39;pe&#39;, &#39;logfO2&#39;, or &#39;Ah&#39;&#34;)
        
        if redox_flag == &#34;O2(g)&#34; or redox_flag == -3:
            redox_flag = -3
        elif redox_flag == &#34;pe&#34; or redox_flag == -2:
            redox_flag = -2
        elif redox_flag == &#34;Eh&#34; or redox_flag == -1:
            redox_flag = -1
        elif redox_flag == &#34;logfO2&#34; or redox_flag == 0:
            redox_flag = 0
        elif redox_flag == &#34;redox aux&#34; or redox_flag == 1:
            redox_flag = 1
        else:
            self.err_handler.raise_exception(&#34;Unrecognized redox flag. Valid options are &#39;O2(g)&#39;&#34;
                                             &#34;, &#39;pe&#39;, &#39;Eh&#39;, &#39;logfO2&#39;, &#39;redox aux&#39;&#34;)
            
        # handle batch_3o naming
        if batch_3o_filename != None:
            if &#34;.rds&#34; in batch_3o_filename[-4:]:
                batch_3o_filename = batch_3o_filename
            else:
                batch_3o_filename = &#34;batch_3o_{}.rds&#34;.format(data0_lettercode)
        else:
            batch_3o_filename = ro.r(&#34;NULL&#34;)
        
        # reset logK_models whenever speciate() is called
        # (prevents errors when speciations are run back-to-back)
        self.logK_models = {}
        
        # dynamic data0 creation per sample
        if dynamic_db:
            db_args[&#34;fill_data0&#34;] = False
            db_args[&#34;dynamic_db&#34;] = True
            db_args[&#34;verbose&#34;] = self.verbose
            db_args[&#34;dynamic_db_sample_temps&#34;] = sample_temps
            db_args[&#34;dynamic_db_sample_press&#34;] = sample_press
            
            if db_logK != None:
                self.thermo._load_logK(db_logK, source=&#34;file&#34;)
            
            if logK_extrapolate != None:
                db_args[&#34;logK_extrapolate&#34;] = logK_extrapolate
            elif self.thermo.logK_active:
                db_args[&#34;logK_extrapolate&#34;] = self.thermo.logK_extrapolate
                logK_extrapolate = self.thermo.logK_extrapolate
            else:
                logK_extrapolate = &#34;none&#34;

            if db_solid_solution != None:
                if not (db_solid_solution[0:8].lower() == &#34;https://&#34; or db_solid_solution[0:7].lower() == &#34;http://&#34; or db_solid_solution[0:4].lower() == &#34;www.&#34;):
                    if os.path.exists(db_solid_solution) and os.path.isfile(db_solid_solution):
                        db_args[&#34;filename_ss&#34;] = db_solid_solution
                    else:
                        self.err_handler.raise_exception(&#34;Error: could not locate &#34; + str(db_solid_solution))
                else:
                    db_solid_solution_csv_name = db_solid_solution.split(&#34;/&#34;)[-1].lower()
            
                    # Download from URL and decode as UTF-8 text.
                    with urlopen(db_solid_solution) as webpage:
                        content = webpage.read().decode()
                        
                    # Save to CSV file.
                    with open(db_solid_solution_csv_name, &#39;w&#39;) as output:
                        output.write(content)
                        
                    db_args[&#34;filename_ss&#34;] = db_solid_solution_csv_name
                    
            if self.verbose &gt; 0:
                print(&#34;Getting&#34;, self.thermo.thermo_db_filename, &#34;ready. This will take a moment...&#34;)
    
            thermo_df, data0_file_lines, grid_temps, grid_press, data0_lettercode, water_model, P1, plot_poly_fit = self.create_data0(**db_args)
            
        if self.thermo.custom_data0 and not dynamic_db:
            self.__mk_check_del_directory(&#39;eqpt_files&#39;)
            if self.thermo.thermo_db_type != &#34;data1&#34;:
                self.runeqpt(data0_lettercode)
            
            if os.path.exists(&#34;data1.&#34;+data0_lettercode) and os.path.isfile(&#34;data1.&#34;+data0_lettercode):
                try:
                    # store contents of data1 file in AqEquil object
                    with open(&#34;data1.&#34;+data0_lettercode, mode=&#39;rb&#39;) as data1:
                        self.data1[&#34;all_samples&#34;] = data1.read()
                    # move or copy data1
                    if self.thermo.thermo_db_type != &#34;data1&#34;:
                        shutil.move(&#34;data1.&#34;+data0_lettercode, &#34;eqpt_files/data1.&#34;+data0_lettercode)
                    else:
                        shutil.copyfile(&#34;data1.&#34;+data0_lettercode, &#34;eqpt_files/data1.&#34;+data0_lettercode)
                        
                except:
                    if self.verbose &gt; 0:
                        print(&#39;Error: Could not move&#39;, &#34;data1.&#34;+data0_lettercode, &#34;to eqpt_files&#34;)
            
            data1_path = os.getcwd()+&#34;/eqpt_files&#34; # creating a folder name without spaces to store the data1 overcomes the problem where environment variables with spaces do not work properly when assigned to EQ36DA
            
            data0_path = &#34;data0.&#34; + data0_lettercode
            
        elif dynamic_db:
            self.__mk_check_del_directory(&#39;eqpt_files&#39;)
            
        else:
            data0_path = self.eq36da + &#34;/data0.&#34; + data0_lettercode
        
        # gather information from data0 file and perform checks
        if not dynamic_db:
            if os.path.exists(data0_path) and os.path.isfile(data0_path):
                with open(data0_path) as data0:
                    data0_lines = data0.readlines()
                    start_index = [i+1 for i, s in enumerate(data0_lines) if s == &#39;temperatures\n&#39;]
                    if activity_model == &#39;davies&#39; or activity_model == &#39;b-dot&#39;:
                        end_index = [i for i, s in enumerate(data0_lines) if s == &#39;debye huckel a (adh)\n&#39;]
                    elif activity_model == &#39;pitzer&#39;:
                        end_index = [i for i, s in enumerate(data0_lines) if s == &#39;debye huckel aphi\n&#39;]
                    db_grids_unformatted = [i.split(&#34;pressures&#34;)[0] for i in data0_lines[start_index[0]:end_index[0]]]
                    db_grids = [&#34; &#34;.join(i.split()) for i in db_grids_unformatted if i != &#39;&#39;]
                    grid_temps = db_grids[0] + &#34; &#34; + db_grids[1]
                    grid_press = db_grids[2] + &#34; &#34; + db_grids[3]
                    grid_temps = grid_temps.split(&#34; &#34;)
                    grid_press = grid_press.split(&#34; &#34;)

                    try:
                        n_TP_points = data0_lines[2].split(&#34;points: &#34;)[1] # extract number of TP points from the third line of data0 file
                        n_TP_points = n_TP_points.replace(&#34;\n&#34;, &#34;&#34;)
                        n_TP_points = int(n_TP_points)
                    except:
                        n_TP_points = 8
                    if n_TP_points == 1:
                        grid_temps = grid_temps[0]
                        grid_press = grid_press[0]

                    try:
                        water_model = data0_lines[1].split(&#34;model: &#34;)[1] # extract water model from the second line of data0 file
                        water_model = water_model.replace(&#34;\n&#34;, &#34;&#34;)
                    except:
                        water_model = &#34;SUPCRT92&#34;
    #                     print(&#34;Water model could not be referenced from {}&#34;.format(data0_path)+&#34;&#34;
    #                           &#34;. Defaulting to SUPCRT92 water model...&#34;)


                    if(water_model not in [&#34;SUPCRT92&#34;, &#34;IAPWS95&#34;, &#34;DEW&#34;]):
                        water_model = &#34;SUPCRT92&#34; # the default for EQ3/6
                        print(&#34;Water model given in {}&#34;.format(data0_path)+&#34; was not &#34;
                              &#34;recognized. Defaulting to SUPCRT92 water model...&#34;)
                    
            else: # if a data0 file can&#39;t be found, assume default water model, 0-350 C and PSAT
                water_model = &#34;SUPCRT92&#34;
                grid_temps = [&#34;0.0100&#34;, &#34;50.0000&#34;, &#34;100.0000&#34;, &#34;150.0000&#34;,
                             &#34;200.0000&#34;, &#34;250.0000&#34;, &#34;300.0000&#34;, &#34;350.0000&#34;]
                grid_press = [&#34;1.0000&#34;, &#34;1.0000&#34;, &#34;1.0132&#34;, &#34;4.7572&#34;,
                              &#34;15.5365&#34;, &#34;39.7365&#34;, &#34;85.8378&#34;, &#34;165.2113&#34;]
                
            grid_press_numeric = [float(n) for n in grid_press]
            if min(grid_press_numeric) == 1:
                P1=True
            else:
                P1=False
                
            self._capture_r_output()
        
            r_check_TP_grid = pkg_resources.resource_string(__name__, &#39;check_TP_grid.r&#39;).decode(&#34;utf-8&#34;)
        
            ro.r(r_check_TP_grid)
        
            list_tp = ro.r.check_TP_grid(grid_temps=_convert_to_RVector(grid_temps),
                                         grid_press=_convert_to_RVector(grid_press),
                                         P1=P1,
                                         water_model=water_model,
                                         check_for_errors=False,
                                         verbose=self.verbose)
        
            self._print_captured_r_output()
            
            grid_temps = list(list_tp.rx2(&#34;grid_temps&#34;))
            grid_press = list(list_tp.rx2(&#34;grid_press&#34;))
            poly_coeffs_1 = list_tp.rx2(&#34;poly_coeffs_1&#34;)
            poly_coeffs_2 = list_tp.rx2(&#34;poly_coeffs_2&#34;)
            
            
        else:
            grid_temps = ro.r(&#34;NULL&#34;)
            grid_press = ro.r(&#34;NULL&#34;)
            poly_coeffs_1 = ro.r(&#34;NULL&#34;)
            poly_coeffs_2 = ro.r(&#34;NULL&#34;)
            
            
        if get_affinity_energy:
            if rxn_filename == None and self.affinity_energy_reactions_raw==None:
                err = (&#34;get_affinity_energy is set to True but a reaction TXT &#34;
                       &#34;file is not specified or redox reactions have not yet &#34;
                       &#34;been generated with make_redox_reactions()&#34;)
                self.err_handler.raise_exception(err)
            elif rxn_filename != None:
                self.__file_exists(rxn_filename, &#39;.txt&#39;)
                
                self.affinity_energy_reactions_raw = pd.read_csv(rxn_filename, sep=&#34;\t&#34;, header=None, names=[&#34;col&#34;+str(i) for i in range(1,50)])
                load_rxn_file = True
            else:
                if self.thermo.thermo_db_type != &#34;CSV&#34;:
                    if self.verbose &gt; 0:
                        warn_msg = (&#34;Warning: get_affinity_energy is set to True but &#34;
                            &#34;the active thermodynamic database (&#34;+self.thermo.db+&#34;) is not &#34;
                            &#34;in CSV format. This indicates a possible mismatch between &#34;
                            &#34;the thermodynamic database used to generate redox reactions &#34;
                            &#34;and the one used in this speciation calculation. Continuing anyway...&#34;)
                        print(warn_msg)
                rxn_filename = self.affinity_energy_reactions_raw
                load_rxn_file = False
            

            
        else:
            rxn_filename = &#34;&#34;
            load_rxn_file=False

        
        # handle Alter/Suppress options
        # e.g. [[&#34;CaCl+&#34;, &#34;AugmentLogK&#34;, -1], [&#34;CaOH+&#34;, &#34;Suppress&#34;]]
        alter_options_dict = {}
        if len(alter_options) &gt; 0:
            for ao in alter_options:
                if not isinstance(ao, list):
                    err = (&#34;alter_options must be a list of lists, e.g.,\n&#34;
                          &#34;[[&#39;CaCl+&#39;, &#39;AugmentLogK&#39;, -1], [&#39;CaOH+&#39;, &#39;Suppress&#39;]]&#34;
                          &#34;\nor\n[[&#39;CaHCO3+&#39;, &#39;Suppress&#39;]]&#34;)
                    self.err_handler.raise_exception(err)
                key = ao[0]
                if ao[1] == &#34;Suppress&#34; and len(ao) == 2:
                    ao += [&#34;0&#34;]
                alter_options_dict[key] = _convert_to_RVector(list(ao[1:]))
        alter_options = ro.ListVector(alter_options_dict)
        
        input_dir = &#34;rxn_3i&#34;
        output_dir = &#34;rxn_3o&#34;
        pickup_dir = &#34;rxn_3p&#34;
            
        # preprocess for EQ3 using R scripts
        self._capture_r_output()
        
        r_prescript = pkg_resources.resource_string(
            __name__, &#39;preprocess_for_EQ3.r&#39;).decode(&#34;utf-8&#34;)
        ro.r(r_prescript)
        
        input_processed_list = ro.r.preprocess(input_filename=input_filename,
                                               exclude=_convert_to_RVector(exclude),
                                               grid_temps=_convert_to_RVector(grid_temps),
                                               grid_press=_convert_to_RVector(grid_press),
                                               strict_minimum_pressure=strict_minimum_pressure,
                                               dynamic_db=dynamic_db,
                                               poly_coeffs_1=poly_coeffs_1,
                                               poly_coeffs_2=poly_coeffs_2,
                                               water_model=water_model,
                                               verbose=self.verbose)
        
        
        self._print_captured_r_output()
        
        self.df_input_processed = ro.conversion.rpy2py(input_processed_list.rx2(&#34;df&#34;))
        
        
        if blanks_are_0:
            self.df_input_processed = self.df_input_processed.fillna(1E-18)
        
        self.__mk_check_del_directory(&#39;rxn_3i&#39;)
        self.__mk_check_del_directory(&#39;rxn_3o&#39;)
        self.__mk_check_del_directory(&#39;rxn_3p&#39;)
        if dynamic_db:
            self.__mk_check_del_directory(&#39;rxn_data0&#39;)
        
        # Has the user been warned about redox column during write_3i_file()?
        # Prevents repeated warnings.
        warned_about_redox_column = False
        
        self.batch_T = list(input_processed_list.rx2(&#34;temp_degC&#34;))
        self.batch_P = list(input_processed_list.rx2(&#34;pressure_bar&#34;))
        
        # create and run a 3i file for each sample
        for sample_row_index in range(0, self.df_input_processed.shape[0]):
            
            temp_degC = list(input_processed_list.rx2(&#34;temp_degC&#34;))[sample_row_index]
            pressure_bar = list(input_processed_list.rx2(&#34;pressure_bar&#34;))[sample_row_index]
            
            df = self.df_input_processed.iloc[[sample_row_index]] # double brackets to keep as df row instead of series
            
            samplename = str(df.index[0])
            
            # handle dynamic data0 creation
            if dynamic_db:
                
                self.__fill_data0(thermo_df=ro.conversion.rpy2py(thermo_df),
                                  data0_file_lines=copy.deepcopy(data0_file_lines),
                                  grid_temps=[temp_degC],
                                  grid_press=[pressure_bar],
                                  db=data0_lettercode,
                                  water_model=water_model,
                                  activity_model=activity_model,
                                  P1=P1,
                                  plot_poly_fit=plot_poly_fit,
                                  logK_extrapolate=logK_extrapolate,
                                  dynamic_db=dynamic_db,
                                  verbose=verbose)
                
                if self.thermo.thermo_db_type != &#34;data1&#34;:
                    self.runeqpt(data0_lettercode, dynamic_db=True)
                
                if os.path.exists(&#34;data1.&#34;+data0_lettercode) and os.path.isfile(&#34;data1.&#34;+data0_lettercode):
                    # store contents of data1 file in AqEquil object
                    with open(&#34;data1.&#34;+data0_lettercode, mode=&#39;rb&#39;) as data1:
                        self.data1[samplename] = data1.read()
                    try:
                        # move data1
                        shutil.move(&#34;data1.&#34;+data0_lettercode, &#34;eqpt_files/data1.&#34;+data0_lettercode)
                    except:
                        if self.verbose &gt; 0:
                            print(&#39;Error: Could not move&#39;, &#34;data1.&#34;+data0_lettercode, &#34;to eqpt_files&#34;)

                data1_path = os.getcwd()+&#34;/eqpt_files&#34; # creating a folder name without spaces to store the data1 overcomes the problem where environment variables with spaces do not work properly when assigned to EQ36DA

                data0_path = &#34;data0.&#34; + data0_lettercode
                
            else:
                pressure_bar = list(input_processed_list.rx2(&#34;pressure_bar&#34;))[sample_row_index]
                data1_path = self.thermo.eq36da
            
            # allowed aq block species are left after any category exclusion in db_args
            allowed_aq_block_species = [&#34;all&#34;]
            if dynamic_db:
                allowed_aq_block_species = list(thermo_df[&#34;name&#34;]) + FIXED_SPECIES
            
            # write 3i files
            self._capture_r_output()

            warned_about_redox_column = ro.r.write_3i_file(df=ro.conversion.py2rpy(df),
                               temp_degC=temp_degC,
                               pressure_bar=pressure_bar,
                               minimum_pressure=input_processed_list.rx2(&#34;minimum_pressure&#34;),
                               strict_minimum_pressure=strict_minimum_pressure,
                               pressure_override=dynamic_db,
                               suppress_missing=suppress_missing,
                               exclude=input_processed_list.rx2(&#34;exclude&#34;),
                               allowed_aq_block_species=_convert_to_RVector(allowed_aq_block_species),
                               charge_balance_on=charge_balance_on,
                               suppress=_convert_to_RVector(suppress),
                               alter_options=alter_options,
                               aq_scale=aq_scale,
                               get_solid_solutions=get_solid_solutions,
                               input_dir=input_dir,
                               redox_flag=redox_flag,
                               redox_aux=redox_aux,
                               default_logfO2=default_logfO2,
                               water_model=water_model,
                               warned_about_redox_column=warned_about_redox_column,
                               activity_model=activity_model,
                               verbose=self.verbose)

            self._print_captured_r_output()
        
            # run EQ3 on each 3i file
            samplename = self.df_input_processed.iloc[sample_row_index, self.df_input_processed.columns.get_loc(&#34;Sample&#34;)]
            filename_3i = self.df_input_processed.index[sample_row_index]+&#34;.3i&#34;
            filename_3o = filename_3i[:-1] + &#39;o&#39;
            filename_3p = filename_3i[:-1] + &#39;p&#39;
            
            
            if dynamic_db:
                dynamic_db_name = self.thermo.thermo_db_filename
            else:
                dynamic_db_name = None
            
            self.runeq3(filename_3i=filename_3i,
                        db=data0_lettercode,
                        samplename=samplename,
                        path_3i=input_dir,
                        path_3o=output_dir,
                        path_3p=pickup_dir,
                        data1_path=data1_path,
                        dynamic_db_name=dynamic_db_name)
            
            # store input, output, and pickup as dicts in AqEquil object
            try:
                with open(input_dir + &#34;/&#34; + filename_3i, &#34;r&#34;) as f:
                    lines=f.readlines()
                self.raw_3_input_dict[samplename] = lines
            except:
                pass
            try:
                with open(output_dir + &#34;/&#34; + filename_3o, &#34;r&#34;) as f:
                    lines=f.readlines()
                self.raw_3_output_dict[samplename] = lines
            except:
                pass
            try:
                with open(pickup_dir + &#34;/&#34; + filename_3p, &#34;r&#34;) as f:
                    lines=f.readlines()
                    
                # capture everything after &#34;start of the bottom half&#34;
                top_half = []
                bottom_half = []
                capture = False
                for line in lines:
                    if &#34;Start of the bottom half of the input file&#34; in line:
                        capture = True
                    if capture:
                        bottom_half.append(line)
                    else:
                        top_half.append(line)
                        
                self.raw_3_pickup_dict_top[samplename] = top_half # top half of the 3p file, including header for mixing calcs
                self.raw_3_pickup_dict_bottom[samplename] = bottom_half # the bottom half
                
            except:
                pass
            
            if dynamic_db:
                shutil.move(&#34;data0.dyn&#34;, &#34;rxn_data0/&#34;+filename_3i[0:-3]+&#34;_data0.dat&#34;)

        if self.thermo.custom_data0:
            # delete straggling data1 files generated after running eq3
            if os.path.exists(&#34;data1&#34;) and os.path.isfile(&#34;data1&#34;):
                os.remove(&#34;data1&#34;)

        files_3o = [file+&#34;.3o&#34; for file in self.df_input_processed.index]
        
        df_input_processed_names = _convert_to_RVector(list(self.df_input_processed.columns))
        
        if self.thermo.thermo_db_type == &#34;CSV&#34;:
            custom_obigt = self.thermo.thermo_db
        else:
            custom_obigt = ro.r(&#34;NULL&#34;)
        
        # mine output
        self._capture_r_output()
        
        r_3o_mine = pkg_resources.resource_string(
            __name__, &#39;3o_mine.r&#39;).decode(&#34;utf-8&#34;)
        ro.r(r_3o_mine)
        
        batch_3o = ro.r.main_3o_mine(
            files_3o=_convert_to_RVector(files_3o),
            input_filename=input_filename,
            input_pressures=_convert_to_RVector(list(input_processed_list.rx2(&#34;pressure_bar&#34;))),
            rxn_filename=rxn_filename,
            get_aq_dist=get_aq_dist,
            aq_dist_type=aq_dist_type,
            get_mass_contribution=get_mass_contribution,
            mass_contribution_other=mass_contribution_other,
            get_mineral_sat=get_mineral_sat,
            mineral_sat_type=mineral_sat_type,
            get_redox=get_redox,
            redox_type=redox_type,
            get_charge_balance=get_charge_balance,
            get_ion_activity_ratios=get_ion_activity_ratios,
            get_fugacity=get_fugacity,
            get_basis_totals=get_basis_totals,
            get_solid_solutions=get_solid_solutions,
            get_affinity_energy=get_affinity_energy,
            negative_energy_supplies=negative_energy_supplies,
            load_rxn_file=load_rxn_file,
            not_limiting=_convert_to_RVector(not_limiting),
            batch_3o_filename=batch_3o_filename,
            df_input_processed=ro.conversion.py2rpy(self.df_input_processed),
            # New rpy2 py2rpy2 conversion might not need the workaround below.
            # The old note regarding deprecated pandas2ri is shown below...
            # OLD NOTE:
            # Needed for keeping symbols in column names after porting
            #   df_input_processed in the line above. Some kind of check.names
            #   option for pandas2ri.py2ri would be nice. Workaround:
            df_input_processed_names=df_input_processed_names,
            custom_obigt=custom_obigt,
            water_model=water_model,
            fixed_species=_convert_to_RVector(FIXED_SPECIES),
            verbose=self.verbose,
        )

        self._print_captured_r_output()
        
        if len(batch_3o) == 0:
            self.err_handler.raise_exception(&#34;Could not compile a speciation report. This is &#34;
                            &#34;likely because errors occurred during &#34;
                            &#34;the speciation calculation.&#34;)
            return
        
        if get_mass_contribution:
            mass_contribution = ro.conversion.rpy2py(batch_3o.rx2(&#39;mass_contribution&#39;))
        df_report = ro.conversion.rpy2py(batch_3o.rx2(&#39;report&#39;))
        
        #df_input = ro.conversion.rpy2py(batch_3o.rx2(&#39;input&#39;))
        report_divs = batch_3o.rx2(&#39;report_divs&#39;)

        input_cols = list(report_divs.rx2(&#39;input&#39;))
        df_input = df_report[input_cols].copy()
        
        # add a pressure column to df_input
        df_input[&#34;Pressure_bar&#34;] = pd.Series(dtype=&#39;float&#39;)
        sample_data = batch_3o.rx2(&#39;sample_data&#39;)
        for sample in sample_data:
            df_input.loc[str(sample.rx2(&#39;name&#39;)[0]), &#34;Pressure_bar&#34;] = float(sample.rx2(&#39;pressure&#39;)[0])
        report_divs[0] = _convert_to_RVector(input_cols + [&#34;Pressure_bar&#34;])
            
        # handle headers and subheaders of input section
        headers = [col.split(&#34;_&#34;)[0] for col in list(df_input.columns)]
        headers = [&#34;pH&#34; if header == &#34;H+&#34; else header for header in headers]
        headers = [header+&#34;_(input)&#34; if header not in [&#34;Temperature&#34;, &#34;logfO2&#34;, &#34;Pressure&#34;]+exclude else header for header in headers]
        report_divs[0] = _convert_to_RVector(headers) # modify headers in the &#39;input&#39; section, report_divs[0]
        subheaders = [subheader[1] if len(subheader) &gt; 1 else &#34;&#34; for subheader in [
            col.split(&#34;_&#34;) for col in list(df_input.columns)]]
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        
        df_input.columns = multicolumns

        df_join = df_input

        if get_aq_dist:
            aq_distribution_cols = list(report_divs.rx2(&#39;aq_distribution&#39;))
            df_aq_distribution = df_report[aq_distribution_cols]
            df_aq_distribution = df_aq_distribution.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            
            # create a pH column from H+
            df_aq_distribution[&#34;pH&#34;] = np.nan # pH values are assigned when sample data is assembled later
            
            # handle headers of aq_distribution section
            headers = df_aq_distribution.columns
            subheaders = [aq_dist_type]*(len(headers)-1) # -1 because the last column will have subheader pH (see next line)
            subheaders = subheaders + [&#34;pH&#34;]
            
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_aq_distribution.columns = multicolumns
            
            # ensure final pH column is included in report_divs aq_distribution section
            aq_dist_indx = list(report_divs.names).index(&#34;aq_distribution&#34;)
            report_divs[aq_dist_indx] = _convert_to_RVector(list(headers))
            
            df_join = df_join.join(df_aq_distribution)

        if get_mineral_sat:
            mineral_sat_cols = list(report_divs.rx2(&#39;mineral_sat&#39;))
            mineral_sat_cols = [col for col in mineral_sat_cols if col != &#34;df&#34;] # TO DO: why is df appearing in mineral sat cols and redox sections?
            df_mineral_sat = df_report[mineral_sat_cols]
            df_mineral_sat = df_mineral_sat.apply(pd.to_numeric, errors=&#39;coerce&#39;)

            # handle headers of df_mineral_sat section
            if mineral_sat_type == &#34;affinity&#34;:
                mineral_sat_unit = &#34;affinity_kcal&#34;
            elif mineral_sat_type == &#34;logQoverK&#34;:
                mineral_sat_unit = &#34;logQ/K&#34;
            else:
                self.err_handler.raise_exception(
                    &#34;mineral_sat_type must be either &#39;affinity&#39; or &#39;logQoverK&#39;&#34;)

            headers = df_mineral_sat.columns
            subheaders = [mineral_sat_unit]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_mineral_sat.columns = multicolumns
            df_join = df_join.join(df_mineral_sat)

        if get_redox:
            redox_cols = list(report_divs.rx2(&#39;redox&#39;))
            redox_cols = [col for col in redox_cols if col != &#34;df&#34;] # TO DO: why is df appearing in mineral sat cols and redox sections?
            df_redox = df_report[redox_cols]
            df_redox = df_redox.apply(pd.to_numeric, errors=&#39;coerce&#39;)

            # handle headers of df_redox section
            if redox_type == &#34;Eh&#34;:
                redox_unit = &#34;Eh_volts&#34;
            elif redox_type == &#34;pe&#34;:
                redox_unit = &#34;pe&#34;
            elif redox_type == &#34;logfO2&#34;:
                redox_unit = &#34;logfO2&#34;
            elif redox_type == &#34;Ah&#34;:
                redox_unit = &#34;Ah_kcal&#34;
            else:
                self.err_handler.raise_exception(
                    &#34;redox_type must be either &#39;Eh&#39;, &#39;pe&#39;, &#39;logfO2&#39;, or &#39;Ah&#39;&#34;)

            headers = df_redox.columns
            subheaders = [redox_unit]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_redox.columns = multicolumns
            df_join = df_join.join(df_redox)

        if get_charge_balance:
            charge_balance_cols = list(report_divs.rx2(&#39;charge_balance&#39;))
            df_charge_balance = df_report[charge_balance_cols]
            df_charge_balance = df_charge_balance.apply(pd.to_numeric, errors=&#39;coerce&#39;)

            # handle headers of df_charge_balance section
            headers = df_charge_balance.columns
            subheaders = [&#34;%&#34;]*2 + [&#39;eq/kg.H2O&#39;, &#39;molality&#39;] + \
                [&#39;eq/kg.H2O&#39;]*4 + [&#39;molality&#39;]
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_charge_balance.columns = multicolumns
            df_join = df_join.join(df_charge_balance)
            
        if get_ion_activity_ratios:
            if type(report_divs.rx2(&#39;ion_activity_ratios&#39;)) != rpy2.rinterface_lib.sexp.NULLType:
                ion_activity_ratio_cols = list(report_divs.rx2(&#39;ion_activity_ratios&#39;))

                df_ion_activity_ratios = df_report[ion_activity_ratio_cols]
                df_ion_activity_ratios = df_ion_activity_ratios.apply(pd.to_numeric, errors=&#39;coerce&#39;)

                # handle headers of df_ion_activity_ratios section
                headers = df_ion_activity_ratios.columns
                subheaders = [&#34;Log ion-H+ activity ratio&#34;]*len(headers)
                multicolumns = pd.MultiIndex.from_arrays(
                    [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
                df_ion_activity_ratios.columns = multicolumns
                df_join = df_join.join(df_ion_activity_ratios)
            
        if get_fugacity:
            fugacity_cols = list(report_divs.rx2(&#39;fugacity&#39;))
            df_fugacity = df_report[fugacity_cols]
            df_fugacity = df_fugacity.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            
            # handle headers of fugacity section
            headers = df_fugacity.columns
            subheaders = [&#34;log_fugacity&#34;]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_fugacity.columns = multicolumns
            df_join = df_join.join(df_fugacity)

        if get_basis_totals:
            sc_cols = list(report_divs.rx2(&#39;basis_totals&#39;))
            df_sc = df_report[sc_cols]
            df_sc = df_sc.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            
            # handle headers of basis_totals section
            headers = df_sc.columns
            subheaders = [&#34;molality&#34;]*(len(headers))
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_sc.columns = multicolumns
            df_join = df_join.join(df_sc)
            
        if get_affinity_energy:
            affinity_cols = list(report_divs.rx2(&#39;affinity&#39;))
            energy_cols = list(report_divs.rx2(&#39;energy&#39;))
            
            df_affinity = df_report[affinity_cols]
            df_energy = df_report[energy_cols]
            
            df_affinity = df_affinity.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            df_energy = df_energy.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            
            # handle headers of df_affinity section
            headers = df_affinity.columns
            subheaders = [&#39;cal/mol e-&#39;]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_affinity.columns = multicolumns

            # handle headers of df_energy section
            headers = df_energy.columns
            subheaders = [&#39;cal/kg.H2O&#39;]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_energy.columns = multicolumns
            df_join = df_join.join(df_affinity)
            df_join = df_join.join(df_energy)

        out_dict = {&#39;sample_data&#39;: {},
                    &#39;report&#39;: df_join,
                    &#39;input&#39;: df_input, &#39;report_divs&#39;: report_divs}
        
        if get_mass_contribution:
            out_dict[&#39;mass_contribution&#39;] = mass_contribution

        sample_data = batch_3o.rx2(&#39;sample_data&#39;)

        # assemble sample data
        for i, sample in enumerate(sample_data):
            dict_sample_data = {
                &#34;filename&#34;: str(sample.rx2(&#39;filename&#39;)[0]),
                &#34;name&#34;: str(sample.rx2(&#39;name&#39;)[0]),
                &#34;temperature&#34;: float(sample.rx2(&#39;temperature&#39;)[0]),
                &#34;pressure&#34;: float(sample.rx2(&#39;pressure&#39;)[0]),
                &#34;logact_H2O&#34;: float(sample.rx2(&#39;logact_H2O&#39;)[0]),
                &#34;H2O_density&#34;: float(sample.rx2(&#39;H2O_density&#39;)[0]),
                &#34;H2O_molality&#34;: float(sample.rx2(&#39;H2O_molality&#39;)[0]),
                &#34;H2O_log_molality&#34;: float(sample.rx2(&#39;H2O_log_molality&#39;)[0]),
                }

            if get_aq_dist:
                sample_aq_dist = ro.conversion.rpy2py(sample.rx2(&#39;aq_distribution&#39;))
                sample_aq_dist = sample_aq_dist.apply(pd.to_numeric, errors=&#39;coerce&#39;)
                
                sample_pH = -sample_aq_dist.loc[&#34;H+&#34;, &#34;log_activity&#34;]
                out_dict[&#34;report&#34;].loc[str(sample.rx2(&#39;name&#39;)[0]), &#34;pH&#34;] = sample_pH
                
                dict_sample_data.update({&#34;aq_distribution&#34;: sample_aq_dist})

            if get_mass_contribution:
                sample_mass_contribution = mass_contribution[mass_contribution[&#34;sample&#34;] == sample.rx2(&#39;name&#39;)[0]]
                dict_sample_data.update(
                    {&#34;mass_contribution&#34;: sample_mass_contribution})

            if get_mineral_sat:
                dict_sample_data.update(
                    {&#34;mineral_sat&#34;: ro.conversion.rpy2py(sample.rx2(&#39;mineral_sat&#39;)).apply(pd.to_numeric, errors=&#39;coerce&#39;)})
                # replace sample mineral_sat entry with None if there is no mineral saturation data.
                if(len(dict_sample_data[&#39;mineral_sat&#39;].index) == 1 and dict_sample_data[&#39;mineral_sat&#39;].index[0] == &#39;None&#39;):
                    dict_sample_data[&#39;mineral_sat&#39;] = None

            if get_redox:
                dict_sample_data.update(
                    {&#34;redox&#34;: ro.conversion.rpy2py(sample.rx2(&#39;redox&#39;)).apply(pd.to_numeric, errors=&#39;coerce&#39;)})

            if get_charge_balance:
                dict_sample_data.update({&#34;charge_balance&#34;: df_charge_balance.loc[sample.rx2(&#39;name&#39;)[0], :]})
            
            if get_ion_activity_ratios:
                
                try:
                    dict_sample_data.update(
                        {&#34;ion_activity_ratios&#34;: ro.conversion.rpy2py(sample.rx2(&#39;ion_activity_ratios&#39;))})
                except:
                    dict_sample_data[&#39;ion_activity_ratios&#39;] = None
            
            if get_fugacity:
                dict_sample_data.update(
                    {&#34;fugacity&#34;: ro.conversion.rpy2py(sample.rx2(&#39;fugacity&#39;)).apply(pd.to_numeric, errors=&#39;coerce&#39;)})
                # replace sample fugacity entry with None if there is no fugacity data.
                if(len(dict_sample_data[&#39;fugacity&#39;].index) == 1 and dict_sample_data[&#39;fugacity&#39;].index[0] == &#39;None&#39;):
                    dict_sample_data[&#39;fugacity&#39;] = None
                else:
                    dict_sample_data[&#34;fugacity&#34;][&#34;fugacity&#34;] = 10**dict_sample_data[&#34;fugacity&#34;][&#34;log_fugacity&#34;]
                    
            if get_basis_totals:
                sc_dist = ro.conversion.rpy2py(sample.rx2(&#39;basis_totals&#39;))
                sc_dist = sc_dist.apply(pd.to_numeric, errors=&#39;coerce&#39;)
                dict_sample_data.update({&#34;basis_totals&#34;: sc_dist})

            if get_solid_solutions:
                sample_solid_solutions = batch_3o.rx2[&#34;sample_data&#34;].rx2[str(sample.rx2(&#39;name&#39;)[0])].rx2[&#34;solid_solutions&#34;]

                if not type(sample_solid_solutions.names) == rpy2.rinterface_lib.sexp.NULLType:

                    ss_df_list = []
                    for ss in list(sample_solid_solutions.names):
                        df_ss_ideal = ro.conversion.rpy2py(sample_solid_solutions.rx2[str(ss)].rx2[&#34;ideal solution&#34;])
                        df_ss_mineral = ro.conversion.rpy2py(sample_solid_solutions.rx2[str(ss)].rx2[&#34;mineral&#34;])
                        df_merged = pd.merge(df_ss_mineral, df_ss_ideal, left_on=&#39;mineral&#39;, right_on=&#39;component&#39;, how=&#39;left&#39;)
                        df_merged.insert(0, &#39;solid solution&#39;, ss)
                        del df_merged[&#39;component&#39;]
                        ss_df_list.append(df_merged)
                
                    dict_sample_data.update(
                        {&#34;solid_solutions&#34;: pd.concat(ss_df_list)})
            
            if get_affinity_energy:
                dict_sample_data.update({&#34;affinity_energy_raw&#34;: ro.conversion.rpy2py(
                    sample.rx2(&#39;affinity_energy_raw&#39;))})
                dict_sample_data.update(
                    {&#34;affinity_energy&#34;: ro.conversion.rpy2py(sample.rx2(&#39;affinity_energy&#39;))})

            out_dict[&#34;sample_data&#34;].update(
                {sample_data.names[i]: dict_sample_data})

        out_dict.update({&#34;batch_3o&#34;: batch_3o})
        
        out_dict.update({&#34;water_model&#34;:water_model, &#34;grid_temps&#34;:grid_temps, &#34;grid_press&#34;:grid_press})
        
        speciation = Speciation(out_dict, hide_traceback=self.hide_traceback)
        
        if get_affinity_energy:
            speciation.half_cell_reactions = self.half_cell_reactions
            speciation.affinity_energy_reactions_table = self.affinity_energy_reactions_table
            speciation.affinity_energy_formatted_reactions = self.affinity_energy_formatted_reactions
            speciation.show_redox_reactions = self.show_redox_reactions
        
        if report_filename != None:
            if &#34;.csv&#34; in report_filename[-4:]:
                out_dict[&#34;report&#34;].to_csv(report_filename)
            else:
                out_dict[&#34;report&#34;].to_csv(report_filename+&#34;.csv&#34;)

        if delete_generated_folders:
            self._delete_rxn_folders()
            try:
                # delete straggler data1 file
                os.remove(&#34;data1&#34;)
            except:
                pass
        
        if self.verbose &gt; 0:
            print(&#34;Finished!&#34;)
        
        speciation.raw_3_input_dict = self.raw_3_input_dict
        speciation.raw_3_output_dict = self.raw_3_output_dict
        speciation.raw_3_pickup_dict_top = self.raw_3_pickup_dict_top
        speciation.raw_3_pickup_dict_bottom = self.raw_3_pickup_dict_bottom
        speciation.raw_6_input_dict = {}
        speciation.raw_6_output_dict = {}
        speciation.raw_6_pickup_dict = {}
        speciation.thermo = self.thermo
        speciation.data1 = self.data1
        
        speciation.logK_models = self.logK_models
        speciation.batch_T = self.batch_T
        speciation.batch_P = self.batch_P
        
        return speciation
    

    @staticmethod
    def __s_d(x, k):
        # specify how many decimals are printed
        # e.g. 12.433 becomes &#34;12.4330&#34; if k=4
        kstr = &#39;{:.&#39;+str(k)+&#39;f}&#39;
        return kstr.format(round(x, k)).strip()
    
    
    def __fill_data0(self, thermo_df, data0_file_lines, grid_temps, grid_press, db,
                   water_model, activity_model, P1, plot_poly_fit, logK_extrapolate,
                   dynamic_db, verbose):
        
        
        self._capture_r_output()
        
        r_check_TP_grid = pkg_resources.resource_string(
            __name__, &#39;check_TP_grid.r&#39;).decode(&#34;utf-8&#34;)
        
        ro.r(r_check_TP_grid)
        
        list_tp = ro.r.check_TP_grid(grid_temps=_convert_to_RVector(grid_temps),
                                     grid_press=_convert_to_RVector(grid_press),
                                     P1=P1,
                                     water_model=water_model,
                                     check_for_errors=True,
                                     verbose=self.verbose)
        
        self._print_captured_r_output()
        
        grid_temps = list(list_tp.rx2(&#34;grid_temps&#34;))
        grid_press = list(list_tp.rx2(&#34;grid_press&#34;))
        
        if plot_poly_fit and len(grid_temps) == 8:
            self.__plot_TP_grid_polyfit(xvals=grid_temps,
                                        yvals=grid_press,
                                        poly_coeffs_1=list(list_tp.rx2(&#34;poly_coeffs_1&#34;)),
                                        poly_coeffs_2=list(list_tp.rx2(&#34;poly_coeffs_2&#34;)),
                                        res=500)

        self._print_captured_r_output()
        
        # calculate logK at each T and P for every species
        out_dfs = []
        for i,Tc in enumerate(grid_temps):
            out_dfs.append(calc_logK(thermo_df, Tc=Tc, P=grid_press[i], TP_i=i, water_model=water_model))
        
        dissrxn_logK_dict = {&#39;name&#39;: out_dfs[0][&#34;name&#34;],
                             &#39;logK_0&#39;: out_dfs[0][&#34;dissrxn_logK_0&#34;]}
        
        if len(grid_temps) == 8:
            for i in range(1, len(grid_temps)):
                dissrxn_logK_dict[&#39;logK_&#39;+str(i)] = out_dfs[i][&#34;dissrxn_logK_&#34;+str(i)]
                
        if len(grid_temps) == 1:
            dissrxn_logK_dict[&#39;logK_1&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_2&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_3&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_4&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_5&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_6&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
            dissrxn_logK_dict[&#39;logK_7&#39;] = float(&#39;nan&#39;) #out_dfs[0][&#34;dissrxn_logK_0&#34;]
    
        dissrxn_logK = pd.DataFrame(dissrxn_logK_dict)
        
        # remove duplicate rows (e.g., for mineral polymorphs)
        dissrxn_logK = dissrxn_logK.drop_duplicates(&#34;name&#34;)
        
        # handle free logK values
        free_logK_names = []
        if &#34;logK1&#34; in thermo_df.columns:
            
            free_logK_df = thermo_df.dropna(subset=[&#39;logK1&#39;])
            free_logK_names = list(free_logK_df[&#34;name&#34;])
    
            sp_dupes = []
            for i,sp in enumerate(free_logK_names):
                logK_grid = list(free_logK_df[[&#34;logK1&#34;, &#34;logK2&#34;, &#34;logK3&#34;,
                                               &#34;logK4&#34;, &#34;logK5&#34;, &#34;logK6&#34;,
                                               &#34;logK7&#34;, &#34;logK8&#34;]].iloc[i]) # logK at T and P in datasheet
                
                T_grid = list(free_logK_df[[&#34;T1&#34;, &#34;T2&#34;, &#34;T3&#34;,
                                            &#34;T4&#34;, &#34;T5&#34;, &#34;T6&#34;,
                                            &#34;T7&#34;, &#34;T8&#34;]].iloc[i]) # T for free logK grid
                
                P_grid = list(free_logK_df[[&#34;P1&#34;, &#34;P2&#34;, &#34;P3&#34;,
                                            &#34;P4&#34;, &#34;P5&#34;, &#34;P6&#34;,
                                            &#34;P7&#34;, &#34;P8&#34;]].iloc[i]) # P for free logK grid
                
                
                for ii,T in enumerate(grid_temps):
                    
                    logK, model = self._interpolate_logK(T, logK_grid, T_grid, logK_extrapolate)
                    
                    dissrxn_logK.loc[(dissrxn_logK.name == sp), &#34;logK_&#34;+str(ii)] = logK
                
                
                self.logK_models[sp] = {&#34;logK_grid&#34;:logK_grid,
                                        &#34;T_grid&#34;:T_grid,
                                        &#34;P_grid&#34;:P_grid,
                                        &#34;logK_extrapolate&#34;:logK_extrapolate,
                                        &#34;type&#34;:&#34;free logK values&#34;,
                                        }
        
                # check that there aren&#39;t duplicates between OBIGT-style datasheet and
                # the &#39;free logK&#39; datasheet
                if sp in dissrxn_logK[&#34;name&#34;]:
                    sp_errs.append(sp)
                    
            if len(sp_dupes) &gt; 0:
                msg = (&#34;The following species are duplicated between the &#34;
                       &#34;thermodynamic datafiles used: &#34; + &#34;,&#34;.join(sp_errs))
                self.err_handler.raise_exception(msg)
        
        # calculate and process logK values of species in the OBIGT-style datasheet
        for idx in range(0, dissrxn_logK.shape[0]):

            name = dissrxn_logK.iloc[idx, dissrxn_logK.columns.get_loc(&#39;name&#39;)]

            # format the logK reaction block of this species&#39; data0 entry
            logK_grid = list(dissrxn_logK.iloc[idx, 1:9])
            
            if not dynamic_db:
                if name not in self.logK_models.keys() and name not in free_logK_names:
                    self.logK_models[name] = {&#34;logK_grid&#34;:logK_grid,
                                  &#34;T_grid&#34;:grid_temps,
                                  &#34;P_grid&#34;:grid_press,
                                  &#34;logK_extrapolate&#34;:logK_extrapolate,
                                  &#34;type&#34;:&#34;calculated logK values&#34;,
                                  }
            elif dynamic_db:
                if name not in self.logK_models.keys() and name not in free_logK_names:
                    self.logK_models[name] = {&#34;logK_grid&#34;:[logK_grid[0]],
                                              &#34;T_grid&#34;:[grid_temps[0]],
                                              &#34;P_grid&#34;:[grid_press[0]],
                                              &#34;logK_extrapolate&#34;:&#34;no fit&#34;,
                                              &#34;type&#34;:&#34;calculated logK values&#34;,
                                              }
                    
                elif name not in free_logK_names:
                    self.logK_models[name][&#34;logK_grid&#34;] += [logK_grid[0]]
                    self.logK_models[name][&#34;T_grid&#34;] += [grid_temps[0]]
                    self.logK_models[name][&#34;P_grid&#34;] += [grid_press[0]]

            # filter out strict basis species
            # TODO: do this by species tag, not just whether it has a logK grid of all 0s
            if len(set(logK_grid)) == 1:
                if set(logK_grid) == set([0]):
                    continue

            # loop through logK values and format for data0
            logK_list = []
            for i in range(0, len(logK_grid)):
                logK_val = self.__s_d(logK_grid[i], 4)
                
                # conditional formatting based on position
                if (i+1) == 1 or (i+1) % 5 == 0: # first entry of a line
                    max_length = 11
                    end_char = &#34;&#34;
                elif (i+1) % 4 == 0 and (i+1) != len(logK_grid): # last entry of a line
                    max_length = 6
                    end_char = &#34;\n&#34;
                else:
                    max_length = 6
                    end_char = &#34;&#34;

                # get decimal position and format spaces accordingly
                decimal_position = logK_val.find(&#34;.&#34;)
                logK_val = &#34;&#34;.join([&#34; &#34;]*(max_length-decimal_position)) + logK_val + end_char
                # append to logk list
                logK_list.append(logK_val)

            logK_list = &#34;&#34;.join(logK_list)
            
            # todo: make this more robust to catch any potential logK_grid skips
            if &#34;logK_grid_&#34;+name in data0_file_lines:
                data0_file_lines[data0_file_lines.index(&#34;logK_grid_&#34;+name)] = logK_list

        # handle data0 header section
        self._capture_r_output()
        
        r_fill_data0_header = pkg_resources.resource_string(
            __name__, &#39;fill_data0_header.r&#39;).decode(&#34;utf-8&#34;)
        
        ro.r(r_fill_data0_header)
        
        data0_file_lines = ro.r.fill_data0_head(data0_template=data0_file_lines,
                                       db=db,
                                       grid_temps=_convert_to_RVector(grid_temps),
                                       grid_press=_convert_to_RVector(grid_press),
                                       water_model=water_model,
                                       activity_model=activity_model)
        
        self._print_captured_r_output()
        
        with open(&#34;data0.&#34;+db, &#39;w&#39;) as f:
            for item in data0_file_lines:
                f.write(&#34;%s&#34; % item)

                
    def plot_logK_fit(self, name, plot_out=False, res=200, internal=True, logK_extrapolate=None, T_vals=[]):
        &#34;&#34;&#34;
        Plot the fit of logK values used in the speciation.

        Parameters
        ----------
        name : str
            Name of the chemical species.
        
        plot_out : bool, default False
            Return a Plotly figure object? If False, a figure is simply shown.
            If True, the function returns a Plotly figure object and does
            not show the plot.
        
        res : int
            Resolution of the fit line. Higher resolutions will be smoother.
            
        internal : bool, default True
            Reuse calculated fits if they already exist?
        
        logK_extrapolate : str, optional
            Option for extrapolating logK values in the plot. Possible values
            for this parameter include &#39;poly&#39;, &#39;linear&#39;, &#39;flat&#39;, or &#39;none&#39;.
            This is for planning and visualization only and does not affect
            results in `speciate()` or `create_data0()`. Those functions have
            their own parameters for setting logK extrapolation options.
        
        T_vals : list, optional
            Option for visualizing how the fit of logK values will be
            used to estimate the logK values at the temperatures specified in
            the list given to this parameter. This is useful for visualizing
            logK extrapolation options defined by `logK_extrapolate`.
        
        Returns
        ----------
        fig : a Plotly figure object
            Returned if `plot_out` is True.

        &#34;&#34;&#34;
        
        if internal and len(self.logK_models.keys()) &gt; 0:
            # use internally calculated logK models already stored...
            if name not in self.logK_models.keys():
                if name not in list(self.thermo.df_rejected_species[&#34;name&#34;]):
                    msg = &#34;The chemical species &#34; + str(name) + &#34; is not recognized.&#34;
                    self.err_handler.raise_exception(msg)
                else:
                    reject_reason = list(self.thermo.df_rejected_species.loc[self.thermo.df_rejected_species[&#39;name&#39;] == name, &#39;reason for rejection&#39;])[0]
                    
                    msg = (&#34;The chemical species &#34; + str(name) + &#34; cannot be &#34;
                           &#34;plotted because it was rejected from the &#34;
                           &#34;speciation:\n&#34; + str(reject_reason))
                    self.err_handler.raise_exception(msg)

            logK_grid = self.logK_models[name][&#34;logK_grid&#34;]
            T_grid = self.logK_models[name][&#34;T_grid&#34;]
            P_grid = self.logK_models[name][&#34;P_grid&#34;]
        
        else:
            # load logK models from Thermodata class&#39;s logK_db
            df_logK = self.thermo.logK_db
            
            i = list(df_logK[&#34;name&#34;]).index(name)
            
            logK_grid = list(df_logK[[&#34;logK1&#34;, &#34;logK2&#34;, &#34;logK3&#34;,
                                      &#34;logK4&#34;, &#34;logK5&#34;, &#34;logK6&#34;,
                                      &#34;logK7&#34;, &#34;logK8&#34;]].iloc[i]) # logK at T and P in datasheet

            T_grid = list(df_logK[[&#34;T1&#34;, &#34;T2&#34;, &#34;T3&#34;,
                                   &#34;T4&#34;, &#34;T5&#34;, &#34;T6&#34;,
                                   &#34;T7&#34;, &#34;T8&#34;]].iloc[i]) # T for free logK grid

            P_grid = list(df_logK[[&#34;P1&#34;, &#34;P2&#34;, &#34;P3&#34;,
                                   &#34;P4&#34;, &#34;P5&#34;, &#34;P6&#34;,
                                   &#34;P7&#34;, &#34;P8&#34;]].iloc[i]) # P for free logK grid
            
            if not isinstance(logK_extrapolate, str):
                logK_extrapolate = self.thermo.logK_extrapolate
            
        
        if not isinstance(logK_extrapolate, str):
            logK_extrapolate = self.logK_models[name][&#34;logK_extrapolate&#34;]
        
        if len(T_vals) == 0:
            grid_temps = self.batch_T
        else:
            grid_temps = T_vals
        
        grid_press = self.batch_P
        
        T_grid = [t for t in T_grid if not pd.isna(t)]
        P_grid = [p for p in P_grid if not pd.isna(p)]
        logK_grid = [k for k in logK_grid if not pd.isna(k)]
        
        fig = px.scatter(x=T_grid, y=logK_grid)
        
        if len(grid_temps) &gt; 0:
            if min(grid_temps) &lt;= min(T_grid):
                plot_T_min = min(grid_temps)
            else:
                plot_T_min = min(T_grid)
            if max(grid_temps) &gt;= max(T_grid):
                plot_T_max = max(grid_temps)
            else:
                plot_T_max = max(T_grid)
        else:
            plot_T_min = min(T_grid)
            plot_T_max = max(T_grid)
        
        plot_temps = np.linspace(plot_T_min, plot_T_max, res)

        pred_logK = []
        pred_model = []
        for t in plot_temps:
            logK, model = self._interpolate_logK(t, logK_grid, T_grid, logK_extrapolate)
            pred_logK.append(logK)
            pred_model.append(model)
        
        df_plot = pd.DataFrame({&#34;T&#34;:plot_temps, &#34;logK&#34;:pred_logK, &#34;model&#34;:pred_model})
        
        if logK_extrapolate != &#34;no fit&#34;:
            fig = px.line(df_plot, x=&#39;T&#39;, y=&#39;logK&#39;, color=&#39;model&#39;, title=name, template=&#34;simple_white&#34;)
        else:
            fig = px.line(x=[0], y=[0], title=name, template=&#34;simple_white&#34;) # dummy figure
            
        fig.update_traces(hovertemplate=&#34;T = %{x} C&lt;br&gt;Predicted logK = %{y}&lt;extra&gt;&lt;/extra&gt;&#34;)
        fig.update_layout(xaxis_range=[min(plot_temps) - 0.15*(max(plot_temps) - min(plot_temps)),
                                       max(plot_temps) + 0.15*(max(plot_temps) - min(plot_temps))],
                          xaxis_title=&#34;T,C&#34;, yaxis_title=&#34;logK&#34;)
        
        logK_label = &#34;fitted logK value(s)&#34;
        annotation = &#34;&#34;
        
        if len(grid_temps) &gt; 0:
            for i,gt in enumerate(grid_temps):
                # make vertical lines representing batch temperatures

                if i==0:
                    showlegend=True
                else:
                    showlegend=False

                if isinstance(grid_press, str):
                    ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;br&gt;P = PSAT&lt;extra&gt;&lt;/extra&gt;&#34;
                else:
                    if len(grid_press) &gt; 0:
                        ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;br&gt;P = &#34; + str(grid_press[i]) + &#34; bar(s)&lt;extra&gt;&lt;/extra&gt;&#34;
                    else:
                        ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;extra&gt;&lt;/extra&gt;&#34;
                        
                if len(T_grid) &gt; 1:
                    
                    if logK_extrapolate == &#34;none&#34; and (gt &gt; max(T_grid) or gt &lt; min(T_grid)):
                        viz_logK = max(logK_grid)
                    else:
                        viz_logK, _ = self._interpolate_logK(gt, logK_grid, T_grid, logK_extrapolate)
                    
                    vline_y_vals = [min(logK_grid)-0.15*(max(logK_grid)-min(logK_grid)), viz_logK]
                    
                    
                if logK_extrapolate == &#34;no fit&#34;:
                    vline_y_vals = [min(logK_grid)-0.15*(max(logK_grid)-min(logK_grid)), logK_grid[i]]
                    logK_label = &#34;calculated LogK value(s)&#34;
                    annotation = (&#34;LogK values are calculated from&lt;br&gt;G of dissociation into basis species&#34;
                                  &#34;&lt;br&gt;at the T and P of the speciated samples&lt;br&gt;and do not require a fit.&#34;)

                if _all_equal(logK_grid):
                    # if a flat horizontal logK fit line...
                    # then fix the y-axis range to prevent zoomed-in steppy wierdness
                    fig.update_layout(yaxis_range=[logK_grid[0]-1,logK_grid[0]+1])
                    vline_y_vals = [logK_grid[0]-1, logK_grid[0]]

                fig.add_trace(
                    go.Scatter(x=[gt, gt],
                               y=vline_y_vals,
                               mode=&#34;lines&#34;,
                               line=dict(color=&#39;rgba(255, 0, 0, 0.75)&#39;, width=3, dash=&#34;dot&#34;),
                               legendgroup=&#39;batch temperatures&#39;,
                               name=&#39;batch temperatures&#39;,
                               showlegend=showlegend,
                               hovertemplate=ht_samples,
                              ),
                )
        
        # add fitted logK points
        fig.add_trace(go.Scatter(x=T_grid, y=logK_grid, name=logK_label,
                                 mode=&#39;markers&#39;, marker=dict(color=&#34;black&#34;),
                                 text = P_grid,
                                 hovertemplate=&#34;T = %{x} C&lt;br&gt;P = %{text} bar(s)&lt;br&gt;logK = %{y}&lt;extra&gt;&lt;/extra&gt;&#34;,
                                 ),
                      )
        
        fig.add_annotation(x=0, y=0, xref=&#34;paper&#34;, yref=&#34;paper&#34;, align=&#39;left&#39;,
                           text=annotation, bgcolor=&#34;rgba(255, 255, 255, 0.5)&#34;,
                           showarrow=False)
        
        if plot_out:
            return fig
        else:
            fig.show()

        
    def __get_i_of_valid_free_logK_sp(self, free_logK_df, grid_temps,
                                      grid_press, dynamic_db,
                                      logK_extrapolate, db_sp_names):
            &#34;&#34;&#34;
            Check for species in the free logK database with pressure values that
            are permitted in the context of grid_temps and grid_press, then
            return their indices.
            &#34;&#34;&#34;
            
            if not isinstance(grid_press, list):
                # &#34;Psat&#34; to [&#34;psat&#34;]
                grid_press_list = [grid_press.lower()]
            else:
                grid_press_list = grid_press

            valid_sp_i = []
            rejected_sp_i_dict = {}
            
            for i,sp in enumerate(list(free_logK_df[&#34;name&#34;])):
                
                sp_temps_grid = [free_logK_df.iloc[i][&#34;T&#34;+str(ii)] for ii in range(1,9) if not math.isnan(free_logK_df.iloc[i][&#34;T&#34;+str(ii)])]
                sp_press_grid_init = [float(free_logK_df.iloc[i][&#34;P&#34;+str(ii)]) if free_logK_df.iloc[i][&#34;P&#34;+str(ii)] not in [&#34;Psat&#34;, &#34;psat&#34;] else &#39;psat&#39; for ii in range(1,9)]

                sp_grid_len = len(sp_temps_grid)
                
                sp_press_grid = []
                for p in sp_press_grid_init:
                    if isinstance(p, str):
                        sp_press_grid.append(p)
                    elif not math.isnan(p):
                        sp_press_grid.append(p)

                if sp_press_grid == grid_press_list and sp_temps_grid == grid_temps:
                    # If pressures and temperature grid exactly matches that of the sp...
                    # need to test this!
                    valid_sp_i.append(i)
                elif (logK_extrapolate != &#34;none&#34; or (min(grid_temps) &gt;= min(sp_temps_grid) and max(grid_temps) &lt;= max(sp_temps_grid))) and _all_equal(sp_press_grid + grid_press_list):
                    # If all grid temperatures are within minimum and maximum file temperatures,
                    # and all pressures in file for the sp are equal, and all grid pressures match
                    # file pressure, then the species is valid
                    valid_sp_i.append(i)
                
                else:
                    # species is invalid. Define reasons.
                    
                    reject_reason_list = []
                    

                    
                    if min(grid_temps) &lt; min(sp_temps_grid) and _all_equal(sp_press_grid + grid_press_list) and logK_extrapolate == &#34;none&#34;:
                        print(sp)
                        print(logK_extrapolate)
                        
                        min_sp = str(min(sp_temps_grid))
                        min_grid = str(min(grid_temps))
                        if dynamic_db:
                            reject_reason_list.append(&#34;Minimum temperature in this batch of samples is &#34;+min_grid+&#34;C, which is below the minimum applicability temperature of this species is &#34;+min_sp+&#34;C.&#34;)
                        else:
                            reject_reason_list.append(&#34;Minimum temperature in this data0 file is &#34;+min_grid+&#34;C, which is below the minimum applicability temperature of this species is &#34;+min_sp+&#34;C.&#34;)
                    
                    if max(grid_temps) &gt; max(sp_temps_grid) and _all_equal(sp_press_grid + grid_press_list) and logK_extrapolate == &#34;none&#34;:
                        max_sp = str(max(sp_temps_grid))
                        max_grid = str(max(grid_temps))
                        if dynamic_db:
                            reject_reason_list.append(&#34;Maximum temperature in this batch of samples is &#34;+max_grid+&#34;C, which is above the maximum applicability temperature of this species is &#34;+max_sp+&#34;C.&#34;)
                        else:
                            reject_reason_list.append(&#34;Maximum temperature in this data0 file is &#34;+max_grid+&#34;C, which is above the maximum applicability temperature of this species is &#34;+max_sp+&#34;C.&#34;)
                    
                    if not _all_equal(sp_press_grid + grid_press_list):
                        if dynamic_db:
                            reject_reason_list.append(&#34;Mismatch between pressures of samples in this batch and the applicable pressures for &#34;+str(sp)+&#34; given in the logK thermodynamic database.&#34;)
                        else:
                            reject_reason_list.append(&#34;Mismatch between desired pressure grid of data0 file and the applicable pressures for &#34;+str(sp)+&#34; given in the logK thermodynamic database.&#34;)
                    
                    if len(reject_reason_list) == 0:
                        reject_reason_list.append(&#34;Unknown&#34;)
                    
                    rejected_sp_i_dict[i] = &#34;\n&#34;.join(reject_reason_list)

            # loop through valid species and reject them if their dissociation reactions
            # contain species that have been rejected.
            
            valid_sp_i = list(dict.fromkeys(valid_sp_i))
            while True:
                valid_sp_i_before = copy.deepcopy(valid_sp_i)
                valid_sp_i, rejected_sp_i_dict = self._check_valid_free_logK_sp_dissrxn(valid_sp_i, rejected_sp_i_dict, free_logK_df, db_sp_names)
                if valid_sp_i_before == valid_sp_i:
                    break
            
            reject_indices = list(rejected_sp_i_dict.keys())
            reject_names = list(free_logK_df.iloc[reject_indices][&#34;name&#34;])
            reject_reasons =list(rejected_sp_i_dict.values())
            
            self.thermo.df_rejected_species = pd.concat([self.thermo.df_rejected_species, pd.DataFrame({&#39;database name&#39;:[self.thermo.logK_db_filename]*len(reject_indices), &#39;database index&#39;:reject_indices, &#34;name&#34;:reject_names, &#34;reason for rejection&#34;:reject_reasons})], ignore_index=True)
                        
            return valid_sp_i
            
            
    def _check_valid_free_logK_sp_dissrxn(self, valid_sp_i, rejected_sp_i_dict, free_logK_df, db_sp_names):
        
        valid_sp_names = list(free_logK_df.iloc[valid_sp_i][&#34;name&#34;])
        
        rejected_sp_names = list(free_logK_df.iloc[list(rejected_sp_i_dict.keys())][&#34;name&#34;])

        for i in valid_sp_i:
            dissrxn_i = free_logK_df.iloc[i][&#34;dissrxn&#34;]
            dissrxn_sp = dissrxn_i.split(&#34; &#34;)[1::2] # get species names from dissrxn
            dissrxn_sp = dissrxn_sp[1:] # ignore the species itself
            
            for sp in dissrxn_sp:
                if sp in rejected_sp_names and sp not in valid_sp_names and sp not in db_sp_names:
                    valid_sp_i.remove(i)
                    rejected_sp_i_dict[i] = &#34;Dissociation reaction contains the species &#34; + sp + &#34;, which has been rejected.&#34;
                    return valid_sp_i, rejected_sp_i_dict
                    
        return valid_sp_i, rejected_sp_i_dict
            
        
    def create_data0(self,
                     db,
                     filename_ss=None,
                     activity_model=&#34;b-dot&#34;,
                     exceed_Ttr=True,
                     grid_temps=[0.0100, 50.0000, 100.0000, 150.0000,
                                 200.0000, 250.0000, 300.0000, 350.0000],
                     grid_press=&#34;Psat&#34;,
                     P1=True,
                     plot_poly_fit=False,
                     logK_extrapolate=&#34;none&#34;,
                     fill_data0=True,
                     dynamic_db=False,
                     dynamic_db_sample_temps=[],
                     dynamic_db_sample_press=[],
                     verbose=1):
        &#34;&#34;&#34;
        Create a data0 file from a custom thermodynamic dataset.
        
        Parameters
        ----------
        db : str
            Desired three letter code of data0 output.
            
        filename_ss : str, optional
            Name of file containing solid solution parameters.

        grid_temps : list of eight float, default [0.0100, 50.0000, 100.0000, 150.0000, 200.0000, 250.0000, 300.0000, 350.0000]
            Eight temperature values that make up the T-P grid.
        
        grid_press : list of float, default &#34;Psat&#34;
            Eight pressure values that make up the T-P grid. &#34;Psat&#34; for
            calculations along the liquid-vapor saturation curve.
        
        P1 : bool, default True,
            Use pressure of 1 bar below 100 degrees C instead of calculated
            values of Psat? Ignored if `grid_press` is not &#34;Psat&#34;.
        
        plot_poly_fit : bool, default False
            Plot the polynomial fit of the temperature pressure grid?
        
        dynamic_db : bool, default False
            Are data0 files being created dynamically? If unsure, use False.
            Used by `speciate` to display valid messages.
        
        verbose : int, 0, 1, or 2, default 1
            Level determining how many messages are returned during a
            calculation. 2 for all messages, 1 for errors or warnings only,
            0 for silent.
        &#34;&#34;&#34;
        
        thermo_df = self.thermo.thermo_db
        db_logK = self.thermo.logK_db
        water_model = self.thermo.water_model
        
        self.verbose = verbose
        
        self.batch_T = grid_temps
        self.batch_P = grid_press
        
        if not dynamic_db:
            if self.verbose &gt;= 1:
                print(&#34;Creating data0.{}...&#34;.format(db), flush=True)
        
        if len(grid_temps) not in [1, 8]:
            self.err_handler.raise_exception(&#34;&#39;grid_temps&#39; must have either one or eight values.&#34;)
        if isinstance(grid_press, list):
            if len(grid_press) not in [1, 8]:
                self.err_handler.raise_exception(&#34;&#39;grid_press&#39; must have either one or eight values.&#34;)
        
        if sum([T &gt;= 10000 for T in grid_temps]):
            self.err_handler.raise_exception(&#34;Grid temperatures must be below 10k C.&#34;)
        
        if isinstance(grid_press, list):
            if sum([P &gt;= 10000 for P in grid_press]) and water_model != &#34;DEW&#34;:
                self.err_handler.raise_exception(&#34;Grid pressures must be below 10 kilobars.&#34;)
                
        if water_model == &#34;SUPCRT92&#34;:
            min_T = 0
            max_T = 2250
            min_P = 0
            max_P = 30000
        elif water_model == &#34;IAPWS95&#34;:
            min_T = 0
            max_T = 1000
            min_P = 0
            max_P = 10000
        elif water_model == &#34;DEW&#34;:
            min_T = 0
            max_T = 1000
            min_P = 1000
            max_P = 60000
        else:
            self.err_handler.raise_exception(&#34;The water model &#39;{}&#39; &#34;.format(water_model)+&#34;is not &#34;
                &#34;recognized. Try &#39;SUPCRT92&#39;, &#39;IAPWS95&#39;, or &#39;DEW&#39;.&#34;)
        
        # check that T and P are above minimum values
        if sum([T &lt;= min_T for T in grid_temps]):
            print(&#34;WARNING: one or more temperatures in &#39;grid_temps&#39; is below &#34;
                  &#34;or equal to {} C&#34;.format(min_T)+&#34; and is outside the valid &#34;
                  &#34;temperature range for the {} water model.&#34;.format(water_model))
        if isinstance(grid_press, list):
            if sum([P &lt; min_P for P in grid_press]):
                print(&#34;WARNING: one or more pressures in &#39;grid_press&#39; is below &#34;
                      &#34;{} bar&#34;.format(min_P)+&#34;, the minimum valid &#34;
                      &#34;pressure for the {} water model.&#34;.format(water_model))
        
        # check that T and P are below maximum values
        if sum([T &gt; max_T for T in grid_temps]):
            print(&#34;WARNING: one or more temperatures in &#39;grid_temps&#39; is above &#34;
                  &#34;{} C&#34;.format(max_T)+&#34;, the maximum valid &#34;
                  &#34;temperature for the {} water model.&#34;.format(water_model))
        if isinstance(grid_press, list):
            if sum([P &gt; max_P for P in grid_press]):
                print(&#34;WARNING: one or more pressures in &#39;grid_press&#39; is above &#34;
                      &#34;{} bar&#34;.format(max_P)+&#34;, the maximum valid &#34;
                      &#34;pressure for the {} water model.&#34;.format(water_model))
            
        if water_model != &#34;SUPCRT92&#34;:
            print(&#34;WARNING: water models other than SUPCRT92 are not yet fully supported.&#34;)
        
        # reset logK_models whenever create_data0() is called
        # (prevents errors when create_data0() functions are run back-to-back)
        self.logK_models = {}
        
        # interpolate logK values from &#34;free logK&#34; datasheet at T and P
        if isinstance(db_logK, pd.DataFrame):

            if len(dynamic_db_sample_temps) &gt; 0:
                grid_or_sample_temps = dynamic_db_sample_temps
            else:
                grid_or_sample_temps = grid_temps
                
            if len(dynamic_db_sample_press) &gt; 0:
                grid_or_sample_press = dynamic_db_sample_press
            else:
                grid_or_sample_press = grid_press
            
            free_logK_df = _clean_rpy2_pandas_conversion(self.thermo.logK_db)

            valid_i = self.__get_i_of_valid_free_logK_sp(
                free_logK_df,
                grid_or_sample_temps,
                grid_or_sample_press,
                dynamic_db,
                logK_extrapolate,
                db_sp_names=thermo_df[&#34;name&#34;],
                )
            free_logK_df_valid = copy.deepcopy(free_logK_df.iloc[valid_i])
            thermo_df = pd.concat([thermo_df, free_logK_df_valid], ignore_index=True)
            
            thermo_df = _clean_rpy2_pandas_conversion(thermo_df)
        
        if self.thermo.solid_solutions_active:
            solid_solution_df = ro.conversion.py2rpy(self.thermo.solid_solution_db)
        else:
            solid_solution_df = ro.r(&#34;NULL&#34;)
        
        template = pkg_resources.resource_string(
            __name__, &#39;data0.min&#39;).decode(&#34;utf-8&#34;)
        
        out_list = self.thermo.out_list
    
        self._capture_r_output()
    
        r_create_data0 = pkg_resources.resource_string(
            __name__, &#39;create_data0.r&#39;).decode(&#34;utf-8&#34;)
        
        ro.r(r_create_data0)
        
        # assemble data0 file
        data0_file_lines = ro.r.create_data0(thermo_df=ro.conversion.py2rpy(thermo_df),
                          solid_solution_df=solid_solution_df,
                          db=db,
                          water_model=water_model,
                          template=template,
                          dissrxns=out_list.rx2(&#34;dissrxns&#34;),
                          basis_pref=out_list.rx2(&#34;basis_pref&#34;),
                          exceed_Ttr=exceed_Ttr,
                          fixed_species=_convert_to_RVector(FIXED_SPECIES),
                          verbose=self.verbose)
        
        self._print_captured_r_output()
        
        data0_file_lines = data0_file_lines[0].split(&#34;\n&#34;)
        
        if fill_data0:
            
            # begin TP-dependent processes
            self.__fill_data0(thermo_df=ro.conversion.rpy2py(thermo_df),
                              data0_file_lines=copy.deepcopy(data0_file_lines),
                              grid_temps=grid_temps,
                              grid_press=grid_press,
                              db=db,
                              water_model=water_model,
                              activity_model=activity_model,
                              P1=P1,
                              plot_poly_fit=plot_poly_fit,
                              logK_extrapolate=logK_extrapolate,
                              dynamic_db=dynamic_db,
                              verbose=self.verbose)
    
        else:
            return thermo_df, data0_file_lines, grid_temps, grid_press, db, water_model, P1, plot_poly_fit

        if self.verbose &gt; 0:
            print(&#34;Finished creating data0.{}.&#34;.format(db))
            

    def make_redox_reactions(self, db=None, redox_pairs=&#34;all&#34;, auto_load_db=True):
        
        &#34;&#34;&#34;
        Generate an organized collection of redox reactions for calculating
        chemical affinity and energy supply values during speciation.
        
        Parameters
        ----------
        db : str
            Determines which thermodynamic database is used in the speciation
            calculation. The database must be a CSV file (not a data0file)
            because the code must look up properties of chemical species to
            calculate affinities and energy supplies of reactions.
            The `db` parameter can either be:
            - The name of a CSV file containing thermodynamic data located in
            the current working directory, e.g., &#34;wrm_data.csv&#34;. The CSV file
            will be used to generate a data0 file for each sample (using
            additional arguments from `db_args` if desired).
            - The URL of a CSV file containing thermodynamic data, e.g.,
            &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
        
        redox_pairs : list of int or &#34;all&#34;, default &#34;all&#34;
            List of indices of half reactions in the half cell reaction table
            to be combined when generating full redox reactions.
            E.g. [0, 1, 4] will combine half reactions with indices 0, 1, and 4
            in the table stored in the `half_cell_reactions` attribute of the
            `AqEquil` class.
            If &#34;all&#34;, generate all possible redox reactions from available half
            cell reactions.
        
        auto_load_db : bool, default True
            Automatically download and use a WORM-styled CSV if the currently
            active thermodynamic database does not support affinity and energy
            supply calculations? If True, the most up-to-date copy of the
            wrm_data.csv will be downloaded from the URL
            https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv
            and set as the active thermodynamic database.
        
        Returns
        ----------
        Output is stored in the `affinity_energy_reactions_raw` and
        `affinity_energy_reactions_table` attributes of the `AqEquil` class.
        &#34;&#34;&#34;
        
        if db != None:
            self.thermo._set_active_db(db)
            
        if self.thermo.thermo_db_type != &#34;CSV&#34;:
            if self.verbose &gt; 0:
                if auto_load_db:
                    print(&#34;Warning: Redox reactions require a WORM-styled thermodynamic database CSV file.&#34;)
                else:
                    self.err_handler.raise_exception(&#34;Error: Redox reactions require a WORM-styled CSV file as the active thermodynamic database.&#34;)
            
            if auto_load_db:
                if self.verbose &gt; 0:
                    print(&#34;Warning: switching thermodynamic database from&#34;, str(self.thermo.thermo_db_filename), &#34;to wrm_data.csv...&#34;)
                self.thermo._set_active_db(db=&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;)
            
        db = self.thermo.db
        
        # reset all redox variables stored in the AqEquil class
        self.affinity_energy_reactions_raw = None
        self.affinity_energy_reactions_table = None
        self.affinity_energy_formatted_reactions = None
        
        if self.verbose &gt; 1:
            print(&#34;Generating redox reactions...&#34;)

        err_msg = (&#34;redox_pairs can either be &#39;all&#39; or a list of integers &#34;
               &#34;indicating the indices of half cell reactions in &#34;
               &#34;the half_cell_reactions table that should be combined into &#34;
               &#34;full redox reactions. For example, redox_pairs=[0, 1, 2, 6] &#34;
               &#34;will combine half cell reactions with indices 0, 1, 2, and 6 in &#34;
               &#34;the half_cell_reactions table. This table is an attribute in the &#34;
               &#34;class AqEquil.&#34;)
        if isinstance(redox_pairs, str):
            if redox_pairs == &#34;all&#34;:
                redox_pairs = list(range(0, self.half_cell_reactions.shape[0]))
            else:
                self.err_handler.raise_exception(err_msg)
        elif isinstance(redox_pairs, list):
            if not all([isinstance(i, int) for i in redox_pairs]):
                self.err_handler.raise_exception(err_msg)
        else:
            self.err_handler.raise_exception(err_msg)
        
        self.redox_pairs = redox_pairs
        
        df = self.half_cell_reactions.iloc[redox_pairs].reset_index(drop=True)
        
        wrm_data = self.thermo.thermo_db
        basis_df = wrm_data.loc[wrm_data[&#39;tag&#39;] == &#39;basis&#39;]
        
        db_names = []
        formulas = []
        for column in list(df.columns)[1:]:
            for item in list(df[column]):
                if item != &#39;nan&#39;:
                    if item in list(wrm_data.name) and isinstance(item, str):
                        index = wrm_data.loc[wrm_data[&#39;name&#39;] == item].index[0]
                        formula = wrm_data.loc[wrm_data[&#39;name&#39;] == item][&#39;formula&#39;][index]
                        df.replace(item, formula, inplace=True)
                        if item not in db_names:
                            db_names.append(item)
                            formulas.append(formula)
                    elif item in list(wrm_data.abbrv) and isinstance(item, str):
                        index = wrm_data.loc[wrm_data[&#39;abbrv&#39;] == item].index[0]
                        formula = wrm_data.loc[wrm_data[&#39;abbrv&#39;] == item][&#39;formula&#39;][index]
                        df.replace(item, formula, inplace=True)
                        if item not in db_names:
                            db_names.append(item)
                            formulas.append(formula)
                            
        df.replace(&#39;sulfur&#39;, &#39;S&#39;, inplace = True) ### remove this eventually
        db_names.append(&#39;sulfur&#39;) ### remove this eventually
        formulas.append(&#39;S&#39;) ### remove this eventually

        # append H+ and H2O to db for balancing
        if not &#39;H+&#39; in db_names:
            db_names.append(&#39;H+&#39;)
            formulas.append(&#39;H+&#39;)
        if not &#39;H2O&#39; in db_names:
            db_names.append(&#39;H2O&#39;)
            formulas.append(&#39;H2O&#39;)
        
        Oxidant_1 = df[&#39;Oxidant_1&#39;]
        Oxidant_2 = df[&#39;Oxidant_2&#39;]
        Oxidant_3 = df[&#39;Oxidant_3&#39;]
        Reductant_1 = df[&#39;Reductant_1&#39;]
        Reductant_2 = df[&#39;Reductant_2&#39;]
        
        #CREATING A LIST OF ALL SPECIES AND THEIR ELEMENT DICTIONARIES
        elements = [str(e) for e in list(periodictable.elements)[1:]]+[&#39;+&#39;,&#39;-&#39;]
        element_dictionary = dict()
        for i in formulas:
                parsed_formula = parse_formula(i)
                element_dictionary[i] = parsed_formula
                for e in elements:
                    if element_dictionary[i].get(e, 0) == 0:
                        element_dictionary[i][e] = 0
                        
        df_reax = pd.DataFrame() # empty df of reactions
        df_reax[&#39;rO_coeff&#39;] = &#39;&#39;
        df_reax[&#39;rO&#39;] = &#39;&#39;
        df_reax[&#39;rR_coeff&#39;] = &#39;&#39;
        df_reax[&#39;rR&#39;] = &#39;&#39;
        df_reax[&#39;pO_coeff&#39;] = &#39;&#39;
        df_reax[&#39;pO&#39;] = &#39;&#39;
        df_reax[&#39;pR_coeff&#39;] = &#39;&#39;
        df_reax[&#39;pR&#39;] = &#39;&#39;
        df_reax[&#39;Reaction&#39;] = &#39;&#39;
        df_reax[&#39;redox_pair&#39;] = &#39;&#39;
        index = 0

        reaction = [] 
        indices = np.arange(0, len(Oxidant_1), 1).tolist()*2 # how to loop back through the redox pairs to not run into out-of-range index
        rxn_num = 0 # counting unique reactions
        rxn_list = [] # list of unique reactions
        rxn_names = []
        rxn_pairs = [] # list of paired half reactions

        for i in range(0, len(Oxidant_1),1): # length of redox pairs - columns
            for n in range(0, len(Oxidant_1), 1):
                if Reductant_1[i] == Reductant_1[indices[i+n]] or Reductant_1[i] == Reductant_2[indices[i+n]]: # if both reductants are the same thing, skip
                    continue
                if Oxidant_1[i] == Oxidant_1[indices[i+n]] or Oxidant_1[i] == Oxidant_2[indices[i+n]] or Oxidant_1[i] == Oxidant_3[indices[i+n]]:
                    continue
#                 if Oxidant_1[i] == &#39;H2O&#39; and Reductant_1[indices[i+n]] == &#39;H2O&#39;: #suppress the splitting of water
#                     continue
                else:

                    # GENERATING REACTIONS BETWEEN OXIDANT_1 AND REDUCTANT_1
                    reaction.append(Oxidant_1[i]+&#39; \t &#39; + Reductant_1[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_num+=1
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_1[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_1[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index+=1

                # REACTIONS INVOLVING OTHER PH-DEPENDENT SPECIES
                if pd.isnull(Oxidant_2[i]) != True and Oxidant_2[i] != Reductant_2[indices[i+n]]:
                    reaction.append(Oxidant_2[i] + &#39; \t &#39; + Reductant_1[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_2[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_1[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                    if pd.isnull(Reductant_2[indices[i+n]]) != True:
                        reaction.append(Oxidant_2[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                        rxn_list.append(rxn_num)
                        rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                        df_reax.loc[index, &#39;rO&#39;] = Oxidant_2[i]
                        df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                        df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                        df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                        rxn_pairs.append([i, indices[i+n]])
                        index +=1
                        
                if pd.isnull(Oxidant_2[i]) != True and Oxidant_2[i] == Reductant_2[indices[i+n]]:
                    reaction.append(Oxidant_2[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_2[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                if pd.isnull(Reductant_2[indices[i+n]]) != True and Oxidant_2[i] != Reductant_2[indices[i+n]]:
                    reaction.append(Oxidant_1[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_1[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                if pd.isnull(Oxidant_3[i]) != True:
                    reaction.append(Oxidant_3[i] + &#39; \t &#39; + Reductant_1[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_3[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_1[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                    if pd.isnull(Reductant_2[indices[i+n]]) != True:
                        reaction.append(Oxidant_3[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                        rxn_list.append(rxn_num)
                        rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                        df_reax.loc[index, &#39;rO&#39;] = Oxidant_3[i]
                        df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                        df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                        df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                        rxn_pairs.append([i, indices[i+n]])
                        index +=1
        
        df_reax[&#39;Reaction&#39;] = rxn_list
        df_reax[&#39;Names&#39;] = rxn_names
        df_reax[&#39;Temp_Pairs&#39;] = rxn_pairs
        
        # if there are no reactions, return nothing
        if df_reax.shape[0] == 0:
            incompatible_half_reactions = pd.Series(self.half_cell_reactions[&#34;Redox Couple&#34;], index=redox_pairs).tolist()
            redundant_reductant_or_oxidant = []
            for col in [&#34;Oxidant_1&#34;, &#34;Oxidant_2&#34;, &#34;Oxidant_3&#34;, &#34;Reductant_1&#34;, &#34;Reductant_2&#34;]:
                redox_col = pd.Series(self.half_cell_reactions[col], index=[0,1])
                if redox_col.eq(redox_col[0]).all():
                    redundant_reductant_or_oxidant.append(redox_col[0])
            err_no_rxns = (&#34;Valid reactions could not be written between the half &#34;
                &#34;reactions {} &#34;.format(incompatible_half_reactions)+&#34;because &#34;
                &#34;{}&#34;.format(redundant_reductant_or_oxidant)+&#34; is on both sides &#34;
                &#34;of all reactions.&#34;)
            print(err_no_rxns)
            return
        
        ### BALANCING NON-O, H ELEMENTS
        for r in range(0, len(df_reax[&#39;rO&#39;])):
            count = 0 #to restart the loop through the elements
            temp_rO_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -
            temp_rR_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -
            temp_pO_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -
            temp_pR_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -

            
            for e in elements:
                if e in [&#39;O&#39;,&#39;H&#39;,&#39;+&#39;,&#39;-&#39;]:
                    continue
                else:
            
                    temp1 = int(element_dictionary[df_reax[&#39;rO&#39;][r]][e]) #count for the element in the list for rO at index r
                    temp2 = int(element_dictionary[df_reax[&#39;pR&#39;][r]][e])
                    temp3 = int(element_dictionary[df_reax[&#39;rR&#39;][r]][e])
                    temp4 = int(element_dictionary[df_reax[&#39;pO&#39;][r]][e])
                    if temp1 == temp2:
                        temp_rO_coeff[count] = 1
                        temp_pR_coeff[count] = 1
                    if temp1 != temp2:
                        if temp1 ==0:
                            temp_rO_coeff[count] = 1
                        if temp1 != 0:
                            temp_rO_coeff[count] = np.lcm(temp1,temp2)/temp1
                        if temp2 == 0:
                            temp_pR_coeff[count] = 1
                        if temp2 != 0:
                            temp_pR_coeff[count] = np.lcm(temp1,temp2)/temp2
                    if temp3 == temp4:
                        temp_rR_coeff[count] = 1
                        temp_pO_coeff[count] = 1
                    if temp4 != temp3:
                        if temp3 == 0:
                            temp_rR_coeff[count] = 1
                        if temp3 != 0:
                            temp_rR_coeff[count] = np.lcm(temp3,temp4)/temp3
                        if temp4 == 0.0:
                            temp_pO_coeff[count] = 1
                        if temp4 !=0.0:
                            temp_pO_coeff[count] = np.lcm(temp3,temp4)/temp4
                    count +=1
            df_reax.loc[r, &#39;rO_coeff&#39;] = -max(temp_rO_coeff)
            df_reax.loc[r, &#39;rR_coeff&#39;] = -max(temp_rR_coeff)
            df_reax.loc[r, &#39;pR_coeff&#39;] = max(temp_pR_coeff)
            df_reax.loc[r, &#39;pO_coeff&#39;] = max(temp_pO_coeff)
        
        all_reax = df_reax.copy(deep=True)
        all_reax[&#39;rO_2_coeff&#39;] = &#39;&#39;
        all_reax[&#39;rO_2&#39;] = &#39;&#39;
        all_reax[&#39;rO_3_coeff&#39;] = &#39;&#39;
        all_reax[&#39;rO_3&#39;] = &#39;&#39;
        all_reax[&#39;rR_2_coeff&#39;] = &#39;&#39;
        all_reax[&#39;rR_2&#39;] = &#39;&#39;
        
        ### MAIN REACTION
        for r in range(1, max(all_reax[&#39;Reaction&#39;]+1)): # each reaction number once, 1 to 305
            if len(all_reax[all_reax[&#39;Reaction&#39;]==r].index.values) == 1: # if nothing to combine, skip
                continue
            else:
                temp = all_reax[all_reax[&#39;Reaction&#39;]==r].index.values[0] #index of first instance of this reaction which has multiple subreactions
                lst2 = []
                all_reax.loc[temp-0.5] = all_reax.loc[temp] # replicating the row to build on
                all_reax = all_reax.sort_index() # putting the replicated row above the first instance
                for i in all_reax[all_reax[&#39;Reaction&#39;]==r].index.values[2:]: #all but the first instance in the reactions (since that&#39;s copied already)
                    if all_reax.loc[i, &#39;rO&#39;] != all_reax.loc[temp, &#39;rO&#39;] and all_reax.loc[i, &#39;rO&#39;] not in lst2: # if rO is new (and not the same as the first)
                        lst2.append(all_reax.loc[i, &#39;rO&#39;]) # list unique rO besides the first
                        for l in range(0, len(lst2)): # looping through unique rO
                            temp2 = &#39;rO_&#39;+str(2+int(l)) # adding 0 or 1 to the rO number
                            all_reax.loc[temp-0.5,str(temp2)] = lst2[l] # add the unique rO to rO_2 or 3
                    if all_reax.loc[i, &#39;rR&#39;] != all_reax.loc[temp, &#39;rR&#39;]: # if rR is new
                            all_reax.loc[temp-0.5,&#39;rR_2&#39;] = all_reax.loc[i, &#39;rR&#39;] # add it to rR_2

                ##CHANGING COEFFICIENTS
                rO = all_reax.loc[temp-0.5,&#39;rO&#39;] #assigning easy variables
                rO_2 = all_reax.loc[temp-0.5,&#39;rO_2&#39;]
                rO_3 = all_reax.loc[temp-0.5,&#39;rO_3&#39;]
                rR = all_reax.loc[temp-0.5,&#39;rR&#39;]
                rR_2 = all_reax.loc[temp-0.5,&#39;rR_2&#39;]
                rO_coeff = all_reax.loc[temp-0.5,&#39;rO_coeff&#39;] #these are empty at the moment
                rO_2_coeff = all_reax.loc[temp-0.5,&#39;rO_2_coeff&#39;]
                rO_3_coeff = all_reax.loc[temp-0.5,&#39;rO_3_coeff&#39;]
                rR_2_coeff = all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;]
                rR_coeff = all_reax.loc[temp-0.5,&#39;rR_coeff&#39;]
                if rO_3 != &#39;&#39; and rO_2 != &#39;&#39;: #if DIC is the oxidant
                    all_reax.loc[temp-0.5,&#39;rO_coeff&#39;] = rO_coeff/3 #this works fine
                    all_reax.loc[temp-0.5,&#39;rO_2_coeff&#39;] = rO_coeff/3
                    all_reax.loc[temp-0.5,&#39;rO_3_coeff&#39;] = rO_coeff/3

                    if rR_2 != &#39;&#39;:
                        all_reax.loc[temp-0.5,&#39;rR_coeff&#39;] = rR_coeff/2 #this works fine
                        all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;] = rR_coeff/2

                        all_reax.loc[temp-0.4] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR - this works fine : line 4
                        all_reax.loc[temp-0.4, &#39;rR_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.4, &#39;rR_coeff&#39;] = rR_coeff

                        all_reax.loc[temp-0.3] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR_2 - this works fine: line 5
                        all_reax.loc[temp-0.3, &#39;rR_2_coeff&#39;] = rR_coeff
                        all_reax.loc[temp-0.3, &#39;rR_coeff&#39;] = 0

                        #NEW ROWS WITH TWO DIC AND BOTH rR
                        all_reax.loc[temp-0.25] = all_reax.loc[temp-0.5] #eliminate CO2
                        all_reax.loc[temp-0.25, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.25, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.25, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.24] = all_reax.loc[temp-0.5] #eliminate HCO3-
                        all_reax.loc[temp-0.24, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.24, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.24, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.23] = all_reax.loc[temp-0.5] #eliminate CO3-2
                        all_reax.loc[temp-0.23, &#39;rO_3_coeff&#39;] = 0                
                        all_reax.loc[temp-0.23, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.23, &#39;rO_coeff&#39;] = rO_coeff/2

                        all_reax.loc[temp-0.2] = all_reax.loc[temp-0.4] #NEW ROW WITH ONLY rR ELIMINATING CO2: line 6
                        all_reax.loc[temp-0.2, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.2, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.2, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1] = all_reax.loc[temp-0.4] #NEW ROW WITH ONLY rR ELIMINATING HCO3-: line 7
                        all_reax.loc[temp-0.1, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.1, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05] = all_reax.loc[temp-0.4] #NEW ROW WITH ONLY rR ELIMINATING CO3-2: line 8
                        all_reax.loc[temp-0.05, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.04] = all_reax.loc[temp-0.3] #NEW ROW WITH ONLY rR_2 ELIMINATING CO2: line 9
                        all_reax.loc[temp-0.04, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.04, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.04, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.03] = all_reax.loc[temp-0.3] #NEW ROW WITH ONLY rR_2 ELIMINATING HCO3-: line 10
                        all_reax.loc[temp-0.03, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.03, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.03, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.02] = all_reax.loc[temp-0.3] #NEW ROW WITH ONLY rR_2 ELIMINATING CO3-2: line 11
                        all_reax.loc[temp-0.02, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.02, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.02, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.01] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY CO2 and both RR
                        all_reax.loc[temp-0.01, &#39;rO_coeff&#39;] = rO_coeff
                        all_reax.loc[temp-0.01, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.01, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.009] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY HCO3- and both RR
                        all_reax.loc[temp-0.009, &#39;rO_coeff&#39;] = 0 ###
                        all_reax.loc[temp-0.009, &#39;rO_2_coeff&#39;] = rO_coeff
                        all_reax.loc[temp-0.009, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.008] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY CO2 and both RR
                        all_reax.loc[temp-0.008, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.008, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.008, &#39;rO_3_coeff&#39;] = rO_coeff

                    if rR_2 == &#39;&#39;:
                        all_reax.loc[temp-0.2] = all_reax.loc[temp-0.5] #NEW ROW ELIMINATING CO2
                        all_reax.loc[temp-0.2, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.2, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.2, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1] = all_reax.loc[temp-0.5] #NEW ROW ELIMINATING HCO3-
                        all_reax.loc[temp-0.1, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.1, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05] = all_reax.loc[temp-0.5] #NEW ROW ELIMINATING CO3-2
                        all_reax.loc[temp-0.05, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_3_coeff&#39;] = 0

                if rO_2 != &#39;&#39; and rO_3 == &#39;&#39;: # IF THERE ARE TWO OXIDANT OPTIONS
                    all_reax.loc[temp-0.5,&#39;rO_coeff&#39;] = rO_coeff/2
                    all_reax.loc[temp-0.5,&#39;rO_2_coeff&#39;] = rO_coeff/2

                    if rR_2 != &#39;&#39;: #IF THERE ARE TWO REDUCTANT OPTIONS
                        all_reax.loc[temp-0.5,&#39;rR_coeff&#39;] = rR_coeff/2
                        all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;] = rR_coeff/2
                        
                        if rR_2 == rO_2:
                            continue
                        else:

                            all_reax.loc[temp-0.4] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR
                            all_reax.loc[temp-0.4, &#39;rR_2_coeff&#39;] = 0
                            all_reax.loc[temp-0.4, &#39;rR_coeff&#39;] = rR_coeff

                            all_reax.loc[temp-0.3] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR_2
                            all_reax.loc[temp-0.3, &#39;rR_2_coeff&#39;] = rR_coeff
                            all_reax.loc[temp-0.3, &#39;rR_coeff&#39;] = 0

                            all_reax.loc[temp-0.2] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rO_2
                            all_reax.loc[temp-0.2, &#39;rO_2_coeff&#39;] = rO_coeff
                            all_reax.loc[temp-0.2, &#39;rO_coeff&#39;] = 0

                            all_reax.loc[temp-0.1] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rO
                            all_reax.loc[temp-0.1, &#39;rO_2_coeff&#39;] = 0
                            all_reax.loc[temp-0.1, &#39;rO_coeff&#39;] = rO_coeff

                if rO_2 == &#39;&#39; and rO_3 == &#39;&#39; and rR_2 != &#39;&#39;: # IF THERE IS ONLY ONE OXIDANT BUT TWO REDUCTANTS
                    all_reax.loc[temp-0.5,&#39;rR_coeff&#39;] = rR_coeff/2
                    all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;] = rR_coeff/2

        all_reax = all_reax.sort_index().reset_index(drop=True)
        
        pair_list = []
        for i in range(0, len(all_reax[&#39;Temp_Pairs&#39;])):
            pair_list.append([redox_pairs[all_reax.loc[i, &#39;Temp_Pairs&#39;][0]], redox_pairs[all_reax.loc[i, &#39;Temp_Pairs&#39;][1]]])
        all_reax[&#39;pairs&#39;] = pair_list

        new_elements = []
        for r in range(0, len(all_reax[&#39;rO&#39;])):
            for e in elements:
                if e in [&#39;O&#39;,&#39;H&#39;,&#39;+&#39;,&#39;-&#39;]:
                    continue
                else:
                    temp1 = int(element_dictionary[all_reax[&#39;rO&#39;][r]][e]) #count for the element in the list for rO at index r
                    temp2 = int(element_dictionary[all_reax[&#39;pR&#39;][r]][e])
                    temp3 = int(element_dictionary[all_reax[&#39;rR&#39;][r]][e])
                    temp4 = int(element_dictionary[all_reax[&#39;pO&#39;][r]][e])
                    if temp1 != temp2:
                        if temp1 ==0:
                            all_reax.loc[r, &#39;red_&#39;+e+&#39;_coeff&#39;] = -temp2
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;red_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)
                        if temp2 == 0:
                            all_reax.loc[r, &#39;red_&#39;+e+&#39;_coeff&#39;] = temp1
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;red_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)
                    if temp4 != temp3:
                        if temp3 == 0:
                            all_reax.loc[r, &#39;ox_&#39;+e+&#39;_coeff&#39;] = -temp4
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;ox_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)
                        if temp4 == 0.0:
                            all_reax.loc[r, &#39;ox_&#39;+e+&#39;_coeff&#39;] = temp3
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;ox_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)


        for i in new_elements:
            if i not in db_names:
                db_names.append(i)
            if i not in formulas:
                formulas.append(i)
            parsed_formula = parse_formula(i)
            element_dictionary[i] = parsed_formula
            for e in elements:
                if element_dictionary[i].get(e, 0) == 0:
                    element_dictionary[i][e] = 0

        reax = all_reax.copy(deep=True)
        reax.drop(&#39;Temp_Pairs&#39;, axis=1, inplace=True)
        reax.drop(&#39;pairs&#39;, axis=1, inplace=True)
        reax.reset_index(drop=True, inplace=True)
        for s in [&#39;O&#39;, &#39;H&#39;,&#39;-&#39;,&#39;+&#39;]:
            for i in range(0,len(reax[&#39;rO&#39;])):
                red = 0
                ox=0
                for j in reax.columns.tolist():
                    if &#39;_coeff&#39; in j:
                        if &#39;rO_&#39; in j or &#39;pR_&#39; in j or &#39;red_&#39; in j:
                            if str(reax[j][i]) != &#39;nan&#39; and str(reax[j][i]) != &#39;&#39;:
                                red_temp_coeff = reax[j][i]
                                red_temp = element_dictionary[reax[j.split(&#39;_coeff&#39;)[0]][i]][s]
                                red -= red_temp_coeff*red_temp

                        if &#39;rR_&#39; in j or &#39;pO_&#39; in j or &#39;ox_&#39; in j:
                            if str(reax[j][i]) != &#39;nan&#39; and str(reax[j][i]) != &#39;&#39;:
                                ox_temp_coeff = reax[j][i]
                                ox_temp = element_dictionary[reax[j.split(&#39;_coeff&#39;)[0]][i]][s]
                                ox -= ox_temp_coeff*ox_temp      

                reax.loc[i, &#39;r_&#39;+s] = red
                reax.loc[i, &#39;o_&#39;+s] = ox

        reax[&#39;r_H&#39;] = reax[&#39;r_H&#39;] - 2*reax[&#39;r_O&#39;]
        reax[&#39;o_H&#39;] = reax[&#39;o_H&#39;] - 2*reax[&#39;o_O&#39;]
        reax[&#39;r_+&#39;] = reax[&#39;r_+&#39;] - reax[&#39;r_H&#39;]
        reax[&#39;o_+&#39;] = reax[&#39;o_+&#39;] - reax[&#39;o_H&#39;]
        reax[&#39;r_e-&#39;] = reax[&#39;r_+&#39;] - reax[&#39;r_-&#39;] 
        reax[&#39;o_e-&#39;] = reax[&#39;o_+&#39;] - reax[&#39;o_-&#39;] 
        reax.rename({&#39;r_O&#39;: &#39;r_H2O&#39;, &#39;r_H&#39;: &#39;r_H+&#39;, &#39;o_O&#39;: &#39;o_H2O&#39;, &#39;o_H&#39;: &#39;o_H+&#39;}, axis=1, inplace = True)
        
        ### MULTIPLYING SUB-REACTIONS
        lcm_charge = []
        electrons = []
        for i in range(0, len(reax[&#39;rO&#39;])):
        # for i in range(0, 1):
            lcm_charge = np.lcm(round(reax[&#39;r_e-&#39;][i]), round(reax[&#39;o_e-&#39;][i]))
            electrons.append(str(lcm_charge)+&#39;e&#39;)
            r_multiplier = abs(lcm_charge/int(reax[&#39;r_e-&#39;][i]))
            o_multiplier = abs(lcm_charge/int(reax[&#39;o_e-&#39;][i]))
            for s in list(reax.columns):
                if (&#39;red_&#39; in s and &#39;coeff&#39; in s) or (&#39;rO_&#39; in s and &#39;coeff&#39; in s) or (&#39;pR_&#39; in s and &#39;coeff&#39; in s) or &#39;r_H2O&#39; in s or &#39;r_H+&#39; in s:
                    reax.loc[i, s] = reax.loc[i, s]*int(r_multiplier )
                if (&#39;ox_&#39; in s and &#39;coeff&#39; in s) or (&#39;rR_&#39; in s and &#39;coeff&#39; in s) or (&#39;pO_&#39; in s and &#39;coeff&#39; in s) or &#39;o_H2O&#39; in s or &#39;o_H+&#39; in s:
                    reax.loc[i, s] = reax.loc[i, s]*int(o_multiplier)
        reax[&#39;H+&#39;] = reax[&#39;r_H+&#39;] + reax[&#39;o_H+&#39;]
        reax[&#39;protons&#39;] = &#39;H+&#39;
        reax[&#39;H2O&#39;] = reax[&#39;r_H2O&#39;] + reax[&#39;o_H2O&#39;]
        reax[&#39;water&#39;] = &#39;H2O&#39;
        reax.drop(columns = [&#39;r_H2O&#39;, &#39;r_H+&#39;, &#39;r_-&#39;, &#39;r_+&#39;, &#39;r_e-&#39;, &#39;o_H2O&#39;, &#39;o_H+&#39;, &#39;o_-&#39;, &#39;o_+&#39;, &#39;o_e-&#39;],axis = 1, inplace = True)

        count = 0
        for i in db_names:
            db_names[count] = &#39;start&#39;+i+&#39;end&#39;
            count += 1

        real_reax = reax.replace(formulas,db_names)
        real_reax[&#39;rO_coeff&#39;] = real_reax[&#39;rO_coeff&#39;].astype(&#39;float&#39;) 
        real_reax[&#39;rR_coeff&#39;] = real_reax[&#39;rR_coeff&#39;].astype(&#39;float&#39;) 
        real_reax[&#39;pO_coeff&#39;] = real_reax[&#39;pO_coeff&#39;].astype(&#39;float&#39;) 
        real_reax[&#39;pR_coeff&#39;] = real_reax[&#39;pR_coeff&#39;].astype(&#39;float&#39;) 
        
        count = 0
        rxn_count = []
        rxn_number = []

        for i in real_reax[&#39;Reaction&#39;]:
            if i not in rxn_count:
                rxn_count.append(i)
                rxn_number.append(real_reax[&#39;Names&#39;][count]+ &#39;_&#39;+str(count))
            else:
                rxn_number.append(real_reax[&#39;Names&#39;][count]+ &#39;_&#39;+str(count)+&#39;_sub&#39;)
            count += 1
        real_reax.insert(0, &#39;Reaction Number&#39;, rxn_number)
        real_reax.insert(1, &#39;electrons&#39;, electrons)

        lst3 = [] #list of reaction numbers
        lst4 = [] #list of reactions with issues
        for i in range(0, len(real_reax[&#39;Reaction&#39;])):
            if real_reax[&#39;Reaction&#39;][i] not in lst3:
                lst3.append(real_reax[&#39;Reaction&#39;][i])
        for j in lst3: #looping through reaction numbers
            first_e = real_reax.loc[real_reax[&#39;Reaction&#39;] == j][&#39;electrons&#39;].reset_index(drop=True)[0]
            for k in real_reax.loc[real_reax[&#39;Reaction&#39;] == j][&#39;electrons&#39;].reset_index(drop=True):
                if k != first_e:
                    if j not in lst4:
                        lst4.append(j)
        for l in lst4:
            print(real_reax.loc[real_reax[&#39;Reaction&#39;] ==  l])

        real_reax.drop(labels=&#39;Reaction&#39;, axis=1, inplace = True)
        real_reax.drop(columns = &#39;Names&#39;, inplace = True)
        pairs = real_reax[&#39;redox_pair&#39;]
        real_reax.drop(columns = &#39;redox_pair&#39;, inplace = True)
        
        # 2-16-2022 CHANGES START HERE
        for i in range(0, len(real_reax[&#39;Reaction Number&#39;])):
            for j in range(2, len(real_reax.columns)):
                if str(real_reax.iloc[i, j]) == &#39;nan&#39;:
                    real_reax.iloc[i, j] = &#39;&#39;
        
        test_df = real_reax.copy(deep=True)
        count = 0
        for i in range(0, len(test_df[&#39;Reaction Number&#39;])):
            coefficients = []
            species = []
            for j in range(2, len(test_df.columns)):
                if count % 2 == 0: 
                    if test_df.iloc[i, j] != &#39;&#39;:
                        test_df.iloc[i, j] = round(test_df.iloc[i, j], 14)
                    if test_df.iloc[i, j] == 0 or test_df.iloc[i, j] == 0.0:
                        test_df.iloc[i, j] = &#39;&#39;
                        test_df.iloc[i, j+1] = &#39;&#39;
                    coefficient = test_df.iloc[i, j]
                    coefficients.append(test_df.iloc[i, j])
                if count % 2 != 0:
                    if test_df.iloc[i, j] != &#39;&#39;:
                        test_df.iloc[i, j] = str(test_df.iloc[i, j]).split(&#39;start&#39;)[1].split(&#39;end&#39;)[0]
                    compound = test_df.iloc[i, j]
                    if compound in species:
                        og_location = species.index(compound) 
                        df_location = 3+og_location*2 
                        df_location_coeff = df_location - 1
                        old_coeff = coefficients[og_location] 
                        new_coeff = coefficient + old_coeff 
                        test_df.iloc[i, j] = &#39;&#39;
                        test_df.iloc[i, j-1] = &#39;&#39;
                        df_value = test_df.iloc[i, df_location] #values from first occurence remaining
                        test_df.iloc[i, df_location_coeff] = new_coeff
                    species.append(compound)
                count+=1
        for m in range(0, 7):
            for i in range(0, len(test_df[&#39;Reaction Number&#39;])):
                line = []
                for j in range(2, len(test_df.columns)):
                    line.append(test_df.iloc[i, j])
                    if test_df.iloc[i, j] != &#39;&#39; and test_df.iloc[i, j-2] ==&#39;&#39;:
                        test_df.iloc[i, j-2] = test_df.iloc[i, j]
                        test_df.iloc[i, j] = &#39;&#39;

        file = test_df.to_csv(sep=&#39;\t&#39;, header=False, index=False, lineterminator=&#39;\n&#39;)

        file = file.split(&#34;\n&#34;) #not sure if I should keep this
        
        newlines = []
        for line in file:   
            line = line.strip()
            newlines.append(line)

        self.affinity_energy_reactions_raw = &#34;\n&#34;.join(newlines)
        df_rxn = pd.DataFrame([x.split(&#39;\t&#39;) for x in self.affinity_energy_reactions_raw.split(&#39;\n&#39;)])
        df_rxn.columns = df_rxn.columns.map(str)
        df_rxn = df_rxn.rename(columns={&#34;0&#34;: &#34;reaction_name&#34;, &#34;1&#34;: &#34;mol_e-_transferred_per_mol_rxn&#34;})
        df_rxn.insert(1, &#39;redox_pairs&#39;, all_reax[&#39;pairs&#39;])
        df_rxn = df_rxn.set_index(&#34;reaction_name&#34;)
        df_rxn = df_rxn[df_rxn[&#39;mol_e-_transferred_per_mol_rxn&#39;].notna()]
        self.affinity_energy_reactions_table = df_rxn
        
        prev_was_coeff = False
        n = 1
        for col in self.affinity_energy_reactions_table.iloc[:, 2:].columns:
            if not prev_was_coeff:
                new_col_name = &#34;coeff_&#34;+str(n)
                prev_was_coeff = True
            else:
                new_col_name = &#34;species_&#34;+str(n)
                prev_was_coeff = False
                n += 1
            self.affinity_energy_reactions_table = self.affinity_energy_reactions_table.rename(columns={col: new_col_name})
        
        nonsub_reaction_names = [name for name in self.affinity_energy_reactions_table.index if &#34;_sub&#34; not in name[-4:]]
        if self.verbose != 0:
            print(&#34;{} redox reactions have been generated.&#34;.format(len(nonsub_reaction_names)))

        
    def show_redox_reactions(self, formatted=True, charge_sign_at_end=False,
                                  hide_subreactions=True, simplify=True,
                                  show=True):
        
        &#34;&#34;&#34;
        Show a table of redox reactions generated with the function
        `make_redox_reactions`.
        
        Parameters
        ----------
        formatted : bool, default True
            Should reactions be formatted for html output?
            
        charge_sign_at_end : bool, default False
            Display charge with sign after the number (e.g. SO4 2-)? Ignored if
            `formatted` is False.
        
        hide_subreactions : bool, default True
            Hide subreactions?
        
        show : bool, default False
            Show the table of reactions? Ignored if not run in a Jupyter
            notebook.
        
        Returns
        ----------
        A pandas dataframe containing balanced redox reactions written in full.
        &#34;&#34;&#34;
        
        self.affinity_energy_formatted_reactions = copy.copy(self.affinity_energy_reactions_table.iloc[:, 0:1])
        
        df = copy.copy(self.affinity_energy_reactions_table)
        
        if simplify:
            main_rxn_names = df.loc[[ind for ind in df.index if &#34;_sub&#34; not in ind[-4:]]].index
            df = df.iloc[[i-1 for i in range(0, len(df.index)) if &#34;_sub&#34; not in df.index[i][-4:]]]
            
            self.affinity_energy_formatted_reactions = copy.copy(df.iloc[:, 0:1])
            
            reactions = []
            for irow in range(0, df.shape[0]):
                redox_pair = df.loc[df.index[irow], &#34;redox_pairs&#34;]

                oxidant_1 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[0]], &#34;Oxidant_1&#34;]
                oxidant_2 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[0]], &#34;Oxidant_2&#34;]
                oxidant_3 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[0]], &#34;Oxidant_3&#34;]
                reductant_1 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[1]], &#34;Reductant_1&#34;]
                reductant_2 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[1]], &#34;Reductant_2&#34;]
                
                oxidants = [ox for ox in [oxidant_1, oxidant_2, oxidant_3] if str(ox) != &#39;nan&#39;]
                reductants = [rd for rd in [reductant_1, reductant_2] if str(rd) != &#39;nan&#39;]
                
                if len(oxidants) &gt; 1:
                    oxidant_sigma_needed = True
                else:
                    oxidant_sigma_needed = False
                if len(reductants) &gt; 1:
                    reductant_sigma_needed = True
                else:
                    reductant_sigma_needed = False
                    
                rxn_row = df.iloc[irow, 2:]
                rxn = rxn_row[rxn_row.notna()]
                coeffs = copy.copy(rxn[::2]).tolist()
                names = copy.copy(rxn[1::2]).tolist()
                
                if oxidant_sigma_needed or reductant_sigma_needed:

                    reactant_names = [names[i] for i in range(0, len(names)) if float(coeffs[i]) &lt; 0]
                    for sp in reactant_names:
                        if sp in oxidants and oxidant_sigma_needed:
                            i = names.index(sp)
                            names[i] = u&#34;\u03A3&#34;+sp
                        if sp in reductants and reductant_sigma_needed:
                            if u&#34;\u03A3&#34;+sp not in names:
                                i = names.index(sp)
                                names[i] = u&#34;\u03A3&#34;+sp
                    
                react_grid = pd.DataFrame({&#34;coeff&#34;:coeffs, &#34;name&#34;:names})
                react_grid[&#34;coeff&#34;] = pd.to_numeric(react_grid[&#34;coeff&#34;])
                react_grid = react_grid.astype({&#39;coeff&#39;: &#39;float&#39;})

                reactants = &#34; + &#34;.join([(str(-int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else -react_grid[&#34;coeff&#34;][i])+&#34; &#34; if -react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                products = &#34; + &#34;.join([(str(int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else react_grid[&#34;coeff&#34;][i])+&#34; &#34; if react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
                if formatted:
                    reactants = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                    products = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
                reaction = reactants + &#34; = &#34; + products
                reactions.append(reaction)

            self.affinity_energy_formatted_reactions[&#34;reaction&#34;] = reactions[1:] + reactions[:1] # because reactions got rotated with respect to reaction names, rotate the other way
            self.affinity_energy_formatted_reactions.index = main_rxn_names
            
        else:
            reactions = []
            for irow in range(0, df.shape[0]):
                redox_pair = df.loc[self.affinity_energy_reactions_table.index[irow], &#34;redox_pairs&#34;]

                oxidant = redox_pair[0]
                reductant = redox_pair[1]

                rxn_row = df.iloc[irow, 2:]
                rxn = rxn_row[rxn_row.notna()]
                coeffs = copy.copy(rxn[::2]).tolist()
                names = copy.copy(rxn[1::2]).tolist()
                react_grid = pd.DataFrame({&#34;coeff&#34;:coeffs, &#34;name&#34;:names})
                react_grid[&#34;coeff&#34;] = pd.to_numeric(react_grid[&#34;coeff&#34;])
                react_grid = react_grid.astype({&#39;coeff&#39;: &#39;float&#39;})

                reactants = &#34; + &#34;.join([(str(-int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else -react_grid[&#34;coeff&#34;][i])+&#34; &#34; if -react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                products = &#34; + &#34;.join([(str(int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else react_grid[&#34;coeff&#34;][i])+&#34; &#34; if react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
                if formatted:
                    reactants = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                    products = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
                reaction = reactants + &#34; = &#34; + products
                reactions.append(reaction)
        
            self.affinity_energy_formatted_reactions[&#34;reaction&#34;] = reactions
        

        df_out = copy.copy(self.affinity_energy_formatted_reactions)

        if hide_subreactions and not simplify:
            df_out = self.affinity_energy_formatted_reactions.loc[[ind for ind in self.affinity_energy_formatted_reactions.index if &#34;_sub&#34; not in ind[-4:]]]
        
        if _isnotebook() and show:
            display(HTML(df_out.to_html(escape=False)))
        
        return df_out


    class Thermodata(object):
        &#34;&#34;&#34;
        Metaclass to store and load thermodynamic databases.
        Inherits attributes from its outer class, AqEquil.
        
        &#34;&#34;&#34;

        def __init__(self, AqEquil_instance):

            self.AqEquil_instance = AqEquil_instance
            
            # attributes to add to AqEquil class
            self.db = self.AqEquil_instance.db
            self.elements = self.AqEquil_instance.elements
            solid_solutions = self.AqEquil_instance.solid_solutions
            self.exclude_category = self.AqEquil_instance.exclude_category
            self.water_model = self.AqEquil_instance.water_model
            logK = self.AqEquil_instance.logK
            logK_S = self.AqEquil_instance.logK_S
            download_csv_files = self.AqEquil_instance.download_csv_files
            #exclude_category = self.AqEquil_instance.exclude_category
            suppress_redox = self.AqEquil_instance.suppress_redox
            exceed_Ttr = self.AqEquil_instance.exceed_Ttr
            input_template = self.AqEquil_instance.input_template
            verbose = self.AqEquil_instance.verbose
            
            self.hide_traceback = self.AqEquil_instance.hide_traceback
            self.err_handler = Error_Handler(clean=self.hide_traceback)

            self.eq36da = self.AqEquil_instance.eq36da
            self.eq36co = self.AqEquil_instance.eq36co

            self.df_rejected_species = pd.DataFrame({&#39;database name&#39;:[],
                                                     &#39;database index&#39;:[],
                                                     &#34;name&#34;:[],
                                                     &#34;reason for rejection&#34;:[]})
            
            # active thermo db attributes
            self.thermo_db = None
            self.thermo_db_type = None
            self.thermo_db_source = None
            self.thermo_db_filename = None
            self.custom_data0 = None
            self.data0_lettercode = None
            self.dynamic_db = None
            self.custom_obigt = None
            self.db_csv_name = None

            # data1 attributes
            self.data1 = {}

            # data0 attributes
            self.data0_db = None
            self.data0_db_type = None
            self.data0_db_source = None
            self.data0_db_filename = None

            # csv attributes
            self.csv_db = None
            self.csv_db_type = None
            self.csv_db_source = None
            self.csv_db_filename = None

            # element attributes
            self.element_db = None
            self.element_db_source = None
            self.element_db_filename = None
            self.element_active = None

            # solid solution attributes
            self.solid_solutions_active = False
            self.solid_solution_db = None
            self.solid_solution_db_source = None
            self.solid_solution_db_filename = None

            # logK attributes
            self.logK_active = False
            self.logK_extrapolate = self.AqEquil_instance.logK_extrapolate
            self.logK_db = None
            self.logK_db_source = None
            self.logK_db_filename = None

            # logK attributes
            self.logK_S_active = False
            self.logK_S_db = None
            self.logK_S_db_source = None
            self.logK_S_db_filename = None

            self.verbose=verbose

            if self.db == &#34;WORM&#34;:
                if self.verbose &gt; 0:
                    print(&#34;Loading Water-Organic-Rock-Microbe (WORM) thermodynamic databases...&#34;)
                self.db = &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
                self._set_active_db(db=self.db, download_csv_files=download_csv_files)
                if self.elements == None:
                    self._load_elements(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/elements.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)
                if solid_solutions == None:
                    self._load_solid_solutions(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/solid_solutions.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)
                if logK == None:
                    self._load_logK(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data_logK.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)
                if logK_S == None:
                    self._load_logK_S(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data_logK_S.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)
            else:
                self._set_active_db(db=self.db, download_csv_files=download_csv_files)
                

            # elements must be loaded if thermo_db_type is a CSV
            if self.elements != None:
                self._load_elements(elements, source=&#34;file&#34;)
            if not self.element_active and self.thermo_db_type==&#34;CSV&#34;:
                self._load_elements(&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/elements.csv&#34;, source=&#34;URL&#34;, download_csv_files=download_csv_files)

            if solid_solutions != None:
                self._load_solid_solutions(solid_solutions, source=&#34;file&#34;)

            if logK != None:
                self._load_logK(logK, source=&#34;file&#34;)

            # must be loaded after the logK database
            if logK_S != None:
                self._load_logK_S(logK_S, source=&#34;file&#34;)
                
            if self.logK_active:
                self.thermo_db = pd.concat([self.thermo_db, self.logK_db], ignore_index=True)
                
            # process dissociation reactions
            if self.thermo_db_type == &#34;CSV&#34;:
                self._suppress_redox_and_generate_dissrxns(
                    suppress_redox=suppress_redox,
                    exceed_Ttr=exceed_Ttr)
            elif len(suppress_redox) &gt; 0 and self.verbose &gt; 0:
                print(&#34;Warning: redox suppression option is not recognized if a data0 or data1 database is used.&#34;)
                
            if self.logK_active:
                self.logK_db = self.thermo_db[~self.thermo_db[&#34;logK1&#34;].isnull()]
                self.thermo_db = self.thermo_db[self.thermo_db[&#34;logK1&#34;].isnull()]
                
            # generate input file template
            # (after species have been excluded)
            if input_template != &#34;none&#34;:
                if input_template == &#39;strict&#39;:
                    template_names = list(self.thermo_db[self.thermo_db[&#34;tag&#34;]==&#34;basis&#34;][&#34;name&#34;])
                elif input_template == &#39;basis&#39;:
                    template_names = list(self.thermo_db[self.thermo_db[&#34;tag&#34;].isin([&#34;basis&#34;, &#34;aux&#34;])][&#34;name&#34;])
                elif input_template == &#39;all&#39;:
                    template_names = list(self.thermo_db[self.thermo_db[&#34;state&#34;]==&#34;aq&#34;][&#34;name&#34;])

                template_names = sorted(template_names)
                input_template = pd.DataFrame({&#34;Sample&#34;:[&#34;id&#34;], &#34;H+&#34;:[&#34;pH&#34;], &#34;Temperature&#34;:[&#34;degC&#34;], &#34;logfO2&#34;:[&#34;logfO2&#34;]})
                input_template_2 = pd.DataFrame({name:[&#34;Molality&#34;] for name in template_names})
                input_template = pd.concat([input_template, input_template_2], axis=1)

                input_template.to_csv(&#34;sample_input_template.csv&#34;, index=False)


        def _remove_missing_G_species(self):
            # remove species that are missing a gibbs free energy value.
            # handle minerals first. Reject any that have missing G in any polymorph.
            mineral_name_reject = list(set(self.csv_db[(self.csv_db[&#34;G&#34;].isnull()) &amp; (self.csv_db[&#39;state&#39;].str.contains(&#39;cr&#39;))][&#34;name&#34;]))
            
            idx = list(self.csv_db[self.csv_db[&#34;name&#34;].isin(mineral_name_reject)].index)

            names = self.csv_db[&#34;name&#34;].loc[idx]

            self.csv_db = self.csv_db[~self.csv_db[&#34;name&#34;].isin(mineral_name_reject)]

            for i,name in enumerate(names):
                d = pd.DataFrame({&#39;database name&#39;: [self.csv_db_filename], &#39;database index&#39;: [idx[i]], &#39;name&#39;: [name], &#39;reason for rejection&#39;: [&#34;missing Gibbs free energy in at least one polymorph&#34;]})
                self.df_rejected_species = pd.concat([self.df_rejected_species, d], ignore_index=True)
            
            # TODO: other states besides minerals
                
        def _set_active_db(self, db=None, download_csv_files=False):
            &#34;&#34;&#34;
            Set the main active thermodynamic database to a CSV file, a data0 file,
            or a data1 file on the server, a local file, or from a URL address.
            &#34;&#34;&#34;

            if len(db) == 3:
                # e.g., &#34;wrm&#34;

                self.data0_lettercode = db
                self.dynamic_db = False

                # search for a data1 file in the eq36da directory
                if os.path.exists(self.eq36da + &#34;/data1.&#34; + db) and os.path.isfile(self.eq36da + &#34;/data1.&#34; + db):
                    self.thermo_db = None
                    self.thermo_db_type = &#34;data1&#34;
                    self.thermo_db_source = &#34;file&#34;
                    self.thermo_db_filename = &#34;data1.&#34;+db

                    # store contents of data1 file in AqEquil object
                    with open(self.eq36da + &#34;/data1.&#34; + db, mode=&#39;rb&#39;) as data1_file:
                        self.data1[&#34;all_samples&#34;] = data1_file.read()

                elif os.path.exists(&#34;data0.&#34; + db) and os.path.isfile(&#34;data0.&#34; + db):

                    if self.verbose &gt; 0:
                        print(&#34;data1.&#34; + db + &#34; was not found in the EQ36DA directory &#34;
                              &#34;but a data0.&#34;+db+&#34; was found in the current working &#34;
                              &#34;directory. Using it...&#34;)

                    self._load_data0(&#34;data0.&#34; + db, source=&#34;file&#34;)

                    self.thermo_db = self.data0_db
                    self.thermo_db_filename = self.data0_db_filename
                    self.thermo_db_type = &#34;data0&#34;
                    self.thermo_db_source = &#34;file&#34;
                    self.custom_data0 = True
                    self.data0_lettercode = db[-3:].lower()
                    self.custom_obigt = None
                    self.eq36da = os.getcwd()+&#34;/eqpt_files&#34;

                elif os.path.exists(&#34;data1.&#34; + db) and os.path.isfile(&#34;data1.&#34; + db):
                    
                    if self.verbose &gt; 0:
                        print(&#34;data1.&#34; + db + &#34; was not found in the EQ36DA directory &#34;
                              &#34;but a data1.&#34;+db+&#34; was found in the current working &#34;
                              &#34;directory. Using it...&#34;)

                    self.custom_data0 = True
                    self.thermo_db = None
                    self.eq36da = os.getcwd()+&#34;/eqpt_files&#34;

                    # search for a data1 locally

                    # store contents of data1 file in AqEquil object
                    with open(&#34;data1.&#34; + db, mode=&#39;rb&#39;) as data1_file:
                        self.data1[&#34;all_samples&#34;] = data1_file.read()
                        self.thermo_db_type = &#34;data1&#34;
                        self.thermo_db_source = &#34;file&#34;
                        self.thermo_db_filename = &#34;data1.&#34;+db

                else:
                    msg = (&#34;Could not locate a &#39;data1.&#34;+db+&#34;&#39; file in the EQ36DA &#34;
                          &#34;directory, nor a &#39;data0.&#34;+db+&#34;&#39; or &#39;data1.&#34;+db+&#34;&#39; file in &#34;
                          &#34;the current working directory.&#34;)
                    self.err_handler.raise_exception(msg)

            elif &#34;data0.&#34; in db[-9:].lower() and db[-4:].lower() != &#34;.csv&#34; and (db[0:8].lower() == &#34;https://&#34; or db[0:7].lower() == &#34;http://&#34; or db[0:4].lower() == &#34;www.&#34;):
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#34;

                self._load_data0(db, source=&#34;URL&#34;)

                self.thermo_db = self.data0_db
                self.thermo_db_filename = self.data0_db_filename
                self.thermo_db_type = &#34;data0&#34;
                self.thermo_db_source = &#34;URL&#34;
                self.custom_data0 = True
                self.data0_lettercode = db[-3:]
                self.dynamic_db = False
                self.custom_obigt = None

            elif db[0:-4].lower() == &#34;data0&#34; and not (db[0:8].lower() == &#34;https://&#34; or db[0:7].lower() == &#34;http://&#34; or db[0:4].lower() == &#34;www.&#34;):
                # e.g., &#34;data0.wrm&#34;

                self._load_data0(db, source=&#34;file&#34;)

                self.thermo_db = self.data0_db
                self.thermo_db_filename = self.data0_db_filename
                self.thermo_db_type = &#34;data0&#34;
                self.thermo_db_source = &#34;file&#34;
                self.custom_data0 = True
                self.data0_lettercode = db[-3:].lower()
                self.dynamic_db = False
                self.custom_obigt = None

            elif db[-4:].lower() == &#34;.csv&#34; and not (db[0:8].lower() == &#34;https://&#34; or db[0:7].lower() == &#34;http://&#34; or db[0:4].lower() == &#34;www.&#34;):
                # e.g., &#34;wrm_data.csv&#34;

                self._load_csv(db, source=&#34;file&#34;)

                self.thermo_db = self.csv_db
                self.thermo_db_filename = self.csv_db_filename
                self.thermo_db_type = &#34;CSV&#34;
                self.thermo_db_source = &#34;file&#34;
                self.dynamic_db = True
                self.custom_data0 = False
                self.custom_obigt = self.csv_db_filename
                self.data0_lettercode = None

            elif db[-4:].lower() == &#34;.csv&#34; and (db[0:8].lower() == &#34;https://&#34; or db[0:7].lower() == &#34;http://&#34; or db[0:4].lower() == &#34;www.&#34;):
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;

                self._load_csv(db, source=&#34;URL&#34;, download_csv_files=download_csv_files)

                self.thermo_db = self.csv_db
                self.thermo_db_filename = self.csv_db_filename
                self.thermo_db_type = &#34;CSV&#34;
                self.thermo_db_source = &#34;URL&#34;
                self.dynamic_db = True
                self.custom_data0 = False
                self.custom_obigt = self.csv_db_filename
                self.data0_lettercode = None

            else:
                self.err_handler.raise_exception(&#34;Unrecognized thermodynamic &#34;
                    &#34;database &#39;{}&#39;&#34;.format(db)+&#34; specified for db. A database can specified as:&#34;
                    &#34;\n - a three letter code designating a data0 file. e.g., db=&#39;wrm&#39;&#34;
                    &#34;\n - a data0 file in your working directory. e.g., db=&#39;data0.wrm&#39;&#34;
                    &#34;\n - a csv file in your working directory. e.g., db=&#39;wrm_data.csv&#39;&#34;
                    &#34;\n - a URL directing to a data0 file. e.g.,&#34;
                    &#34;\n\t db=&#39;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#39;&#34;
                    &#34;\n\t (note the data0 file in the URL must have &#39;data0.&#39; followed by a three letter code)&#34;
                    &#34;\n - a URL directing to a valid csv file. e.g.,&#34;
                    &#34;\n\t db=&#39;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#39;&#34;)

            if self.verbose &gt; 0:
                print(self.thermo_db_filename, &#34;is now set as the active thermodynamic database.&#34;)

                if self.thermo_db_filename in [&#39;data0.wrm&#39;, &#39;data1.wrm&#39;]:
                    print(&#34;This database is meant for rapid calculations between 0 and 350 C at water saturation pressure.&#34;)
                elif self.thermo_db_filename == &#34;wrm_data.csv&#34;:
                    print(&#34;This database is meant for calculations between 0 and 1000 C and up to 5 kb pressure.&#34;)

            self.db = db


        def __df_from_url(self, url, download_csv_files=False):
            &#34;&#34;&#34;
            Get a filename and dataframe from a URL pointing to a CSV file.
            &#34;&#34;&#34;

            filename = url.split(&#34;/&#34;)[-1].lower()

            # Download from URL and decode as UTF-8 text.
            with urlopen(url) as webpage:
                content = webpage.read().decode()

            if download_csv_files:
                if self.verbose &gt; 0:
                    print(&#34;Downloading&#34;, filename, &#34;from&#34;, url)
                with open(filename, &#39;w&#39;) as output:
                    output.write(content)

            return filename, pd.read_csv(StringIO(content), sep=&#34;,&#34;)


        def __str_from_url(self, url):
            &#34;&#34;&#34;
            Get a filename and contents from a URL pointing to a txt file.
            &#34;&#34;&#34;

            filename = url.split(&#34;/&#34;)[-1].lower()

            # Download from URL and decode as UTF-8 text.
            with urlopen(url) as webpage:
                txt_content = webpage.read().decode()

            if self.verbose &gt; 0:
                print(&#34;Downloading&#34;, filename, &#34;from&#34;, url)
            with open(filename, &#39;w&#39;) as output:
                output.write(txt_content)

            return filename, txt_content


        def _load_elements(self, db, source=&#34;url&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load an element database CSV file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;elements.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.element_db = pd.read_csv(db)
                    self.element_db_source = &#34;file&#34;
                    self.element_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/elements.csv&#34;
                self.element_db_filename, self.element_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.element_db_source = &#34;URL&#34;
            else:
                if self.verbose &gt; 0:
                    print(&#34;No element database loaded.&#34;)

            if self.thermo_db_type == &#34;CSV&#34;:
                if self.verbose &gt; 0:
                    print(&#34;Element database&#34;, self.element_db_filename, &#34;is active.&#34;)
                self.element_active = True
            else:
                if self.verbose &gt; 0:
                    print(&#34;Element database is not active because the active thermodynamic database is a&#34;, self.thermo_db_type, &#34;and not a CSV.&#34;)


        def _load_solid_solutions(self, db, source=&#34;url&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load a solid solution database CSV file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;solid_solutions.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.solid_solution_db = pd.read_csv(db)
                    self.solid_solution_db_source = &#34;file&#34;
                    self.solid_solution_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/solid_solutions.csv&#34;
                self.solid_solution_db_filename, self.solid_solution_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.solid_solution_db_source = &#34;URL&#34;
            else:
                if self.verbose &gt; 0:
                    print(&#34;No solid solution database loaded.&#34;)

            if self.thermo_db_type == &#34;CSV&#34;:
                if self.verbose &gt; 0:
                    print(&#34;Solid solution database&#34;, self.solid_solution_db_filename, &#34;is active.&#34;)
                self.solid_solutions_active = True
            else:
                if self.verbose &gt; 0:
                    print(&#34;Solid solution database is not active because the active thermodynamic database is a&#34;, self.thermo_db_type, &#34;and not a CSV.&#34;)


        def _load_logK(self, db, source=&#34;URL&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load a logK database CSV file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;logK.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.logK_db = pd.read_csv(db)
                    self.logK_db_source = &#34;file&#34;
                    self.logK_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data_logK.csv&#34;
                self.logK_db_filename, self.logK_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.logK_db_source = &#34;URL&#34;

            else:
                if self.verbose &gt; 0:
                    print(&#34;No logK database loaded.&#34;)

            if self.thermo_db_type == &#34;CSV&#34;:
                if self.verbose &gt; 0:
                    print(&#34;LogK database&#34;, self.logK_db_filename, &#34;is active.&#34;)
                self.logK_active = True
            else:
                if self.verbose &gt; 0:
                    print(&#34;LogK database is not active because the active thermodynamic database is a&#34;, self.thermo_db_type, &#34;and not a CSV.&#34;)

            self.logK_db = self._exclude_category(df=self.logK_db, df_name=self.logK_db_filename)


        def _load_logK_S(self, db, source=&#34;URL&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load a logK_S database CSV file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;logK_S.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.logK_S_db = pd.read_csv(db)
                    self.logK_S_db_source = &#34;file&#34;
                    self.logK_S_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data_logK_S.csv&#34;
                self.logK_S_db_filename, self.logK_S_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.logK_S_db_source = &#34;URL&#34;

            else:
                if self.verbose &gt; 0:
                    print(&#34;No logK_S database loaded.&#34;)

            if self.logK_active and self.element_active:
                if self.verbose &gt; 0:
                    print(&#34;LogK_S database&#34;, self.logK_S_db_filename, &#34;is active.&#34;)
                self.logK_S_active = True
            else:
                if self.verbose &gt; 0:
                    print(&#34;LogK_S database is not active because there is no active logK database.&#34;)

            self.logK_S_db = self._exclude_category(df=self.logK_S_db, df_name=self.logK_S_db_filename)

            if self.logK_S_active:
                for i,sp in enumerate(self.logK_S_db[&#34;name&#34;]):
                    
                    logK_25C = float(self.logK_S_db[&#34;logK_25&#34;][i])
                    
                    IS_ref = float(self.logK_S_db[&#34;logK_25_IS&#34;][i])
                    
                    T_list = self.logK_S_db[&#34;T_vals&#34;][i].split(&#34; &#34;)
                    T_list = [float(T) for T in T_list]

                    Delta_S = float(self.logK_S_db[&#34;DeltaS&#34;][i])
                    
                    if IS_ref &gt; 0:
                        # extrapolate to ionic strength 0
                        
                        # collect azero values for metal, ligand, and complex
                        metal_name = self.logK_S_db[&#34;metal_name&#34;][i]
                        
                        if self.thermo_db[&#34;name&#34;].isin([metal_name]).any():
                            metal_azero = list(self.thermo_db[self.thermo_db[&#34;name&#34;] == metal_name][&#34;azero&#34;])[0]
                            metal_charge = float(list(self.thermo_db[self.thermo_db[&#34;name&#34;] == metal_name][&#34;z.T&#34;])[0])
#                         elif:
#                             # todo: get metal azero and charge from other databases, e.g., logK db
#                             pass
                        else:
                            # todo: throw error
                            pass
                        
                        ligand_name = self.logK_S_db[&#34;ligand_name&#34;][i]
                        if isinstance(self.logK_S_db[&#34;ligand_azero&#34;][i], float):
                            ligand_azero = float(self.logK_S_db[&#34;ligand_azero&#34;][i])
                        elif self.thermo_db[&#34;name&#34;].isin([ligand_name]).any():
                            ligand_azero = float(list(self.thermo_db[self.thermo_db[&#34;name&#34;] == ligand_name][&#34;azero&#34;])[0])
                        else:
                            # todo: elif ligand_name in logK database names, get azero from there...
                            # or maybe this is not necessary if logK is merged with thermo_db at this point
                            pass
                        
                        if isinstance(self.logK_S_db[&#34;ligand_charge&#34;][i], float):
                            ligand_charge = float(self.logK_S_db[&#34;ligand_charge&#34;][i])
                        elif self.thermo_db[&#34;name&#34;].isin([ligand_name]).any():
                            ligand_charge = float(list(self.thermo_db[self.thermo_db[&#34;name&#34;] == ligand_name][&#34;z.T&#34;])[0])
                        else:
                            # todo: elif ligand_name in logK database names, get charge from there...
                            # or maybe this is not necessary if logK is merged with thermo_db at this point
                            pass
                    
                        dissrxn = self.logK_S_db[&#34;dissrxn&#34;][i].split(&#34; &#34;)
                        n_metal = float(dissrxn[dissrxn.index(metal_name)-1])
                        n_ligand = float(dissrxn[dissrxn.index(ligand_name)-1])
                        n_complex = -float(dissrxn[dissrxn.index(sp)-1])
                        
                        complex_charge = n_metal*metal_charge + n_ligand*ligand_charge
                        complex_azero = self.logK_S_db[&#34;azero&#34;][i]
                        
                        A=0.5114
                        B=0.3288
                        Bdot=0.041
                        If = 0 # what ionic strength to extrapolate to
                        
                        ari=[metal_azero, ligand_azero]
                        api=[complex_azero]
                        vri=[n_metal, n_ligand]
                        vpi=[n_complex]
                        zri=[metal_charge, ligand_charge]
                        zpi=[complex_charge]
                        
                        def loggamma(vparam, zparam, aparam, I):
                            x=[v*((-1*A*z**2*I**0.5)/(1+a*B*I**0.5)+Bdot*I) for v,z,a in zip(vparam, zparam, aparam)]
                            return x
                        
                        def f(vparam, zparam, aparam, I):
                            return sum(loggamma(vparam, zparam, aparam, I))
                        
                        logK_25C = -(-logK_25C+(f(vpi,zpi,api,IS_ref)-f(vri,zri,ari,IS_ref))-(f(vpi,zpi,api,If)-f(vri,zri,ari,If)))
                        
                    logK_list = self._est_logK_S(T_list, logK_25C, Delta_S)
                    
                    
                    if isinstance(self.logK_S_db[&#34;ligand_element&#34;][i], str):
                        # modify element database with pseudoelements
                        pseudoelement = self.logK_S_db[&#34;ligand_element&#34;][i]
                        if pseudoelement not in self.element_db[&#34;element&#34;]:
                            e_df = pd.DataFrame(
                                {&#39;element&#39;:[self.logK_S_db[&#34;ligand_element&#34;][i]],
                                 &#39;state&#39;:[self.logK_S_db[&#34;state&#34;][i]],
                                 &#39;source&#39;:[self.logK_S_db[&#34;ligand_name&#34;][i]],
                                 &#39;mass&#39;:[self.logK_S_db[&#34;ligand_mass&#34;][i]],
                                 &#39;s&#39;:[self.logK_S_db[&#34;ligand_entropy&#34;][i]],
                                 &#39;n&#39;:[self.logK_S_db[&#34;ligand_n&#34;][i]],
                                })

                            self.element_db = pd.concat([self.element_db, e_df], ignore_index=True)

                    if isinstance(self.logK_S_db[&#34;ligand_basis&#34;][i], str):
                        # add a basis species representing the pseudoelement
                        basis = self.logK_S_db[&#34;ligand_basis&#34;][i]
                        if basis not in self.thermo_db[&#34;name&#34;]:
                            b_df = pd.DataFrame(
                                {&#39;name&#39;:[self.logK_S_db[&#34;ligand_basis&#34;][i]],
                                 &#39;abbrv&#39;:[&#34;&#34;],
                                 &#39;formula&#39;:[self.logK_S_db[&#34;ligand_formula&#34;][i]],
                                 &#39;state&#39;:[self.logK_S_db[&#34;state&#34;][i]],
                                 &#39;ref1&#39;:[self.logK_S_db[&#34;ref1&#34;][i]],
                                 &#39;ref2&#39;:[self.logK_S_db[&#34;ref2&#34;][i]],
                                 &#39;date&#39;:[self.logK_S_db[&#34;date&#34;][i]],
                                 &#39;E_units&#39;:[&#34;cal&#34;],
                                 &#39;G&#39;:[0], &#39;H&#39;:[0], &#39;S&#39;:[0],
                                 &#39;Cp&#39;:[0], &#39;V&#39;:[0], &#39;a1.a&#39;:[0],
                                 &#39;a2.b&#39;:[0], &#39;a3.c&#39;:[0], &#39;a4.d&#39;:[0],
                                 &#39;c1.e&#39;:[0], &#39;c2.f&#39;:[0],
                                 &#39;omega.lambda&#39;:[0],
                                 &#39;z.T&#39;:[self.logK_S_db[&#34;ligand_charge&#34;][i]],
                                 &#39;azero&#39;:[self.logK_S_db[&#34;ligand_azero&#34;][i]],
                                 &#39;neutral_ion_type&#39;:[0],
                                 &#39;dissrxn&#39;:[&#39;&#39;],
                                 &#39;tag&#39;:[&#39;basis&#39;],
                                 &#39;formula_ox&#39;:[self.logK_S_db[&#34;ligand_formula&#34;][i]],
                                 &#39;category_1&#39;:[self.logK_S_db[&#34;category_1&#34;][i]],
                                })

                            self.thermo_db = pd.concat([self.thermo_db, b_df], ignore_index=True)

                    if self.logK_S_db[&#34;name&#34;][i] not in self.thermo_db[&#34;name&#34;] and self.logK_S_db[&#34;name&#34;][i] not in self.logK_db[&#34;name&#34;]:
                        s_df = pd.DataFrame(
                                {&#39;name&#39;:[self.logK_S_db[&#34;name&#34;][i]],
                                 &#39;abbrv&#39;:[&#34;&#34;],
                                 &#39;formula&#39;:[self.logK_S_db[&#34;formula&#34;][i]],
                                 &#39;state&#39;:[self.logK_S_db[&#34;state&#34;][i]],
                                 &#39;ref1&#39;:[self.logK_S_db[&#34;ref1&#34;][i]],
                                 &#39;ref2&#39;:[self.logK_S_db[&#34;ref2&#34;][i]],
                                 &#39;date&#39;:[self.logK_S_db[&#34;date&#34;][i]],
                                 &#39;logK1&#39;:[np.nan],&#39;logK2&#39;:[np.nan],&#39;logK3&#39;:[np.nan],&#39;logK4&#39;:[np.nan],&#39;logK5&#39;:[np.nan],&#39;logK6&#39;:[np.nan],&#39;logK7&#39;:[np.nan],&#39;logK8&#39;:[np.nan],
                                 &#39;T1&#39;:[np.nan],&#39;T2&#39;:[np.nan],&#39;T3&#39;:[np.nan],&#39;T4&#39;:[np.nan],&#39;T5&#39;:[np.nan],&#39;T6&#39;:[np.nan],&#39;T7&#39;:[np.nan],&#39;T8&#39;:[np.nan],
                                 &#39;P1&#39;:[np.nan],&#39;P2&#39;:[np.nan],&#39;P3&#39;:[np.nan],&#39;P4&#39;:[np.nan],&#39;P5&#39;:[np.nan],&#39;P6&#39;:[np.nan],&#39;P7&#39;:[np.nan],&#39;P8&#39;:[np.nan],
                                 &#39;azero&#39;:[self.logK_S_db[&#34;azero&#34;][i]],
                                 &#39;dissrxn&#39;:[self.logK_S_db[&#34;dissrxn&#34;][i]],
                                 &#39;tag&#39;:[&#39;&#39;],
                                 &#39;formula_ox&#39;:[self.logK_S_db[&#34;formula_ox&#34;][i]],
                                 &#39;category_1&#39;:[self.logK_S_db[&#34;category_1&#34;][i]],
                                })
                        self.logK_db = pd.concat([self.logK_db, s_df], ignore_index=True)

                        for ti in range(0, len(T_list)):
                            if ti+1 &gt; 8:
                                self.err_handler.raise_exception(&#34;Species &#34;, sp, &#34;in&#34;,
                                    self.logK_S_db_filename, &#34;may only have up to&#34;,
                                    &#34;eight temperature values in column T_vals&#34;)

                            self.logK_db.loc[self.logK_db.index[-1], &#34;logK&#34;+str(ti+1)] = logK_list[ti]
                            self.logK_db.loc[self.logK_db.index[-1], &#34;T&#34;+str(ti+1)] = T_list[ti]
                            self.logK_db.loc[self.logK_db.index[-1], &#34;P&#34;+str(ti+1)] = &#39;psat&#39;

        def _est_logK_S(self, T_list, logK_25C, Delta_S):

            R = 8.31446261815324/4.184 # cal/(mol K)

            # solve for G of reaction:
            # _r G= -2.303RT logK
            G_25 = -2.303*R*298.15*logK_25C # in cal/mol

            # solve for H of reaction:
            # _r G= _r H-T_r S
            H = G_25 + 298.15*Delta_S # in cal/mol

            logK_list = []
            for T_C in T_list:

                T_K = T_C+273.15 # convert C to Kelvin

                # estimate G at temperature
                G_T = H - T_K*Delta_S

                # convert G to logK
                logK_T = G_T/(-2.303*R*T_K)
                logK_list.append(logK_T)

            return logK_list


        def _load_data0(self, db, source=&#34;URL&#34;):
            &#34;&#34;&#34;
            Load a data0 file from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#34;
                self.data0_db_filename, self.data0_db = self.__str_from_url(db)
                self.data0_db_type = &#34;data0&#34;
                self.data0_db_source = &#34;URL&#34;

            elif source == &#34;file&#34;:
                # e.g., &#34;data0.wrm&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    with open(db) as data0_content:
                        self.data0_db = data0_content.read()
                        self.data0_db_type = &#34;data0&#34;
                        self.data0_db_source = &#34;file&#34;
                        self.data0_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the data0 file &#39;&#34;+db+&#34;&#39;&#34;)


        def _load_csv(self, db, source=&#34;URL&#34;, download_csv_files=False):
            &#34;&#34;&#34;
            Load a WORM-styled thermodynamic database CSV from a file or URL.
            &#34;&#34;&#34;

            if source == &#34;file&#34;:
                # e.g., &#34;wrm_data.csv&#34;
                if os.path.exists(db) and os.path.isfile(db):
                    self.csv_db = pd.read_csv(db)
                    self.csv_db_type = &#34;CSV&#34;
                    self.csv_db_source = &#34;file&#34;
                    self.csv_db_filename = db
                else:
                    self.err_handler.raise_exception(&#34;Could not locate the CSV file &#39;&#34;+db+&#34;&#39;&#34;)

            elif source == &#34;URL&#34;:
                # e.g., &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
                self.csv_db_filename, self.csv_db = self.__df_from_url(db, download_csv_files=download_csv_files)
                self.csv_db_type = &#34;CSV&#34;
                self.csv_db_source = &#34;URL&#34;

            self.csv_db = self.csv_db.astype({&#39;name&#39;:&#39;str&#39;, &#39;abbrv&#39;:&#39;str&#39;, &#39;formula&#39;:&#39;str&#39;,
                                          &#39;state&#39;:&#39;str&#39;, &#39;ref1&#39;:&#39;str&#39;, &#39;ref2&#39;:&#39;str&#39;,
                                          &#39;date&#39;: &#39;str&#39;, &#39;E_units&#39;:&#39;str&#39;,
                                          &#39;G&#39;:&#39;float&#39;, &#39;H&#39;:&#39;float&#39;, &#39;S&#39;:&#39;float&#39;,
                                          &#39;Cp&#39;:&#39;float&#39;, &#39;V&#39;:&#39;float&#39;, &#39;a1.a&#39;:&#39;float&#39;,
                                          &#39;a2.b&#39;:&#39;float&#39;, &#39;a3.c&#39;:&#39;float&#39;, &#39;a4.d&#39;:&#39;float&#39;,
                                          &#39;c1.e&#39;:&#39;float&#39;, &#39;c2.f&#39;:&#39;float&#39;,
                                          &#39;omega.lambda&#39;:&#39;float&#39;, &#39;z.T&#39;:&#39;float&#39;,
                                          &#39;azero&#39;:&#39;float&#39;, &#39;neutral_ion_type&#39;:&#39;float&#39;,
                                          &#39;dissrxn&#39;:&#39;str&#39;, &#39;tag&#39;:&#39;str&#39;,
                                          &#39;formula_ox&#39;:&#39;str&#39;, &#39;category_1&#39;:&#39;str&#39;})

            # Check that thermodynamic database input files exist and are formatted correctly.
            self._check_csv_db()
            self._remove_missing_G_species()

            self.csv_db = self._exclude_category(df=self.csv_db, df_name=self.csv_db_filename)


        def _exclude_category(self, df, df_name):
            &#34;&#34;&#34;
            Exclude entries from a df based on values in columns.
            e.g., {&#34;category_1&#34;:[&#34;organic_aq&#34;, &#34;organic_cr&#34;]}
            &#34;&#34;&#34;
            
            exclude_keys = list(self.exclude_category.keys())
            if len(exclude_keys) &gt; 0:
                for key in exclude_keys:
                    if self.verbose &gt; 0:
                        print(&#34;Excluding&#34;, str(self.exclude_category[key]), &#34;from column&#34;, str(key), &#34;in&#34;, df_name)
                        
                    if isinstance(self.exclude_category[key], list):
                        
                        idx = list(df[df[key].isin(self.exclude_category[key])].index)
                        
                        names = df[&#34;name&#34;].loc[idx]
                        
                        df = df[~df[key].isin(self.exclude_category[key])]
                        
                        for i,name in enumerate(names):
                            d = pd.DataFrame({&#39;database name&#39;: [df_name], &#39;database index&#39;: [idx[i]], &#39;name&#39;: [name], &#39;reason for rejection&#39;: [&#34;excluded by user&#34;]})
                            self.df_rejected_species = pd.concat([self.df_rejected_species, d], ignore_index=True)
                        
                    elif isinstance(self.exclude_category[key], str):
                        
                        idx = list(df[df[key] != self.exclude_category[key]].index)
                        names = df[&#34;name&#34;].loc[idx]
                        
                        df = df[~df[key] != self.exclude_category[key]]
                        
                        for i,name in enumerate(names):
                            d = pd.DataFrame({&#39;database name&#39;: [df_name], &#39;database index&#39;: [idx[i]], &#39;name&#39;: [name], &#39;reason for rejection&#39;: [&#34;excluded by user&#34;]})
                            self.df_rejected_species = pd.concat([self.df_rejected_species, d], ignore_index=True)
                    else:
                        self.err_handler.raise_exception(&#34;The parameter exclude_category must either be a string or a list.&#34;)
            return df


        def _check_csv_db(self):
            &#34;&#34;&#34;
            Check for problems in the thermodynamic database CSV.
            &#34;&#34;&#34;

            thermo_df = self.csv_db

            # does this file have the proper headers?
            required_headers = [&#34;name&#34;, &#34;abbrv&#34;, &#34;formula&#34;, &#34;state&#34;,
                                &#34;ref1&#34;, &#34;ref2&#34;, &#34;date&#34;, &#34;E_units&#34;,
                                &#34;G&#34;, &#34;H&#34;, &#34;S&#34;, &#34;Cp&#34;, &#34;V&#34;,
                                &#34;a1.a&#34;, &#34;a2.b&#34;, &#34;a3.c&#34;, &#34;a4.d&#34;, &#34;c1.e&#34;, &#34;c2.f&#34;,
                                &#34;omega.lambda&#34;, &#34;z.T&#34;,
                                &#34;azero&#34;, &#34;neutral_ion_type&#34;,
                                &#34;dissrxn&#34;, &#34;tag&#34;, &#34;formula_ox&#34;]

            missing_headers = []
            for header in required_headers:
                if header not in thermo_df.columns:
                    missing_headers.append(header)
            if len(missing_headers) &gt; 0:
                msg = (&#34;The thermodynamic database file &#34;
                       &#34;is missing one or more required columns: &#34;
                       &#34;{}&#34;.format(&#34;, &#34;.join(missing_headers))+&#34;. &#34;
                       &#34;Are these headers spelled correctly in the file?&#34;)
                self.err_handler.raise_exception(msg)

            # does Cl-, O2(g), and O2 exist in the file?
            required_species = [&#34;Cl-&#34;, &#34;O2&#34;, &#34;O2(g)&#34;]
            missing_species = []
            for species in required_species:
                if species not in list(thermo_df[&#34;name&#34;]):
                    missing_species.append(species)
            if len(missing_species) &gt; 0:
                msg = (&#34;The thermodynamic database file &#34;
                       &#34;is missing required species:&#34;
                       &#34;{}&#34;.format(missing_species)+&#34;. Default thermodynamic values&#34;
                       &#34; will be used.&#34;)
                warnings.warn(msg)

            return


        def _suppress_redox_and_generate_dissrxns(self,
                                                  suppress_redox,
                                                  exceed_Ttr=True):

            thermo_df = self.thermo_db
            
            suppress_redox = _convert_to_RVector(suppress_redox)

            # if elements are being redox-suppressed, exclude all species with a
            # formula containing one or more of the redox-suppressed elements if the
            # species does not have a formula_ox.
            # e.g., if &#34;methionine&#34; does not have a formula_ox, ensure it is excluded
            #       if sulfur is redox-suppressed.
            if len(suppress_redox) &gt; 0:
                thermo_db_no_formula_ox = thermo_df[thermo_df[&#34;formula_ox&#34;].isnull()]
                if thermo_db_no_formula_ox.shape[0] &gt; 0:
                    sp_names_to_exclude = []
                    for i,sp in enumerate(thermo_db_no_formula_ox[&#34;name&#34;]):
                        f = thermo_db_no_formula_ox.iloc[i, thermo_db_no_formula_ox.columns.get_loc(&#34;formula&#34;)]
                        f_elems = list(parse_formula(f).keys())
                        for elem in suppress_redox:
                            if elem in f_elems:
                                sp_names_to_exclude.append(sp)
                    self.exclude_category[&#34;name&#34;] = sp_names_to_exclude
                    if self.verbose &gt; 0 and len(sp_names_to_exclude) &gt; 0:
                        print(&#34;Excluding the following chemical species because &#34;
                              &#34;they contain redox-suppressed elements but do not &#34;
                              &#34;have element oxidation states given in the &#34;
                              &#34;&#39;formula_ox&#39; column of the thermodynamic database: &#34;
                              &#34;&#34;+str(sp_names_to_exclude))

            if len(self.exclude_category) &gt; 0:
                exclude_category_R =  {k:_convert_to_RVector(l) for k,l in zip(self.exclude_category.keys(), self.exclude_category.values())}
            else:
                exclude_category_R = {}
            exclude_category_R = ro.ListVector(exclude_category_R)

            self.AqEquil_instance._capture_r_output()

            r_redox_dissrxns = pkg_resources.resource_string(
                __name__, &#39;redox_and_dissrxns.r&#39;).decode(&#34;utf-8&#34;)

            ro.r(r_redox_dissrxns)
            
            thermo_df = _clean_rpy2_pandas_conversion(thermo_df)

            ro.conversion.py2rpy(thermo_df)

            self.out_list = ro.r.suppress_redox_and_generate_dissrxns(
                                   thermo_df=ro.conversion.py2rpy(thermo_df),
                                   water_model=self.water_model,
                                   exceed_Ttr=exceed_Ttr,
                                   suppress_redox=suppress_redox,
                                   exclude_category=exclude_category_R,
                                   element_df=ro.conversion.py2rpy(self.element_db),
                                   fixed_species=_convert_to_RVector(FIXED_SPECIES),
                                   verbose=self.verbose)
            
            self.AqEquil_instance._print_captured_r_output()

            thermo_df = self.out_list.rx2(&#34;thermo_df&#34;)
            thermo_df=ro.conversion.rpy2py(thermo_df)

    #         regenerated_dissrxns = out_list.rx2(&#34;dissrxns&#34;)
    #         regenerated_dissrxn_dict = {}
    #         for name in regenerated_dissrxns.names:
    #             if name != &#34;basis_list&#34;:
    #                 regenerated_dissrxn_dict[name] = regenerated_dissrxns.rx2(name)[0]


            thermo_df = _clean_rpy2_pandas_conversion(thermo_df)

            # convert E units and calculate missing GHS values
            self.thermo_db = OBIGT2eos(thermo_df, fixGHS=True, tocal=True)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="AqEquil.AqSpeciation.AqEquil.Thermodata"><code class="name">var <span class="ident">Thermodata</span></code></dt>
<dd>
<div class="desc"><p>Metaclass to store and load thermodynamic databases.
Inherits attributes from its outer class, AqEquil.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="AqEquil.AqSpeciation.AqEquil.create_data0"><code class="name flex">
<span>def <span class="ident">create_data0</span></span>(<span>self, db, filename_ss=None, activity_model='b-dot', exceed_Ttr=True, grid_temps=[0.01, 50.0, 100.0, 150.0, 200.0, 250.0, 300.0, 350.0], grid_press='Psat', P1=True, plot_poly_fit=False, logK_extrapolate='none', fill_data0=True, dynamic_db=False, dynamic_db_sample_temps=[], dynamic_db_sample_press=[], verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a data0 file from a custom thermodynamic dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>db</code></strong> :&ensp;<code>str</code></dt>
<dd>Desired three letter code of data0 output.</dd>
<dt><strong><code>filename_ss</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name of file containing solid solution parameters.</dd>
<dt><strong><code>grid_temps</code></strong> :&ensp;<code>list</code> of <code>eight float</code>, default <code>[0.0100, 50.0000, 100.0000, 150.0000, 200.0000, 250.0000, 300.0000, 350.0000]</code></dt>
<dd>Eight temperature values that make up the T-P grid.</dd>
<dt><strong><code>grid_press</code></strong> :&ensp;<code>list</code> of <code>float</code>, default <code>"Psat"</code></dt>
<dd>Eight pressure values that make up the T-P grid. "Psat" for
calculations along the liquid-vapor saturation curve.</dd>
<dt><strong><code>P1</code></strong> :&ensp;<code>bool</code>, default <code>True,</code></dt>
<dd>Use pressure of 1 bar below 100 degrees C instead of calculated
values of Psat? Ignored if <code>grid_press</code> is not "Psat".</dd>
<dt><strong><code>plot_poly_fit</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Plot the polynomial fit of the temperature pressure grid?</dd>
<dt><strong><code>dynamic_db</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Are data0 files being created dynamically? If unsure, use False.
Used by <code>speciate</code> to display valid messages.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int, 0, 1,</code> or <code>2</code>, default <code>1</code></dt>
<dd>Level determining how many messages are returned during a
calculation. 2 for all messages, 1 for errors or warnings only,
0 for silent.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_data0(self,
                 db,
                 filename_ss=None,
                 activity_model=&#34;b-dot&#34;,
                 exceed_Ttr=True,
                 grid_temps=[0.0100, 50.0000, 100.0000, 150.0000,
                             200.0000, 250.0000, 300.0000, 350.0000],
                 grid_press=&#34;Psat&#34;,
                 P1=True,
                 plot_poly_fit=False,
                 logK_extrapolate=&#34;none&#34;,
                 fill_data0=True,
                 dynamic_db=False,
                 dynamic_db_sample_temps=[],
                 dynamic_db_sample_press=[],
                 verbose=1):
    &#34;&#34;&#34;
    Create a data0 file from a custom thermodynamic dataset.
    
    Parameters
    ----------
    db : str
        Desired three letter code of data0 output.
        
    filename_ss : str, optional
        Name of file containing solid solution parameters.

    grid_temps : list of eight float, default [0.0100, 50.0000, 100.0000, 150.0000, 200.0000, 250.0000, 300.0000, 350.0000]
        Eight temperature values that make up the T-P grid.
    
    grid_press : list of float, default &#34;Psat&#34;
        Eight pressure values that make up the T-P grid. &#34;Psat&#34; for
        calculations along the liquid-vapor saturation curve.
    
    P1 : bool, default True,
        Use pressure of 1 bar below 100 degrees C instead of calculated
        values of Psat? Ignored if `grid_press` is not &#34;Psat&#34;.
    
    plot_poly_fit : bool, default False
        Plot the polynomial fit of the temperature pressure grid?
    
    dynamic_db : bool, default False
        Are data0 files being created dynamically? If unsure, use False.
        Used by `speciate` to display valid messages.
    
    verbose : int, 0, 1, or 2, default 1
        Level determining how many messages are returned during a
        calculation. 2 for all messages, 1 for errors or warnings only,
        0 for silent.
    &#34;&#34;&#34;
    
    thermo_df = self.thermo.thermo_db
    db_logK = self.thermo.logK_db
    water_model = self.thermo.water_model
    
    self.verbose = verbose
    
    self.batch_T = grid_temps
    self.batch_P = grid_press
    
    if not dynamic_db:
        if self.verbose &gt;= 1:
            print(&#34;Creating data0.{}...&#34;.format(db), flush=True)
    
    if len(grid_temps) not in [1, 8]:
        self.err_handler.raise_exception(&#34;&#39;grid_temps&#39; must have either one or eight values.&#34;)
    if isinstance(grid_press, list):
        if len(grid_press) not in [1, 8]:
            self.err_handler.raise_exception(&#34;&#39;grid_press&#39; must have either one or eight values.&#34;)
    
    if sum([T &gt;= 10000 for T in grid_temps]):
        self.err_handler.raise_exception(&#34;Grid temperatures must be below 10k C.&#34;)
    
    if isinstance(grid_press, list):
        if sum([P &gt;= 10000 for P in grid_press]) and water_model != &#34;DEW&#34;:
            self.err_handler.raise_exception(&#34;Grid pressures must be below 10 kilobars.&#34;)
            
    if water_model == &#34;SUPCRT92&#34;:
        min_T = 0
        max_T = 2250
        min_P = 0
        max_P = 30000
    elif water_model == &#34;IAPWS95&#34;:
        min_T = 0
        max_T = 1000
        min_P = 0
        max_P = 10000
    elif water_model == &#34;DEW&#34;:
        min_T = 0
        max_T = 1000
        min_P = 1000
        max_P = 60000
    else:
        self.err_handler.raise_exception(&#34;The water model &#39;{}&#39; &#34;.format(water_model)+&#34;is not &#34;
            &#34;recognized. Try &#39;SUPCRT92&#39;, &#39;IAPWS95&#39;, or &#39;DEW&#39;.&#34;)
    
    # check that T and P are above minimum values
    if sum([T &lt;= min_T for T in grid_temps]):
        print(&#34;WARNING: one or more temperatures in &#39;grid_temps&#39; is below &#34;
              &#34;or equal to {} C&#34;.format(min_T)+&#34; and is outside the valid &#34;
              &#34;temperature range for the {} water model.&#34;.format(water_model))
    if isinstance(grid_press, list):
        if sum([P &lt; min_P for P in grid_press]):
            print(&#34;WARNING: one or more pressures in &#39;grid_press&#39; is below &#34;
                  &#34;{} bar&#34;.format(min_P)+&#34;, the minimum valid &#34;
                  &#34;pressure for the {} water model.&#34;.format(water_model))
    
    # check that T and P are below maximum values
    if sum([T &gt; max_T for T in grid_temps]):
        print(&#34;WARNING: one or more temperatures in &#39;grid_temps&#39; is above &#34;
              &#34;{} C&#34;.format(max_T)+&#34;, the maximum valid &#34;
              &#34;temperature for the {} water model.&#34;.format(water_model))
    if isinstance(grid_press, list):
        if sum([P &gt; max_P for P in grid_press]):
            print(&#34;WARNING: one or more pressures in &#39;grid_press&#39; is above &#34;
                  &#34;{} bar&#34;.format(max_P)+&#34;, the maximum valid &#34;
                  &#34;pressure for the {} water model.&#34;.format(water_model))
        
    if water_model != &#34;SUPCRT92&#34;:
        print(&#34;WARNING: water models other than SUPCRT92 are not yet fully supported.&#34;)
    
    # reset logK_models whenever create_data0() is called
    # (prevents errors when create_data0() functions are run back-to-back)
    self.logK_models = {}
    
    # interpolate logK values from &#34;free logK&#34; datasheet at T and P
    if isinstance(db_logK, pd.DataFrame):

        if len(dynamic_db_sample_temps) &gt; 0:
            grid_or_sample_temps = dynamic_db_sample_temps
        else:
            grid_or_sample_temps = grid_temps
            
        if len(dynamic_db_sample_press) &gt; 0:
            grid_or_sample_press = dynamic_db_sample_press
        else:
            grid_or_sample_press = grid_press
        
        free_logK_df = _clean_rpy2_pandas_conversion(self.thermo.logK_db)

        valid_i = self.__get_i_of_valid_free_logK_sp(
            free_logK_df,
            grid_or_sample_temps,
            grid_or_sample_press,
            dynamic_db,
            logK_extrapolate,
            db_sp_names=thermo_df[&#34;name&#34;],
            )
        free_logK_df_valid = copy.deepcopy(free_logK_df.iloc[valid_i])
        thermo_df = pd.concat([thermo_df, free_logK_df_valid], ignore_index=True)
        
        thermo_df = _clean_rpy2_pandas_conversion(thermo_df)
    
    if self.thermo.solid_solutions_active:
        solid_solution_df = ro.conversion.py2rpy(self.thermo.solid_solution_db)
    else:
        solid_solution_df = ro.r(&#34;NULL&#34;)
    
    template = pkg_resources.resource_string(
        __name__, &#39;data0.min&#39;).decode(&#34;utf-8&#34;)
    
    out_list = self.thermo.out_list

    self._capture_r_output()

    r_create_data0 = pkg_resources.resource_string(
        __name__, &#39;create_data0.r&#39;).decode(&#34;utf-8&#34;)
    
    ro.r(r_create_data0)
    
    # assemble data0 file
    data0_file_lines = ro.r.create_data0(thermo_df=ro.conversion.py2rpy(thermo_df),
                      solid_solution_df=solid_solution_df,
                      db=db,
                      water_model=water_model,
                      template=template,
                      dissrxns=out_list.rx2(&#34;dissrxns&#34;),
                      basis_pref=out_list.rx2(&#34;basis_pref&#34;),
                      exceed_Ttr=exceed_Ttr,
                      fixed_species=_convert_to_RVector(FIXED_SPECIES),
                      verbose=self.verbose)
    
    self._print_captured_r_output()
    
    data0_file_lines = data0_file_lines[0].split(&#34;\n&#34;)
    
    if fill_data0:
        
        # begin TP-dependent processes
        self.__fill_data0(thermo_df=ro.conversion.rpy2py(thermo_df),
                          data0_file_lines=copy.deepcopy(data0_file_lines),
                          grid_temps=grid_temps,
                          grid_press=grid_press,
                          db=db,
                          water_model=water_model,
                          activity_model=activity_model,
                          P1=P1,
                          plot_poly_fit=plot_poly_fit,
                          logK_extrapolate=logK_extrapolate,
                          dynamic_db=dynamic_db,
                          verbose=self.verbose)

    else:
        return thermo_df, data0_file_lines, grid_temps, grid_press, db, water_model, P1, plot_poly_fit

    if self.verbose &gt; 0:
        print(&#34;Finished creating data0.{}.&#34;.format(db))</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.AqEquil.make_redox_reactions"><code class="name flex">
<span>def <span class="ident">make_redox_reactions</span></span>(<span>self, db=None, redox_pairs='all', auto_load_db=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate an organized collection of redox reactions for calculating
chemical affinity and energy supply values during speciation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>db</code></strong> :&ensp;<code>str</code></dt>
<dd>Determines which thermodynamic database is used in the speciation
calculation. The database must be a CSV file (not a data0file)
because the code must look up properties of chemical species to
calculate affinities and energy supplies of reactions.
The <code>db</code> parameter can either be:
- The name of a CSV file containing thermodynamic data located in
the current working directory, e.g., "wrm_data.csv". The CSV file
will be used to generate a data0 file for each sample (using
additional arguments from <code>db_args</code> if desired).
- The URL of a CSV file containing thermodynamic data, e.g.,
"https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv"</dd>
<dt><strong><code>redox_pairs</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>"all"</code>, default <code>"all"</code></dt>
<dd>List of indices of half reactions in the half cell reaction table
to be combined when generating full redox reactions.
E.g. [0, 1, 4] will combine half reactions with indices 0, 1, and 4
in the table stored in the <code>half_cell_reactions</code> attribute of the
<code><a title="AqEquil.AqSpeciation.AqEquil" href="#AqEquil.AqSpeciation.AqEquil">AqEquil</a></code> class.
If "all", generate all possible redox reactions from available half
cell reactions.</dd>
<dt><strong><code>auto_load_db</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Automatically download and use a WORM-styled CSV if the currently
active thermodynamic database does not support affinity and energy
supply calculations? If True, the most up-to-date copy of the
wrm_data.csv will be downloaded from the URL
<a href="https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv">https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv</a>
and set as the active thermodynamic database.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Output is stored in the <code>affinity_energy_reactions_raw</code> and
<code>affinity_energy_reactions_table</code> attributes of the <code><a title="AqEquil.AqSpeciation.AqEquil" href="#AqEquil.AqSpeciation.AqEquil">AqEquil</a></code> class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def make_redox_reactions(self, db=None, redox_pairs=&#34;all&#34;, auto_load_db=True):
        
        &#34;&#34;&#34;
        Generate an organized collection of redox reactions for calculating
        chemical affinity and energy supply values during speciation.
        
        Parameters
        ----------
        db : str
            Determines which thermodynamic database is used in the speciation
            calculation. The database must be a CSV file (not a data0file)
            because the code must look up properties of chemical species to
            calculate affinities and energy supplies of reactions.
            The `db` parameter can either be:
            - The name of a CSV file containing thermodynamic data located in
            the current working directory, e.g., &#34;wrm_data.csv&#34;. The CSV file
            will be used to generate a data0 file for each sample (using
            additional arguments from `db_args` if desired).
            - The URL of a CSV file containing thermodynamic data, e.g.,
            &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
        
        redox_pairs : list of int or &#34;all&#34;, default &#34;all&#34;
            List of indices of half reactions in the half cell reaction table
            to be combined when generating full redox reactions.
            E.g. [0, 1, 4] will combine half reactions with indices 0, 1, and 4
            in the table stored in the `half_cell_reactions` attribute of the
            `AqEquil` class.
            If &#34;all&#34;, generate all possible redox reactions from available half
            cell reactions.
        
        auto_load_db : bool, default True
            Automatically download and use a WORM-styled CSV if the currently
            active thermodynamic database does not support affinity and energy
            supply calculations? If True, the most up-to-date copy of the
            wrm_data.csv will be downloaded from the URL
            https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv
            and set as the active thermodynamic database.
        
        Returns
        ----------
        Output is stored in the `affinity_energy_reactions_raw` and
        `affinity_energy_reactions_table` attributes of the `AqEquil` class.
        &#34;&#34;&#34;
        
        if db != None:
            self.thermo._set_active_db(db)
            
        if self.thermo.thermo_db_type != &#34;CSV&#34;:
            if self.verbose &gt; 0:
                if auto_load_db:
                    print(&#34;Warning: Redox reactions require a WORM-styled thermodynamic database CSV file.&#34;)
                else:
                    self.err_handler.raise_exception(&#34;Error: Redox reactions require a WORM-styled CSV file as the active thermodynamic database.&#34;)
            
            if auto_load_db:
                if self.verbose &gt; 0:
                    print(&#34;Warning: switching thermodynamic database from&#34;, str(self.thermo.thermo_db_filename), &#34;to wrm_data.csv...&#34;)
                self.thermo._set_active_db(db=&#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;)
            
        db = self.thermo.db
        
        # reset all redox variables stored in the AqEquil class
        self.affinity_energy_reactions_raw = None
        self.affinity_energy_reactions_table = None
        self.affinity_energy_formatted_reactions = None
        
        if self.verbose &gt; 1:
            print(&#34;Generating redox reactions...&#34;)

        err_msg = (&#34;redox_pairs can either be &#39;all&#39; or a list of integers &#34;
               &#34;indicating the indices of half cell reactions in &#34;
               &#34;the half_cell_reactions table that should be combined into &#34;
               &#34;full redox reactions. For example, redox_pairs=[0, 1, 2, 6] &#34;
               &#34;will combine half cell reactions with indices 0, 1, 2, and 6 in &#34;
               &#34;the half_cell_reactions table. This table is an attribute in the &#34;
               &#34;class AqEquil.&#34;)
        if isinstance(redox_pairs, str):
            if redox_pairs == &#34;all&#34;:
                redox_pairs = list(range(0, self.half_cell_reactions.shape[0]))
            else:
                self.err_handler.raise_exception(err_msg)
        elif isinstance(redox_pairs, list):
            if not all([isinstance(i, int) for i in redox_pairs]):
                self.err_handler.raise_exception(err_msg)
        else:
            self.err_handler.raise_exception(err_msg)
        
        self.redox_pairs = redox_pairs
        
        df = self.half_cell_reactions.iloc[redox_pairs].reset_index(drop=True)
        
        wrm_data = self.thermo.thermo_db
        basis_df = wrm_data.loc[wrm_data[&#39;tag&#39;] == &#39;basis&#39;]
        
        db_names = []
        formulas = []
        for column in list(df.columns)[1:]:
            for item in list(df[column]):
                if item != &#39;nan&#39;:
                    if item in list(wrm_data.name) and isinstance(item, str):
                        index = wrm_data.loc[wrm_data[&#39;name&#39;] == item].index[0]
                        formula = wrm_data.loc[wrm_data[&#39;name&#39;] == item][&#39;formula&#39;][index]
                        df.replace(item, formula, inplace=True)
                        if item not in db_names:
                            db_names.append(item)
                            formulas.append(formula)
                    elif item in list(wrm_data.abbrv) and isinstance(item, str):
                        index = wrm_data.loc[wrm_data[&#39;abbrv&#39;] == item].index[0]
                        formula = wrm_data.loc[wrm_data[&#39;abbrv&#39;] == item][&#39;formula&#39;][index]
                        df.replace(item, formula, inplace=True)
                        if item not in db_names:
                            db_names.append(item)
                            formulas.append(formula)
                            
        df.replace(&#39;sulfur&#39;, &#39;S&#39;, inplace = True) ### remove this eventually
        db_names.append(&#39;sulfur&#39;) ### remove this eventually
        formulas.append(&#39;S&#39;) ### remove this eventually

        # append H+ and H2O to db for balancing
        if not &#39;H+&#39; in db_names:
            db_names.append(&#39;H+&#39;)
            formulas.append(&#39;H+&#39;)
        if not &#39;H2O&#39; in db_names:
            db_names.append(&#39;H2O&#39;)
            formulas.append(&#39;H2O&#39;)
        
        Oxidant_1 = df[&#39;Oxidant_1&#39;]
        Oxidant_2 = df[&#39;Oxidant_2&#39;]
        Oxidant_3 = df[&#39;Oxidant_3&#39;]
        Reductant_1 = df[&#39;Reductant_1&#39;]
        Reductant_2 = df[&#39;Reductant_2&#39;]
        
        #CREATING A LIST OF ALL SPECIES AND THEIR ELEMENT DICTIONARIES
        elements = [str(e) for e in list(periodictable.elements)[1:]]+[&#39;+&#39;,&#39;-&#39;]
        element_dictionary = dict()
        for i in formulas:
                parsed_formula = parse_formula(i)
                element_dictionary[i] = parsed_formula
                for e in elements:
                    if element_dictionary[i].get(e, 0) == 0:
                        element_dictionary[i][e] = 0
                        
        df_reax = pd.DataFrame() # empty df of reactions
        df_reax[&#39;rO_coeff&#39;] = &#39;&#39;
        df_reax[&#39;rO&#39;] = &#39;&#39;
        df_reax[&#39;rR_coeff&#39;] = &#39;&#39;
        df_reax[&#39;rR&#39;] = &#39;&#39;
        df_reax[&#39;pO_coeff&#39;] = &#39;&#39;
        df_reax[&#39;pO&#39;] = &#39;&#39;
        df_reax[&#39;pR_coeff&#39;] = &#39;&#39;
        df_reax[&#39;pR&#39;] = &#39;&#39;
        df_reax[&#39;Reaction&#39;] = &#39;&#39;
        df_reax[&#39;redox_pair&#39;] = &#39;&#39;
        index = 0

        reaction = [] 
        indices = np.arange(0, len(Oxidant_1), 1).tolist()*2 # how to loop back through the redox pairs to not run into out-of-range index
        rxn_num = 0 # counting unique reactions
        rxn_list = [] # list of unique reactions
        rxn_names = []
        rxn_pairs = [] # list of paired half reactions

        for i in range(0, len(Oxidant_1),1): # length of redox pairs - columns
            for n in range(0, len(Oxidant_1), 1):
                if Reductant_1[i] == Reductant_1[indices[i+n]] or Reductant_1[i] == Reductant_2[indices[i+n]]: # if both reductants are the same thing, skip
                    continue
                if Oxidant_1[i] == Oxidant_1[indices[i+n]] or Oxidant_1[i] == Oxidant_2[indices[i+n]] or Oxidant_1[i] == Oxidant_3[indices[i+n]]:
                    continue
#                 if Oxidant_1[i] == &#39;H2O&#39; and Reductant_1[indices[i+n]] == &#39;H2O&#39;: #suppress the splitting of water
#                     continue
                else:

                    # GENERATING REACTIONS BETWEEN OXIDANT_1 AND REDUCTANT_1
                    reaction.append(Oxidant_1[i]+&#39; \t &#39; + Reductant_1[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_num+=1
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_1[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_1[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index+=1

                # REACTIONS INVOLVING OTHER PH-DEPENDENT SPECIES
                if pd.isnull(Oxidant_2[i]) != True and Oxidant_2[i] != Reductant_2[indices[i+n]]:
                    reaction.append(Oxidant_2[i] + &#39; \t &#39; + Reductant_1[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_2[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_1[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                    if pd.isnull(Reductant_2[indices[i+n]]) != True:
                        reaction.append(Oxidant_2[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                        rxn_list.append(rxn_num)
                        rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                        df_reax.loc[index, &#39;rO&#39;] = Oxidant_2[i]
                        df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                        df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                        df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                        rxn_pairs.append([i, indices[i+n]])
                        index +=1
                        
                if pd.isnull(Oxidant_2[i]) != True and Oxidant_2[i] == Reductant_2[indices[i+n]]:
                    reaction.append(Oxidant_2[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_2[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                if pd.isnull(Reductant_2[indices[i+n]]) != True and Oxidant_2[i] != Reductant_2[indices[i+n]]:
                    reaction.append(Oxidant_1[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_1[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                if pd.isnull(Oxidant_3[i]) != True:
                    reaction.append(Oxidant_3[i] + &#39; \t &#39; + Reductant_1[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                    rxn_list.append(rxn_num)
                    rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                    df_reax.loc[index, &#39;rO&#39;] = Oxidant_3[i]
                    df_reax.loc[index, &#39;rR&#39;] = Reductant_1[indices[i+n]]
                    df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                    df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                    rxn_pairs.append([i, indices[i+n]])
                    index +=1

                    if pd.isnull(Reductant_2[indices[i+n]]) != True:
                        reaction.append(Oxidant_3[i] + &#39; \t &#39; + Reductant_2[indices[i+n]] + &#39;=&#39; + Reductant_1[i] + &#39; \t &#39; + Oxidant_1[indices[i+n]])
                        rxn_list.append(rxn_num)
                        rxn_names.append(&#39;red_&#39;+Oxidant_1[i]+&#39;_&#39;+Reductant_1[i]+&#39;_ox_&#39;+Reductant_1[indices[i+n]]+&#39;_&#39;+Oxidant_1[indices[i+n]])
                        df_reax.loc[index, &#39;rO&#39;] = Oxidant_3[i]
                        df_reax.loc[index, &#39;rR&#39;] = Reductant_2[indices[i+n]]
                        df_reax.loc[index, &#39;pR&#39;] = Reductant_1[i]
                        df_reax.loc[index, &#39;pO&#39;] = Oxidant_1[indices[i+n]]
                        rxn_pairs.append([i, indices[i+n]])
                        index +=1
        
        df_reax[&#39;Reaction&#39;] = rxn_list
        df_reax[&#39;Names&#39;] = rxn_names
        df_reax[&#39;Temp_Pairs&#39;] = rxn_pairs
        
        # if there are no reactions, return nothing
        if df_reax.shape[0] == 0:
            incompatible_half_reactions = pd.Series(self.half_cell_reactions[&#34;Redox Couple&#34;], index=redox_pairs).tolist()
            redundant_reductant_or_oxidant = []
            for col in [&#34;Oxidant_1&#34;, &#34;Oxidant_2&#34;, &#34;Oxidant_3&#34;, &#34;Reductant_1&#34;, &#34;Reductant_2&#34;]:
                redox_col = pd.Series(self.half_cell_reactions[col], index=[0,1])
                if redox_col.eq(redox_col[0]).all():
                    redundant_reductant_or_oxidant.append(redox_col[0])
            err_no_rxns = (&#34;Valid reactions could not be written between the half &#34;
                &#34;reactions {} &#34;.format(incompatible_half_reactions)+&#34;because &#34;
                &#34;{}&#34;.format(redundant_reductant_or_oxidant)+&#34; is on both sides &#34;
                &#34;of all reactions.&#34;)
            print(err_no_rxns)
            return
        
        ### BALANCING NON-O, H ELEMENTS
        for r in range(0, len(df_reax[&#39;rO&#39;])):
            count = 0 #to restart the loop through the elements
            temp_rO_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -
            temp_rR_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -
            temp_pO_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -
            temp_pR_coeff = [1] *(len(elements)-4) #loop through all elements except O, H, +, and -

            
            for e in elements:
                if e in [&#39;O&#39;,&#39;H&#39;,&#39;+&#39;,&#39;-&#39;]:
                    continue
                else:
            
                    temp1 = int(element_dictionary[df_reax[&#39;rO&#39;][r]][e]) #count for the element in the list for rO at index r
                    temp2 = int(element_dictionary[df_reax[&#39;pR&#39;][r]][e])
                    temp3 = int(element_dictionary[df_reax[&#39;rR&#39;][r]][e])
                    temp4 = int(element_dictionary[df_reax[&#39;pO&#39;][r]][e])
                    if temp1 == temp2:
                        temp_rO_coeff[count] = 1
                        temp_pR_coeff[count] = 1
                    if temp1 != temp2:
                        if temp1 ==0:
                            temp_rO_coeff[count] = 1
                        if temp1 != 0:
                            temp_rO_coeff[count] = np.lcm(temp1,temp2)/temp1
                        if temp2 == 0:
                            temp_pR_coeff[count] = 1
                        if temp2 != 0:
                            temp_pR_coeff[count] = np.lcm(temp1,temp2)/temp2
                    if temp3 == temp4:
                        temp_rR_coeff[count] = 1
                        temp_pO_coeff[count] = 1
                    if temp4 != temp3:
                        if temp3 == 0:
                            temp_rR_coeff[count] = 1
                        if temp3 != 0:
                            temp_rR_coeff[count] = np.lcm(temp3,temp4)/temp3
                        if temp4 == 0.0:
                            temp_pO_coeff[count] = 1
                        if temp4 !=0.0:
                            temp_pO_coeff[count] = np.lcm(temp3,temp4)/temp4
                    count +=1
            df_reax.loc[r, &#39;rO_coeff&#39;] = -max(temp_rO_coeff)
            df_reax.loc[r, &#39;rR_coeff&#39;] = -max(temp_rR_coeff)
            df_reax.loc[r, &#39;pR_coeff&#39;] = max(temp_pR_coeff)
            df_reax.loc[r, &#39;pO_coeff&#39;] = max(temp_pO_coeff)
        
        all_reax = df_reax.copy(deep=True)
        all_reax[&#39;rO_2_coeff&#39;] = &#39;&#39;
        all_reax[&#39;rO_2&#39;] = &#39;&#39;
        all_reax[&#39;rO_3_coeff&#39;] = &#39;&#39;
        all_reax[&#39;rO_3&#39;] = &#39;&#39;
        all_reax[&#39;rR_2_coeff&#39;] = &#39;&#39;
        all_reax[&#39;rR_2&#39;] = &#39;&#39;
        
        ### MAIN REACTION
        for r in range(1, max(all_reax[&#39;Reaction&#39;]+1)): # each reaction number once, 1 to 305
            if len(all_reax[all_reax[&#39;Reaction&#39;]==r].index.values) == 1: # if nothing to combine, skip
                continue
            else:
                temp = all_reax[all_reax[&#39;Reaction&#39;]==r].index.values[0] #index of first instance of this reaction which has multiple subreactions
                lst2 = []
                all_reax.loc[temp-0.5] = all_reax.loc[temp] # replicating the row to build on
                all_reax = all_reax.sort_index() # putting the replicated row above the first instance
                for i in all_reax[all_reax[&#39;Reaction&#39;]==r].index.values[2:]: #all but the first instance in the reactions (since that&#39;s copied already)
                    if all_reax.loc[i, &#39;rO&#39;] != all_reax.loc[temp, &#39;rO&#39;] and all_reax.loc[i, &#39;rO&#39;] not in lst2: # if rO is new (and not the same as the first)
                        lst2.append(all_reax.loc[i, &#39;rO&#39;]) # list unique rO besides the first
                        for l in range(0, len(lst2)): # looping through unique rO
                            temp2 = &#39;rO_&#39;+str(2+int(l)) # adding 0 or 1 to the rO number
                            all_reax.loc[temp-0.5,str(temp2)] = lst2[l] # add the unique rO to rO_2 or 3
                    if all_reax.loc[i, &#39;rR&#39;] != all_reax.loc[temp, &#39;rR&#39;]: # if rR is new
                            all_reax.loc[temp-0.5,&#39;rR_2&#39;] = all_reax.loc[i, &#39;rR&#39;] # add it to rR_2

                ##CHANGING COEFFICIENTS
                rO = all_reax.loc[temp-0.5,&#39;rO&#39;] #assigning easy variables
                rO_2 = all_reax.loc[temp-0.5,&#39;rO_2&#39;]
                rO_3 = all_reax.loc[temp-0.5,&#39;rO_3&#39;]
                rR = all_reax.loc[temp-0.5,&#39;rR&#39;]
                rR_2 = all_reax.loc[temp-0.5,&#39;rR_2&#39;]
                rO_coeff = all_reax.loc[temp-0.5,&#39;rO_coeff&#39;] #these are empty at the moment
                rO_2_coeff = all_reax.loc[temp-0.5,&#39;rO_2_coeff&#39;]
                rO_3_coeff = all_reax.loc[temp-0.5,&#39;rO_3_coeff&#39;]
                rR_2_coeff = all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;]
                rR_coeff = all_reax.loc[temp-0.5,&#39;rR_coeff&#39;]
                if rO_3 != &#39;&#39; and rO_2 != &#39;&#39;: #if DIC is the oxidant
                    all_reax.loc[temp-0.5,&#39;rO_coeff&#39;] = rO_coeff/3 #this works fine
                    all_reax.loc[temp-0.5,&#39;rO_2_coeff&#39;] = rO_coeff/3
                    all_reax.loc[temp-0.5,&#39;rO_3_coeff&#39;] = rO_coeff/3

                    if rR_2 != &#39;&#39;:
                        all_reax.loc[temp-0.5,&#39;rR_coeff&#39;] = rR_coeff/2 #this works fine
                        all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;] = rR_coeff/2

                        all_reax.loc[temp-0.4] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR - this works fine : line 4
                        all_reax.loc[temp-0.4, &#39;rR_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.4, &#39;rR_coeff&#39;] = rR_coeff

                        all_reax.loc[temp-0.3] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR_2 - this works fine: line 5
                        all_reax.loc[temp-0.3, &#39;rR_2_coeff&#39;] = rR_coeff
                        all_reax.loc[temp-0.3, &#39;rR_coeff&#39;] = 0

                        #NEW ROWS WITH TWO DIC AND BOTH rR
                        all_reax.loc[temp-0.25] = all_reax.loc[temp-0.5] #eliminate CO2
                        all_reax.loc[temp-0.25, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.25, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.25, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.24] = all_reax.loc[temp-0.5] #eliminate HCO3-
                        all_reax.loc[temp-0.24, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.24, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.24, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.23] = all_reax.loc[temp-0.5] #eliminate CO3-2
                        all_reax.loc[temp-0.23, &#39;rO_3_coeff&#39;] = 0                
                        all_reax.loc[temp-0.23, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.23, &#39;rO_coeff&#39;] = rO_coeff/2

                        all_reax.loc[temp-0.2] = all_reax.loc[temp-0.4] #NEW ROW WITH ONLY rR ELIMINATING CO2: line 6
                        all_reax.loc[temp-0.2, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.2, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.2, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1] = all_reax.loc[temp-0.4] #NEW ROW WITH ONLY rR ELIMINATING HCO3-: line 7
                        all_reax.loc[temp-0.1, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.1, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05] = all_reax.loc[temp-0.4] #NEW ROW WITH ONLY rR ELIMINATING CO3-2: line 8
                        all_reax.loc[temp-0.05, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.04] = all_reax.loc[temp-0.3] #NEW ROW WITH ONLY rR_2 ELIMINATING CO2: line 9
                        all_reax.loc[temp-0.04, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.04, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.04, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.03] = all_reax.loc[temp-0.3] #NEW ROW WITH ONLY rR_2 ELIMINATING HCO3-: line 10
                        all_reax.loc[temp-0.03, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.03, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.03, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.02] = all_reax.loc[temp-0.3] #NEW ROW WITH ONLY rR_2 ELIMINATING CO3-2: line 11
                        all_reax.loc[temp-0.02, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.02, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.02, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.01] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY CO2 and both RR
                        all_reax.loc[temp-0.01, &#39;rO_coeff&#39;] = rO_coeff
                        all_reax.loc[temp-0.01, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.01, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.009] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY HCO3- and both RR
                        all_reax.loc[temp-0.009, &#39;rO_coeff&#39;] = 0 ###
                        all_reax.loc[temp-0.009, &#39;rO_2_coeff&#39;] = rO_coeff
                        all_reax.loc[temp-0.009, &#39;rO_3_coeff&#39;] = 0

                        all_reax.loc[temp-0.008] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY CO2 and both RR
                        all_reax.loc[temp-0.008, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.008, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.008, &#39;rO_3_coeff&#39;] = rO_coeff

                    if rR_2 == &#39;&#39;:
                        all_reax.loc[temp-0.2] = all_reax.loc[temp-0.5] #NEW ROW ELIMINATING CO2
                        all_reax.loc[temp-0.2, &#39;rO_coeff&#39;] = 0
                        all_reax.loc[temp-0.2, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.2, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1] = all_reax.loc[temp-0.5] #NEW ROW ELIMINATING HCO3-
                        all_reax.loc[temp-0.1, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.1, &#39;rO_2_coeff&#39;] = 0
                        all_reax.loc[temp-0.1, &#39;rO_3_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05] = all_reax.loc[temp-0.5] #NEW ROW ELIMINATING CO3-2
                        all_reax.loc[temp-0.05, &#39;rO_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_2_coeff&#39;] = rO_coeff/2
                        all_reax.loc[temp-0.05, &#39;rO_3_coeff&#39;] = 0

                if rO_2 != &#39;&#39; and rO_3 == &#39;&#39;: # IF THERE ARE TWO OXIDANT OPTIONS
                    all_reax.loc[temp-0.5,&#39;rO_coeff&#39;] = rO_coeff/2
                    all_reax.loc[temp-0.5,&#39;rO_2_coeff&#39;] = rO_coeff/2

                    if rR_2 != &#39;&#39;: #IF THERE ARE TWO REDUCTANT OPTIONS
                        all_reax.loc[temp-0.5,&#39;rR_coeff&#39;] = rR_coeff/2
                        all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;] = rR_coeff/2
                        
                        if rR_2 == rO_2:
                            continue
                        else:

                            all_reax.loc[temp-0.4] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR
                            all_reax.loc[temp-0.4, &#39;rR_2_coeff&#39;] = 0
                            all_reax.loc[temp-0.4, &#39;rR_coeff&#39;] = rR_coeff

                            all_reax.loc[temp-0.3] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rR_2
                            all_reax.loc[temp-0.3, &#39;rR_2_coeff&#39;] = rR_coeff
                            all_reax.loc[temp-0.3, &#39;rR_coeff&#39;] = 0

                            all_reax.loc[temp-0.2] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rO_2
                            all_reax.loc[temp-0.2, &#39;rO_2_coeff&#39;] = rO_coeff
                            all_reax.loc[temp-0.2, &#39;rO_coeff&#39;] = 0

                            all_reax.loc[temp-0.1] = all_reax.loc[temp-0.5] #NEW ROW WITH ONLY rO
                            all_reax.loc[temp-0.1, &#39;rO_2_coeff&#39;] = 0
                            all_reax.loc[temp-0.1, &#39;rO_coeff&#39;] = rO_coeff

                if rO_2 == &#39;&#39; and rO_3 == &#39;&#39; and rR_2 != &#39;&#39;: # IF THERE IS ONLY ONE OXIDANT BUT TWO REDUCTANTS
                    all_reax.loc[temp-0.5,&#39;rR_coeff&#39;] = rR_coeff/2
                    all_reax.loc[temp-0.5,&#39;rR_2_coeff&#39;] = rR_coeff/2

        all_reax = all_reax.sort_index().reset_index(drop=True)
        
        pair_list = []
        for i in range(0, len(all_reax[&#39;Temp_Pairs&#39;])):
            pair_list.append([redox_pairs[all_reax.loc[i, &#39;Temp_Pairs&#39;][0]], redox_pairs[all_reax.loc[i, &#39;Temp_Pairs&#39;][1]]])
        all_reax[&#39;pairs&#39;] = pair_list

        new_elements = []
        for r in range(0, len(all_reax[&#39;rO&#39;])):
            for e in elements:
                if e in [&#39;O&#39;,&#39;H&#39;,&#39;+&#39;,&#39;-&#39;]:
                    continue
                else:
                    temp1 = int(element_dictionary[all_reax[&#39;rO&#39;][r]][e]) #count for the element in the list for rO at index r
                    temp2 = int(element_dictionary[all_reax[&#39;pR&#39;][r]][e])
                    temp3 = int(element_dictionary[all_reax[&#39;rR&#39;][r]][e])
                    temp4 = int(element_dictionary[all_reax[&#39;pO&#39;][r]][e])
                    if temp1 != temp2:
                        if temp1 ==0:
                            all_reax.loc[r, &#39;red_&#39;+e+&#39;_coeff&#39;] = -temp2
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;red_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)
                        if temp2 == 0:
                            all_reax.loc[r, &#39;red_&#39;+e+&#39;_coeff&#39;] = temp1
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;red_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)
                    if temp4 != temp3:
                        if temp3 == 0:
                            all_reax.loc[r, &#39;ox_&#39;+e+&#39;_coeff&#39;] = -temp4
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;ox_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)
                        if temp4 == 0.0:
                            all_reax.loc[r, &#39;ox_&#39;+e+&#39;_coeff&#39;] = temp3
                            elmnt = basis_df.loc[basis_df[&#39;name&#39;].str.contains(e)][&#39;formula&#39;].tolist()[0]
                            all_reax.loc[r, &#39;ox_&#39;+e] = elmnt
                            if elmnt not in new_elements:
                                new_elements.append(elmnt)


        for i in new_elements:
            if i not in db_names:
                db_names.append(i)
            if i not in formulas:
                formulas.append(i)
            parsed_formula = parse_formula(i)
            element_dictionary[i] = parsed_formula
            for e in elements:
                if element_dictionary[i].get(e, 0) == 0:
                    element_dictionary[i][e] = 0

        reax = all_reax.copy(deep=True)
        reax.drop(&#39;Temp_Pairs&#39;, axis=1, inplace=True)
        reax.drop(&#39;pairs&#39;, axis=1, inplace=True)
        reax.reset_index(drop=True, inplace=True)
        for s in [&#39;O&#39;, &#39;H&#39;,&#39;-&#39;,&#39;+&#39;]:
            for i in range(0,len(reax[&#39;rO&#39;])):
                red = 0
                ox=0
                for j in reax.columns.tolist():
                    if &#39;_coeff&#39; in j:
                        if &#39;rO_&#39; in j or &#39;pR_&#39; in j or &#39;red_&#39; in j:
                            if str(reax[j][i]) != &#39;nan&#39; and str(reax[j][i]) != &#39;&#39;:
                                red_temp_coeff = reax[j][i]
                                red_temp = element_dictionary[reax[j.split(&#39;_coeff&#39;)[0]][i]][s]
                                red -= red_temp_coeff*red_temp

                        if &#39;rR_&#39; in j or &#39;pO_&#39; in j or &#39;ox_&#39; in j:
                            if str(reax[j][i]) != &#39;nan&#39; and str(reax[j][i]) != &#39;&#39;:
                                ox_temp_coeff = reax[j][i]
                                ox_temp = element_dictionary[reax[j.split(&#39;_coeff&#39;)[0]][i]][s]
                                ox -= ox_temp_coeff*ox_temp      

                reax.loc[i, &#39;r_&#39;+s] = red
                reax.loc[i, &#39;o_&#39;+s] = ox

        reax[&#39;r_H&#39;] = reax[&#39;r_H&#39;] - 2*reax[&#39;r_O&#39;]
        reax[&#39;o_H&#39;] = reax[&#39;o_H&#39;] - 2*reax[&#39;o_O&#39;]
        reax[&#39;r_+&#39;] = reax[&#39;r_+&#39;] - reax[&#39;r_H&#39;]
        reax[&#39;o_+&#39;] = reax[&#39;o_+&#39;] - reax[&#39;o_H&#39;]
        reax[&#39;r_e-&#39;] = reax[&#39;r_+&#39;] - reax[&#39;r_-&#39;] 
        reax[&#39;o_e-&#39;] = reax[&#39;o_+&#39;] - reax[&#39;o_-&#39;] 
        reax.rename({&#39;r_O&#39;: &#39;r_H2O&#39;, &#39;r_H&#39;: &#39;r_H+&#39;, &#39;o_O&#39;: &#39;o_H2O&#39;, &#39;o_H&#39;: &#39;o_H+&#39;}, axis=1, inplace = True)
        
        ### MULTIPLYING SUB-REACTIONS
        lcm_charge = []
        electrons = []
        for i in range(0, len(reax[&#39;rO&#39;])):
        # for i in range(0, 1):
            lcm_charge = np.lcm(round(reax[&#39;r_e-&#39;][i]), round(reax[&#39;o_e-&#39;][i]))
            electrons.append(str(lcm_charge)+&#39;e&#39;)
            r_multiplier = abs(lcm_charge/int(reax[&#39;r_e-&#39;][i]))
            o_multiplier = abs(lcm_charge/int(reax[&#39;o_e-&#39;][i]))
            for s in list(reax.columns):
                if (&#39;red_&#39; in s and &#39;coeff&#39; in s) or (&#39;rO_&#39; in s and &#39;coeff&#39; in s) or (&#39;pR_&#39; in s and &#39;coeff&#39; in s) or &#39;r_H2O&#39; in s or &#39;r_H+&#39; in s:
                    reax.loc[i, s] = reax.loc[i, s]*int(r_multiplier )
                if (&#39;ox_&#39; in s and &#39;coeff&#39; in s) or (&#39;rR_&#39; in s and &#39;coeff&#39; in s) or (&#39;pO_&#39; in s and &#39;coeff&#39; in s) or &#39;o_H2O&#39; in s or &#39;o_H+&#39; in s:
                    reax.loc[i, s] = reax.loc[i, s]*int(o_multiplier)
        reax[&#39;H+&#39;] = reax[&#39;r_H+&#39;] + reax[&#39;o_H+&#39;]
        reax[&#39;protons&#39;] = &#39;H+&#39;
        reax[&#39;H2O&#39;] = reax[&#39;r_H2O&#39;] + reax[&#39;o_H2O&#39;]
        reax[&#39;water&#39;] = &#39;H2O&#39;
        reax.drop(columns = [&#39;r_H2O&#39;, &#39;r_H+&#39;, &#39;r_-&#39;, &#39;r_+&#39;, &#39;r_e-&#39;, &#39;o_H2O&#39;, &#39;o_H+&#39;, &#39;o_-&#39;, &#39;o_+&#39;, &#39;o_e-&#39;],axis = 1, inplace = True)

        count = 0
        for i in db_names:
            db_names[count] = &#39;start&#39;+i+&#39;end&#39;
            count += 1

        real_reax = reax.replace(formulas,db_names)
        real_reax[&#39;rO_coeff&#39;] = real_reax[&#39;rO_coeff&#39;].astype(&#39;float&#39;) 
        real_reax[&#39;rR_coeff&#39;] = real_reax[&#39;rR_coeff&#39;].astype(&#39;float&#39;) 
        real_reax[&#39;pO_coeff&#39;] = real_reax[&#39;pO_coeff&#39;].astype(&#39;float&#39;) 
        real_reax[&#39;pR_coeff&#39;] = real_reax[&#39;pR_coeff&#39;].astype(&#39;float&#39;) 
        
        count = 0
        rxn_count = []
        rxn_number = []

        for i in real_reax[&#39;Reaction&#39;]:
            if i not in rxn_count:
                rxn_count.append(i)
                rxn_number.append(real_reax[&#39;Names&#39;][count]+ &#39;_&#39;+str(count))
            else:
                rxn_number.append(real_reax[&#39;Names&#39;][count]+ &#39;_&#39;+str(count)+&#39;_sub&#39;)
            count += 1
        real_reax.insert(0, &#39;Reaction Number&#39;, rxn_number)
        real_reax.insert(1, &#39;electrons&#39;, electrons)

        lst3 = [] #list of reaction numbers
        lst4 = [] #list of reactions with issues
        for i in range(0, len(real_reax[&#39;Reaction&#39;])):
            if real_reax[&#39;Reaction&#39;][i] not in lst3:
                lst3.append(real_reax[&#39;Reaction&#39;][i])
        for j in lst3: #looping through reaction numbers
            first_e = real_reax.loc[real_reax[&#39;Reaction&#39;] == j][&#39;electrons&#39;].reset_index(drop=True)[0]
            for k in real_reax.loc[real_reax[&#39;Reaction&#39;] == j][&#39;electrons&#39;].reset_index(drop=True):
                if k != first_e:
                    if j not in lst4:
                        lst4.append(j)
        for l in lst4:
            print(real_reax.loc[real_reax[&#39;Reaction&#39;] ==  l])

        real_reax.drop(labels=&#39;Reaction&#39;, axis=1, inplace = True)
        real_reax.drop(columns = &#39;Names&#39;, inplace = True)
        pairs = real_reax[&#39;redox_pair&#39;]
        real_reax.drop(columns = &#39;redox_pair&#39;, inplace = True)
        
        # 2-16-2022 CHANGES START HERE
        for i in range(0, len(real_reax[&#39;Reaction Number&#39;])):
            for j in range(2, len(real_reax.columns)):
                if str(real_reax.iloc[i, j]) == &#39;nan&#39;:
                    real_reax.iloc[i, j] = &#39;&#39;
        
        test_df = real_reax.copy(deep=True)
        count = 0
        for i in range(0, len(test_df[&#39;Reaction Number&#39;])):
            coefficients = []
            species = []
            for j in range(2, len(test_df.columns)):
                if count % 2 == 0: 
                    if test_df.iloc[i, j] != &#39;&#39;:
                        test_df.iloc[i, j] = round(test_df.iloc[i, j], 14)
                    if test_df.iloc[i, j] == 0 or test_df.iloc[i, j] == 0.0:
                        test_df.iloc[i, j] = &#39;&#39;
                        test_df.iloc[i, j+1] = &#39;&#39;
                    coefficient = test_df.iloc[i, j]
                    coefficients.append(test_df.iloc[i, j])
                if count % 2 != 0:
                    if test_df.iloc[i, j] != &#39;&#39;:
                        test_df.iloc[i, j] = str(test_df.iloc[i, j]).split(&#39;start&#39;)[1].split(&#39;end&#39;)[0]
                    compound = test_df.iloc[i, j]
                    if compound in species:
                        og_location = species.index(compound) 
                        df_location = 3+og_location*2 
                        df_location_coeff = df_location - 1
                        old_coeff = coefficients[og_location] 
                        new_coeff = coefficient + old_coeff 
                        test_df.iloc[i, j] = &#39;&#39;
                        test_df.iloc[i, j-1] = &#39;&#39;
                        df_value = test_df.iloc[i, df_location] #values from first occurence remaining
                        test_df.iloc[i, df_location_coeff] = new_coeff
                    species.append(compound)
                count+=1
        for m in range(0, 7):
            for i in range(0, len(test_df[&#39;Reaction Number&#39;])):
                line = []
                for j in range(2, len(test_df.columns)):
                    line.append(test_df.iloc[i, j])
                    if test_df.iloc[i, j] != &#39;&#39; and test_df.iloc[i, j-2] ==&#39;&#39;:
                        test_df.iloc[i, j-2] = test_df.iloc[i, j]
                        test_df.iloc[i, j] = &#39;&#39;

        file = test_df.to_csv(sep=&#39;\t&#39;, header=False, index=False, lineterminator=&#39;\n&#39;)

        file = file.split(&#34;\n&#34;) #not sure if I should keep this
        
        newlines = []
        for line in file:   
            line = line.strip()
            newlines.append(line)

        self.affinity_energy_reactions_raw = &#34;\n&#34;.join(newlines)
        df_rxn = pd.DataFrame([x.split(&#39;\t&#39;) for x in self.affinity_energy_reactions_raw.split(&#39;\n&#39;)])
        df_rxn.columns = df_rxn.columns.map(str)
        df_rxn = df_rxn.rename(columns={&#34;0&#34;: &#34;reaction_name&#34;, &#34;1&#34;: &#34;mol_e-_transferred_per_mol_rxn&#34;})
        df_rxn.insert(1, &#39;redox_pairs&#39;, all_reax[&#39;pairs&#39;])
        df_rxn = df_rxn.set_index(&#34;reaction_name&#34;)
        df_rxn = df_rxn[df_rxn[&#39;mol_e-_transferred_per_mol_rxn&#39;].notna()]
        self.affinity_energy_reactions_table = df_rxn
        
        prev_was_coeff = False
        n = 1
        for col in self.affinity_energy_reactions_table.iloc[:, 2:].columns:
            if not prev_was_coeff:
                new_col_name = &#34;coeff_&#34;+str(n)
                prev_was_coeff = True
            else:
                new_col_name = &#34;species_&#34;+str(n)
                prev_was_coeff = False
                n += 1
            self.affinity_energy_reactions_table = self.affinity_energy_reactions_table.rename(columns={col: new_col_name})
        
        nonsub_reaction_names = [name for name in self.affinity_energy_reactions_table.index if &#34;_sub&#34; not in name[-4:]]
        if self.verbose != 0:
            print(&#34;{} redox reactions have been generated.&#34;.format(len(nonsub_reaction_names)))</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.AqEquil.plot_logK_fit"><code class="name flex">
<span>def <span class="ident">plot_logK_fit</span></span>(<span>self, name, plot_out=False, res=200, internal=True, logK_extrapolate=None, T_vals=[])</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the fit of logK values used in the speciation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the chemical species.</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Return a Plotly figure object? If False, a figure is simply shown.
If True, the function returns a Plotly figure object and does
not show the plot.</dd>
<dt><strong><code>res</code></strong> :&ensp;<code>int</code></dt>
<dd>Resolution of the fit line. Higher resolutions will be smoother.</dd>
<dt><strong><code>internal</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Reuse calculated fits if they already exist?</dd>
<dt><strong><code>logK_extrapolate</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Option for extrapolating logK values in the plot. Possible values
for this parameter include 'poly', 'linear', 'flat', or 'none'.
This is for planning and visualization only and does not affect
results in <code>speciate()</code> or <code>create_data0()</code>. Those functions have
their own parameters for setting logK extrapolation options.</dd>
<dt><strong><code>T_vals</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>Option for visualizing how the fit of logK values will be
used to estimate the logK values at the temperatures specified in
the list given to this parameter. This is useful for visualizing
logK extrapolation options defined by <code>logK_extrapolate</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>a Plotly figure object</code></dt>
<dd>Returned if <code>plot_out</code> is True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_logK_fit(self, name, plot_out=False, res=200, internal=True, logK_extrapolate=None, T_vals=[]):
    &#34;&#34;&#34;
    Plot the fit of logK values used in the speciation.

    Parameters
    ----------
    name : str
        Name of the chemical species.
    
    plot_out : bool, default False
        Return a Plotly figure object? If False, a figure is simply shown.
        If True, the function returns a Plotly figure object and does
        not show the plot.
    
    res : int
        Resolution of the fit line. Higher resolutions will be smoother.
        
    internal : bool, default True
        Reuse calculated fits if they already exist?
    
    logK_extrapolate : str, optional
        Option for extrapolating logK values in the plot. Possible values
        for this parameter include &#39;poly&#39;, &#39;linear&#39;, &#39;flat&#39;, or &#39;none&#39;.
        This is for planning and visualization only and does not affect
        results in `speciate()` or `create_data0()`. Those functions have
        their own parameters for setting logK extrapolation options.
    
    T_vals : list, optional
        Option for visualizing how the fit of logK values will be
        used to estimate the logK values at the temperatures specified in
        the list given to this parameter. This is useful for visualizing
        logK extrapolation options defined by `logK_extrapolate`.
    
    Returns
    ----------
    fig : a Plotly figure object
        Returned if `plot_out` is True.

    &#34;&#34;&#34;
    
    if internal and len(self.logK_models.keys()) &gt; 0:
        # use internally calculated logK models already stored...
        if name not in self.logK_models.keys():
            if name not in list(self.thermo.df_rejected_species[&#34;name&#34;]):
                msg = &#34;The chemical species &#34; + str(name) + &#34; is not recognized.&#34;
                self.err_handler.raise_exception(msg)
            else:
                reject_reason = list(self.thermo.df_rejected_species.loc[self.thermo.df_rejected_species[&#39;name&#39;] == name, &#39;reason for rejection&#39;])[0]
                
                msg = (&#34;The chemical species &#34; + str(name) + &#34; cannot be &#34;
                       &#34;plotted because it was rejected from the &#34;
                       &#34;speciation:\n&#34; + str(reject_reason))
                self.err_handler.raise_exception(msg)

        logK_grid = self.logK_models[name][&#34;logK_grid&#34;]
        T_grid = self.logK_models[name][&#34;T_grid&#34;]
        P_grid = self.logK_models[name][&#34;P_grid&#34;]
    
    else:
        # load logK models from Thermodata class&#39;s logK_db
        df_logK = self.thermo.logK_db
        
        i = list(df_logK[&#34;name&#34;]).index(name)
        
        logK_grid = list(df_logK[[&#34;logK1&#34;, &#34;logK2&#34;, &#34;logK3&#34;,
                                  &#34;logK4&#34;, &#34;logK5&#34;, &#34;logK6&#34;,
                                  &#34;logK7&#34;, &#34;logK8&#34;]].iloc[i]) # logK at T and P in datasheet

        T_grid = list(df_logK[[&#34;T1&#34;, &#34;T2&#34;, &#34;T3&#34;,
                               &#34;T4&#34;, &#34;T5&#34;, &#34;T6&#34;,
                               &#34;T7&#34;, &#34;T8&#34;]].iloc[i]) # T for free logK grid

        P_grid = list(df_logK[[&#34;P1&#34;, &#34;P2&#34;, &#34;P3&#34;,
                               &#34;P4&#34;, &#34;P5&#34;, &#34;P6&#34;,
                               &#34;P7&#34;, &#34;P8&#34;]].iloc[i]) # P for free logK grid
        
        if not isinstance(logK_extrapolate, str):
            logK_extrapolate = self.thermo.logK_extrapolate
        
    
    if not isinstance(logK_extrapolate, str):
        logK_extrapolate = self.logK_models[name][&#34;logK_extrapolate&#34;]
    
    if len(T_vals) == 0:
        grid_temps = self.batch_T
    else:
        grid_temps = T_vals
    
    grid_press = self.batch_P
    
    T_grid = [t for t in T_grid if not pd.isna(t)]
    P_grid = [p for p in P_grid if not pd.isna(p)]
    logK_grid = [k for k in logK_grid if not pd.isna(k)]
    
    fig = px.scatter(x=T_grid, y=logK_grid)
    
    if len(grid_temps) &gt; 0:
        if min(grid_temps) &lt;= min(T_grid):
            plot_T_min = min(grid_temps)
        else:
            plot_T_min = min(T_grid)
        if max(grid_temps) &gt;= max(T_grid):
            plot_T_max = max(grid_temps)
        else:
            plot_T_max = max(T_grid)
    else:
        plot_T_min = min(T_grid)
        plot_T_max = max(T_grid)
    
    plot_temps = np.linspace(plot_T_min, plot_T_max, res)

    pred_logK = []
    pred_model = []
    for t in plot_temps:
        logK, model = self._interpolate_logK(t, logK_grid, T_grid, logK_extrapolate)
        pred_logK.append(logK)
        pred_model.append(model)
    
    df_plot = pd.DataFrame({&#34;T&#34;:plot_temps, &#34;logK&#34;:pred_logK, &#34;model&#34;:pred_model})
    
    if logK_extrapolate != &#34;no fit&#34;:
        fig = px.line(df_plot, x=&#39;T&#39;, y=&#39;logK&#39;, color=&#39;model&#39;, title=name, template=&#34;simple_white&#34;)
    else:
        fig = px.line(x=[0], y=[0], title=name, template=&#34;simple_white&#34;) # dummy figure
        
    fig.update_traces(hovertemplate=&#34;T = %{x} C&lt;br&gt;Predicted logK = %{y}&lt;extra&gt;&lt;/extra&gt;&#34;)
    fig.update_layout(xaxis_range=[min(plot_temps) - 0.15*(max(plot_temps) - min(plot_temps)),
                                   max(plot_temps) + 0.15*(max(plot_temps) - min(plot_temps))],
                      xaxis_title=&#34;T,C&#34;, yaxis_title=&#34;logK&#34;)
    
    logK_label = &#34;fitted logK value(s)&#34;
    annotation = &#34;&#34;
    
    if len(grid_temps) &gt; 0:
        for i,gt in enumerate(grid_temps):
            # make vertical lines representing batch temperatures

            if i==0:
                showlegend=True
            else:
                showlegend=False

            if isinstance(grid_press, str):
                ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;br&gt;P = PSAT&lt;extra&gt;&lt;/extra&gt;&#34;
            else:
                if len(grid_press) &gt; 0:
                    ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;br&gt;P = &#34; + str(grid_press[i]) + &#34; bar(s)&lt;extra&gt;&lt;/extra&gt;&#34;
                else:
                    ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;extra&gt;&lt;/extra&gt;&#34;
                    
            if len(T_grid) &gt; 1:
                
                if logK_extrapolate == &#34;none&#34; and (gt &gt; max(T_grid) or gt &lt; min(T_grid)):
                    viz_logK = max(logK_grid)
                else:
                    viz_logK, _ = self._interpolate_logK(gt, logK_grid, T_grid, logK_extrapolate)
                
                vline_y_vals = [min(logK_grid)-0.15*(max(logK_grid)-min(logK_grid)), viz_logK]
                
                
            if logK_extrapolate == &#34;no fit&#34;:
                vline_y_vals = [min(logK_grid)-0.15*(max(logK_grid)-min(logK_grid)), logK_grid[i]]
                logK_label = &#34;calculated LogK value(s)&#34;
                annotation = (&#34;LogK values are calculated from&lt;br&gt;G of dissociation into basis species&#34;
                              &#34;&lt;br&gt;at the T and P of the speciated samples&lt;br&gt;and do not require a fit.&#34;)

            if _all_equal(logK_grid):
                # if a flat horizontal logK fit line...
                # then fix the y-axis range to prevent zoomed-in steppy wierdness
                fig.update_layout(yaxis_range=[logK_grid[0]-1,logK_grid[0]+1])
                vline_y_vals = [logK_grid[0]-1, logK_grid[0]]

            fig.add_trace(
                go.Scatter(x=[gt, gt],
                           y=vline_y_vals,
                           mode=&#34;lines&#34;,
                           line=dict(color=&#39;rgba(255, 0, 0, 0.75)&#39;, width=3, dash=&#34;dot&#34;),
                           legendgroup=&#39;batch temperatures&#39;,
                           name=&#39;batch temperatures&#39;,
                           showlegend=showlegend,
                           hovertemplate=ht_samples,
                          ),
            )
    
    # add fitted logK points
    fig.add_trace(go.Scatter(x=T_grid, y=logK_grid, name=logK_label,
                             mode=&#39;markers&#39;, marker=dict(color=&#34;black&#34;),
                             text = P_grid,
                             hovertemplate=&#34;T = %{x} C&lt;br&gt;P = %{text} bar(s)&lt;br&gt;logK = %{y}&lt;extra&gt;&lt;/extra&gt;&#34;,
                             ),
                  )
    
    fig.add_annotation(x=0, y=0, xref=&#34;paper&#34;, yref=&#34;paper&#34;, align=&#39;left&#39;,
                       text=annotation, bgcolor=&#34;rgba(255, 255, 255, 0.5)&#34;,
                       showarrow=False)
    
    if plot_out:
        return fig
    else:
        fig.show()</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.AqEquil.runeq3"><code class="name flex">
<span>def <span class="ident">runeq3</span></span>(<span>self, filename_3i, db, samplename=None, path_3i='', path_3o='', path_3p='', data1_path='', dynamic_db_name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Call EQ3 on a .3i input file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename_3i</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of 3i input file.</dd>
<dt><strong><code>db</code></strong> :&ensp;<code>str</code></dt>
<dd>Three letter code of database.</dd>
<dt><strong><code>path_3i</code></strong> :&ensp;<code>path str</code>, default <code>current working directory</code></dt>
<dd>Path of .3i input files.</dd>
<dt><strong><code>path_3o</code></strong> :&ensp;<code>path str</code>, default <code>current working directory</code></dt>
<dd>Path of .3o output files.</dd>
<dt><strong><code>path_3p</code></strong> :&ensp;<code>path str</code>, default <code>current working directory</code></dt>
<dd>Path of .3p pickup files.</dd>
<dt><strong><code>data1_path</code></strong> :&ensp;<code>str</code>, default <code>None</code></dt>
<dd>File path of data1 file.</dd>
<dt><strong><code>dynamic_db_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Database name to be printed if dynamic databases are being used.
This parameter is for internal use.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def runeq3(self,
           filename_3i,
           db,
           samplename=None,
           path_3i=&#34;&#34;,
           path_3o=&#34;&#34;,
           path_3p=&#34;&#34;,
           data1_path=&#34;&#34;,
           dynamic_db_name=None):
    
    &#34;&#34;&#34;
    Call EQ3 on a .3i input file.
    
    Parameters
    ----------
    filename_3i : str
        Name of 3i input file.
    
    db : str
        Three letter code of database.
    
    path_3i : path str, default current working directory
        Path of .3i input files.
        
    path_3o : path str, default current working directory
        Path of .3o output files.
    
    path_3p : path str, default current working directory
        Path of .3p pickup files.
    
    data1_path : str, default None
        File path of data1 file.
        
    dynamic_db_name : str
        Database name to be printed if dynamic databases are being used.
        This parameter is for internal use.
    &#34;&#34;&#34;

    # get current working dir
    cwd = os.getcwd()
    cwdd = cwd + &#34;/&#34;
    
    if samplename == None:
        samplename = filename_3i[:-3]
    
    if self.verbose &gt; 0 and dynamic_db_name == None:
        print(&#39;Using &#39; + db + &#39; to speciate &#39; + samplename)
    elif self.verbose &gt; 0 and isinstance(dynamic_db_name, str):
        print(&#39;Using &#39; + dynamic_db_name + &#39; to speciate &#39; + samplename)
        
    args = [&#34;cd&#34;, &#34;&#39;&#34; + cwdd+path_3i+&#34;&#39;&#34;, &#34;;&#34;, # change directory to where 3i files are stored
            self.eq36co + &#39;/eq3nr&#39;, # path to EQ3NR executable
            &#34;&#39;&#34; + data1_path + &#34;/data1.&#34; + db+&#34;&#39;&#34;, # path to data1 file
            &#34;&#39;&#34;+cwdd + path_3i +&#34;/&#34;+ filename_3i+&#34;&#39;&#34;] # path to 3i file
    
    args = &#34; &#34;.join(args)
    
    self.__run_script_and_wait(args) # run EQ3
    
    filename_3o = filename_3i[:-1] + &#39;o&#39;
    filename_3p = filename_3i[:-1] + &#39;p&#39;
    
    # The new eq36 build truncates names, e.g., MLS.Source.3i creates MLS.3o
    # Correct for this here:
    files_3o = [file for file in os.listdir(cwdd + path_3i) if &#34;.3o&#34; in file]
    files_3p = [file for file in os.listdir(cwdd + path_3i) if &#34;.3p&#34; in file]
    
    if len(files_3o) == 0:
        if self.verbose &gt; 0:
            print(&#39;Error: EQ3 failed to produce output for &#39; + filename_3i)
    elif len(files_3o) == 1:
        file_3o = files_3o[0]
        try:
            # move output
            shutil.move(cwdd + path_3i+&#34;/&#34;+file_3o, cwdd + path_3o+&#34;/&#34;+filename_3o)
        except:
            self.err_handler.raise_exception(&#34;Error: could not move&#34;, path_3i+&#34;/&#34;+file_3o, &#34;to&#34;, path_3o+&#34;/&#34;+filename_3o)
    else:
        self.err_handler.raise_exception(&#34;Error: multiple output files detected for one speciation calculation.&#34;)
        
    if len(files_3p) == 0:
        if self.verbose &gt; 0:
            print(&#39;Error: EQ3 failed to produce output for &#39; + filename_3i)
    elif len(files_3p) == 1:
        file_3p = files_3p[0]
        try:
            # move output
            shutil.move(cwdd + path_3i+&#34;/&#34;+file_3p, cwdd + path_3p+&#34;/&#34;+filename_3p)
        except:
            self.err_handler.raise_exception(&#34;Error: could not move&#34;, path_3i+&#34;/&#34;+file_3p, &#34;to&#34;, path_3p+&#34;/&#34;+filename_3p)
    else:
        self.err_handler.raise_exception(&#34;Error: multiple pickup files detected for one speciation calculation.&#34;)</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.AqEquil.runeq6"><code class="name flex">
<span>def <span class="ident">runeq6</span></span>(<span>self, filename_6i, db, samplename=None, path_6i='', data1_path=None, dynamic_db_name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Call EQ6 on a .6i input file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename_6i</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of 6i input file.</dd>
<dt><strong><code>db</code></strong> :&ensp;<code>str</code></dt>
<dd>Three letter code of database.</dd>
<dt><strong><code>samplename</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the sample, used to announce which sample is being run.</dd>
<dt><strong><code>path_6i</code></strong> :&ensp;<code>path str</code>, default <code>current working directory</code></dt>
<dd>Path of directory containing .6i input files.</dd>
<dt><strong><code>data1_path</code></strong> :&ensp;<code>path str</code>, default <code>current working directory</code></dt>
<dd>Path of directory where the data1 thermodynamic database file is
stored. The data1 file will be called from this location to
perform the speciation. The data1 file must be named
data1.xyz, where xyz matches <code>db</code>, the three letter code of your
chosen database.</dd>
<dt><strong><code>dynamic_db_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Database name to be printed if dynamic databases are being used.
This parameter is for internal use.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def runeq6(self,
           filename_6i,
           db,
           samplename=None,
           path_6i=&#34;&#34;,
           data1_path=None,
           dynamic_db_name=None):
    
    &#34;&#34;&#34;
    Call EQ6 on a .6i input file.
    
    Parameters
    ----------
    filename_6i : str
        Name of 6i input file.
    
    db : str
        Three letter code of database.
    
    samplename : str
        The name of the sample, used to announce which sample is being run.
    
    path_6i : path str, default current working directory
        Path of directory containing .6i input files.
        
    data1_path : path str, default current working directory
        Path of directory where the data1 thermodynamic database file is
        stored. The data1 file will be called from this location to
        perform the speciation. The data1 file must be named
        data1.xyz, where xyz matches `db`, the three letter code of your
        chosen database.
        
    dynamic_db_name : str
        Database name to be printed if dynamic databases are being used.
        This parameter is for internal use.
    &#34;&#34;&#34;

    if data1_path == None:
        data1_path = self.eq36da
    
    # get current working dir
    cwd = os.getcwd()
    cwdd = cwd + &#34;/&#34;
    
    if samplename == None:
        samplename = filename_6i[:-3]
    
    if self.verbose &gt; 0 and dynamic_db_name == None:
        print(&#39;Using &#39; + db + &#39; to react &#39; + samplename)
    elif self.verbose &gt; 0 and isinstance(dynamic_db_name, str):
        print(&#39;Using &#39; + dynamic_db_name + &#39; to react &#39; + samplename)

    args = [&#34;cd&#34;, &#34;&#39;&#34; + cwdd+path_6i+&#34;&#39;&#34;, &#34;;&#34;, # change directory to 6i folder
            self.eq36co+&#39;/eq6&#39;, # path of EQ6 executable
            &#34;&#39;&#34; + data1_path + &#34;/data1.&#34; + db+&#34;&#39;&#34;, # path to data1 file
            &#34;&#39;&#34;+cwdd+path_6i + filename_6i+&#34;&#39;&#34;] # path of 6i file
    
    args = &#34; &#34;.join(args)
    
    self.__run_script_and_wait(args) # run EQ6</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.AqEquil.runeqpt"><code class="name flex">
<span>def <span class="ident">runeqpt</span></span>(<span>self, db, dynamic_db=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a data0 into a data1 file with EQPT.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>db</code></strong> :&ensp;<code>str</code></dt>
<dd>Three letter code of database.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def runeqpt(self, db, dynamic_db=False):
    
    &#34;&#34;&#34;
    Convert a data0 into a data1 file with EQPT.
    
    Parameters
    ----------
    db : str
        Three letter code of database.
    &#34;&#34;&#34;

    if os.path.exists(&#34;data0.&#34;+db) and os.path.isfile(&#34;data0.&#34;+db):
        pass
    else:
        self.err_handler.raise_exception(&#34; &#34;.join([&#34;Error: could not locate custom database&#34;,
                        &#34;data0.{} in {}.&#34;.format(db, os.getcwd())]))

    if os.path.exists(&#34;data1.&#34;+db) and os.path.isfile(&#34;data1.&#34;+db):
        os.remove(&#34;data1.&#34;+db)

    self.__move_eqpt_extra_output()
    
    args = [&#34;cd&#34;, os.getcwd(), &#34;;&#34;, self.eq36co+&#39;/eqpt&#39;, &#34;&#39;&#34;+os.getcwd()+&#34;/data0.&#34;+db+&#34;&#39;&#34;]
    args = &#34; &#34;.join(args)

    try:
        self.__run_script_and_wait(args) # run EQPT
    except:
        self.err_handler.raise_exception(
            &#34;Error: EQPT failed to run on {}.&#34;.format(&#34;data0.&#34;+db))

    if os.path.exists(&#34;data1&#34;) and os.path.isfile(&#34;data1&#34;):
        os.rename(&#34;data1&#34;, &#34;data1.&#34;+db)
    if os.path.exists(&#34;data0.d1&#34;) and os.path.isfile(&#34;data0.d1&#34;):
        os.rename(&#34;data0.d1&#34;, &#34;data1.&#34;+db)
    if os.path.exists(&#34;data0.po&#34;) and os.path.isfile(&#34;data0.po&#34;):
        os.rename(&#34;data0.po&#34;, &#34;eqpt_log.txt&#34;)
    if os.path.exists(&#34;data0.d1f&#34;) and os.path.isfile(&#34;data0.d1f&#34;):
        os.rename(&#34;data0.d1f&#34;, &#34;data1f.txt&#34;)
    if os.path.exists(&#34;data0.s&#34;) and os.path.isfile(&#34;data0.s&#34;):
        os.rename(&#34;data0.s&#34;, &#34;slist.txt&#34;)

    if os.path.exists(&#34;data1.&#34;+db) and os.path.isfile(&#34;data1.&#34;+db):
        if self.verbose &gt; 0:
            if not dynamic_db:
                print(&#34;Successfully created a data1.&#34;+db+&#34; from data0.&#34;+db)
    else:
        if dynamic_db:
            msg = (&#34;EQPT has encounted a problem processing the database &#34;
                   &#34;for this sample. Check eqpt_log.txt for details.&#34;)
        else:
            msg = (&#34;EQPT could not create data1.&#34;+db+&#34; from &#34;
                   &#34;data0.&#34;+db+&#34;. Check eqpt_log.txt for details.&#34;)
        self.err_handler.raise_exception(msg)
    
    self.__move_eqpt_extra_output()</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.AqEquil.show_redox_reactions"><code class="name flex">
<span>def <span class="ident">show_redox_reactions</span></span>(<span>self, formatted=True, charge_sign_at_end=False, hide_subreactions=True, simplify=True, show=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Show a table of redox reactions generated with the function
<code>make_redox_reactions</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>formatted</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Should reactions be formatted for html output?</dd>
<dt><strong><code>charge_sign_at_end</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Display charge with sign after the number (e.g. SO4 2-)? Ignored if
<code>formatted</code> is False.</dd>
<dt><strong><code>hide_subreactions</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Hide subreactions?</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Show the table of reactions? Ignored if not run in a Jupyter
notebook.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A pandas dataframe containing balanced redox reactions written in full.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show_redox_reactions(self, formatted=True, charge_sign_at_end=False,
                              hide_subreactions=True, simplify=True,
                              show=True):
    
    &#34;&#34;&#34;
    Show a table of redox reactions generated with the function
    `make_redox_reactions`.
    
    Parameters
    ----------
    formatted : bool, default True
        Should reactions be formatted for html output?
        
    charge_sign_at_end : bool, default False
        Display charge with sign after the number (e.g. SO4 2-)? Ignored if
        `formatted` is False.
    
    hide_subreactions : bool, default True
        Hide subreactions?
    
    show : bool, default False
        Show the table of reactions? Ignored if not run in a Jupyter
        notebook.
    
    Returns
    ----------
    A pandas dataframe containing balanced redox reactions written in full.
    &#34;&#34;&#34;
    
    self.affinity_energy_formatted_reactions = copy.copy(self.affinity_energy_reactions_table.iloc[:, 0:1])
    
    df = copy.copy(self.affinity_energy_reactions_table)
    
    if simplify:
        main_rxn_names = df.loc[[ind for ind in df.index if &#34;_sub&#34; not in ind[-4:]]].index
        df = df.iloc[[i-1 for i in range(0, len(df.index)) if &#34;_sub&#34; not in df.index[i][-4:]]]
        
        self.affinity_energy_formatted_reactions = copy.copy(df.iloc[:, 0:1])
        
        reactions = []
        for irow in range(0, df.shape[0]):
            redox_pair = df.loc[df.index[irow], &#34;redox_pairs&#34;]

            oxidant_1 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[0]], &#34;Oxidant_1&#34;]
            oxidant_2 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[0]], &#34;Oxidant_2&#34;]
            oxidant_3 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[0]], &#34;Oxidant_3&#34;]
            reductant_1 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[1]], &#34;Reductant_1&#34;]
            reductant_2 = self.half_cell_reactions.loc[self.half_cell_reactions.index[redox_pair[1]], &#34;Reductant_2&#34;]
            
            oxidants = [ox for ox in [oxidant_1, oxidant_2, oxidant_3] if str(ox) != &#39;nan&#39;]
            reductants = [rd for rd in [reductant_1, reductant_2] if str(rd) != &#39;nan&#39;]
            
            if len(oxidants) &gt; 1:
                oxidant_sigma_needed = True
            else:
                oxidant_sigma_needed = False
            if len(reductants) &gt; 1:
                reductant_sigma_needed = True
            else:
                reductant_sigma_needed = False
                
            rxn_row = df.iloc[irow, 2:]
            rxn = rxn_row[rxn_row.notna()]
            coeffs = copy.copy(rxn[::2]).tolist()
            names = copy.copy(rxn[1::2]).tolist()
            
            if oxidant_sigma_needed or reductant_sigma_needed:

                reactant_names = [names[i] for i in range(0, len(names)) if float(coeffs[i]) &lt; 0]
                for sp in reactant_names:
                    if sp in oxidants and oxidant_sigma_needed:
                        i = names.index(sp)
                        names[i] = u&#34;\u03A3&#34;+sp
                    if sp in reductants and reductant_sigma_needed:
                        if u&#34;\u03A3&#34;+sp not in names:
                            i = names.index(sp)
                            names[i] = u&#34;\u03A3&#34;+sp
                
            react_grid = pd.DataFrame({&#34;coeff&#34;:coeffs, &#34;name&#34;:names})
            react_grid[&#34;coeff&#34;] = pd.to_numeric(react_grid[&#34;coeff&#34;])
            react_grid = react_grid.astype({&#39;coeff&#39;: &#39;float&#39;})

            reactants = &#34; + &#34;.join([(str(-int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else -react_grid[&#34;coeff&#34;][i])+&#34; &#34; if -react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
            products = &#34; + &#34;.join([(str(int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else react_grid[&#34;coeff&#34;][i])+&#34; &#34; if react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
            if formatted:
                reactants = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                products = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
            reaction = reactants + &#34; = &#34; + products
            reactions.append(reaction)

        self.affinity_energy_formatted_reactions[&#34;reaction&#34;] = reactions[1:] + reactions[:1] # because reactions got rotated with respect to reaction names, rotate the other way
        self.affinity_energy_formatted_reactions.index = main_rxn_names
        
    else:
        reactions = []
        for irow in range(0, df.shape[0]):
            redox_pair = df.loc[self.affinity_energy_reactions_table.index[irow], &#34;redox_pairs&#34;]

            oxidant = redox_pair[0]
            reductant = redox_pair[1]

            rxn_row = df.iloc[irow, 2:]
            rxn = rxn_row[rxn_row.notna()]
            coeffs = copy.copy(rxn[::2]).tolist()
            names = copy.copy(rxn[1::2]).tolist()
            react_grid = pd.DataFrame({&#34;coeff&#34;:coeffs, &#34;name&#34;:names})
            react_grid[&#34;coeff&#34;] = pd.to_numeric(react_grid[&#34;coeff&#34;])
            react_grid = react_grid.astype({&#39;coeff&#39;: &#39;float&#39;})

            reactants = &#34; + &#34;.join([(str(-int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else -react_grid[&#34;coeff&#34;][i])+&#34; &#34; if -react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
            products = &#34; + &#34;.join([(str(int(react_grid[&#34;coeff&#34;][i]) if react_grid[&#34;coeff&#34;][i].is_integer() else react_grid[&#34;coeff&#34;][i])+&#34; &#34; if react_grid[&#34;coeff&#34;][i] != 1 else &#34;&#34;) + react_grid[&#34;name&#34;][i] for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
            if formatted:
                reactants = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &lt; 0])
                products = &#34; + &#34;.join([_format_coeff(react_grid[&#34;coeff&#34;][i]) + chemlabel(react_grid[&#34;name&#34;][i], charge_sign_at_end=charge_sign_at_end) for i in range(0, len(react_grid[&#34;name&#34;])) if react_grid[&#34;coeff&#34;][i] &gt; 0])
            reaction = reactants + &#34; = &#34; + products
            reactions.append(reaction)
    
        self.affinity_energy_formatted_reactions[&#34;reaction&#34;] = reactions
    

    df_out = copy.copy(self.affinity_energy_formatted_reactions)

    if hide_subreactions and not simplify:
        df_out = self.affinity_energy_formatted_reactions.loc[[ind for ind in self.affinity_energy_formatted_reactions.index if &#34;_sub&#34; not in ind[-4:]]]
    
    if _isnotebook() and show:
        display(HTML(df_out.to_html(escape=False)))
    
    return df_out</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.AqEquil.speciate"><code class="name flex">
<span>def <span class="ident">speciate</span></span>(<span>self, input_filename, db=None, db_solid_solution=None, db_logK=None, logK_extrapolate=None, activity_model='b-dot', redox_flag='logfO2', redox_aux='Fe+3', default_logfO2=-6, exclude=[], suppress=[], alter_options=[], charge_balance_on='none', suppress_missing=True, blanks_are_0=False, strict_minimum_pressure=True, aq_scale=1, verbose=1, report_filename=None, get_aq_dist=True, aq_dist_type='log_activity', get_mass_contribution=True, mass_contribution_other=True, get_mineral_sat=True, mineral_sat_type='affinity', get_redox=True, redox_type='Eh', get_ion_activity_ratios=True, get_fugacity=True, get_basis_totals=True, get_solid_solutions=True, get_affinity_energy=False, negative_energy_supplies=False, rxn_filename=None, not_limiting=['H+', 'OH-', 'H2O'], get_charge_balance=True, custom_db=False, batch_3o_filename=None, delete_generated_folders=False, db_args={})</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the equilibrium distribution of chemical species in solution.
Additionally, calculate chemical affinities and energy supplies for
user-specified reactions.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>input_filename</code></strong> :&ensp;<code>str</code></dt>
<dd>
<p>User-supplied utf8-encoded comma separated value (csv) file
containing sample data intended for speciation. The file must
follow this format:</p>
<ul>
<li>the first row is a header row that must contain the names of the
species to be included in the speciation calculation. There
cannot be duplicate headers.</li>
<li>
<p>the second row must contain subheaders for each species in the
header row. These subheaders must be taken from the following:</p>
<pre><code>degC
ppm
ppb
Suppressed
Molality
Molarity
mg/L
mg/kg.sol
Alk., eq/kg.H2O
Alk., eq/L
Alk., eq/kg.sol
Alk., mg/L CaCO3
Alk., mg/L HCO3-
Log activity
Log act combo
Log mean act
pX
pH
pHCl
pmH
pmX
Hetero. equil.
Homo. equil.
Make non-basis
</code></pre>
</li>
<li>
<p>'Temperature' must be included as a header, with 'degC' as its
subheader.</p>
</li>
<li>The first column must contain sample names. There cannot be
duplicate sample names.</li>
</ul>
</dd>
<dt><strong><code>db</code></strong> :&ensp;<code>str</code>, default <code>"wrm"</code></dt>
<dd>Determines which thermodynamic database is used in the speciation
calculation. There are several options available:
- Three letter file extension for the desired data1 database, e.g.,
"wrm". This will use a data1 file with this file extension, e.g.,
"data1.wrm" located in the path stored in the 'EQ36DA' environment
variable used by EQ3NR.
- The name of a data0 file located in the current working directory,
e.g., "data0.wrm". This data0 file will be compiled by EQPT
automatically during the speciation calculation.
- The name of a CSV file containing thermodynamic data located in
the current working directory, e.g., "wrm_data.csv". The CSV file
will be used to generate a data0 file for each sample (using
additional arguments from <code>db_args</code> if desired).
- The URL of a data0 file, e.g.,
"https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm"
- The URL of a CSV file containing thermodynamic data, e.g.,
"https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv"</dd>
<dt><strong><code>db_solid_solution</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Used only if <code>db</code> points to a thermodynamic data CSV file (or the
URL of a CSV hosted online). Determines which thermodynamic database
is used for idealized solid solutions in the speciation calculation.
There are two options:
- The name of a CSV file containing solid solution parameters
located in the current working directory, e.g.,
"wrm_solid_solutions.csv"
- The URL of a CSV file containing solid solution parameters, e.g.,
"https://raw.githubusercontent.com/worm-portal/WORM-db/master/solid_solutions.csv"</dd>
<dt><strong><code>db_logK</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The name of the CSV file containing species with dissociation
constants but no other properties or parameters. Used only if <code>db</code>
points to a thermodynamic data CSV file (or the URL of a CSV hosted
online).</dd>
<dt><strong><code>activity_model</code></strong> :&ensp;<code>str</code>, default <code>"b-dot"</code></dt>
<dd>Activity model to use for speciation. Can be either "b-dot",
or "davies". NOTE: the "pitzer" model is not yet implemented.</dd>
<dt><strong><code>redox_flag</code></strong> :&ensp;<code>str</code>, default <code>"O2(g)"</code></dt>
<dd>
<p>Determines which column in the sample input file sets the overall
redox state of the samples. Options for redox_flag include 'O2(g)',
'pe', 'Eh', 'logfO2', and 'redox aux'. The code will search your
sample spreadsheet file (see <code>filename</code>) for a column corresponding
to the option you chose:</p>
<ul>
<li>'O2(g)' with a valid subheader for a gas</li>
<li>'pe' with subheader pe</li>
<li>'Eh' with subheader volts</li>
<li>'logfO2' with subheader logfO2</li>
<li>'redox aux' will search for a column corresponding to the
auxilliary basis species selected to form a redox couple with its
linked strict basis species (see <code>redox_aux</code>). For example, the
redox couple Fe+2/Fe+3 would require a column named Fe+3</li>
</ul>
<p>If an appropriate header or redox data cannot be found to define
redox state, <code>default_logfO2</code> is used to set sample logfO2.</p>
<p>There is a special case where dissolved oxygen can be used to impose
sample redox state if <code>redox_flag</code> is set to logfO2 and a column named
logfO2 does not appear in your sample spreadsheet. If there is a
column corresponding to dissolved oxygen measurements, logfO2 is
calculated from the equilibrium reaction O2(aq) = O2(g) at the
temperature and pressure of the sample using the revised Helgeson-
Kirkham-Flowers (HKF) equation of state (JC Tanger IV and HC
Helgeson, Am. J. Sci., 1988, 288, 19).</p>
</dd>
<dt><strong><code>redox_aux</code></strong> :&ensp;<code>default "Fe+3"</code>, optional</dt>
<dd>Ignored unless <code>redox_flag</code> equals 1. Name of the auxilliary species
whose reaction links it to a basis species (or another auxilliary
species) such that they form a redox couple that controls sample
fO2. For instance, Fe+3 is linked to Fe+2 in many supporting data
files, so selecting <code>redox_flag</code> = 1 and <code>redox_aux</code> = "Fe+3" will
set sample fO2 based on the Fe+2/Fe+3 redox couple.</dd>
<dt><strong><code>default_logfO2</code></strong> :&ensp;<code>float</code>, default <code>-6</code></dt>
<dd>Default value for sample logfO2 in case redox data cannot be found
in the user-supplied sample spreadsheet.</dd>
<dt><strong><code>exclude</code></strong> :&ensp;<code>list</code> of <code>str</code>, default <code>[]</code></dt>
<dd>Names of columns in the user-supplied sample spreadsheet that should
not be considered aqueous species. Useful for excluding columns
containing sample metatadata, such as "Year" and "Location".</dd>
<dt><strong><code>suppress</code></strong> :&ensp;<code>list</code> of <code>str</code>, default <code>[]</code></dt>
<dd>Names of chemical species that will be prevented from forming in the
speciation calculation.</dd>
<dt><strong><code>alter_options</code></strong> :&ensp;<code>list</code>, default <code>[]</code></dt>
<dd>A list of lists, e.g.,
[["CaOH+", "Suppress"], ["CaCl+", "AugmentLogK", -1]]
The first element of each interior list is the name of a species.
The second element is an option to alter the species, and can be:
- Suppress : suppress the formation of the species. (See also:
<code>suppress</code>).
- Replace : replace the species' log K value with a desired value.
- AugmentLogK : augment the value of the species' log K.
- AugmentG : augment the Gibbs free energy of the species by a
desired value, in kcal/mol.
The third element is a numeric value corresponding to the chosen
option. A third element is not required for Suppress.</dd>
<dt><strong><code>charge_balance_on</code></strong> :&ensp;<code>str</code>, default <code>"none"</code></dt>
<dd>If "none", will not balance electrical charge between cations and
anions in the speciation calculation. If a name of a species is
supplied instead, the activity of that species will be allowed to
change until charge balance is obtained. For example,
charge_balance_on = "H+" will calculate what pH a sample must have
to have zero net charge.</dd>
<dt><strong><code>suppress_missing</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Suppress the formation of an aqueous species if it is missing a
value in the user-supplied sample spreadsheet?</dd>
<dt><strong><code>blanks_are_0</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Assume all blank values in the water chemistry input file are 0?</dd>
<dt><strong><code>strict_minimum_pressure</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Ensure that the minimum pressure in the speciation calculation does
not go below the minimum pressure in the TP grid of the data0 file?</dd>
<dt><strong><code>aq_scale</code></strong> :&ensp;<code>float</code>, default <code>1</code></dt>
<dd>Scale factor for the mass of the aqueous phase. By default, the
aqueous phase is 1 kg of solvent.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int, 0, 1,</code> or <code>2</code>, default <code>1</code></dt>
<dd>Level determining how many messages are returned during a
calculation. 2 for all messages, 1 for errors or warnings only,
0 for silent.</dd>
<dt><strong><code>report_filename</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name of the comma separated values (csv) report file generated when
the calculation is complete. If this argument is not defined, a
report file is not generated.</dd>
<dt><strong><code>get_aq_dist</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Calculate distributions of aqueous species?</dd>
<dt><strong><code>aq_dist_type</code></strong> :&ensp;<code>str</code>, default <code>"log_activity"</code></dt>
<dd>Desired units of measurement for reported distributions of aqueous
species. Can be "molality", "log_molality", "log_gamma", or
"log_activity". Ignored if <code>get_aq_dist</code> is False.</dd>
<dt><strong><code>get_mass_contribution</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Calculate basis species contributions to mass balance of aqueous
species?</dd>
<dt><strong><code>mass_contribution_other</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Include an "other" species for the sake of summing percents of basis
species contributions to 100%? Ignored if <code>get_mass_contribution</code> is
False.</dd>
<dt><strong><code>get_mineral_sat</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Calculate saturation states of pure solids?</dd>
<dt><strong><code>mineral_sat_type</code></strong> :&ensp;<code>str</code>, default <code>"affinity"</code></dt>
<dd>Desired units of measurement for reported saturation states of pure
solids. Can be "logQoverK" or "affinity". Ignored if
<code>get_mineral_sat</code> is False.</dd>
<dt><strong><code>get_redox</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Calculate potentials of redox couples?</dd>
<dt><strong><code>redox_type</code></strong> :&ensp;<code>str</code>, default <code>"Eh"</code></dt>
<dd>Desired units of measurement for reported redox potentials. Can be
"Eh", "pe", "logfO2", or "Ah". Ignored if <code>get_redox</code> is False.</dd>
<dt><strong><code>get_ion_activity_ratios</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Calculate ion/H+ activity ratios and neutral species activities?</dd>
<dt><strong><code>get_fugacity</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Calculate gas fugacities?</dd>
<dt><strong><code>get_basis_totals</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Report total compositions of basis aqueous species?</dd>
<dt><strong><code>get_solid_solutions</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Permit the calculation of solid solutions and include them in the
speciation report?</dd>
<dt><strong><code>get_affinity_energy</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Calculate affinities and energy supplies of reactions listed in a
separate user-supplied file?</dd>
<dt><strong><code>negative_energy_supplies</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Report negative energy supplies? If False, negative energy supplies
are reported as 0 cal/kg H2O. If True, negative energy supplies are
reported. A 'negative energy supply' represents the energy cost of
depleting the limiting reactant of a reaction. This metric is not
always helpful when examing energy supply results, so this option is
set to False by default.</dd>
<dt><strong><code>rxn_filename</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name of .txt file containing reactions used to calculate affinities
and energy supplies. Ignored if <code>get_affinity_energy</code> is False.</dd>
<dt><strong><code>not_limiting</code></strong> :&ensp;<code>list</code>, default <code>["H+", "OH-", "H2O"]</code></dt>
<dd>List containing names of species that are not considered limiting
when calculating energy supplies. Ignored if <code>get_affinity_energy</code>
is False.</dd>
<dt><strong><code>get_charge_balance</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Calculate charge balance and ionic strength?</dd>
<dt><strong><code>batch_3o_filename</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name of rds (R object) file exported after the speciation
calculation? No file will be generated if this argument is not
defined.</dd>
<dt><strong><code>delete_generated_folders</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Delete the 'rxn_3i', 'rxn_3o', 'rxn_3p', and 'eqpt_files' folders
containing raw EQ3NR input, output, pickup, and EQPT files once the
speciation calculation is complete?</dd>
<dt><strong><code>db_args</code></strong> :&ensp;<code>dict</code>, default <code>{}</code></dt>
<dd>
<p>Dictionary of arguments to modify how the thermodynamic database is
processed. Only used when <code>db</code> points to thermodynamic data in a CSV
file. Ignored if <code>db</code> points to a data0 file (because a data0 file
is already ready for a speciation calculation). Options for
<code>db_args</code> are passed to the <code>create_data0</code> function, so refer to
<code>create_data0</code> for more information about what options are possible.</p>
<ul>
<li>Example of <code>db_args</code> where organics are excluded and redox is
suppressed for Fe and S:
db_args = {
"exclude_category":{"category_1":["organic_aq"]},
"suppress_redox":["Fe", "S"],
}</li>
</ul>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>speciation</code></strong> :&ensp;<code>object</code> of <code>class <a title="AqEquil.AqSpeciation.Speciation" href="#AqEquil.AqSpeciation.Speciation">Speciation</a></code></dt>
<dd>Contains the results of the speciation calculation.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def speciate(self,
             input_filename,
             db=None,
             db_solid_solution=None,
             db_logK=None,
             logK_extrapolate=None,
             activity_model=&#34;b-dot&#34;,
             redox_flag=&#34;logfO2&#34;,
             redox_aux=&#34;Fe+3&#34;,
             default_logfO2=-6,
             exclude=[],
             suppress=[],
             alter_options=[],
             charge_balance_on=&#34;none&#34;,
             suppress_missing=True,
             blanks_are_0=False,
             strict_minimum_pressure=True,
             aq_scale=1,
             verbose=1,
             report_filename=None,
             get_aq_dist=True,
             aq_dist_type=&#34;log_activity&#34;,
             get_mass_contribution=True,
             mass_contribution_other=True,
             get_mineral_sat=True,
             mineral_sat_type=&#34;affinity&#34;,
             get_redox=True,
             redox_type=&#34;Eh&#34;,
             get_ion_activity_ratios=True,
             get_fugacity=True,
             get_basis_totals=True,
             get_solid_solutions=True,
             get_affinity_energy=False,
             negative_energy_supplies=False,
             rxn_filename=None,
             not_limiting=[&#34;H+&#34;, &#34;OH-&#34;, &#34;H2O&#34;],
             get_charge_balance=True,
             custom_db=False, # deprecated
             batch_3o_filename=None,
             delete_generated_folders=False,
             db_args={}):
    
    &#34;&#34;&#34;
    Calculate the equilibrium distribution of chemical species in solution.
    Additionally, calculate chemical affinities and energy supplies for
    user-specified reactions.
    
    Parameters
    ----------
    input_filename : str
        User-supplied utf8-encoded comma separated value (csv) file
        containing sample data intended for speciation. The file must
        follow this format:
        
        - the first row is a header row that must contain the names of the
          species to be included in the speciation calculation. There
          cannot be duplicate headers.
        - the second row must contain subheaders for each species in the
          header row. These subheaders must be taken from the following:
          
                degC
                ppm
                ppb
                Suppressed
                Molality
                Molarity
                mg/L
                mg/kg.sol
                Alk., eq/kg.H2O
                Alk., eq/L
                Alk., eq/kg.sol
                Alk., mg/L CaCO3
                Alk., mg/L HCO3-
                Log activity
                Log act combo
                Log mean act
                pX
                pH
                pHCl
                pmH
                pmX
                Hetero. equil.
                Homo. equil.
                Make non-basis
                
        - &#39;Temperature&#39; must be included as a header, with &#39;degC&#39; as its
          subheader.
        - The first column must contain sample names. There cannot be
          duplicate sample names.
    
    db : str, default &#34;wrm&#34;
        Determines which thermodynamic database is used in the speciation
        calculation. There are several options available:
        - Three letter file extension for the desired data1 database, e.g.,
        &#34;wrm&#34;. This will use a data1 file with this file extension, e.g.,
        &#34;data1.wrm&#34; located in the path stored in the &#39;EQ36DA&#39; environment
        variable used by EQ3NR.
        - The name of a data0 file located in the current working directory,
        e.g., &#34;data0.wrm&#34;. This data0 file will be compiled by EQPT
        automatically during the speciation calculation.
        - The name of a CSV file containing thermodynamic data located in
        the current working directory, e.g., &#34;wrm_data.csv&#34;. The CSV file
        will be used to generate a data0 file for each sample (using
        additional arguments from `db_args` if desired).
        - The URL of a data0 file, e.g.,
        &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/data0.wrm&#34;
        - The URL of a CSV file containing thermodynamic data, e.g.,
        &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/wrm_data.csv&#34;
    
    db_solid_solution : str, optional
        Used only if `db` points to a thermodynamic data CSV file (or the
        URL of a CSV hosted online). Determines which thermodynamic database
        is used for idealized solid solutions in the speciation calculation.
        There are two options:
        - The name of a CSV file containing solid solution parameters
        located in the current working directory, e.g.,
        &#34;wrm_solid_solutions.csv&#34;
        - The URL of a CSV file containing solid solution parameters, e.g.,
        &#34;https://raw.githubusercontent.com/worm-portal/WORM-db/master/solid_solutions.csv&#34;
    
    db_logK : str, optional
        The name of the CSV file containing species with dissociation
        constants but no other properties or parameters. Used only if `db`
        points to a thermodynamic data CSV file (or the URL of a CSV hosted
        online).
    
    activity_model : str, default &#34;b-dot&#34;
        Activity model to use for speciation. Can be either &#34;b-dot&#34;,
        or &#34;davies&#34;. NOTE: the &#34;pitzer&#34; model is not yet implemented.
    
    redox_flag : str, default &#34;O2(g)&#34;
        Determines which column in the sample input file sets the overall
        redox state of the samples. Options for redox_flag include &#39;O2(g)&#39;,
        &#39;pe&#39;, &#39;Eh&#39;, &#39;logfO2&#39;, and &#39;redox aux&#39;. The code will search your
        sample spreadsheet file (see `filename`) for a column corresponding
        to the option you chose:
        
        * &#39;O2(g)&#39; with a valid subheader for a gas
        * &#39;pe&#39; with subheader pe
        * &#39;Eh&#39; with subheader volts
        * &#39;logfO2&#39; with subheader logfO2
        * &#39;redox aux&#39; will search for a column corresponding to the
          auxilliary basis species selected to form a redox couple with its
          linked strict basis species (see `redox_aux`). For example, the
          redox couple Fe+2/Fe+3 would require a column named Fe+3
        
        If an appropriate header or redox data cannot be found to define
        redox state, `default_logfO2` is used to set sample logfO2.
        
        There is a special case where dissolved oxygen can be used to impose
        sample redox state if `redox_flag` is set to logfO2 and a column named
        logfO2 does not appear in your sample spreadsheet. If there is a
        column corresponding to dissolved oxygen measurements, logfO2 is
        calculated from the equilibrium reaction O2(aq) = O2(g) at the
        temperature and pressure of the sample using the revised Helgeson-
        Kirkham-Flowers (HKF) equation of state (JC Tanger IV and HC
        Helgeson, Am. J. Sci., 1988, 288, 19).
    
    redox_aux : default &#34;Fe+3&#34;, optional
        Ignored unless `redox_flag` equals 1. Name of the auxilliary species
        whose reaction links it to a basis species (or another auxilliary
        species) such that they form a redox couple that controls sample
        fO2. For instance, Fe+3 is linked to Fe+2 in many supporting data
        files, so selecting `redox_flag` = 1 and `redox_aux` = &#34;Fe+3&#34; will
        set sample fO2 based on the Fe+2/Fe+3 redox couple.
    
    default_logfO2 : float, default -6
        Default value for sample logfO2 in case redox data cannot be found
        in the user-supplied sample spreadsheet.
    
    exclude : list of str, default []
        Names of columns in the user-supplied sample spreadsheet that should
        not be considered aqueous species. Useful for excluding columns
        containing sample metatadata, such as &#34;Year&#34; and &#34;Location&#34;.
        
    suppress : list of str, default []
        Names of chemical species that will be prevented from forming in the
        speciation calculation.
    
    alter_options : list, default []
        A list of lists, e.g.,
        [[&#34;CaOH+&#34;, &#34;Suppress&#34;], [&#34;CaCl+&#34;, &#34;AugmentLogK&#34;, -1]]
        The first element of each interior list is the name of a species.
        The second element is an option to alter the species, and can be:
        - Suppress : suppress the formation of the species. (See also:
        `suppress`).
        - Replace : replace the species&#39; log K value with a desired value.
        - AugmentLogK : augment the value of the species&#39; log K.
        - AugmentG : augment the Gibbs free energy of the species by a
        desired value, in kcal/mol.
        The third element is a numeric value corresponding to the chosen
        option. A third element is not required for Suppress.
        
    charge_balance_on : str, default &#34;none&#34;
        If &#34;none&#34;, will not balance electrical charge between cations and
        anions in the speciation calculation. If a name of a species is
        supplied instead, the activity of that species will be allowed to
        change until charge balance is obtained. For example,
        charge_balance_on = &#34;H+&#34; will calculate what pH a sample must have
        to have zero net charge.
    
    suppress_missing : bool, default True
        Suppress the formation of an aqueous species if it is missing a
        value in the user-supplied sample spreadsheet?

    blanks_are_0 : bool, default False
        Assume all blank values in the water chemistry input file are 0?
        
    strict_minimum_pressure : bool, default True
        Ensure that the minimum pressure in the speciation calculation does
        not go below the minimum pressure in the TP grid of the data0 file?
    
    aq_scale : float, default 1
        Scale factor for the mass of the aqueous phase. By default, the
        aqueous phase is 1 kg of solvent.
    
    verbose : int, 0, 1, or 2, default 1
        Level determining how many messages are returned during a
        calculation. 2 for all messages, 1 for errors or warnings only,
        0 for silent.
        
    report_filename : str, optional
        Name of the comma separated values (csv) report file generated when
        the calculation is complete. If this argument is not defined, a
        report file is not generated.
        
    get_aq_dist : bool, default True
        Calculate distributions of aqueous species?
    
    aq_dist_type : str, default &#34;log_activity&#34;
        Desired units of measurement for reported distributions of aqueous
        species. Can be &#34;molality&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, or
        &#34;log_activity&#34;. Ignored if `get_aq_dist` is False.
    
    get_mass_contribution : bool, default True
        Calculate basis species contributions to mass balance of aqueous
        species?
    
    mass_contribution_other : bool, default True
        Include an &#34;other&#34; species for the sake of summing percents of basis
        species contributions to 100%? Ignored if `get_mass_contribution` is
        False.
    
    get_mineral_sat : bool, default True
        Calculate saturation states of pure solids?
    
    mineral_sat_type : str, default &#34;affinity&#34;
        Desired units of measurement for reported saturation states of pure
        solids. Can be &#34;logQoverK&#34; or &#34;affinity&#34;. Ignored if
        `get_mineral_sat` is False.
    
    get_redox : bool, default True
        Calculate potentials of redox couples?
        
    redox_type : str, default &#34;Eh&#34;
        Desired units of measurement for reported redox potentials. Can be
        &#34;Eh&#34;, &#34;pe&#34;, &#34;logfO2&#34;, or &#34;Ah&#34;. Ignored if `get_redox` is False.
    
    get_ion_activity_ratios : bool, default True
        Calculate ion/H+ activity ratios and neutral species activities?
    
    get_fugacity : bool, default True
        Calculate gas fugacities?

    get_basis_totals : bool, default True
        Report total compositions of basis aqueous species?

    get_solid_solutions : bool, default True
        Permit the calculation of solid solutions and include them in the
        speciation report?
    
    get_affinity_energy : bool, default False
        Calculate affinities and energy supplies of reactions listed in a
        separate user-supplied file?
    
    negative_energy_supplies : bool, default False
        Report negative energy supplies? If False, negative energy supplies
        are reported as 0 cal/kg H2O. If True, negative energy supplies are
        reported. A &#39;negative energy supply&#39; represents the energy cost of
        depleting the limiting reactant of a reaction. This metric is not
        always helpful when examing energy supply results, so this option is
        set to False by default.
    
    rxn_filename : str, optional
        Name of .txt file containing reactions used to calculate affinities
        and energy supplies. Ignored if `get_affinity_energy` is False.
    
    not_limiting : list, default [&#34;H+&#34;, &#34;OH-&#34;, &#34;H2O&#34;]
        List containing names of species that are not considered limiting
        when calculating energy supplies. Ignored if `get_affinity_energy`
        is False.
    
    get_charge_balance : bool, default True
        Calculate charge balance and ionic strength?
    
    batch_3o_filename : str, optional
        Name of rds (R object) file exported after the speciation
        calculation? No file will be generated if this argument is not
        defined.
        
    delete_generated_folders : bool, default False
        Delete the &#39;rxn_3i&#39;, &#39;rxn_3o&#39;, &#39;rxn_3p&#39;, and &#39;eqpt_files&#39; folders
        containing raw EQ3NR input, output, pickup, and EQPT files once the
        speciation calculation is complete?
       
    db_args : dict, default {}
        Dictionary of arguments to modify how the thermodynamic database is
        processed. Only used when `db` points to thermodynamic data in a CSV
        file. Ignored if `db` points to a data0 file (because a data0 file
        is already ready for a speciation calculation). Options for
        `db_args` are passed to the `create_data0` function, so refer to
        `create_data0` for more information about what options are possible.
        
        - Example of `db_args` where organics are excluded and redox is
        suppressed for Fe and S:
        db_args = {
           &#34;exclude_category&#34;:{&#34;category_1&#34;:[&#34;organic_aq&#34;]},
           &#34;suppress_redox&#34;:[&#34;Fe&#34;, &#34;S&#34;],
        }
        
    
    Returns
    -------
    speciation : object of class Speciation
        Contains the results of the speciation calculation.
    
    &#34;&#34;&#34;
    
    self.batch_T = []
    self.batch_P = []
    
    self.verbose = verbose
    
    if db != None:
        # load new thermodynamic database
        self.thermo._set_active_db(db)
    else:
        db = self.thermo.db
        
    if self.thermo.thermo_db_type == &#34;CSV&#34;:
        db_args[&#34;db&#34;] = &#34;dyn&#34;
        
    dynamic_db = self.thermo.dynamic_db
    data0_lettercode = self.thermo.data0_lettercode # needs to be this way
    
    
    if (self.thermo.thermo_db_type == &#34;data0&#34; or self.thermo.thermo_db_type == &#34;data1&#34;) and len(db_args) &gt; 0:
        if self.verbose &gt; 0:
            print(&#34;Warning: Ignoring db_args because a premade data0 or data1 file is being used: &#39;&#34; + db + &#34;&#39;&#34;)
        
    redox_suppression = False
    if &#34;suppress_redox&#34; in db_args.keys() and self.thermo.thermo_db_type != &#34;data0&#34; and self.thermo.thermo_db_type != &#34;data1&#34;:
        if len(db_args[&#34;suppress_redox&#34;]) &gt; 0:
            redox_suppression = True
    
    # check input sample file for errors
    if activity_model != &#39;pitzer&#39;: # TODO: allow check_sample_input_file() to handle pitzer
        sample_temps, sample_press = self._check_sample_input_file(
                                      input_filename, exclude, db,
                                      dynamic_db, charge_balance_on, suppress_missing,
                                      redox_suppression)
    
    if aq_dist_type not in [&#34;molality&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, &#34;log_activity&#34;]:
        self.err_handler.raise_exception(&#34;Unrecognized aq_dist_type. Valid &#34;
            &#34;options are &#39;molality&#39;, &#39;log_molality&#39;, &#39;log_gamma&#39;, &#39;log_activity&#39;&#34;)
    if mineral_sat_type not in [&#34;logQoverK&#34;, &#34;affinity&#34;]:
        self.err_handler.raise_exception(&#34;Unrecognized mineral_sat_type. Valid &#34;
            &#34;options are &#39;logQoverK&#39; or &#39;affinity&#39;&#34;)
    if redox_type not in [&#34;Eh&#34;, &#34;pe&#34;, &#34;logfO2&#34;, &#34;Ah&#34;]:
        self.err_handler.raise_exception(&#34;Unrecognized redox_type. Valid &#34;
            &#34;options are &#39;Eh&#39;, &#39;pe&#39;, &#39;logfO2&#39;, or &#39;Ah&#39;&#34;)
    
    if redox_flag == &#34;O2(g)&#34; or redox_flag == -3:
        redox_flag = -3
    elif redox_flag == &#34;pe&#34; or redox_flag == -2:
        redox_flag = -2
    elif redox_flag == &#34;Eh&#34; or redox_flag == -1:
        redox_flag = -1
    elif redox_flag == &#34;logfO2&#34; or redox_flag == 0:
        redox_flag = 0
    elif redox_flag == &#34;redox aux&#34; or redox_flag == 1:
        redox_flag = 1
    else:
        self.err_handler.raise_exception(&#34;Unrecognized redox flag. Valid options are &#39;O2(g)&#39;&#34;
                                         &#34;, &#39;pe&#39;, &#39;Eh&#39;, &#39;logfO2&#39;, &#39;redox aux&#39;&#34;)
        
    # handle batch_3o naming
    if batch_3o_filename != None:
        if &#34;.rds&#34; in batch_3o_filename[-4:]:
            batch_3o_filename = batch_3o_filename
        else:
            batch_3o_filename = &#34;batch_3o_{}.rds&#34;.format(data0_lettercode)
    else:
        batch_3o_filename = ro.r(&#34;NULL&#34;)
    
    # reset logK_models whenever speciate() is called
    # (prevents errors when speciations are run back-to-back)
    self.logK_models = {}
    
    # dynamic data0 creation per sample
    if dynamic_db:
        db_args[&#34;fill_data0&#34;] = False
        db_args[&#34;dynamic_db&#34;] = True
        db_args[&#34;verbose&#34;] = self.verbose
        db_args[&#34;dynamic_db_sample_temps&#34;] = sample_temps
        db_args[&#34;dynamic_db_sample_press&#34;] = sample_press
        
        if db_logK != None:
            self.thermo._load_logK(db_logK, source=&#34;file&#34;)
        
        if logK_extrapolate != None:
            db_args[&#34;logK_extrapolate&#34;] = logK_extrapolate
        elif self.thermo.logK_active:
            db_args[&#34;logK_extrapolate&#34;] = self.thermo.logK_extrapolate
            logK_extrapolate = self.thermo.logK_extrapolate
        else:
            logK_extrapolate = &#34;none&#34;

        if db_solid_solution != None:
            if not (db_solid_solution[0:8].lower() == &#34;https://&#34; or db_solid_solution[0:7].lower() == &#34;http://&#34; or db_solid_solution[0:4].lower() == &#34;www.&#34;):
                if os.path.exists(db_solid_solution) and os.path.isfile(db_solid_solution):
                    db_args[&#34;filename_ss&#34;] = db_solid_solution
                else:
                    self.err_handler.raise_exception(&#34;Error: could not locate &#34; + str(db_solid_solution))
            else:
                db_solid_solution_csv_name = db_solid_solution.split(&#34;/&#34;)[-1].lower()
        
                # Download from URL and decode as UTF-8 text.
                with urlopen(db_solid_solution) as webpage:
                    content = webpage.read().decode()
                    
                # Save to CSV file.
                with open(db_solid_solution_csv_name, &#39;w&#39;) as output:
                    output.write(content)
                    
                db_args[&#34;filename_ss&#34;] = db_solid_solution_csv_name
                
        if self.verbose &gt; 0:
            print(&#34;Getting&#34;, self.thermo.thermo_db_filename, &#34;ready. This will take a moment...&#34;)

        thermo_df, data0_file_lines, grid_temps, grid_press, data0_lettercode, water_model, P1, plot_poly_fit = self.create_data0(**db_args)
        
    if self.thermo.custom_data0 and not dynamic_db:
        self.__mk_check_del_directory(&#39;eqpt_files&#39;)
        if self.thermo.thermo_db_type != &#34;data1&#34;:
            self.runeqpt(data0_lettercode)
        
        if os.path.exists(&#34;data1.&#34;+data0_lettercode) and os.path.isfile(&#34;data1.&#34;+data0_lettercode):
            try:
                # store contents of data1 file in AqEquil object
                with open(&#34;data1.&#34;+data0_lettercode, mode=&#39;rb&#39;) as data1:
                    self.data1[&#34;all_samples&#34;] = data1.read()
                # move or copy data1
                if self.thermo.thermo_db_type != &#34;data1&#34;:
                    shutil.move(&#34;data1.&#34;+data0_lettercode, &#34;eqpt_files/data1.&#34;+data0_lettercode)
                else:
                    shutil.copyfile(&#34;data1.&#34;+data0_lettercode, &#34;eqpt_files/data1.&#34;+data0_lettercode)
                    
            except:
                if self.verbose &gt; 0:
                    print(&#39;Error: Could not move&#39;, &#34;data1.&#34;+data0_lettercode, &#34;to eqpt_files&#34;)
        
        data1_path = os.getcwd()+&#34;/eqpt_files&#34; # creating a folder name without spaces to store the data1 overcomes the problem where environment variables with spaces do not work properly when assigned to EQ36DA
        
        data0_path = &#34;data0.&#34; + data0_lettercode
        
    elif dynamic_db:
        self.__mk_check_del_directory(&#39;eqpt_files&#39;)
        
    else:
        data0_path = self.eq36da + &#34;/data0.&#34; + data0_lettercode
    
    # gather information from data0 file and perform checks
    if not dynamic_db:
        if os.path.exists(data0_path) and os.path.isfile(data0_path):
            with open(data0_path) as data0:
                data0_lines = data0.readlines()
                start_index = [i+1 for i, s in enumerate(data0_lines) if s == &#39;temperatures\n&#39;]
                if activity_model == &#39;davies&#39; or activity_model == &#39;b-dot&#39;:
                    end_index = [i for i, s in enumerate(data0_lines) if s == &#39;debye huckel a (adh)\n&#39;]
                elif activity_model == &#39;pitzer&#39;:
                    end_index = [i for i, s in enumerate(data0_lines) if s == &#39;debye huckel aphi\n&#39;]
                db_grids_unformatted = [i.split(&#34;pressures&#34;)[0] for i in data0_lines[start_index[0]:end_index[0]]]
                db_grids = [&#34; &#34;.join(i.split()) for i in db_grids_unformatted if i != &#39;&#39;]
                grid_temps = db_grids[0] + &#34; &#34; + db_grids[1]
                grid_press = db_grids[2] + &#34; &#34; + db_grids[3]
                grid_temps = grid_temps.split(&#34; &#34;)
                grid_press = grid_press.split(&#34; &#34;)

                try:
                    n_TP_points = data0_lines[2].split(&#34;points: &#34;)[1] # extract number of TP points from the third line of data0 file
                    n_TP_points = n_TP_points.replace(&#34;\n&#34;, &#34;&#34;)
                    n_TP_points = int(n_TP_points)
                except:
                    n_TP_points = 8
                if n_TP_points == 1:
                    grid_temps = grid_temps[0]
                    grid_press = grid_press[0]

                try:
                    water_model = data0_lines[1].split(&#34;model: &#34;)[1] # extract water model from the second line of data0 file
                    water_model = water_model.replace(&#34;\n&#34;, &#34;&#34;)
                except:
                    water_model = &#34;SUPCRT92&#34;
#                     print(&#34;Water model could not be referenced from {}&#34;.format(data0_path)+&#34;&#34;
#                           &#34;. Defaulting to SUPCRT92 water model...&#34;)


                if(water_model not in [&#34;SUPCRT92&#34;, &#34;IAPWS95&#34;, &#34;DEW&#34;]):
                    water_model = &#34;SUPCRT92&#34; # the default for EQ3/6
                    print(&#34;Water model given in {}&#34;.format(data0_path)+&#34; was not &#34;
                          &#34;recognized. Defaulting to SUPCRT92 water model...&#34;)
                
        else: # if a data0 file can&#39;t be found, assume default water model, 0-350 C and PSAT
            water_model = &#34;SUPCRT92&#34;
            grid_temps = [&#34;0.0100&#34;, &#34;50.0000&#34;, &#34;100.0000&#34;, &#34;150.0000&#34;,
                         &#34;200.0000&#34;, &#34;250.0000&#34;, &#34;300.0000&#34;, &#34;350.0000&#34;]
            grid_press = [&#34;1.0000&#34;, &#34;1.0000&#34;, &#34;1.0132&#34;, &#34;4.7572&#34;,
                          &#34;15.5365&#34;, &#34;39.7365&#34;, &#34;85.8378&#34;, &#34;165.2113&#34;]
            
        grid_press_numeric = [float(n) for n in grid_press]
        if min(grid_press_numeric) == 1:
            P1=True
        else:
            P1=False
            
        self._capture_r_output()
    
        r_check_TP_grid = pkg_resources.resource_string(__name__, &#39;check_TP_grid.r&#39;).decode(&#34;utf-8&#34;)
    
        ro.r(r_check_TP_grid)
    
        list_tp = ro.r.check_TP_grid(grid_temps=_convert_to_RVector(grid_temps),
                                     grid_press=_convert_to_RVector(grid_press),
                                     P1=P1,
                                     water_model=water_model,
                                     check_for_errors=False,
                                     verbose=self.verbose)
    
        self._print_captured_r_output()
        
        grid_temps = list(list_tp.rx2(&#34;grid_temps&#34;))
        grid_press = list(list_tp.rx2(&#34;grid_press&#34;))
        poly_coeffs_1 = list_tp.rx2(&#34;poly_coeffs_1&#34;)
        poly_coeffs_2 = list_tp.rx2(&#34;poly_coeffs_2&#34;)
        
        
    else:
        grid_temps = ro.r(&#34;NULL&#34;)
        grid_press = ro.r(&#34;NULL&#34;)
        poly_coeffs_1 = ro.r(&#34;NULL&#34;)
        poly_coeffs_2 = ro.r(&#34;NULL&#34;)
        
        
    if get_affinity_energy:
        if rxn_filename == None and self.affinity_energy_reactions_raw==None:
            err = (&#34;get_affinity_energy is set to True but a reaction TXT &#34;
                   &#34;file is not specified or redox reactions have not yet &#34;
                   &#34;been generated with make_redox_reactions()&#34;)
            self.err_handler.raise_exception(err)
        elif rxn_filename != None:
            self.__file_exists(rxn_filename, &#39;.txt&#39;)
            
            self.affinity_energy_reactions_raw = pd.read_csv(rxn_filename, sep=&#34;\t&#34;, header=None, names=[&#34;col&#34;+str(i) for i in range(1,50)])
            load_rxn_file = True
        else:
            if self.thermo.thermo_db_type != &#34;CSV&#34;:
                if self.verbose &gt; 0:
                    warn_msg = (&#34;Warning: get_affinity_energy is set to True but &#34;
                        &#34;the active thermodynamic database (&#34;+self.thermo.db+&#34;) is not &#34;
                        &#34;in CSV format. This indicates a possible mismatch between &#34;
                        &#34;the thermodynamic database used to generate redox reactions &#34;
                        &#34;and the one used in this speciation calculation. Continuing anyway...&#34;)
                    print(warn_msg)
            rxn_filename = self.affinity_energy_reactions_raw
            load_rxn_file = False
        

        
    else:
        rxn_filename = &#34;&#34;
        load_rxn_file=False

    
    # handle Alter/Suppress options
    # e.g. [[&#34;CaCl+&#34;, &#34;AugmentLogK&#34;, -1], [&#34;CaOH+&#34;, &#34;Suppress&#34;]]
    alter_options_dict = {}
    if len(alter_options) &gt; 0:
        for ao in alter_options:
            if not isinstance(ao, list):
                err = (&#34;alter_options must be a list of lists, e.g.,\n&#34;
                      &#34;[[&#39;CaCl+&#39;, &#39;AugmentLogK&#39;, -1], [&#39;CaOH+&#39;, &#39;Suppress&#39;]]&#34;
                      &#34;\nor\n[[&#39;CaHCO3+&#39;, &#39;Suppress&#39;]]&#34;)
                self.err_handler.raise_exception(err)
            key = ao[0]
            if ao[1] == &#34;Suppress&#34; and len(ao) == 2:
                ao += [&#34;0&#34;]
            alter_options_dict[key] = _convert_to_RVector(list(ao[1:]))
    alter_options = ro.ListVector(alter_options_dict)
    
    input_dir = &#34;rxn_3i&#34;
    output_dir = &#34;rxn_3o&#34;
    pickup_dir = &#34;rxn_3p&#34;
        
    # preprocess for EQ3 using R scripts
    self._capture_r_output()
    
    r_prescript = pkg_resources.resource_string(
        __name__, &#39;preprocess_for_EQ3.r&#39;).decode(&#34;utf-8&#34;)
    ro.r(r_prescript)
    
    input_processed_list = ro.r.preprocess(input_filename=input_filename,
                                           exclude=_convert_to_RVector(exclude),
                                           grid_temps=_convert_to_RVector(grid_temps),
                                           grid_press=_convert_to_RVector(grid_press),
                                           strict_minimum_pressure=strict_minimum_pressure,
                                           dynamic_db=dynamic_db,
                                           poly_coeffs_1=poly_coeffs_1,
                                           poly_coeffs_2=poly_coeffs_2,
                                           water_model=water_model,
                                           verbose=self.verbose)
    
    
    self._print_captured_r_output()
    
    self.df_input_processed = ro.conversion.rpy2py(input_processed_list.rx2(&#34;df&#34;))
    
    
    if blanks_are_0:
        self.df_input_processed = self.df_input_processed.fillna(1E-18)
    
    self.__mk_check_del_directory(&#39;rxn_3i&#39;)
    self.__mk_check_del_directory(&#39;rxn_3o&#39;)
    self.__mk_check_del_directory(&#39;rxn_3p&#39;)
    if dynamic_db:
        self.__mk_check_del_directory(&#39;rxn_data0&#39;)
    
    # Has the user been warned about redox column during write_3i_file()?
    # Prevents repeated warnings.
    warned_about_redox_column = False
    
    self.batch_T = list(input_processed_list.rx2(&#34;temp_degC&#34;))
    self.batch_P = list(input_processed_list.rx2(&#34;pressure_bar&#34;))
    
    # create and run a 3i file for each sample
    for sample_row_index in range(0, self.df_input_processed.shape[0]):
        
        temp_degC = list(input_processed_list.rx2(&#34;temp_degC&#34;))[sample_row_index]
        pressure_bar = list(input_processed_list.rx2(&#34;pressure_bar&#34;))[sample_row_index]
        
        df = self.df_input_processed.iloc[[sample_row_index]] # double brackets to keep as df row instead of series
        
        samplename = str(df.index[0])
        
        # handle dynamic data0 creation
        if dynamic_db:
            
            self.__fill_data0(thermo_df=ro.conversion.rpy2py(thermo_df),
                              data0_file_lines=copy.deepcopy(data0_file_lines),
                              grid_temps=[temp_degC],
                              grid_press=[pressure_bar],
                              db=data0_lettercode,
                              water_model=water_model,
                              activity_model=activity_model,
                              P1=P1,
                              plot_poly_fit=plot_poly_fit,
                              logK_extrapolate=logK_extrapolate,
                              dynamic_db=dynamic_db,
                              verbose=verbose)
            
            if self.thermo.thermo_db_type != &#34;data1&#34;:
                self.runeqpt(data0_lettercode, dynamic_db=True)
            
            if os.path.exists(&#34;data1.&#34;+data0_lettercode) and os.path.isfile(&#34;data1.&#34;+data0_lettercode):
                # store contents of data1 file in AqEquil object
                with open(&#34;data1.&#34;+data0_lettercode, mode=&#39;rb&#39;) as data1:
                    self.data1[samplename] = data1.read()
                try:
                    # move data1
                    shutil.move(&#34;data1.&#34;+data0_lettercode, &#34;eqpt_files/data1.&#34;+data0_lettercode)
                except:
                    if self.verbose &gt; 0:
                        print(&#39;Error: Could not move&#39;, &#34;data1.&#34;+data0_lettercode, &#34;to eqpt_files&#34;)

            data1_path = os.getcwd()+&#34;/eqpt_files&#34; # creating a folder name without spaces to store the data1 overcomes the problem where environment variables with spaces do not work properly when assigned to EQ36DA

            data0_path = &#34;data0.&#34; + data0_lettercode
            
        else:
            pressure_bar = list(input_processed_list.rx2(&#34;pressure_bar&#34;))[sample_row_index]
            data1_path = self.thermo.eq36da
        
        # allowed aq block species are left after any category exclusion in db_args
        allowed_aq_block_species = [&#34;all&#34;]
        if dynamic_db:
            allowed_aq_block_species = list(thermo_df[&#34;name&#34;]) + FIXED_SPECIES
        
        # write 3i files
        self._capture_r_output()

        warned_about_redox_column = ro.r.write_3i_file(df=ro.conversion.py2rpy(df),
                           temp_degC=temp_degC,
                           pressure_bar=pressure_bar,
                           minimum_pressure=input_processed_list.rx2(&#34;minimum_pressure&#34;),
                           strict_minimum_pressure=strict_minimum_pressure,
                           pressure_override=dynamic_db,
                           suppress_missing=suppress_missing,
                           exclude=input_processed_list.rx2(&#34;exclude&#34;),
                           allowed_aq_block_species=_convert_to_RVector(allowed_aq_block_species),
                           charge_balance_on=charge_balance_on,
                           suppress=_convert_to_RVector(suppress),
                           alter_options=alter_options,
                           aq_scale=aq_scale,
                           get_solid_solutions=get_solid_solutions,
                           input_dir=input_dir,
                           redox_flag=redox_flag,
                           redox_aux=redox_aux,
                           default_logfO2=default_logfO2,
                           water_model=water_model,
                           warned_about_redox_column=warned_about_redox_column,
                           activity_model=activity_model,
                           verbose=self.verbose)

        self._print_captured_r_output()
    
        # run EQ3 on each 3i file
        samplename = self.df_input_processed.iloc[sample_row_index, self.df_input_processed.columns.get_loc(&#34;Sample&#34;)]
        filename_3i = self.df_input_processed.index[sample_row_index]+&#34;.3i&#34;
        filename_3o = filename_3i[:-1] + &#39;o&#39;
        filename_3p = filename_3i[:-1] + &#39;p&#39;
        
        
        if dynamic_db:
            dynamic_db_name = self.thermo.thermo_db_filename
        else:
            dynamic_db_name = None
        
        self.runeq3(filename_3i=filename_3i,
                    db=data0_lettercode,
                    samplename=samplename,
                    path_3i=input_dir,
                    path_3o=output_dir,
                    path_3p=pickup_dir,
                    data1_path=data1_path,
                    dynamic_db_name=dynamic_db_name)
        
        # store input, output, and pickup as dicts in AqEquil object
        try:
            with open(input_dir + &#34;/&#34; + filename_3i, &#34;r&#34;) as f:
                lines=f.readlines()
            self.raw_3_input_dict[samplename] = lines
        except:
            pass
        try:
            with open(output_dir + &#34;/&#34; + filename_3o, &#34;r&#34;) as f:
                lines=f.readlines()
            self.raw_3_output_dict[samplename] = lines
        except:
            pass
        try:
            with open(pickup_dir + &#34;/&#34; + filename_3p, &#34;r&#34;) as f:
                lines=f.readlines()
                
            # capture everything after &#34;start of the bottom half&#34;
            top_half = []
            bottom_half = []
            capture = False
            for line in lines:
                if &#34;Start of the bottom half of the input file&#34; in line:
                    capture = True
                if capture:
                    bottom_half.append(line)
                else:
                    top_half.append(line)
                    
            self.raw_3_pickup_dict_top[samplename] = top_half # top half of the 3p file, including header for mixing calcs
            self.raw_3_pickup_dict_bottom[samplename] = bottom_half # the bottom half
            
        except:
            pass
        
        if dynamic_db:
            shutil.move(&#34;data0.dyn&#34;, &#34;rxn_data0/&#34;+filename_3i[0:-3]+&#34;_data0.dat&#34;)

    if self.thermo.custom_data0:
        # delete straggling data1 files generated after running eq3
        if os.path.exists(&#34;data1&#34;) and os.path.isfile(&#34;data1&#34;):
            os.remove(&#34;data1&#34;)

    files_3o = [file+&#34;.3o&#34; for file in self.df_input_processed.index]
    
    df_input_processed_names = _convert_to_RVector(list(self.df_input_processed.columns))
    
    if self.thermo.thermo_db_type == &#34;CSV&#34;:
        custom_obigt = self.thermo.thermo_db
    else:
        custom_obigt = ro.r(&#34;NULL&#34;)
    
    # mine output
    self._capture_r_output()
    
    r_3o_mine = pkg_resources.resource_string(
        __name__, &#39;3o_mine.r&#39;).decode(&#34;utf-8&#34;)
    ro.r(r_3o_mine)
    
    batch_3o = ro.r.main_3o_mine(
        files_3o=_convert_to_RVector(files_3o),
        input_filename=input_filename,
        input_pressures=_convert_to_RVector(list(input_processed_list.rx2(&#34;pressure_bar&#34;))),
        rxn_filename=rxn_filename,
        get_aq_dist=get_aq_dist,
        aq_dist_type=aq_dist_type,
        get_mass_contribution=get_mass_contribution,
        mass_contribution_other=mass_contribution_other,
        get_mineral_sat=get_mineral_sat,
        mineral_sat_type=mineral_sat_type,
        get_redox=get_redox,
        redox_type=redox_type,
        get_charge_balance=get_charge_balance,
        get_ion_activity_ratios=get_ion_activity_ratios,
        get_fugacity=get_fugacity,
        get_basis_totals=get_basis_totals,
        get_solid_solutions=get_solid_solutions,
        get_affinity_energy=get_affinity_energy,
        negative_energy_supplies=negative_energy_supplies,
        load_rxn_file=load_rxn_file,
        not_limiting=_convert_to_RVector(not_limiting),
        batch_3o_filename=batch_3o_filename,
        df_input_processed=ro.conversion.py2rpy(self.df_input_processed),
        # New rpy2 py2rpy2 conversion might not need the workaround below.
        # The old note regarding deprecated pandas2ri is shown below...
        # OLD NOTE:
        # Needed for keeping symbols in column names after porting
        #   df_input_processed in the line above. Some kind of check.names
        #   option for pandas2ri.py2ri would be nice. Workaround:
        df_input_processed_names=df_input_processed_names,
        custom_obigt=custom_obigt,
        water_model=water_model,
        fixed_species=_convert_to_RVector(FIXED_SPECIES),
        verbose=self.verbose,
    )

    self._print_captured_r_output()
    
    if len(batch_3o) == 0:
        self.err_handler.raise_exception(&#34;Could not compile a speciation report. This is &#34;
                        &#34;likely because errors occurred during &#34;
                        &#34;the speciation calculation.&#34;)
        return
    
    if get_mass_contribution:
        mass_contribution = ro.conversion.rpy2py(batch_3o.rx2(&#39;mass_contribution&#39;))
    df_report = ro.conversion.rpy2py(batch_3o.rx2(&#39;report&#39;))
    
    #df_input = ro.conversion.rpy2py(batch_3o.rx2(&#39;input&#39;))
    report_divs = batch_3o.rx2(&#39;report_divs&#39;)

    input_cols = list(report_divs.rx2(&#39;input&#39;))
    df_input = df_report[input_cols].copy()
    
    # add a pressure column to df_input
    df_input[&#34;Pressure_bar&#34;] = pd.Series(dtype=&#39;float&#39;)
    sample_data = batch_3o.rx2(&#39;sample_data&#39;)
    for sample in sample_data:
        df_input.loc[str(sample.rx2(&#39;name&#39;)[0]), &#34;Pressure_bar&#34;] = float(sample.rx2(&#39;pressure&#39;)[0])
    report_divs[0] = _convert_to_RVector(input_cols + [&#34;Pressure_bar&#34;])
        
    # handle headers and subheaders of input section
    headers = [col.split(&#34;_&#34;)[0] for col in list(df_input.columns)]
    headers = [&#34;pH&#34; if header == &#34;H+&#34; else header for header in headers]
    headers = [header+&#34;_(input)&#34; if header not in [&#34;Temperature&#34;, &#34;logfO2&#34;, &#34;Pressure&#34;]+exclude else header for header in headers]
    report_divs[0] = _convert_to_RVector(headers) # modify headers in the &#39;input&#39; section, report_divs[0]
    subheaders = [subheader[1] if len(subheader) &gt; 1 else &#34;&#34; for subheader in [
        col.split(&#34;_&#34;) for col in list(df_input.columns)]]
    multicolumns = pd.MultiIndex.from_arrays(
        [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
    
    df_input.columns = multicolumns

    df_join = df_input

    if get_aq_dist:
        aq_distribution_cols = list(report_divs.rx2(&#39;aq_distribution&#39;))
        df_aq_distribution = df_report[aq_distribution_cols]
        df_aq_distribution = df_aq_distribution.apply(pd.to_numeric, errors=&#39;coerce&#39;)
        
        # create a pH column from H+
        df_aq_distribution[&#34;pH&#34;] = np.nan # pH values are assigned when sample data is assembled later
        
        # handle headers of aq_distribution section
        headers = df_aq_distribution.columns
        subheaders = [aq_dist_type]*(len(headers)-1) # -1 because the last column will have subheader pH (see next line)
        subheaders = subheaders + [&#34;pH&#34;]
        
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        df_aq_distribution.columns = multicolumns
        
        # ensure final pH column is included in report_divs aq_distribution section
        aq_dist_indx = list(report_divs.names).index(&#34;aq_distribution&#34;)
        report_divs[aq_dist_indx] = _convert_to_RVector(list(headers))
        
        df_join = df_join.join(df_aq_distribution)

    if get_mineral_sat:
        mineral_sat_cols = list(report_divs.rx2(&#39;mineral_sat&#39;))
        mineral_sat_cols = [col for col in mineral_sat_cols if col != &#34;df&#34;] # TO DO: why is df appearing in mineral sat cols and redox sections?
        df_mineral_sat = df_report[mineral_sat_cols]
        df_mineral_sat = df_mineral_sat.apply(pd.to_numeric, errors=&#39;coerce&#39;)

        # handle headers of df_mineral_sat section
        if mineral_sat_type == &#34;affinity&#34;:
            mineral_sat_unit = &#34;affinity_kcal&#34;
        elif mineral_sat_type == &#34;logQoverK&#34;:
            mineral_sat_unit = &#34;logQ/K&#34;
        else:
            self.err_handler.raise_exception(
                &#34;mineral_sat_type must be either &#39;affinity&#39; or &#39;logQoverK&#39;&#34;)

        headers = df_mineral_sat.columns
        subheaders = [mineral_sat_unit]*len(headers)
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        df_mineral_sat.columns = multicolumns
        df_join = df_join.join(df_mineral_sat)

    if get_redox:
        redox_cols = list(report_divs.rx2(&#39;redox&#39;))
        redox_cols = [col for col in redox_cols if col != &#34;df&#34;] # TO DO: why is df appearing in mineral sat cols and redox sections?
        df_redox = df_report[redox_cols]
        df_redox = df_redox.apply(pd.to_numeric, errors=&#39;coerce&#39;)

        # handle headers of df_redox section
        if redox_type == &#34;Eh&#34;:
            redox_unit = &#34;Eh_volts&#34;
        elif redox_type == &#34;pe&#34;:
            redox_unit = &#34;pe&#34;
        elif redox_type == &#34;logfO2&#34;:
            redox_unit = &#34;logfO2&#34;
        elif redox_type == &#34;Ah&#34;:
            redox_unit = &#34;Ah_kcal&#34;
        else:
            self.err_handler.raise_exception(
                &#34;redox_type must be either &#39;Eh&#39;, &#39;pe&#39;, &#39;logfO2&#39;, or &#39;Ah&#39;&#34;)

        headers = df_redox.columns
        subheaders = [redox_unit]*len(headers)
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        df_redox.columns = multicolumns
        df_join = df_join.join(df_redox)

    if get_charge_balance:
        charge_balance_cols = list(report_divs.rx2(&#39;charge_balance&#39;))
        df_charge_balance = df_report[charge_balance_cols]
        df_charge_balance = df_charge_balance.apply(pd.to_numeric, errors=&#39;coerce&#39;)

        # handle headers of df_charge_balance section
        headers = df_charge_balance.columns
        subheaders = [&#34;%&#34;]*2 + [&#39;eq/kg.H2O&#39;, &#39;molality&#39;] + \
            [&#39;eq/kg.H2O&#39;]*4 + [&#39;molality&#39;]
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        df_charge_balance.columns = multicolumns
        df_join = df_join.join(df_charge_balance)
        
    if get_ion_activity_ratios:
        if type(report_divs.rx2(&#39;ion_activity_ratios&#39;)) != rpy2.rinterface_lib.sexp.NULLType:
            ion_activity_ratio_cols = list(report_divs.rx2(&#39;ion_activity_ratios&#39;))

            df_ion_activity_ratios = df_report[ion_activity_ratio_cols]
            df_ion_activity_ratios = df_ion_activity_ratios.apply(pd.to_numeric, errors=&#39;coerce&#39;)

            # handle headers of df_ion_activity_ratios section
            headers = df_ion_activity_ratios.columns
            subheaders = [&#34;Log ion-H+ activity ratio&#34;]*len(headers)
            multicolumns = pd.MultiIndex.from_arrays(
                [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
            df_ion_activity_ratios.columns = multicolumns
            df_join = df_join.join(df_ion_activity_ratios)
        
    if get_fugacity:
        fugacity_cols = list(report_divs.rx2(&#39;fugacity&#39;))
        df_fugacity = df_report[fugacity_cols]
        df_fugacity = df_fugacity.apply(pd.to_numeric, errors=&#39;coerce&#39;)
        
        # handle headers of fugacity section
        headers = df_fugacity.columns
        subheaders = [&#34;log_fugacity&#34;]*len(headers)
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        df_fugacity.columns = multicolumns
        df_join = df_join.join(df_fugacity)

    if get_basis_totals:
        sc_cols = list(report_divs.rx2(&#39;basis_totals&#39;))
        df_sc = df_report[sc_cols]
        df_sc = df_sc.apply(pd.to_numeric, errors=&#39;coerce&#39;)
        
        # handle headers of basis_totals section
        headers = df_sc.columns
        subheaders = [&#34;molality&#34;]*(len(headers))
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        df_sc.columns = multicolumns
        df_join = df_join.join(df_sc)
        
    if get_affinity_energy:
        affinity_cols = list(report_divs.rx2(&#39;affinity&#39;))
        energy_cols = list(report_divs.rx2(&#39;energy&#39;))
        
        df_affinity = df_report[affinity_cols]
        df_energy = df_report[energy_cols]
        
        df_affinity = df_affinity.apply(pd.to_numeric, errors=&#39;coerce&#39;)
        df_energy = df_energy.apply(pd.to_numeric, errors=&#39;coerce&#39;)
        
        # handle headers of df_affinity section
        headers = df_affinity.columns
        subheaders = [&#39;cal/mol e-&#39;]*len(headers)
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        df_affinity.columns = multicolumns

        # handle headers of df_energy section
        headers = df_energy.columns
        subheaders = [&#39;cal/kg.H2O&#39;]*len(headers)
        multicolumns = pd.MultiIndex.from_arrays(
            [headers, subheaders], names=[&#39;Sample&#39;, &#39;&#39;])
        df_energy.columns = multicolumns
        df_join = df_join.join(df_affinity)
        df_join = df_join.join(df_energy)

    out_dict = {&#39;sample_data&#39;: {},
                &#39;report&#39;: df_join,
                &#39;input&#39;: df_input, &#39;report_divs&#39;: report_divs}
    
    if get_mass_contribution:
        out_dict[&#39;mass_contribution&#39;] = mass_contribution

    sample_data = batch_3o.rx2(&#39;sample_data&#39;)

    # assemble sample data
    for i, sample in enumerate(sample_data):
        dict_sample_data = {
            &#34;filename&#34;: str(sample.rx2(&#39;filename&#39;)[0]),
            &#34;name&#34;: str(sample.rx2(&#39;name&#39;)[0]),
            &#34;temperature&#34;: float(sample.rx2(&#39;temperature&#39;)[0]),
            &#34;pressure&#34;: float(sample.rx2(&#39;pressure&#39;)[0]),
            &#34;logact_H2O&#34;: float(sample.rx2(&#39;logact_H2O&#39;)[0]),
            &#34;H2O_density&#34;: float(sample.rx2(&#39;H2O_density&#39;)[0]),
            &#34;H2O_molality&#34;: float(sample.rx2(&#39;H2O_molality&#39;)[0]),
            &#34;H2O_log_molality&#34;: float(sample.rx2(&#39;H2O_log_molality&#39;)[0]),
            }

        if get_aq_dist:
            sample_aq_dist = ro.conversion.rpy2py(sample.rx2(&#39;aq_distribution&#39;))
            sample_aq_dist = sample_aq_dist.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            
            sample_pH = -sample_aq_dist.loc[&#34;H+&#34;, &#34;log_activity&#34;]
            out_dict[&#34;report&#34;].loc[str(sample.rx2(&#39;name&#39;)[0]), &#34;pH&#34;] = sample_pH
            
            dict_sample_data.update({&#34;aq_distribution&#34;: sample_aq_dist})

        if get_mass_contribution:
            sample_mass_contribution = mass_contribution[mass_contribution[&#34;sample&#34;] == sample.rx2(&#39;name&#39;)[0]]
            dict_sample_data.update(
                {&#34;mass_contribution&#34;: sample_mass_contribution})

        if get_mineral_sat:
            dict_sample_data.update(
                {&#34;mineral_sat&#34;: ro.conversion.rpy2py(sample.rx2(&#39;mineral_sat&#39;)).apply(pd.to_numeric, errors=&#39;coerce&#39;)})
            # replace sample mineral_sat entry with None if there is no mineral saturation data.
            if(len(dict_sample_data[&#39;mineral_sat&#39;].index) == 1 and dict_sample_data[&#39;mineral_sat&#39;].index[0] == &#39;None&#39;):
                dict_sample_data[&#39;mineral_sat&#39;] = None

        if get_redox:
            dict_sample_data.update(
                {&#34;redox&#34;: ro.conversion.rpy2py(sample.rx2(&#39;redox&#39;)).apply(pd.to_numeric, errors=&#39;coerce&#39;)})

        if get_charge_balance:
            dict_sample_data.update({&#34;charge_balance&#34;: df_charge_balance.loc[sample.rx2(&#39;name&#39;)[0], :]})
        
        if get_ion_activity_ratios:
            
            try:
                dict_sample_data.update(
                    {&#34;ion_activity_ratios&#34;: ro.conversion.rpy2py(sample.rx2(&#39;ion_activity_ratios&#39;))})
            except:
                dict_sample_data[&#39;ion_activity_ratios&#39;] = None
        
        if get_fugacity:
            dict_sample_data.update(
                {&#34;fugacity&#34;: ro.conversion.rpy2py(sample.rx2(&#39;fugacity&#39;)).apply(pd.to_numeric, errors=&#39;coerce&#39;)})
            # replace sample fugacity entry with None if there is no fugacity data.
            if(len(dict_sample_data[&#39;fugacity&#39;].index) == 1 and dict_sample_data[&#39;fugacity&#39;].index[0] == &#39;None&#39;):
                dict_sample_data[&#39;fugacity&#39;] = None
            else:
                dict_sample_data[&#34;fugacity&#34;][&#34;fugacity&#34;] = 10**dict_sample_data[&#34;fugacity&#34;][&#34;log_fugacity&#34;]
                
        if get_basis_totals:
            sc_dist = ro.conversion.rpy2py(sample.rx2(&#39;basis_totals&#39;))
            sc_dist = sc_dist.apply(pd.to_numeric, errors=&#39;coerce&#39;)
            dict_sample_data.update({&#34;basis_totals&#34;: sc_dist})

        if get_solid_solutions:
            sample_solid_solutions = batch_3o.rx2[&#34;sample_data&#34;].rx2[str(sample.rx2(&#39;name&#39;)[0])].rx2[&#34;solid_solutions&#34;]

            if not type(sample_solid_solutions.names) == rpy2.rinterface_lib.sexp.NULLType:

                ss_df_list = []
                for ss in list(sample_solid_solutions.names):
                    df_ss_ideal = ro.conversion.rpy2py(sample_solid_solutions.rx2[str(ss)].rx2[&#34;ideal solution&#34;])
                    df_ss_mineral = ro.conversion.rpy2py(sample_solid_solutions.rx2[str(ss)].rx2[&#34;mineral&#34;])
                    df_merged = pd.merge(df_ss_mineral, df_ss_ideal, left_on=&#39;mineral&#39;, right_on=&#39;component&#39;, how=&#39;left&#39;)
                    df_merged.insert(0, &#39;solid solution&#39;, ss)
                    del df_merged[&#39;component&#39;]
                    ss_df_list.append(df_merged)
            
                dict_sample_data.update(
                    {&#34;solid_solutions&#34;: pd.concat(ss_df_list)})
        
        if get_affinity_energy:
            dict_sample_data.update({&#34;affinity_energy_raw&#34;: ro.conversion.rpy2py(
                sample.rx2(&#39;affinity_energy_raw&#39;))})
            dict_sample_data.update(
                {&#34;affinity_energy&#34;: ro.conversion.rpy2py(sample.rx2(&#39;affinity_energy&#39;))})

        out_dict[&#34;sample_data&#34;].update(
            {sample_data.names[i]: dict_sample_data})

    out_dict.update({&#34;batch_3o&#34;: batch_3o})
    
    out_dict.update({&#34;water_model&#34;:water_model, &#34;grid_temps&#34;:grid_temps, &#34;grid_press&#34;:grid_press})
    
    speciation = Speciation(out_dict, hide_traceback=self.hide_traceback)
    
    if get_affinity_energy:
        speciation.half_cell_reactions = self.half_cell_reactions
        speciation.affinity_energy_reactions_table = self.affinity_energy_reactions_table
        speciation.affinity_energy_formatted_reactions = self.affinity_energy_formatted_reactions
        speciation.show_redox_reactions = self.show_redox_reactions
    
    if report_filename != None:
        if &#34;.csv&#34; in report_filename[-4:]:
            out_dict[&#34;report&#34;].to_csv(report_filename)
        else:
            out_dict[&#34;report&#34;].to_csv(report_filename+&#34;.csv&#34;)

    if delete_generated_folders:
        self._delete_rxn_folders()
        try:
            # delete straggler data1 file
            os.remove(&#34;data1&#34;)
        except:
            pass
    
    if self.verbose &gt; 0:
        print(&#34;Finished!&#34;)
    
    speciation.raw_3_input_dict = self.raw_3_input_dict
    speciation.raw_3_output_dict = self.raw_3_output_dict
    speciation.raw_3_pickup_dict_top = self.raw_3_pickup_dict_top
    speciation.raw_3_pickup_dict_bottom = self.raw_3_pickup_dict_bottom
    speciation.raw_6_input_dict = {}
    speciation.raw_6_output_dict = {}
    speciation.raw_6_pickup_dict = {}
    speciation.thermo = self.thermo
    speciation.data1 = self.data1
    
    speciation.logK_models = self.logK_models
    speciation.batch_T = self.batch_T
    speciation.batch_P = self.batch_P
    
    return speciation</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="AqEquil.AqSpeciation.Error_Handler"><code class="flex name class">
<span>class <span class="ident">Error_Handler</span></span>
<span>(</span><span>clean=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Handles how errors are printed in Jupyter notebooks. By default, errors that
are handled by AqEquil are printed with an error message, but no traceback.
Errors that are not handled by AqEquil, such as those thrown if the user
encounters a bug, will display a full traceback.</p>
<p>If the error handler prints an error message without traceback, all future
errors regardless of origin will be shown without traceback until the
notebook kernel is restarted.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>clean</code></strong> :&ensp;<code>bool</code></dt>
<dd>Report exceptions without traceback? If True, only the error message is
shown. If False, the entire error message, including traceback, is
shown. Ignored if AqEquil is not being run in a Jupyter notebook.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Error_Handler:
    
    &#34;&#34;&#34;
    Handles how errors are printed in Jupyter notebooks. By default, errors that
    are handled by AqEquil are printed with an error message, but no traceback.
    Errors that are not handled by AqEquil, such as those thrown if the user
    encounters a bug, will display a full traceback.
    
    If the error handler prints an error message without traceback, all future
    errors regardless of origin will be shown without traceback until the
    notebook kernel is restarted.
    
    Parameters
    ----------
    clean : bool
        Report exceptions without traceback? If True, only the error message is
        shown. If False, the entire error message, including traceback, is
        shown. Ignored if AqEquil is not being run in a Jupyter notebook.
    
    &#34;&#34;&#34;
    def __init__(self, clean=True):
        self.clean = clean # bool: hide traceback?
        pass
    
    
    @staticmethod
    def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,
                       exception_only=False, running_compiled_code=False):
        
        &#34;&#34;&#34;
        Return a modified ipython showtraceback function that does not display
        traceback when encountering an error.
        &#34;&#34;&#34;
        
        ipython = get_ipython()
        etype, value, tb = sys.exc_info()
        value.__cause__ = None  # suppress chained exceptions
        return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))
        

    def raise_exception(self, msg):
        
        &#34;&#34;&#34;
        Raise an exception that displays the error message without traceback. This
        happens only when the exception is predicted by the AqEquil package
        (e.g., for common user errors).
        &#34;&#34;&#34;
        if self.clean and _isnotebook():
            ipython = get_ipython()
            ipython.showtraceback = self.hide_traceback
            
        raise Exception(msg)</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="AqEquil.AqSpeciation.Error_Handler.hide_traceback"><code class="name flex">
<span>def <span class="ident">hide_traceback</span></span>(<span>exc_tuple=None, filename=None, tb_offset=None, exception_only=False, running_compiled_code=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a modified ipython showtraceback function that does not display
traceback when encountering an error.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,
                   exception_only=False, running_compiled_code=False):
    
    &#34;&#34;&#34;
    Return a modified ipython showtraceback function that does not display
    traceback when encountering an error.
    &#34;&#34;&#34;
    
    ipython = get_ipython()
    etype, value, tb = sys.exc_info()
    value.__cause__ = None  # suppress chained exceptions
    return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="AqEquil.AqSpeciation.Error_Handler.raise_exception"><code class="name flex">
<span>def <span class="ident">raise_exception</span></span>(<span>self, msg)</span>
</code></dt>
<dd>
<div class="desc"><p>Raise an exception that displays the error message without traceback. This
happens only when the exception is predicted by the AqEquil package
(e.g., for common user errors).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def raise_exception(self, msg):
    
    &#34;&#34;&#34;
    Raise an exception that displays the error message without traceback. This
    happens only when the exception is predicted by the AqEquil package
    (e.g., for common user errors).
    &#34;&#34;&#34;
    if self.clean and _isnotebook():
        ipython = get_ipython()
        ipython.showtraceback = self.hide_traceback
        
    raise Exception(msg)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation"><code class="flex name class">
<span>class <span class="ident">Speciation</span></span>
<span>(</span><span>args, hide_traceback=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Stores the output of a speciation calculation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>args</code></strong> :&ensp;<code>dict</code></dt>
<dd>Arguments inherited from class AqEquil.</dd>
<dt><strong><code>hide_traceback</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Hide traceback message when encountering errors handled by this class?
When True, error messages handled by this class will be short and to
the point.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>input</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Pandas dataframe containing user-supplied sample chemistry data.</dd>
<dt><strong><code>mass_contribution</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Pandas dataframe containing basis species contributions to mass balance
of aqueous species.</dd>
<dt><strong><code>batch_3o</code></strong> :&ensp;<code>rpy2 ListVector</code></dt>
<dd>An rpy2 ListVector (R object) containing speciation results, in case
analysis in R is preferred.</dd>
<dt><strong><code>report</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Pandas dataframe reporting major results of speciation calculation in
across all samples.</dd>
<dt><strong><code>report_divs</code></strong> :&ensp;<code>rpy2 ListVector</code></dt>
<dd>An rpy2 ListVector of column names within the different sections of the
speciation report.</dd>
<dt><strong><code>sample_data</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary with sample names as keys and speciation results as values.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Speciation(object):
    
    &#34;&#34;&#34;
    Stores the output of a speciation calculation.
    
    Parameters
    ----------
    args : dict
        Arguments inherited from class AqEquil.
    
    hide_traceback : bool, default True
        Hide traceback message when encountering errors handled by this class?
        When True, error messages handled by this class will be short and to
        the point.
    
    Attributes
    ----------
    input : pd.DataFrame
        Pandas dataframe containing user-supplied sample chemistry data.
    
    mass_contribution : pd.DataFrame
        Pandas dataframe containing basis species contributions to mass balance
        of aqueous species.
    
    batch_3o : rpy2 ListVector
        An rpy2 ListVector (R object) containing speciation results, in case
        analysis in R is preferred.
    
    report : pd.DataFrame
        Pandas dataframe reporting major results of speciation calculation in
        across all samples.
    
    report_divs : rpy2 ListVector
        An rpy2 ListVector of column names within the different sections of the
        speciation report.
    
    sample_data : dict
        Dictionary with sample names as keys and speciation results as values.
    
    &#34;&#34;&#34;
    
    # get functions from the AqEquil class
    _interpolate_logK = AqEquil._interpolate_logK 
    plot_logK_fit = AqEquil.plot_logK_fit
    
    def __init__(self, args, hide_traceback=True):
        self.err_handler = Error_Handler(clean=hide_traceback)
        
        self.reactions_for_plotting = None # stores formatted reactions for plotting results of affinity and energy supply calculations
        for k in args:
            setattr(self, k, args[k])

    def __getitem__(self, item):
         return getattr(self, item)
    
    @staticmethod
    def __unique(seq):
        &#34;&#34;&#34;
        Provide a sequence, get a list of non-repeating elements in the same order.
        &#34;&#34;&#34;
        seen = set()
        seen_add = seen.add
        return [x for x in seq if not (x in seen or seen_add(x))]

    
    def save(self, filename, messages=True):
        &#34;&#34;&#34;
        Save the speciation as a &#39;.speciation&#39; file to your current working
        directory. This file can be loaded with `AqEquil.load(filename)`.
        
        Parameters
        ----------
        filename : str
            The desired name of the file.
            
        messages : str
            Print a message confirming the save?
        &#34;&#34;&#34;
        
        if filename[-11:] != &#39;.speciation&#39;:
            filename = filename + &#39;.speciation&#39;
        
        with open(filename, &#39;wb&#39;) as handle:
            dill.dump(self, handle, protocol=dill.HIGHEST_PROTOCOL)
            if messages:
                print(&#34;Saved as &#39;{}&#39;&#34;.format(filename))

    
    @staticmethod
    def _save_figure(fig, save_as, save_format, save_scale, plot_width, plot_height, ppi):
        if isinstance(save_format, str) and save_format not in [&#39;png&#39;, &#39;jpg&#39;, &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, &#39;html&#39;]:
            self.err_handler.raise_exception(&#34;{}&#34;.format(save_format)+&#34; is an unrecognized &#34;
                            &#34;save format. Supported formats include &#39;png&#39;, &#34;
                            &#34;&#39;jpg&#39;, &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#34;
                            &#34;&#39;json&#39;, or &#39;html&#39;&#34;)
            
        if isinstance(save_format, str):
            if not isinstance(save_as, str):
                save_as = &#34;newplot&#34;
            if save_format==&#34;html&#34;:
                fig.write_html(save_as+&#34;.html&#34;)
                print(&#34;Saved figure as {}&#34;.format(save_as)+&#34;.html&#34;)
                save_format = &#39;png&#39;
            elif save_format in [&#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;]:
                pio.full_figure_for_development(fig, warn=False)
                pio.write_image(fig, save_as+&#34;.&#34;+save_format, format=save_format, scale=save_scale,
                                width=plot_width*ppi, height=plot_height*ppi)
                print(&#34;Saved figure as {}&#34;.format(save_as)+&#34;.&#34;+save_format)
                save_format = &#34;png&#34;
            else:
                pio.write_image(fig, save_as+&#34;.&#34;+save_format, format=save_format, scale=save_scale,
                                width=plot_width*ppi, height=plot_height*ppi)
                print(&#34;Saved figure as {}&#34;.format(save_as)+&#34;.&#34;+save_format)
        else:
            save_format = &#34;png&#34;
            
        return save_as, save_format
    
    
    @staticmethod
    def __get_unit_info(subheader):
        
        unit_name_dict = {
            &#34;pH&#34; : (&#34;&#34;, &#34;pH&#34;),
            &#34;ppm&#34; : (&#34;&#34;, &#34;ppm&#34;),
            &#34;ppb&#34; : (&#34;&#34;, &#34;ppb&#34;),
            &#34;mg/L&#34; : (&#34;&#34;, &#34;mg/L&#34;),
            &#34;degC&#34; : (&#34;temperature&#34;, &#34;C&#34;),
            &#34;log_molality&#34; : (&#34;log molality&#34;, &#34;log(mol/kg)&#34;),
            &#34;Molality&#34; : (&#34;molality&#34;, &#34;mol/kg&#34;),
            &#34;molality&#34; : (&#34;molality&#34;, &#34;mol/kg&#34;),
            &#34;molal&#34; : (&#34;molality&#34;, &#34;mol/kg&#34;),
            &#34;log_activity&#34; : (&#34;log activity&#34;, &#34;&#34;),
            &#34;Log activity&#34; : (&#34;log activity&#34;, &#34;&#34;),
            &#34;mg/kg.sol&#34; : (&#34;&#34;, &#34;mg solute per kg solution&#34;),
            &#34;Alk., eq/kg.H2O&#34; : (&#34;alkalinity&#34;, &#34;eq/kg&#34;),
            &#34;Alk., eq/L&#34; : (&#34;alkalinity&#34;, &#34;eq/L&#34;),
            &#34;Alk., eq/kg.sol&#34; : (&#34;alkalinity&#34;, &#34;eq/kg solution&#34;),
            &#34;Alk., mg/L CaCO3&#34; : (&#34;alkalinity&#34;, &#34;mg/L CaCO3&#34;),
            &#34;Alk., mg/L HCO3-&#34; : (&#34;alkalinity&#34;, &#34;mg/L HCO3-&#34;),
            &#34;pX&#34; : (&#34;-(log activity)&#34;, &#34;-log(mol/kg)&#34;),
            &#34;activity&#34; : (&#34;activity&#34;, &#34;&#34;),
            &#34;log_gamma&#34; : (&#34;log gamma&#34;, &#34;&#34;),
            &#34;gamma&#34; : (&#34;gamma&#34;, &#34;&#34;),
            &#34;affinity_kcal&#34; : (&#34;affinity&#34;, &#34;kcal/mol&#34;),
            &#34;%&#34; : (&#34;&#34;, &#34;%&#34;),
            &#34;Eh_volts&#34; : (&#34;Eh&#34;, &#34;volts&#34;),
            &#34;eq/kg.H2O&#34; : (&#34;charge&#34;, &#34;eq/kg&#34;),
            &#34;logfO2&#34; : (&#34;&#34;, &#34;&#34;),
            &#34;cal/mol e-&#34; : (&#34;affinity&#34;, &#34;cal/mol e-&#34;),
            &#34;cal/kg.H2O&#34; : (&#34;energy supply&#34;, &#34;cal/kg H2O&#34;),
            &#34;Log ion-H+ activity ratio&#34; : (&#34;Log ion-H+ activity ratio&#34;, &#34;&#34;),
            &#34;log_fugacity&#34; : (&#34;log fugacity&#34;, &#34;log(bar)&#34;),
            &#34;fugacity&#34; : (&#34;fugacity&#34;, &#34;bar&#34;),
            &#34;bar&#34; : (&#34;&#34;, &#34;bar&#34;),
        }
        
        out = unit_name_dict.get(subheader)
        
        return out[0], out[1]

    
    def lookup(self, col=None):
        
        &#34;&#34;&#34;
        Look up desired columns in the speciation report.
        
        Parameters
        ----------
        col : str or list of str
            Leave blank to get a list of section names in the report:
            ```speciation.lookup()```
            Provide the name of a section to look up the names of columns in
            that section of the report:
            ```speciation.lookup(&#34;aq_distribution&#34;)```
            Provide a column name (or a list of column names) to retrieve the
            column from the report:
            ```speciation.lookup([&#34;Temperature&#34;, &#34;O2&#34;])```
            
        Returns
        ----------
        Pandas dataframe or list of str
            If a column name (or list of column names) is provided, returns the
            speciation report with only the desired column(s). Otherwise returns
            a list of section names (if no arguments are provided), or a list of
            columns in a section (if a section name is provided).
        &#34;&#34;&#34;
        
        names_length = len(self.report_divs.names)
        
        if col==None and names_length&gt;0:
            return list(self.report_divs.names)
        
        if names_length&gt;0:
            if col in list(self.report_divs.names):
                return list(self.report_divs.rx2(col))
        
        if isinstance(col, str):
            col = [col]
        
        return self.report.iloc[:, self.report.columns.get_level_values(0).isin(set(col))]
    
    
    def __convert_aq_units_to_log_friendly(self, species, rows):

        col_data = self.lookup(species)
        
        col_data = col_data.loc[rows]
        
        if col_data.columns.get_level_values(1) == &#39;log_activity&#39;:
            y = [10**float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = &#39;activity&#39;
        elif col_data.columns.get_level_values(1) == &#39;log_molality&#39;:
            y = [10**float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = &#39;molality&#39;
        elif col_data.columns.get_level_values(1) == &#39;log_gamma&#39;:
            y = [10**float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = &#39;gamma&#39;
        elif col_data.columns.get_level_values(1) == &#39;log_fugacity&#39;:
            y = [10**float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = &#39;fugacity&#39;
        else:
            y = [float(s[0]) if s[0] != &#39;NA&#39; else float(&#34;nan&#34;) for s in col_data.values.tolist()]
            out_unit = col_data.columns.get_level_values(1)[0]
        return y, out_unit
    
    
    def plot_mineral_saturation(self, sample_name, title=None,
                                mineral_sat_type=&#34;affinity&#34;,
                                plot_width=4, plot_height=3, ppi=122,
                                colors=[&#34;blue&#34;, &#34;orange&#34;],
                                save_as=None, save_format=None, save_scale=1,
                                interactive=True, plot_out=False):
        &#34;&#34;&#34;
        Vizualize mineral saturation states in a sample as a bar plot.
        
        Parameters
        ----------
        sample_name : str
            Name of the sample to plot.
            
        title : str, optional
            Title of the plot.
        
        mineral_sat_type : str, default &#34;affinity&#34;
            Metric for mineral saturation state to plot. Can be &#34;affinity&#34; or
            &#34;logQoverK&#34;.
        
        colors : list of two str, default [&#34;blue&#34;, &#34;orange&#34;]
            Sets the color of the bars representing supersaturated
            and undersaturated states, respectively.
            
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.

        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.

        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
        &#34;&#34;&#34;
        
        if sample_name not in self.report.index:
            msg = (&#34;Could not find &#39;{}&#39;&#34;.format(sample_name)+&#34; among sample &#34;
                   &#34;names in the speciation report. Sample names include &#34;
                   &#34;{}&#34;.format(list(self.report.index)))
            self.err_handler.raise_exception(msg)
        
        if isinstance(self.sample_data[sample_name].get(&#39;mineral_sat&#39;, None), pd.DataFrame):
            mineral_data = self.sample_data[sample_name][&#39;mineral_sat&#39;][mineral_sat_type].astype(float).sort_values(ascending=False)
            x = mineral_data.index
        else:
            msg = (&#34;This sample does not have mineral saturation state data.&#34;
                   &#34;To generate this data, ensure get_mineral_sat=True when &#34;
                   &#34;running speciate(), or ensure this sample has &#34;
                   &#34;mineral-forming basis species.&#34;)
            self.err_handler.raise_exception(msg)
        
        color_list = [colors[0] if m &gt;= 0 else colors[1] for m in mineral_data]
            
        if mineral_sat_type == &#34;affinity&#34;:
            ylabel = &#39;affinity, kcal/mol&#39;
        if mineral_sat_type == &#34;logQoverK&#34;:
            ylabel = &#39;logQ/K&#39;
        
        if title==None:
            title = sample_name + &#34; mineral saturation index&#34;
        
        df = pd.DataFrame(mineral_data)

        fig = px.bar(df, x=df.index, y=&#34;affinity&#34;,
            height=plot_height*ppi, width=plot_width*ppi,
            labels={&#39;affinity&#39;: ylabel}, template=&#34;simple_white&#34;)
        
        fig.update_traces(hovertemplate = &#34;%{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&#34;,
                          marker_color=color_list)
        
        fig.update_layout(xaxis_tickangle=-45, xaxis_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                          margin={&#34;t&#34;:40},
                          xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True, &#39;exponentformat&#39;:&#39;power&#39;})
        
        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)

        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                             &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                             &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                             &#39;toggleSpikelines&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                             &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                             &#39;filename&#39;: save_as,
                                             &#39;height&#39;: plot_height*ppi,
                                             &#39;width&#39;: plot_width*ppi,
                                             &#39;scale&#39;: save_scale,
                                          },
                 }
        if not interactive:
            config[&#39;staticPlot&#39;] = True

        if plot_out:
            return fig
        else:
            fig.show(config=config)

    

    def barplot(self, y=&#34;pH&#34;, title=None, convert_log=True, show_missing=True,
                plot_width=4, plot_height=3, ppi=122, colormap=&#34;WORM&#34;,
                save_as=None, save_format=None, save_scale=1,
                interactive=True, plot_out=False):
        
        &#34;&#34;&#34;
        Show a bar plot to vizualize one or more variables across all samples.
        
        Parameters
        ----------
        y : str or list of str, default &#34;pH&#34;
            Name (or list of names) of the variables to plot. Valid variables
            are columns in the speciation report.

        title : str, optional
            Title of the plot.
            
        convert_log : bool, default True
            Convert units &#34;log_activity&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, and
            &#34;log_fugacity&#34; to &#34;activity&#34;, &#34;molality&#34;, &#34;gamma&#34;, and &#34;fugacity&#34;,
            respectively?
        
        show_missing : bool, default True
            Show samples that do not have bars?
        
        plot_width, plot_height : numeric, default 4 by 3
            Width and height of the plot, in inches.

        ppi : numeric, default 122
            Pixels per inch. Along with `plot_width` and `plot_height`,
            determines the size of interactive plots.
        
        colormap : str, default &#34;WORM&#34;
            Name of the colormap to color plotted data. Accepts &#34;WORM&#34;,
            &#34;colorblind&#34;, or matplotlib colormaps.
            See https://matplotlib.org/stable/tutorials/colors/colormaps.html
            The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
            Color blindness. Nat Methods 8, 441 (2011).
            https://doi.org/10.1038/nmeth.1618
            
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.
        
        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.

        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
            
        Returns
        -------
        fig : Plotly figure object
            A figure object is returned if `plot_out` is true. Otherwise, a
            figure is simply displayed.
        &#34;&#34;&#34;

        if not isinstance(y, list):
            y = [y]

        colors = _get_colors(colormap, len(y))

        # convert rgba to hex
        colors = [matplotlib.colors.rgb2hex(c) for c in colors]

        # map each species to its color, e.g.,
        # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
        dict_species_color = {sp:color for sp,color in zip(y, colors)}
        
        # html format color dict key names
        dict_species_color = {chemlabel(k):v for k,v in dict_species_color.items()}
            
        y_cols = self.lookup(y)

        if not show_missing:
            y_cols = y_cols.dropna(how=&#39;all&#39;) # this df will keep subheaders
        x = y_cols.index # names of samples

        df = self.lookup([&#34;name&#34;]+y).copy()
        if not show_missing:
            df = df.dropna(how=&#39;all&#39;) # this df will lose subheaders (flattened)
        df.loc[:, &#34;name&#34;] = df.index
        df.columns = df.columns.get_level_values(0)

        
        for i, yi in enumerate(y):
            y_col = y_cols.iloc[:, y_cols.columns.get_level_values(0)==yi]

            try:
                subheader = y_col.columns.get_level_values(1)[0]
            except:
                msg = (&#34;Could not find &#39;{}&#39; &#34;.format(yi)+&#34;in the speciation &#34;
                       &#34;report. Available variables include &#34;
                      &#34;{}&#34;.format(list(set(self.report.columns.get_level_values(0)))))
                self.err_handler.raise_exception(msg)
            try:
                unit_type, unit = self.__get_unit_info(subheader)
            except:
                unit_type = &#34;&#34;
                unit = &#34;&#34;
                
            try:
                y_vals = [float(y0[0]) if y0[0] != &#39;NA&#39; else float(&#34;nan&#34;) for y0 in y_col.values.tolist()]
            except:
                msg = (&#34;One or more the values belonging to &#34;
                       &#34;&#39;{}&#39; are non-numeric and cannot be plotted.&#34;.format(y_col.columns.get_level_values(0)[0]))
                self.err_handler.raise_exception(msg)

            if convert_log and [abs(y0) for y0 in y_vals] != y_vals: # convert to bar-friendly units if possible
                if subheader in [&#34;log_activity&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, &#34;log_fugacity&#34;]:
                    y_plot, out_unit = self.__convert_aq_units_to_log_friendly(yi, rows=x)
                    unit_type, unit = self.__get_unit_info(out_unit)
                else:
                    y_plot = y_vals
            else:
                y_plot = y_vals

            if i == 0:
                subheader_previous = subheader
                unit_type_previous = unit_type
            if unit_type != unit_type_previous and i != 0:
                
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(unit, yi_previous, unit_type_previous)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
            elif &#34;activity&#34; in subheader.lower() and &#34;molality&#34; in subheader_previous.lower():
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(&#34;activity&#34;, yi_previous, &#34;molality&#34;)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
            elif &#34;molality&#34; in subheader.lower() and &#34;activity&#34; in subheader_previous.lower():
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(&#34;molality&#34;, yi_previous, &#34;activity&#34;)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)

            yi_previous = copy.deepcopy(yi)
            unit_type_previous = copy.deepcopy(unit_type)
            subheader_previous = copy.deepcopy(subheader)
            
            df.loc[:, yi] = y_plot


        if len(y) &gt; 1:
            if unit != &#34;&#34;:
                ylabel = &#34;{} [{}]&#34;.format(unit_type, unit)
            else:
                ylabel = unit_type

        else:
            if &#39;pH&#39; in y:
                ylabel = &#39;pH&#39;
            elif &#39;Temperature&#39; in y:
                ylabel = &#39;Temperature [C]&#39;
            else:
                if unit != &#34;&#34;:
                    ylabel = &#34;{} {} [{}]&#34;.format(chemlabel(y[0]), unit_type, unit)
                else:
                    ylabel = &#34;{} {}&#34;.format(chemlabel(y[0]), unit_type)

        
        df = pd.melt(df, id_vars=[&#34;name&#34;], value_vars=y)
        df = df.rename(columns={&#34;Sample&#34;: &#34;y_variable&#34;, &#34;value&#34;: &#34;y_value&#34;})

        df[&#39;y_variable&#39;] = df[&#39;y_variable&#39;].apply(chemlabel)
        
        
        if (unit_type == &#34;energy supply&#34; or unit_type == &#34;affinity&#34;) and isinstance(self.affinity_energy_formatted_reactions, pd.DataFrame):
            
            # get formatted reactions to display
            if not isinstance(self.reactions_for_plotting, pd.DataFrame):

                self.reactions_for_plotting = self.show_redox_reactions(formatted=True,
                                                                       charge_sign_at_end=False,
                                                                       show=False, simplify=True)

            y_find = [yi.replace(&#34;_energy&#34;, &#34;&#34;).replace(&#34;_affinity&#34;, &#34;&#34;) for yi in y]
            
            rxns = self.reactions_for_plotting.loc[y_find, :][&#34;reaction&#34;].tolist()
            
            # get the formatted reactions in the right order, then add as a
            # column in df
            formatted_rxn_list = []
            for rxn in rxns:
                for i in range(0,len(x)):
                    formatted_rxn_list.append(rxn)
            df[&#34;formatted_rxns&#34;] = formatted_rxn_list

            if len(y) == 1:
                ylabel = &#34;{}&lt;br&gt;{} [{}]&#34;.format(chemlabel(y_find[0]), unit_type, unit)
            
            # customdata for displaying reactions has to be here instead of in update_traces
            fig = px.bar(df, x=&#34;name&#34;, y=&#34;y_value&#34;,
                height=plot_height*ppi, width=plot_width*ppi,
                color=&#39;y_variable&#39;, barmode=&#39;group&#39;,
                labels={&#39;y_value&#39;: ylabel}, template=&#34;simple_white&#34;,
                color_discrete_map=dict_species_color, custom_data=[&#39;formatted_rxns&#39;])
            
            fig.update_traces(
                hovertemplate = &#34;%{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&lt;br&gt;%{customdata}&#34;)

        else:
            
            fig = px.bar(df, x=&#34;name&#34;, y=&#34;y_value&#34;,
                height=plot_height*ppi, width=plot_width*ppi,
                color=&#39;y_variable&#39;, barmode=&#39;group&#39;,
                labels={&#39;y_value&#39;: ylabel}, template=&#34;simple_white&#34;,
                color_discrete_map=dict_species_color)
            
            fig.update_traces(hovertemplate = &#34;%{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&#34;)

        fig.update_layout(xaxis_tickangle=-45, xaxis_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                          legend_title=None, margin={&#34;t&#34;: 40},
                          xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True, &#39;exponentformat&#39;:&#39;power&#39;})
        if len(y) == 1:
            fig.update_layout(showlegend=False)

        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)
            
        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                             &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                             &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                             &#39;toggleSpikelines&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                             &#39;format&#39;: save_format,
                                             &#39;filename&#39;: save_as,
                                             &#39;height&#39;: plot_height*ppi,
                                             &#39;width&#39;: plot_width*ppi,
                                             &#39;scale&#39;: save_scale,
                                           },
                  }
        if not interactive:
            config[&#39;staticPlot&#39;] = True

        if plot_out:
            return fig
        else:
            fig.show(config=config)

        
    def scatterplot(self, x=&#34;pH&#34;, y=&#34;Temperature&#34;, title=None,
                          plot_width=4, plot_height=3, ppi=122,
                          fill_alpha=0.7, point_size=10,
                          ylab=None, lineplot=False,
                          colormap=&#34;WORM&#34;, save_as=None, save_format=None,
                          save_scale=1, interactive=True, plot_out=False):
        
        &#34;&#34;&#34;
        Vizualize two or more sample variables with a scatterplot.
        
        Parameters
        ----------
        x, y : str, default for x is &#34;pH&#34;, default for y is &#34;Temperature&#34;
            Names of the variables to plot against each other. Valid variables
            are columns in the speciation report. `y` can be a list of
            of variable names for a multi-series scatterplot.

        title : str, optional
            Title of the plot.
        
        plot_width, plot_height : numeric, default 4 by 3
            Width and height of the plot, in inches. Size of interactive plots
            is also determined by pixels per inch, set by the parameter `ppi`.
        
        ppi : numeric, default 122
            Pixels per inch. Along with `plot_width` and `plot_height`,
            determines the size of interactive plots.
        
        fill_alpha : numeric, default 0.7
            Transparency of scatterpoint area fill.
        
        point_size : numeric, default 10
            Size of scatterpoints.
        
        colormap : str, default &#34;WORM&#34;
            Name of the colormap to color the plotted data. Accepts &#34;WORM&#34;,
            &#34;colorblind&#34;, or matplotlib colormaps.
            See https://matplotlib.org/stable/tutorials/colors/colormaps.html
            The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
            Color blindness. Nat Methods 8, 441 (2011).
            https://doi.org/10.1038/nmeth.1618
            
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.

        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.
    
        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
            
        Returns
        -------
        fig : Plotly figure object
            A figure object is returned if `plot_out` is true. Otherwise, a
            figure is simply displayed.
        &#34;&#34;&#34;

        if not isinstance(y, list):
            y = [y]
        
        if not isinstance(x, str):
            self.err_handler.raise_exception(&#34;x must be a string.&#34;)
        
        x_col = self.lookup(x)
        
        try:
            xsubheader = x_col.columns.get_level_values(1)[0]
        except:
            msg = (&#34;Could not find &#39;{}&#39; &#34;.format(x)+&#34;in the speciation &#34;
                   &#34;report. Available variables include &#34;
                   &#34;{}&#34;.format(list(set(self.report.columns.get_level_values(0)))))
            self.err_handler.raise_exception(msg)
            
        try:
            x_plot = [float(x0[0]) if x0[0] != &#39;NA&#39; else float(&#34;nan&#34;) for x0 in x_col.values.tolist()]
        except:
            msg = (&#34;One or more the values belonging to &#34;
                   &#34;&#39;{}&#39; are non-numeric and cannot be plotted.&#34;.format(x_col.columns.get_level_values(0)[0]))
            self.err_handler.raise_exception(msg)
        
        try:
            xunit_type, xunit = self.__get_unit_info(xsubheader)
        except:
            xunit_type = &#34;&#34;
            xunit = &#34;&#34;

        colors = _get_colors(colormap, len(y), alpha=fill_alpha)
        
        for i, yi in enumerate(y):
            y_col = self.lookup(yi)
            
            try:
                subheader = y_col.columns.get_level_values(1)[0]
            except:
                msg = (&#34;Could not find &#39;{}&#39; &#34;.format(yi)+&#34;in the speciation &#34;
                       &#34;report. Available variables include &#34;
                      &#34;{}&#34;.format(list(set(self.report.columns.get_level_values(0)))))
                self.err_handler.raise_exception(msg)
            try:
                unit_type, unit = self.__get_unit_info(subheader)
            except:
                unit_type = &#34;&#34;
                unit = &#34;&#34;
            
            try:
                y_plot = [float(y0[0]) if y0[0] != &#39;NA&#39; else float(&#34;nan&#34;) for y0 in y_col.values.tolist()]
            except:
                msg = (&#34;One or more the values belonging to &#34;
                       &#34;&#39;{}&#39; are non-numeric and cannot be plotted.&#34;.format(y_col.columns.get_level_values(0)[0]))
                self.err_handler.raise_exception(msg)
                
            if i == 0:
                subheader_previous = subheader
                unit_type_previous = unit_type
            if unit_type != unit_type_previous and i != 0:
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(unit_type, yi_previous, unit_type_previous)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
            elif &#34;activity&#34; in subheader.lower() and &#34;molality&#34; in subheader_previous.lower():
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(&#34;activity&#34;, yi_previous, &#34;molality&#34;)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
            elif &#34;molality&#34; in subheader.lower() and &#34;activity&#34; in subheader_previous.lower():
                msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                       &#34;({}) than {} ({}). &#34;.format(&#34;molality&#34;, yi_previous, &#34;activity&#34;)+&#34;&#34;
                       &#34;Plotted variables must share units.&#34;)
                self.err_handler.raise_exception(msg)
                
            yi_previous = copy.deepcopy(yi)
            unit_type_previous = copy.deepcopy(unit_type)
            subheader_previous = copy.deepcopy(subheader)

        if len(y) &gt; 1:
            if unit != &#34;&#34;:
                ylabel = &#34;{} [{}]&#34;.format(unit_type, unit)
            else:
                ylabel = unit_type
        else:
            if &#39;pH&#39; in y:
                ylabel = &#39;pH&#39;
            elif &#39;Temperature&#39; in y:
                ylabel = &#39;Temperature [C]&#39;
            else:
                y_formatted = chemlabel(y[0])
                if unit != &#34;&#34;:
                    ylabel = &#34;{} {} [{}]&#34;.format(y_formatted, unit_type, unit)
                else:
                    ylabel = &#34;{} {}&#34;.format(y_formatted, unit_type)
        
        if x == &#39;pH&#39;:
            xlabel = &#39;pH&#39;
        elif x == &#39;Temperature&#39;:
            xlabel = &#39;Temperature [C]&#39;
        else:
            x_formatted = chemlabel(x)
            if xunit != &#34;&#34;:
                xlabel = &#34;{} {} [{}]&#34;.format(x_formatted, xunit_type, xunit)
            else:
                xlabel = &#34;{} {}&#34;.format(x_formatted, xunit_type)

        # convert rgba to hex
        colors = [matplotlib.colors.rgb2hex(c) for c in colors]

        # map each species to its color, e.g.,
        # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
        dict_species_color = {sp:color for sp,color in zip(y, colors)}
        
        # html format color dict key names
        dict_species_color = {chemlabel(k):v for k,v in dict_species_color.items()}
        
        df = self.lookup([&#34;name&#34;, x]+y).copy()
        df.loc[:, &#34;name&#34;] = df.index
        df.columns = df.columns.get_level_values(0)
        df = pd.melt(df, id_vars=[&#34;name&#34;, x], value_vars=y)
        df = df.rename(columns={&#34;Sample&#34;: &#34;y_variable&#34;, &#34;value&#34;: &#34;y_value&#34;})
        
        if (unit_type == &#34;energy supply&#34; or unit_type == &#34;affinity&#34;) and isinstance(self.reactions_for_plotting, pd.DataFrame):
            
            # get formatted reactions to display
            if not isinstance(self.reactions_for_plotting, pd.DataFrame):
                self.reactions_for_plotting = self.show_redox_reactions(formatted=True,
                                                                       charge_sign_at_end=False,
                                                                       show=False, simplify=True)
            
            y_find = [yi.replace(&#34;_energy&#34;, &#34;&#34;).replace(&#34;_affinity&#34;, &#34;&#34;) for yi in y]
            
            
            rxns = self.reactions_for_plotting.loc[y_find, :][&#34;reaction&#34;].tolist()
            rxn_dict = {rxn_name:rxn for rxn_name,rxn in zip(y, rxns)}

            if len(y) == 1:
                ylabel = &#34;{}&lt;br&gt;{} [{}]&#34;.format(chemlabel(y_find[0]), unit_type, unit)
            
            df[&#34;formatted_rxn&#34;] = df[&#34;y_variable&#34;].map(rxn_dict)
        else:
            df[&#34;formatted_rxn&#34;] = &#34;&#34;
        
        df[&#39;y_variable&#39;] = df[&#39;y_variable&#39;].apply(chemlabel)
        
        if ylab != None:
            ylabel=ylab
        
        if lineplot:
            fig = px.line(df, x=x, y=&#34;y_value&#34;, color=&#34;y_variable&#34;,
                             hover_data=[x, &#34;y_value&#34;, &#34;y_variable&#34;, &#34;name&#34;, &#34;formatted_rxn&#34;],
                             width=plot_width*ppi, height=plot_height*ppi,
                             labels={x: xlabel,  &#34;y_value&#34;: ylabel},
                             category_orders={&#34;species&#34;: y},
                             color_discrete_map=dict_species_color,
                             custom_data=[&#39;name&#39;, &#39;formatted_rxn&#39;],
                             template=&#34;simple_white&#34;)
        else:
            fig = px.scatter(df, x=x, y=&#34;y_value&#34;, color=&#34;y_variable&#34;,
                             hover_data=[x, &#34;y_value&#34;, &#34;y_variable&#34;, &#34;name&#34;, &#34;formatted_rxn&#34;],
                             width=plot_width*ppi, height=plot_height*ppi,
                             labels={x: xlabel,  &#34;y_value&#34;: ylabel},
                             category_orders={&#34;species&#34;: y},
                             color_discrete_map=dict_species_color,
                             opacity=fill_alpha,
                             custom_data=[&#39;name&#39;, &#39;formatted_rxn&#39;],
                             template=&#34;simple_white&#34;)
        
        
        fig.update_traces(marker=dict(size=point_size),
                          hovertemplate = &#34;%{customdata[0]}&lt;br&gt;&#34;+xlabel+&#34;: %{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&lt;br&gt;%{customdata[1]}&#34;)
        fig.update_layout(legend_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                          margin={&#34;t&#34;: 40},
                          yaxis={&#39;exponentformat&#39;:&#39;power&#39;})
        if len(y) == 1:
            fig.update_layout(showlegend=False)
            
        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)

        config = {&#39;displaylogo&#39;: False, &#39;scrollZoom&#39;: True,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;select2d&#39;, &#39;lasso2d&#39;, &#39;toggleSpikelines&#39;, &#39;resetScale2d&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                           &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                           &#39;filename&#39;: save_as,
                                           &#39;height&#39;: plot_height*ppi,
                                           &#39;width&#39;: plot_width*ppi,
                                           &#39;scale&#39;: save_scale,
                                           },
                 }

        if not interactive:
            config[&#39;staticPlot&#39;] = True
        
        if plot_out:
            return fig
        else:
            fig.show(config=config)

            
    def plot_mass_contribution(self, basis, title=None, sort_by=None,
                                     ascending=True, sort_y_by=None, width=0.9,
                                     colormap=&#34;WORM&#34;, sample_label = &#34;sample&#34;,
                                     colors=None,
                                     plot_width=4, plot_height=3, ppi=122,
                                     save_as=None, save_format=None,
                                     save_scale=1, interactive=True,
                                     plot_out=False):
        
        &#34;&#34;&#34;
        Plot basis species contributions to mass balance of aqueous species
        across all samples.
        
        Parameters
        ----------
        basis : str
            Name of the basis species.

        title : str, optional
            Title of the plot.
            
        sort_by : str, optional
            Name of the variable used to sort samples. Variable names must be
            taken from the speciation report column names. No sorting is done by
            default.
        
        ascending : bool, default True
            Should sample sorting be in ascending order? Descending if False.
            Ignored unless `sort_by` is defined.
        
        sort_y_by : list of str or &#39;alphabetical&#39;, optional
            List of species names in the order that they should be stacked, from
            the bottom of the plot to the top. &#39;alphabetical&#39; will sort species
            alphabetically.
        
        width : float, default 0.9
            Width of bars. No space between bars if width=1.0.
        
        colormap : str, default &#34;WORM&#34;
            Name of the colormap to color the scatterpoints. Accepts &#34;WORM&#34;,
            &#34;colorblind&#34;, or matplotlib colormaps.
            See https://matplotlib.org/stable/tutorials/colors/colormaps.html
            The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
            Color blindness. Nat Methods 8, 441 (2011).
            https://doi.org/10.1038/nmeth.1618
        
        sample_label : str, default &#34;sample&#34;
            Name of the label that appears when hovering over an element in the
            interactive mass contribution plot. By default, this is &#34;sample&#34;.
            However, other words might be more appropriate to describe the
            calculations you are performing. For instance, if you are comparing
            reaction progress, `sample_label = &#34;Xi&#34;` might be more appropriate.
        
        plot_width, plot_height : numeric, default 4 by 3
            Width and height of the plot, in inches. Size of interactive plots
            is also determined by pixels per inch, set by the parameter `ppi`.
            
        ppi : numeric, default 122
            Pixels per inch. Along with `plot_width` and `plot_height`,
            determines the size of interactive plots.
        
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.

        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.
    
        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
            
        Returns
        -------
        fig : Plotly figure object
            A figure object is returned if `plot_out` is true. Otherwise, a
            figure is simply displayed.
        &#34;&#34;&#34;
        
        try:
            self.mass_contribution
        except:
            msg = (&#34;Results for basis species contributions to aqueous mass &#34;
                   &#34;balance could not be found. Ensure that &#34;
                   &#34;get_mass_contribution = True when running speciate().&#34;)
            self.err_handler.raise_exception(msg)
            
        if basis not in set(self.mass_contribution[&#39;basis&#39;]):
            msg = (&#34;The basis species {} &#34;.format(basis)+&#34;could not be found &#34;
                   &#34;among available basis species: &#34;
                   &#34;{}&#34;.format(str(list(set(self.mass_contribution[&#39;basis&#39;])))))
            self.err_handler.raise_exception(msg)
            
        df_sp = copy.deepcopy(self.mass_contribution.loc[self.mass_contribution[&#39;basis&#39;] == basis])
        
        if isinstance(sort_y_by, list):
            for species in sort_y_by:
                if species not in df_sp[&#34;species&#34;]:
                    for sample in set(df_sp[&#34;sample&#34;]):
                        df2 = pd.DataFrame({&#39;sample&#39;:[sample], &#39;basis&#39;:[basis], &#39;species&#39;:[species], &#39;factor&#39;:[None], &#39;molality&#39;:[None], &#39;percent&#39;:[0]})
                        df_sp = pd.concat([df_sp, df2], ignore_index=True)
    
        if sort_by != None:
            if sort_by in self.report.columns.get_level_values(0):
                sort_col = self.lookup(sort_by)
                sort_by_unit = sort_col.columns.get_level_values(1)[0]
                sort_index = sort_col.sort_values([(sort_by, sort_by_unit)], ascending=ascending).index
                
                df_list = []
                for i in sort_index:
                    df_list.append(df_sp[df_sp[&#39;sample&#39;]==i])

                df_sp = pd.concat(df_list)
                
            else:
                msg = (&#34;Could not find {}&#34;.format(sort_by)+&#34; in the &#34;
                       &#34;speciation report. Available variables include &#34;
                       &#34;{}&#34;.format(list(self.report.columns.get_level_values(0))))
                self.err_handler.raise_exception(msg)
        
        df_sp[&#39;percent&#39;] = df_sp[&#39;percent&#39;].astype(float)
        
        unique_species = self.__unique(df_sp[&#34;species&#34;])
        
        if &#34;Other&#34; in unique_species:

            unique_species.append(unique_species.pop(unique_species.index(&#34;Other&#34;)))
        
        labels = self.__unique(df_sp[&#34;sample&#34;])

        bottom = np.array([0]*len(labels))

        if sort_y_by != None:
            if isinstance(sort_y_by, list):
                if len(unique_species) == len(sort_y_by):
                    if len([s for s in unique_species if s in sort_y_by]) == len(unique_species) and len([s for s in sort_y_by if s in unique_species]) == len(unique_species):
                        unique_species = sort_y_by
                    else:
                        valid_needed = [s for s in unique_species if s not in sort_y_by]
                        invalid = [s for s in sort_y_by if s not in unique_species]
                        msg = (&#34;sort_y_by is missing the following species: &#34;
                               &#34;{}&#34;.format(valid_needed)+&#34; and was provided &#34;
                               &#34;these invalid species: {}&#34;.format(invalid))
                        self.err_handler.raise_exception(msg)
                        
                elif len(sort_y_by) &lt; len(unique_species):
                    msg = (&#34;sort_y_by must have of all of the &#34;
                           &#34;following species: {}&#34;.format(unique_species)+&#34;. &#34;
                           &#34;You are missing {}&#34;.format([s for s in unique_species if s not in sort_y_by]))
                    self.err_handler.raise_exception(msg)
#                 else:
#                     msg = (&#34;sort_y_by can only have the &#34;
#                            &#34;following species: {}&#34;.format(unique_species)+&#34;.&#34;)
#                     self.err_handler.raise_exception(msg)
            elif sort_y_by == &#34;alphabetical&#34;:
                if &#34;Other&#34; in unique_species:
                    unique_species_no_other = [sp for sp in unique_species if sp != &#34;Other&#34;]
                    unique_species_no_other = sorted(unique_species_no_other)
                    unique_species = unique_species_no_other + [&#34;Other&#34;]
                else:
                    unique_species = sorted(unique_species)
            else:
                self.err_handler.raise_exception(&#34;sort_y_by must be either None, &#39;alphabetical&#39;, &#34;
                                &#34;or a list of species names.&#34;)
        
        if isinstance(colors, list):
            pass
        else:
            # get colormap
            colors = _get_colors(colormap, len(unique_species))

            # convert rgba to hex
            colors = [matplotlib.colors.rgb2hex(c) for c in colors]

        df_sp[&#34;species&#34;] = df_sp[&#34;species&#34;].apply(chemlabel)
        unique_species = [chemlabel(sp) for sp in unique_species]
        
        if title == None:
            title = &#39;&lt;span style=&#34;font-size: 14px;&#34;&gt;Species accounting for mass balance of {}&lt;/span&gt;&#39;.format(chemlabel(basis))
        
        
        # map each species to its color, e.g.,
        # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
        dict_species_color = {sp:color for sp,color in zip(unique_species, colors)}
        
        category_orders = {&#34;species&#34;: unique_species, &#34;sample&#34;: labels}


        fig = px.bar(df_sp, x=&#34;sample&#34;, y=&#34;percent&#34;, color=&#34;species&#34;,
                     width=plot_width*ppi, height=plot_height*ppi,
                     labels={&#34;sample&#34;: sample_label,  &#34;percent&#34;: &#34;mole %&#34;, &#34;species&#34;: &#34;species&#34;},
                     category_orders=category_orders,
                     color_discrete_map=dict_species_color,
                     template=&#34;simple_white&#34;,
                    )
        fig.update_layout(xaxis_tickangle=-45, xaxis_title=None, legend_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                          margin={&#34;t&#34;: 40}, bargap=0, xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True})

        fig.update_traces(width=width, marker_line_width=0)
        
        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)
            
        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                             &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                             &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                             &#39;toggleSpikelines&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                           &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                           &#39;filename&#39;: save_as,
                                           &#39;height&#39;: plot_height*ppi,
                                           &#39;width&#39;: plot_width*ppi,
                                           &#39;scale&#39;: save_scale,
                                           },
                 }
        
        if not interactive:
            config[&#39;staticPlot&#39;] = True
        
        if plot_out:
            return fig
        else:
            fig.show(config=config)


    def plot_solid_solutions(self, sample, title=None,
                                   width=0.9, colormap=&#34;WORM&#34;,
                                   affinity_plot=True,
                                   affinity_plot_colors=[&#34;blue&#34;, &#34;orange&#34;],
                                   plot_width=4, plot_height=4, ppi=122,
                                   save_as=None, save_format=None,
                                   save_scale=1, interactive=True,
                                   plot_out=False):
        
        &#34;&#34;&#34;
        Plot fractions of minerals of hypothetical solid solutions in a sample.
        
        Parameters
        ----------
        sample : str
            Name of the sample.

        title : str, optional
            Title of the plot.
        
        width : float, default 0.9
            Width of bars. No space between bars if width=1.0.
        
        colormap : str, default &#34;WORM&#34;
            Name of the colormap to color the scatterpoints. Accepts &#34;WORM&#34;,
            &#34;colorblind&#34;, or matplotlib colormaps.
            See https://matplotlib.org/stable/tutorials/colors/colormaps.html
            The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
            Color blindness. Nat Methods 8, 441 (2011).
            https://doi.org/10.1038/nmeth.1618
            
        affinity_plot : bool, default True
            Include the affinity subplot?
        
        affinity_plot_colors : list of two str, default [&#34;blue&#34;, &#34;orange&#34;]
            Colors indicating positive and negative values in the affinity
            subplot, respectively.
            
        plot_width, plot_height : numeric, default 4 by 3
            Width and height of the plot, in inches. Size of interactive plots
            is also determined by pixels per inch, set by the parameter `ppi`.
            
        ppi : numeric, default 122
            Pixels per inch. Along with `plot_width` and `plot_height`,
            determines the size of interactive plots.
        
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.

        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.
    
        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
            
        Returns
        -------
        fig : Plotly figure object
            A figure object is returned if `plot_out` is true. Otherwise, a
            figure is simply displayed.
        &#34;&#34;&#34;

        if sample not in self.sample_data.keys():
            msg = (&#34;The sample &#34;+sample+&#34; was not found in this speciation dataset.&#34;
                   &#34; Samples with solid solutions in this dataset include:&#34;+str([s for s in self.sample_data.keys() if &#34;solid_solutions&#34; in self.sample_data[s].keys()]))
            self.err_handler.raise_exception(msg)
        
        try:
            self.sample_data[sample][&#34;solid_solutions&#34;]
        except:
            msg = (&#34;Results for solid solutions could not be found for this &#34;
                   &#34;sample. Samples with solid solutions in this speciation &#34;
                   &#34;dataset include:&#34;+str([s for s in self.sample_data.keys() if &#34;solid_solutions&#34; in self.sample_data[s].keys()]))
            self.err_handler.raise_exception(msg)
        
        if title == None:
            title = &#34;Hypothetical solid solutions in &#34; + sample
        
        df_full = copy.deepcopy(self.sample_data[sample][&#34;solid_solutions&#34;])

        df = copy.deepcopy(df_full.dropna(subset=[&#39;x&#39;]))
        df = df[df[&#39;x&#39;] != 0]

        unique_minerals = self.__unique(df[&#34;mineral&#34;])
        
        # get colormap
        colors = _get_colors(colormap, len(unique_minerals))
        
        # convert rgba to hex
        colors = [matplotlib.colors.rgb2hex(c) for c in colors]
        
        # map each species to its color, e.g.,
        # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
        dict_minerals_color = {sp:color for sp,color in zip(unique_minerals, colors)}

        solid_solutions = list(dict.fromkeys(df[&#34;solid solution&#34;]))
        
        df_ss_only = df_full[df_full[&#34;x&#34;].isnull()]
        
        mineral_dict = {m:[] for m in unique_minerals}
        for ss in solid_solutions:
            for m in unique_minerals:
                df_sub = df.loc[df[&#34;solid solution&#34;] == ss,]
                frac = df_sub.loc[df_sub[&#34;mineral&#34;] == m, &#34;x&#34;]
                if len(frac) &gt; 0:
                    mineral_dict[m] = mineral_dict[m] + list(frac)
                else:
                    mineral_dict[m].append(0)

        if affinity_plot:
            rows = 2
            specs = [[{&#34;type&#34;: &#34;bar&#34;}], [{&#34;type&#34;: &#34;bar&#34;}]]
        else:
            rows = 1
            specs = [[{&#34;type&#34;: &#34;bar&#34;}]]
                    
        fig = make_subplots(
            rows=rows, cols=1,
            specs=specs,
            vertical_spacing = 0.05
        )

        # subplot 1
        for m in unique_minerals[::-1]:
            fig.add_trace(go.Bar(name=m, x=solid_solutions, y=mineral_dict[m], marker_color=dict_minerals_color[m]), row=1, col=1)
        
        # subplot 2
        if affinity_plot:
            fig.add_trace(go.Bar(name=&#34;ss&#34;, x=solid_solutions, y=df_ss_only[&#34;Aff, kcal&#34;],
                                 marker_color=[affinity_plot_colors[0] if val &gt; 0 else affinity_plot_colors[1] for val in df_ss_only[&#34;Aff, kcal&#34;]],
                                 showlegend=False),
                          row=2, col=1)

        fig.update_layout(barmode=&#39;stack&#39;, xaxis_tickangle=-45, xaxis_title=None, legend_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;}, autosize=False,
                          width=plot_width*ppi, height=plot_height*ppi,
                          margin={&#34;t&#34;: 40}, bargap=0, xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True}, template=&#34;simple_white&#34;)


        fig.update_xaxes(tickangle=-45)
        fig[&#39;layout&#39;][&#39;yaxis&#39;][&#39;title&#39;]=&#39;Mole Fraction&#39;
        if affinity_plot:
            fig[&#39;layout&#39;][&#39;yaxis2&#39;][&#39;title&#39;]=&#39;Affinity, kcal/mol&#39;
            fig.update_xaxes(showticklabels=False) # hide all the xticks
            fig.update_xaxes(showticklabels=True, row=2, col=1)
            
        
        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)
            
        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                             &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                             &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                             &#39;toggleSpikelines&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                           &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                           &#39;filename&#39;: save_as,
                                           &#39;height&#39;: plot_height*ppi,
                                           &#39;width&#39;: plot_width*ppi,
                                           &#39;scale&#39;: save_scale,
                                           },
                 }
        
        if not interactive:
            config[&#39;staticPlot&#39;] = True

        if plot_out:
            return fig
        else:
            fig.show(config=config)
            
            
    def join_6i_p(self, filepath_6i, chain_mt):
        path=&#39;rxn_6i&#39;
        if not os.path.exists(path):
            os.makedirs(path)
        else:
            shutil.rmtree(path)
            os.makedirs(path)
            
        if chain_mt:
            raw_p_dict = self.raw_6_pickup_dict
        else:
            raw_p_dict_bottom = self.raw_3_pickup_dict_bottom
            
        for sample_name in raw_p_dict_bottom.keys():
            sample_filename = self.sample_data[sample_name][&#39;filename&#39;][:-3]
            
            if isinstance(filepath_6i, str):
                # if a string (filepath) is given
                with open(filepath_6i, &#34;r&#34;) as f6i:
                    lines_6i = f6i.readlines()
            else:
                # if a Prepare_Reaction object is given
                all_lines = filepath_6i.formatted_reaction.split(&#34;\n&#34;)
                lines_6i = [e+&#34;\n&#34; for e in all_lines if e]
            
            # trim away any extra newlines at end of pre.6i, then add one.
            while lines_6i[-1] == &#34;\n&#34;:
                lines_6i = lines_6i[:-1]
                
            if lines_6i[-1][-1:] != &#34;\n&#34;: # \n counts as 1 character, not 2
                lines_6i[-1] = lines_6i[-1]+&#34;\n&#34;
                
            lines_3p = raw_p_dict_bottom[sample_name]
            
            lines_to_keep = []
            for line in lines_6i:
                if &#34;Start of the bottom half of the input file&#34; in line:
                    break
                else:
                    lines_to_keep.append(line)
            lines_to_keep += lines_3p
            
            if &#34;{tval}&#34; in &#34;&#34;.join(lines_to_keep):
                # grab temperature
                for line in lines_3p:
                    if &#34;Original temperature&#34; in line:
                        o_t = line.split(&#34;|&#34;)[2]
                for i,line in enumerate(lines_to_keep):
                    if &#34;{tval}&#34; in line:
                        lines_to_keep[i] = line.format(tval=o_t)
                        
            if &#34;{pval}&#34; in &#34;&#34;.join(lines_to_keep):
                # grab temperature
                for line in lines_3p:
                    if &#34;Original pressure&#34; in line:
                        o_p = line.split(&#34;|&#34;)[2]
                for i,line in enumerate(lines_to_keep):
                    if &#34;{pval}&#34; in line:
                        lines_to_keep[i] = line.format(tval=o_p)
            
            with open(path + &#34;/&#34; + sample_filename+&#34;.6i&#34;, &#34;w&#34;) as f:
                f.writelines(lines_to_keep)


    def mt(self, sample):
        &#34;&#34;&#34;
        Retrieve mass transfer results for a sample.
        
        Parameters
        ----------
        sample : str
            Name of the sample for which to retrieve mass transfer results.
            
        Returns
        -------
        An object of class `AqEquil.MassTransfer.Mass_Transfer`.
        &#34;&#34;&#34;
        
        sample_data = getattr(self, &#34;sample_data&#34;)
        return sample_data[sample][&#34;mass_transfer&#34;]</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="AqEquil.AqSpeciation.Speciation.barplot"><code class="name flex">
<span>def <span class="ident">barplot</span></span>(<span>self, y='pH', title=None, convert_log=True, show_missing=True, plot_width=4, plot_height=3, ppi=122, colormap='WORM', save_as=None, save_format=None, save_scale=1, interactive=True, plot_out=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Show a bar plot to vizualize one or more variables across all samples.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code>, default <code>"pH"</code></dt>
<dd>Name (or list of names) of the variables to plot. Valid variables
are columns in the speciation report.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Title of the plot.</dd>
<dt><strong><code>convert_log</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Convert units "log_activity", "log_molality", "log_gamma", and
"log_fugacity" to "activity", "molality", "gamma", and "fugacity",
respectively?</dd>
<dt><strong><code>show_missing</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Show samples that do not have bars?</dd>
<dt><strong><code>plot_width</code></strong>, <strong><code>plot_height</code></strong> :&ensp;<code>numeric</code>, default <code>4 by 3</code></dt>
<dd>Width and height of the plot, in inches.</dd>
<dt><strong><code>ppi</code></strong> :&ensp;<code>numeric</code>, default <code>122</code></dt>
<dd>Pixels per inch. Along with <code>plot_width</code> and <code>plot_height</code>,
determines the size of interactive plots.</dd>
<dt><strong><code>colormap</code></strong> :&ensp;<code>str</code>, default <code>"WORM"</code></dt>
<dd>Name of the colormap to color plotted data. Accepts "WORM",
"colorblind", or matplotlib colormaps.
See <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">https://matplotlib.org/stable/tutorials/colors/colormaps.html</a>
The "colorblind" colormap is referenced from Wong, B. Points of view:
Color blindness. Nat Methods 8, 441 (2011).
<a href="https://doi.org/10.1038/nmeth.1618">https://doi.org/10.1038/nmeth.1618</a></dd>
<dt><strong><code>save_as</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Provide a filename to save this figure. Filetype of saved figure is
determined by <code>save_format</code>.
Note: interactive plots can be saved by clicking the 'Download plot'
button in the plot's toolbar.</dd>
<dt><strong><code>save_format</code></strong> :&ensp;<code>str</code>, default <code>"png"</code></dt>
<dd>Desired format of saved or downloaded figure. Can be 'png', 'jpg',
'jpeg', 'webp', 'svg', 'pdf', 'eps', 'json', or 'html'. If 'html',
an interactive plot will be saved. Only 'png', 'svg', 'jpeg',
and 'webp' can be downloaded with the 'download as' button in the
toolbar of an interactive plot.</dd>
<dt><strong><code>save_scale</code></strong> :&ensp;<code>numeric</code>, default <code>1</code></dt>
<dd>Multiply title/legend/axis/canvas sizes by this factor when saving
the figure.</dd>
<dt><strong><code>interactive</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Return an interactive plot if True or a static plot if False.</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Return a plotly figure object? If True, a plot is not displayed as
it is generated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>Plotly figure object</code></dt>
<dd>A figure object is returned if <code>plot_out</code> is true. Otherwise, a
figure is simply displayed.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def barplot(self, y=&#34;pH&#34;, title=None, convert_log=True, show_missing=True,
            plot_width=4, plot_height=3, ppi=122, colormap=&#34;WORM&#34;,
            save_as=None, save_format=None, save_scale=1,
            interactive=True, plot_out=False):
    
    &#34;&#34;&#34;
    Show a bar plot to vizualize one or more variables across all samples.
    
    Parameters
    ----------
    y : str or list of str, default &#34;pH&#34;
        Name (or list of names) of the variables to plot. Valid variables
        are columns in the speciation report.

    title : str, optional
        Title of the plot.
        
    convert_log : bool, default True
        Convert units &#34;log_activity&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, and
        &#34;log_fugacity&#34; to &#34;activity&#34;, &#34;molality&#34;, &#34;gamma&#34;, and &#34;fugacity&#34;,
        respectively?
    
    show_missing : bool, default True
        Show samples that do not have bars?
    
    plot_width, plot_height : numeric, default 4 by 3
        Width and height of the plot, in inches.

    ppi : numeric, default 122
        Pixels per inch. Along with `plot_width` and `plot_height`,
        determines the size of interactive plots.
    
    colormap : str, default &#34;WORM&#34;
        Name of the colormap to color plotted data. Accepts &#34;WORM&#34;,
        &#34;colorblind&#34;, or matplotlib colormaps.
        See https://matplotlib.org/stable/tutorials/colors/colormaps.html
        The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
        Color blindness. Nat Methods 8, 441 (2011).
        https://doi.org/10.1038/nmeth.1618
        
    save_as : str, optional
        Provide a filename to save this figure. Filetype of saved figure is
        determined by `save_format`.
        Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
        button in the plot&#39;s toolbar.
    
    save_format : str, default &#34;png&#34;
        Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
        &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
        an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
        and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
        toolbar of an interactive plot.

    save_scale : numeric, default 1
        Multiply title/legend/axis/canvas sizes by this factor when saving
        the figure.
    
    interactive : bool, default True
        Return an interactive plot if True or a static plot if False.
        
    plot_out : bool, default False
        Return a plotly figure object? If True, a plot is not displayed as
        it is generated.
        
    Returns
    -------
    fig : Plotly figure object
        A figure object is returned if `plot_out` is true. Otherwise, a
        figure is simply displayed.
    &#34;&#34;&#34;

    if not isinstance(y, list):
        y = [y]

    colors = _get_colors(colormap, len(y))

    # convert rgba to hex
    colors = [matplotlib.colors.rgb2hex(c) for c in colors]

    # map each species to its color, e.g.,
    # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
    dict_species_color = {sp:color for sp,color in zip(y, colors)}
    
    # html format color dict key names
    dict_species_color = {chemlabel(k):v for k,v in dict_species_color.items()}
        
    y_cols = self.lookup(y)

    if not show_missing:
        y_cols = y_cols.dropna(how=&#39;all&#39;) # this df will keep subheaders
    x = y_cols.index # names of samples

    df = self.lookup([&#34;name&#34;]+y).copy()
    if not show_missing:
        df = df.dropna(how=&#39;all&#39;) # this df will lose subheaders (flattened)
    df.loc[:, &#34;name&#34;] = df.index
    df.columns = df.columns.get_level_values(0)

    
    for i, yi in enumerate(y):
        y_col = y_cols.iloc[:, y_cols.columns.get_level_values(0)==yi]

        try:
            subheader = y_col.columns.get_level_values(1)[0]
        except:
            msg = (&#34;Could not find &#39;{}&#39; &#34;.format(yi)+&#34;in the speciation &#34;
                   &#34;report. Available variables include &#34;
                  &#34;{}&#34;.format(list(set(self.report.columns.get_level_values(0)))))
            self.err_handler.raise_exception(msg)
        try:
            unit_type, unit = self.__get_unit_info(subheader)
        except:
            unit_type = &#34;&#34;
            unit = &#34;&#34;
            
        try:
            y_vals = [float(y0[0]) if y0[0] != &#39;NA&#39; else float(&#34;nan&#34;) for y0 in y_col.values.tolist()]
        except:
            msg = (&#34;One or more the values belonging to &#34;
                   &#34;&#39;{}&#39; are non-numeric and cannot be plotted.&#34;.format(y_col.columns.get_level_values(0)[0]))
            self.err_handler.raise_exception(msg)

        if convert_log and [abs(y0) for y0 in y_vals] != y_vals: # convert to bar-friendly units if possible
            if subheader in [&#34;log_activity&#34;, &#34;log_molality&#34;, &#34;log_gamma&#34;, &#34;log_fugacity&#34;]:
                y_plot, out_unit = self.__convert_aq_units_to_log_friendly(yi, rows=x)
                unit_type, unit = self.__get_unit_info(out_unit)
            else:
                y_plot = y_vals
        else:
            y_plot = y_vals

        if i == 0:
            subheader_previous = subheader
            unit_type_previous = unit_type
        if unit_type != unit_type_previous and i != 0:
            
            msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                   &#34;({}) than {} ({}). &#34;.format(unit, yi_previous, unit_type_previous)+&#34;&#34;
                   &#34;Plotted variables must share units.&#34;)
            self.err_handler.raise_exception(msg)
        elif &#34;activity&#34; in subheader.lower() and &#34;molality&#34; in subheader_previous.lower():
            msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                   &#34;({}) than {} ({}). &#34;.format(&#34;activity&#34;, yi_previous, &#34;molality&#34;)+&#34;&#34;
                   &#34;Plotted variables must share units.&#34;)
            self.err_handler.raise_exception(msg)
        elif &#34;molality&#34; in subheader.lower() and &#34;activity&#34; in subheader_previous.lower():
            msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                   &#34;({}) than {} ({}). &#34;.format(&#34;molality&#34;, yi_previous, &#34;activity&#34;)+&#34;&#34;
                   &#34;Plotted variables must share units.&#34;)
            self.err_handler.raise_exception(msg)

        yi_previous = copy.deepcopy(yi)
        unit_type_previous = copy.deepcopy(unit_type)
        subheader_previous = copy.deepcopy(subheader)
        
        df.loc[:, yi] = y_plot


    if len(y) &gt; 1:
        if unit != &#34;&#34;:
            ylabel = &#34;{} [{}]&#34;.format(unit_type, unit)
        else:
            ylabel = unit_type

    else:
        if &#39;pH&#39; in y:
            ylabel = &#39;pH&#39;
        elif &#39;Temperature&#39; in y:
            ylabel = &#39;Temperature [C]&#39;
        else:
            if unit != &#34;&#34;:
                ylabel = &#34;{} {} [{}]&#34;.format(chemlabel(y[0]), unit_type, unit)
            else:
                ylabel = &#34;{} {}&#34;.format(chemlabel(y[0]), unit_type)

    
    df = pd.melt(df, id_vars=[&#34;name&#34;], value_vars=y)
    df = df.rename(columns={&#34;Sample&#34;: &#34;y_variable&#34;, &#34;value&#34;: &#34;y_value&#34;})

    df[&#39;y_variable&#39;] = df[&#39;y_variable&#39;].apply(chemlabel)
    
    
    if (unit_type == &#34;energy supply&#34; or unit_type == &#34;affinity&#34;) and isinstance(self.affinity_energy_formatted_reactions, pd.DataFrame):
        
        # get formatted reactions to display
        if not isinstance(self.reactions_for_plotting, pd.DataFrame):

            self.reactions_for_plotting = self.show_redox_reactions(formatted=True,
                                                                   charge_sign_at_end=False,
                                                                   show=False, simplify=True)

        y_find = [yi.replace(&#34;_energy&#34;, &#34;&#34;).replace(&#34;_affinity&#34;, &#34;&#34;) for yi in y]
        
        rxns = self.reactions_for_plotting.loc[y_find, :][&#34;reaction&#34;].tolist()
        
        # get the formatted reactions in the right order, then add as a
        # column in df
        formatted_rxn_list = []
        for rxn in rxns:
            for i in range(0,len(x)):
                formatted_rxn_list.append(rxn)
        df[&#34;formatted_rxns&#34;] = formatted_rxn_list

        if len(y) == 1:
            ylabel = &#34;{}&lt;br&gt;{} [{}]&#34;.format(chemlabel(y_find[0]), unit_type, unit)
        
        # customdata for displaying reactions has to be here instead of in update_traces
        fig = px.bar(df, x=&#34;name&#34;, y=&#34;y_value&#34;,
            height=plot_height*ppi, width=plot_width*ppi,
            color=&#39;y_variable&#39;, barmode=&#39;group&#39;,
            labels={&#39;y_value&#39;: ylabel}, template=&#34;simple_white&#34;,
            color_discrete_map=dict_species_color, custom_data=[&#39;formatted_rxns&#39;])
        
        fig.update_traces(
            hovertemplate = &#34;%{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&lt;br&gt;%{customdata}&#34;)

    else:
        
        fig = px.bar(df, x=&#34;name&#34;, y=&#34;y_value&#34;,
            height=plot_height*ppi, width=plot_width*ppi,
            color=&#39;y_variable&#39;, barmode=&#39;group&#39;,
            labels={&#39;y_value&#39;: ylabel}, template=&#34;simple_white&#34;,
            color_discrete_map=dict_species_color)
        
        fig.update_traces(hovertemplate = &#34;%{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&#34;)

    fig.update_layout(xaxis_tickangle=-45, xaxis_title=None,
                      title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                      legend_title=None, margin={&#34;t&#34;: 40},
                      xaxis={&#39;fixedrange&#39;:True},
                      yaxis={&#39;fixedrange&#39;:True, &#39;exponentformat&#39;:&#39;power&#39;})
    if len(y) == 1:
        fig.update_layout(showlegend=False)

    save_as, save_format = self._save_figure(fig, save_as, save_format,
                                              save_scale, plot_width,
                                              plot_height, ppi)
        
    config = {&#39;displaylogo&#39;: False,
              &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                         &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                         &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                         &#39;toggleSpikelines&#39;],
              &#39;toImageButtonOptions&#39;: {
                                         &#39;format&#39;: save_format,
                                         &#39;filename&#39;: save_as,
                                         &#39;height&#39;: plot_height*ppi,
                                         &#39;width&#39;: plot_width*ppi,
                                         &#39;scale&#39;: save_scale,
                                       },
              }
    if not interactive:
        config[&#39;staticPlot&#39;] = True

    if plot_out:
        return fig
    else:
        fig.show(config=config)</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation.join_6i_p"><code class="name flex">
<span>def <span class="ident">join_6i_p</span></span>(<span>self, filepath_6i, chain_mt)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def join_6i_p(self, filepath_6i, chain_mt):
    path=&#39;rxn_6i&#39;
    if not os.path.exists(path):
        os.makedirs(path)
    else:
        shutil.rmtree(path)
        os.makedirs(path)
        
    if chain_mt:
        raw_p_dict = self.raw_6_pickup_dict
    else:
        raw_p_dict_bottom = self.raw_3_pickup_dict_bottom
        
    for sample_name in raw_p_dict_bottom.keys():
        sample_filename = self.sample_data[sample_name][&#39;filename&#39;][:-3]
        
        if isinstance(filepath_6i, str):
            # if a string (filepath) is given
            with open(filepath_6i, &#34;r&#34;) as f6i:
                lines_6i = f6i.readlines()
        else:
            # if a Prepare_Reaction object is given
            all_lines = filepath_6i.formatted_reaction.split(&#34;\n&#34;)
            lines_6i = [e+&#34;\n&#34; for e in all_lines if e]
        
        # trim away any extra newlines at end of pre.6i, then add one.
        while lines_6i[-1] == &#34;\n&#34;:
            lines_6i = lines_6i[:-1]
            
        if lines_6i[-1][-1:] != &#34;\n&#34;: # \n counts as 1 character, not 2
            lines_6i[-1] = lines_6i[-1]+&#34;\n&#34;
            
        lines_3p = raw_p_dict_bottom[sample_name]
        
        lines_to_keep = []
        for line in lines_6i:
            if &#34;Start of the bottom half of the input file&#34; in line:
                break
            else:
                lines_to_keep.append(line)
        lines_to_keep += lines_3p
        
        if &#34;{tval}&#34; in &#34;&#34;.join(lines_to_keep):
            # grab temperature
            for line in lines_3p:
                if &#34;Original temperature&#34; in line:
                    o_t = line.split(&#34;|&#34;)[2]
            for i,line in enumerate(lines_to_keep):
                if &#34;{tval}&#34; in line:
                    lines_to_keep[i] = line.format(tval=o_t)
                    
        if &#34;{pval}&#34; in &#34;&#34;.join(lines_to_keep):
            # grab temperature
            for line in lines_3p:
                if &#34;Original pressure&#34; in line:
                    o_p = line.split(&#34;|&#34;)[2]
            for i,line in enumerate(lines_to_keep):
                if &#34;{pval}&#34; in line:
                    lines_to_keep[i] = line.format(tval=o_p)
        
        with open(path + &#34;/&#34; + sample_filename+&#34;.6i&#34;, &#34;w&#34;) as f:
            f.writelines(lines_to_keep)</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation.lookup"><code class="name flex">
<span>def <span class="ident">lookup</span></span>(<span>self, col=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Look up desired columns in the speciation report.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>col</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Leave blank to get a list of section names in the report:
<code>speciation.lookup()</code>
Provide the name of a section to look up the names of columns in
that section of the report:
<code>speciation.lookup("aq_distribution")</code>
Provide a column name (or a list of column names) to retrieve the
column from the report:
<code>speciation.lookup(["Temperature", "O2"])</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Pandas dataframe</code> or <code>list</code> of <code>str</code></dt>
<dd>If a column name (or list of column names) is provided, returns the
speciation report with only the desired column(s). Otherwise returns
a list of section names (if no arguments are provided), or a list of
columns in a section (if a section name is provided).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lookup(self, col=None):
    
    &#34;&#34;&#34;
    Look up desired columns in the speciation report.
    
    Parameters
    ----------
    col : str or list of str
        Leave blank to get a list of section names in the report:
        ```speciation.lookup()```
        Provide the name of a section to look up the names of columns in
        that section of the report:
        ```speciation.lookup(&#34;aq_distribution&#34;)```
        Provide a column name (or a list of column names) to retrieve the
        column from the report:
        ```speciation.lookup([&#34;Temperature&#34;, &#34;O2&#34;])```
        
    Returns
    ----------
    Pandas dataframe or list of str
        If a column name (or list of column names) is provided, returns the
        speciation report with only the desired column(s). Otherwise returns
        a list of section names (if no arguments are provided), or a list of
        columns in a section (if a section name is provided).
    &#34;&#34;&#34;
    
    names_length = len(self.report_divs.names)
    
    if col==None and names_length&gt;0:
        return list(self.report_divs.names)
    
    if names_length&gt;0:
        if col in list(self.report_divs.names):
            return list(self.report_divs.rx2(col))
    
    if isinstance(col, str):
        col = [col]
    
    return self.report.iloc[:, self.report.columns.get_level_values(0).isin(set(col))]</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation.mt"><code class="name flex">
<span>def <span class="ident">mt</span></span>(<span>self, sample)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve mass transfer results for a sample.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sample</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the sample for which to retrieve mass transfer results.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>An object of class <code><a title="AqEquil.MassTransfer.Mass_Transfer" href="MassTransfer.html#AqEquil.MassTransfer.Mass_Transfer">Mass_Transfer</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mt(self, sample):
    &#34;&#34;&#34;
    Retrieve mass transfer results for a sample.
    
    Parameters
    ----------
    sample : str
        Name of the sample for which to retrieve mass transfer results.
        
    Returns
    -------
    An object of class `AqEquil.MassTransfer.Mass_Transfer`.
    &#34;&#34;&#34;
    
    sample_data = getattr(self, &#34;sample_data&#34;)
    return sample_data[sample][&#34;mass_transfer&#34;]</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation.plot_logK_fit"><code class="name flex">
<span>def <span class="ident">plot_logK_fit</span></span>(<span>self, name, plot_out=False, res=200, internal=True, logK_extrapolate=None, T_vals=[])</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the fit of logK values used in the speciation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the chemical species.</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Return a Plotly figure object? If False, a figure is simply shown.
If True, the function returns a Plotly figure object and does
not show the plot.</dd>
<dt><strong><code>res</code></strong> :&ensp;<code>int</code></dt>
<dd>Resolution of the fit line. Higher resolutions will be smoother.</dd>
<dt><strong><code>internal</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Reuse calculated fits if they already exist?</dd>
<dt><strong><code>logK_extrapolate</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Option for extrapolating logK values in the plot. Possible values
for this parameter include 'poly', 'linear', 'flat', or 'none'.
This is for planning and visualization only and does not affect
results in <code>speciate()</code> or <code>create_data0()</code>. Those functions have
their own parameters for setting logK extrapolation options.</dd>
<dt><strong><code>T_vals</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>Option for visualizing how the fit of logK values will be
used to estimate the logK values at the temperatures specified in
the list given to this parameter. This is useful for visualizing
logK extrapolation options defined by <code>logK_extrapolate</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>a Plotly figure object</code></dt>
<dd>Returned if <code>plot_out</code> is True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_logK_fit(self, name, plot_out=False, res=200, internal=True, logK_extrapolate=None, T_vals=[]):
    &#34;&#34;&#34;
    Plot the fit of logK values used in the speciation.

    Parameters
    ----------
    name : str
        Name of the chemical species.
    
    plot_out : bool, default False
        Return a Plotly figure object? If False, a figure is simply shown.
        If True, the function returns a Plotly figure object and does
        not show the plot.
    
    res : int
        Resolution of the fit line. Higher resolutions will be smoother.
        
    internal : bool, default True
        Reuse calculated fits if they already exist?
    
    logK_extrapolate : str, optional
        Option for extrapolating logK values in the plot. Possible values
        for this parameter include &#39;poly&#39;, &#39;linear&#39;, &#39;flat&#39;, or &#39;none&#39;.
        This is for planning and visualization only and does not affect
        results in `speciate()` or `create_data0()`. Those functions have
        their own parameters for setting logK extrapolation options.
    
    T_vals : list, optional
        Option for visualizing how the fit of logK values will be
        used to estimate the logK values at the temperatures specified in
        the list given to this parameter. This is useful for visualizing
        logK extrapolation options defined by `logK_extrapolate`.
    
    Returns
    ----------
    fig : a Plotly figure object
        Returned if `plot_out` is True.

    &#34;&#34;&#34;
    
    if internal and len(self.logK_models.keys()) &gt; 0:
        # use internally calculated logK models already stored...
        if name not in self.logK_models.keys():
            if name not in list(self.thermo.df_rejected_species[&#34;name&#34;]):
                msg = &#34;The chemical species &#34; + str(name) + &#34; is not recognized.&#34;
                self.err_handler.raise_exception(msg)
            else:
                reject_reason = list(self.thermo.df_rejected_species.loc[self.thermo.df_rejected_species[&#39;name&#39;] == name, &#39;reason for rejection&#39;])[0]
                
                msg = (&#34;The chemical species &#34; + str(name) + &#34; cannot be &#34;
                       &#34;plotted because it was rejected from the &#34;
                       &#34;speciation:\n&#34; + str(reject_reason))
                self.err_handler.raise_exception(msg)

        logK_grid = self.logK_models[name][&#34;logK_grid&#34;]
        T_grid = self.logK_models[name][&#34;T_grid&#34;]
        P_grid = self.logK_models[name][&#34;P_grid&#34;]
    
    else:
        # load logK models from Thermodata class&#39;s logK_db
        df_logK = self.thermo.logK_db
        
        i = list(df_logK[&#34;name&#34;]).index(name)
        
        logK_grid = list(df_logK[[&#34;logK1&#34;, &#34;logK2&#34;, &#34;logK3&#34;,
                                  &#34;logK4&#34;, &#34;logK5&#34;, &#34;logK6&#34;,
                                  &#34;logK7&#34;, &#34;logK8&#34;]].iloc[i]) # logK at T and P in datasheet

        T_grid = list(df_logK[[&#34;T1&#34;, &#34;T2&#34;, &#34;T3&#34;,
                               &#34;T4&#34;, &#34;T5&#34;, &#34;T6&#34;,
                               &#34;T7&#34;, &#34;T8&#34;]].iloc[i]) # T for free logK grid

        P_grid = list(df_logK[[&#34;P1&#34;, &#34;P2&#34;, &#34;P3&#34;,
                               &#34;P4&#34;, &#34;P5&#34;, &#34;P6&#34;,
                               &#34;P7&#34;, &#34;P8&#34;]].iloc[i]) # P for free logK grid
        
        if not isinstance(logK_extrapolate, str):
            logK_extrapolate = self.thermo.logK_extrapolate
        
    
    if not isinstance(logK_extrapolate, str):
        logK_extrapolate = self.logK_models[name][&#34;logK_extrapolate&#34;]
    
    if len(T_vals) == 0:
        grid_temps = self.batch_T
    else:
        grid_temps = T_vals
    
    grid_press = self.batch_P
    
    T_grid = [t for t in T_grid if not pd.isna(t)]
    P_grid = [p for p in P_grid if not pd.isna(p)]
    logK_grid = [k for k in logK_grid if not pd.isna(k)]
    
    fig = px.scatter(x=T_grid, y=logK_grid)
    
    if len(grid_temps) &gt; 0:
        if min(grid_temps) &lt;= min(T_grid):
            plot_T_min = min(grid_temps)
        else:
            plot_T_min = min(T_grid)
        if max(grid_temps) &gt;= max(T_grid):
            plot_T_max = max(grid_temps)
        else:
            plot_T_max = max(T_grid)
    else:
        plot_T_min = min(T_grid)
        plot_T_max = max(T_grid)
    
    plot_temps = np.linspace(plot_T_min, plot_T_max, res)

    pred_logK = []
    pred_model = []
    for t in plot_temps:
        logK, model = self._interpolate_logK(t, logK_grid, T_grid, logK_extrapolate)
        pred_logK.append(logK)
        pred_model.append(model)
    
    df_plot = pd.DataFrame({&#34;T&#34;:plot_temps, &#34;logK&#34;:pred_logK, &#34;model&#34;:pred_model})
    
    if logK_extrapolate != &#34;no fit&#34;:
        fig = px.line(df_plot, x=&#39;T&#39;, y=&#39;logK&#39;, color=&#39;model&#39;, title=name, template=&#34;simple_white&#34;)
    else:
        fig = px.line(x=[0], y=[0], title=name, template=&#34;simple_white&#34;) # dummy figure
        
    fig.update_traces(hovertemplate=&#34;T = %{x} C&lt;br&gt;Predicted logK = %{y}&lt;extra&gt;&lt;/extra&gt;&#34;)
    fig.update_layout(xaxis_range=[min(plot_temps) - 0.15*(max(plot_temps) - min(plot_temps)),
                                   max(plot_temps) + 0.15*(max(plot_temps) - min(plot_temps))],
                      xaxis_title=&#34;T,C&#34;, yaxis_title=&#34;logK&#34;)
    
    logK_label = &#34;fitted logK value(s)&#34;
    annotation = &#34;&#34;
    
    if len(grid_temps) &gt; 0:
        for i,gt in enumerate(grid_temps):
            # make vertical lines representing batch temperatures

            if i==0:
                showlegend=True
            else:
                showlegend=False

            if isinstance(grid_press, str):
                ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;br&gt;P = PSAT&lt;extra&gt;&lt;/extra&gt;&#34;
            else:
                if len(grid_press) &gt; 0:
                    ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;br&gt;P = &#34; + str(grid_press[i]) + &#34; bar(s)&lt;extra&gt;&lt;/extra&gt;&#34;
                else:
                    ht_samples= &#34;T = &#34;+str(gt) + &#34; C&lt;extra&gt;&lt;/extra&gt;&#34;
                    
            if len(T_grid) &gt; 1:
                
                if logK_extrapolate == &#34;none&#34; and (gt &gt; max(T_grid) or gt &lt; min(T_grid)):
                    viz_logK = max(logK_grid)
                else:
                    viz_logK, _ = self._interpolate_logK(gt, logK_grid, T_grid, logK_extrapolate)
                
                vline_y_vals = [min(logK_grid)-0.15*(max(logK_grid)-min(logK_grid)), viz_logK]
                
                
            if logK_extrapolate == &#34;no fit&#34;:
                vline_y_vals = [min(logK_grid)-0.15*(max(logK_grid)-min(logK_grid)), logK_grid[i]]
                logK_label = &#34;calculated LogK value(s)&#34;
                annotation = (&#34;LogK values are calculated from&lt;br&gt;G of dissociation into basis species&#34;
                              &#34;&lt;br&gt;at the T and P of the speciated samples&lt;br&gt;and do not require a fit.&#34;)

            if _all_equal(logK_grid):
                # if a flat horizontal logK fit line...
                # then fix the y-axis range to prevent zoomed-in steppy wierdness
                fig.update_layout(yaxis_range=[logK_grid[0]-1,logK_grid[0]+1])
                vline_y_vals = [logK_grid[0]-1, logK_grid[0]]

            fig.add_trace(
                go.Scatter(x=[gt, gt],
                           y=vline_y_vals,
                           mode=&#34;lines&#34;,
                           line=dict(color=&#39;rgba(255, 0, 0, 0.75)&#39;, width=3, dash=&#34;dot&#34;),
                           legendgroup=&#39;batch temperatures&#39;,
                           name=&#39;batch temperatures&#39;,
                           showlegend=showlegend,
                           hovertemplate=ht_samples,
                          ),
            )
    
    # add fitted logK points
    fig.add_trace(go.Scatter(x=T_grid, y=logK_grid, name=logK_label,
                             mode=&#39;markers&#39;, marker=dict(color=&#34;black&#34;),
                             text = P_grid,
                             hovertemplate=&#34;T = %{x} C&lt;br&gt;P = %{text} bar(s)&lt;br&gt;logK = %{y}&lt;extra&gt;&lt;/extra&gt;&#34;,
                             ),
                  )
    
    fig.add_annotation(x=0, y=0, xref=&#34;paper&#34;, yref=&#34;paper&#34;, align=&#39;left&#39;,
                       text=annotation, bgcolor=&#34;rgba(255, 255, 255, 0.5)&#34;,
                       showarrow=False)
    
    if plot_out:
        return fig
    else:
        fig.show()</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation.plot_mass_contribution"><code class="name flex">
<span>def <span class="ident">plot_mass_contribution</span></span>(<span>self, basis, title=None, sort_by=None, ascending=True, sort_y_by=None, width=0.9, colormap='WORM', sample_label='sample', colors=None, plot_width=4, plot_height=3, ppi=122, save_as=None, save_format=None, save_scale=1, interactive=True, plot_out=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot basis species contributions to mass balance of aqueous species
across all samples.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>basis</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the basis species.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Title of the plot.</dd>
<dt><strong><code>sort_by</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name of the variable used to sort samples. Variable names must be
taken from the speciation report column names. No sorting is done by
default.</dd>
<dt><strong><code>ascending</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Should sample sorting be in ascending order? Descending if False.
Ignored unless <code>sort_by</code> is defined.</dd>
<dt><strong><code>sort_y_by</code></strong> :&ensp;<code>list</code> of <code>str</code> or <code>'alphabetical'</code>, optional</dt>
<dd>List of species names in the order that they should be stacked, from
the bottom of the plot to the top. 'alphabetical' will sort species
alphabetically.</dd>
<dt><strong><code>width</code></strong> :&ensp;<code>float</code>, default <code>0.9</code></dt>
<dd>Width of bars. No space between bars if width=1.0.</dd>
<dt><strong><code>colormap</code></strong> :&ensp;<code>str</code>, default <code>"WORM"</code></dt>
<dd>Name of the colormap to color the scatterpoints. Accepts "WORM",
"colorblind", or matplotlib colormaps.
See <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">https://matplotlib.org/stable/tutorials/colors/colormaps.html</a>
The "colorblind" colormap is referenced from Wong, B. Points of view:
Color blindness. Nat Methods 8, 441 (2011).
<a href="https://doi.org/10.1038/nmeth.1618">https://doi.org/10.1038/nmeth.1618</a></dd>
<dt><strong><code>sample_label</code></strong> :&ensp;<code>str</code>, default <code>"sample"</code></dt>
<dd>Name of the label that appears when hovering over an element in the
interactive mass contribution plot. By default, this is "sample".
However, other words might be more appropriate to describe the
calculations you are performing. For instance, if you are comparing
reaction progress, <code>sample_label = "Xi"</code> might be more appropriate.</dd>
<dt><strong><code>plot_width</code></strong>, <strong><code>plot_height</code></strong> :&ensp;<code>numeric</code>, default <code>4 by 3</code></dt>
<dd>Width and height of the plot, in inches. Size of interactive plots
is also determined by pixels per inch, set by the parameter <code>ppi</code>.</dd>
<dt><strong><code>ppi</code></strong> :&ensp;<code>numeric</code>, default <code>122</code></dt>
<dd>Pixels per inch. Along with <code>plot_width</code> and <code>plot_height</code>,
determines the size of interactive plots.</dd>
<dt><strong><code>save_as</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Provide a filename to save this figure. Filetype of saved figure is
determined by <code>save_format</code>.
Note: interactive plots can be saved by clicking the 'Download plot'
button in the plot's toolbar.</dd>
<dt><strong><code>save_format</code></strong> :&ensp;<code>str</code>, default <code>"png"</code></dt>
<dd>Desired format of saved or downloaded figure. Can be 'png', 'jpg',
'jpeg', 'webp', 'svg', 'pdf', 'eps', 'json', or 'html'. If 'html',
an interactive plot will be saved. Only 'png', 'svg', 'jpeg',
and 'webp' can be downloaded with the 'download as' button in the
toolbar of an interactive plot.</dd>
<dt><strong><code>save_scale</code></strong> :&ensp;<code>numeric</code>, default <code>1</code></dt>
<dd>Multiply title/legend/axis/canvas sizes by this factor when saving
the figure.</dd>
<dt><strong><code>interactive</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Return an interactive plot if True or a static plot if False.</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Return a plotly figure object? If True, a plot is not displayed as
it is generated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>Plotly figure object</code></dt>
<dd>A figure object is returned if <code>plot_out</code> is true. Otherwise, a
figure is simply displayed.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def plot_mass_contribution(self, basis, title=None, sort_by=None,
                                     ascending=True, sort_y_by=None, width=0.9,
                                     colormap=&#34;WORM&#34;, sample_label = &#34;sample&#34;,
                                     colors=None,
                                     plot_width=4, plot_height=3, ppi=122,
                                     save_as=None, save_format=None,
                                     save_scale=1, interactive=True,
                                     plot_out=False):
        
        &#34;&#34;&#34;
        Plot basis species contributions to mass balance of aqueous species
        across all samples.
        
        Parameters
        ----------
        basis : str
            Name of the basis species.

        title : str, optional
            Title of the plot.
            
        sort_by : str, optional
            Name of the variable used to sort samples. Variable names must be
            taken from the speciation report column names. No sorting is done by
            default.
        
        ascending : bool, default True
            Should sample sorting be in ascending order? Descending if False.
            Ignored unless `sort_by` is defined.
        
        sort_y_by : list of str or &#39;alphabetical&#39;, optional
            List of species names in the order that they should be stacked, from
            the bottom of the plot to the top. &#39;alphabetical&#39; will sort species
            alphabetically.
        
        width : float, default 0.9
            Width of bars. No space between bars if width=1.0.
        
        colormap : str, default &#34;WORM&#34;
            Name of the colormap to color the scatterpoints. Accepts &#34;WORM&#34;,
            &#34;colorblind&#34;, or matplotlib colormaps.
            See https://matplotlib.org/stable/tutorials/colors/colormaps.html
            The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
            Color blindness. Nat Methods 8, 441 (2011).
            https://doi.org/10.1038/nmeth.1618
        
        sample_label : str, default &#34;sample&#34;
            Name of the label that appears when hovering over an element in the
            interactive mass contribution plot. By default, this is &#34;sample&#34;.
            However, other words might be more appropriate to describe the
            calculations you are performing. For instance, if you are comparing
            reaction progress, `sample_label = &#34;Xi&#34;` might be more appropriate.
        
        plot_width, plot_height : numeric, default 4 by 3
            Width and height of the plot, in inches. Size of interactive plots
            is also determined by pixels per inch, set by the parameter `ppi`.
            
        ppi : numeric, default 122
            Pixels per inch. Along with `plot_width` and `plot_height`,
            determines the size of interactive plots.
        
        save_as : str, optional
            Provide a filename to save this figure. Filetype of saved figure is
            determined by `save_format`.
            Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
            button in the plot&#39;s toolbar.

        save_format : str, default &#34;png&#34;
            Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
            &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
            an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
            and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
            toolbar of an interactive plot.
    
        save_scale : numeric, default 1
            Multiply title/legend/axis/canvas sizes by this factor when saving
            the figure.
        
        interactive : bool, default True
            Return an interactive plot if True or a static plot if False.
            
        plot_out : bool, default False
            Return a plotly figure object? If True, a plot is not displayed as
            it is generated.
            
        Returns
        -------
        fig : Plotly figure object
            A figure object is returned if `plot_out` is true. Otherwise, a
            figure is simply displayed.
        &#34;&#34;&#34;
        
        try:
            self.mass_contribution
        except:
            msg = (&#34;Results for basis species contributions to aqueous mass &#34;
                   &#34;balance could not be found. Ensure that &#34;
                   &#34;get_mass_contribution = True when running speciate().&#34;)
            self.err_handler.raise_exception(msg)
            
        if basis not in set(self.mass_contribution[&#39;basis&#39;]):
            msg = (&#34;The basis species {} &#34;.format(basis)+&#34;could not be found &#34;
                   &#34;among available basis species: &#34;
                   &#34;{}&#34;.format(str(list(set(self.mass_contribution[&#39;basis&#39;])))))
            self.err_handler.raise_exception(msg)
            
        df_sp = copy.deepcopy(self.mass_contribution.loc[self.mass_contribution[&#39;basis&#39;] == basis])
        
        if isinstance(sort_y_by, list):
            for species in sort_y_by:
                if species not in df_sp[&#34;species&#34;]:
                    for sample in set(df_sp[&#34;sample&#34;]):
                        df2 = pd.DataFrame({&#39;sample&#39;:[sample], &#39;basis&#39;:[basis], &#39;species&#39;:[species], &#39;factor&#39;:[None], &#39;molality&#39;:[None], &#39;percent&#39;:[0]})
                        df_sp = pd.concat([df_sp, df2], ignore_index=True)
    
        if sort_by != None:
            if sort_by in self.report.columns.get_level_values(0):
                sort_col = self.lookup(sort_by)
                sort_by_unit = sort_col.columns.get_level_values(1)[0]
                sort_index = sort_col.sort_values([(sort_by, sort_by_unit)], ascending=ascending).index
                
                df_list = []
                for i in sort_index:
                    df_list.append(df_sp[df_sp[&#39;sample&#39;]==i])

                df_sp = pd.concat(df_list)
                
            else:
                msg = (&#34;Could not find {}&#34;.format(sort_by)+&#34; in the &#34;
                       &#34;speciation report. Available variables include &#34;
                       &#34;{}&#34;.format(list(self.report.columns.get_level_values(0))))
                self.err_handler.raise_exception(msg)
        
        df_sp[&#39;percent&#39;] = df_sp[&#39;percent&#39;].astype(float)
        
        unique_species = self.__unique(df_sp[&#34;species&#34;])
        
        if &#34;Other&#34; in unique_species:

            unique_species.append(unique_species.pop(unique_species.index(&#34;Other&#34;)))
        
        labels = self.__unique(df_sp[&#34;sample&#34;])

        bottom = np.array([0]*len(labels))

        if sort_y_by != None:
            if isinstance(sort_y_by, list):
                if len(unique_species) == len(sort_y_by):
                    if len([s for s in unique_species if s in sort_y_by]) == len(unique_species) and len([s for s in sort_y_by if s in unique_species]) == len(unique_species):
                        unique_species = sort_y_by
                    else:
                        valid_needed = [s for s in unique_species if s not in sort_y_by]
                        invalid = [s for s in sort_y_by if s not in unique_species]
                        msg = (&#34;sort_y_by is missing the following species: &#34;
                               &#34;{}&#34;.format(valid_needed)+&#34; and was provided &#34;
                               &#34;these invalid species: {}&#34;.format(invalid))
                        self.err_handler.raise_exception(msg)
                        
                elif len(sort_y_by) &lt; len(unique_species):
                    msg = (&#34;sort_y_by must have of all of the &#34;
                           &#34;following species: {}&#34;.format(unique_species)+&#34;. &#34;
                           &#34;You are missing {}&#34;.format([s for s in unique_species if s not in sort_y_by]))
                    self.err_handler.raise_exception(msg)
#                 else:
#                     msg = (&#34;sort_y_by can only have the &#34;
#                            &#34;following species: {}&#34;.format(unique_species)+&#34;.&#34;)
#                     self.err_handler.raise_exception(msg)
            elif sort_y_by == &#34;alphabetical&#34;:
                if &#34;Other&#34; in unique_species:
                    unique_species_no_other = [sp for sp in unique_species if sp != &#34;Other&#34;]
                    unique_species_no_other = sorted(unique_species_no_other)
                    unique_species = unique_species_no_other + [&#34;Other&#34;]
                else:
                    unique_species = sorted(unique_species)
            else:
                self.err_handler.raise_exception(&#34;sort_y_by must be either None, &#39;alphabetical&#39;, &#34;
                                &#34;or a list of species names.&#34;)
        
        if isinstance(colors, list):
            pass
        else:
            # get colormap
            colors = _get_colors(colormap, len(unique_species))

            # convert rgba to hex
            colors = [matplotlib.colors.rgb2hex(c) for c in colors]

        df_sp[&#34;species&#34;] = df_sp[&#34;species&#34;].apply(chemlabel)
        unique_species = [chemlabel(sp) for sp in unique_species]
        
        if title == None:
            title = &#39;&lt;span style=&#34;font-size: 14px;&#34;&gt;Species accounting for mass balance of {}&lt;/span&gt;&#39;.format(chemlabel(basis))
        
        
        # map each species to its color, e.g.,
        # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
        dict_species_color = {sp:color for sp,color in zip(unique_species, colors)}
        
        category_orders = {&#34;species&#34;: unique_species, &#34;sample&#34;: labels}


        fig = px.bar(df_sp, x=&#34;sample&#34;, y=&#34;percent&#34;, color=&#34;species&#34;,
                     width=plot_width*ppi, height=plot_height*ppi,
                     labels={&#34;sample&#34;: sample_label,  &#34;percent&#34;: &#34;mole %&#34;, &#34;species&#34;: &#34;species&#34;},
                     category_orders=category_orders,
                     color_discrete_map=dict_species_color,
                     template=&#34;simple_white&#34;,
                    )
        fig.update_layout(xaxis_tickangle=-45, xaxis_title=None, legend_title=None,
                          title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                          margin={&#34;t&#34;: 40}, bargap=0, xaxis={&#39;fixedrange&#39;:True},
                          yaxis={&#39;fixedrange&#39;:True})

        fig.update_traces(width=width, marker_line_width=0)
        
        save_as, save_format = self._save_figure(fig, save_as, save_format,
                                                  save_scale, plot_width,
                                                  plot_height, ppi)
            
        config = {&#39;displaylogo&#39;: False,
                  &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                             &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                             &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                             &#39;toggleSpikelines&#39;],
                  &#39;toImageButtonOptions&#39;: {
                                           &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                           &#39;filename&#39;: save_as,
                                           &#39;height&#39;: plot_height*ppi,
                                           &#39;width&#39;: plot_width*ppi,
                                           &#39;scale&#39;: save_scale,
                                           },
                 }
        
        if not interactive:
            config[&#39;staticPlot&#39;] = True
        
        if plot_out:
            return fig
        else:
            fig.show(config=config)</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation.plot_mineral_saturation"><code class="name flex">
<span>def <span class="ident">plot_mineral_saturation</span></span>(<span>self, sample_name, title=None, mineral_sat_type='affinity', plot_width=4, plot_height=3, ppi=122, colors=['blue', 'orange'], save_as=None, save_format=None, save_scale=1, interactive=True, plot_out=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Vizualize mineral saturation states in a sample as a bar plot.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sample_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the sample to plot.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Title of the plot.</dd>
<dt><strong><code>mineral_sat_type</code></strong> :&ensp;<code>str</code>, default <code>"affinity"</code></dt>
<dd>Metric for mineral saturation state to plot. Can be "affinity" or
"logQoverK".</dd>
<dt><strong><code>colors</code></strong> :&ensp;<code>list</code> of <code>two str</code>, default <code>["blue", "orange"]</code></dt>
<dd>Sets the color of the bars representing supersaturated
and undersaturated states, respectively.</dd>
<dt><strong><code>save_as</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Provide a filename to save this figure. Filetype of saved figure is
determined by <code>save_format</code>.
Note: interactive plots can be saved by clicking the 'Download plot'
button in the plot's toolbar.</dd>
<dt><strong><code>save_format</code></strong> :&ensp;<code>str</code>, default <code>"png"</code></dt>
<dd>Desired format of saved or downloaded figure. Can be 'png', 'jpg',
'jpeg', 'webp', 'svg', 'pdf', 'eps', 'json', or 'html'. If 'html',
an interactive plot will be saved. Only 'png', 'svg', 'jpeg',
and 'webp' can be downloaded with the 'download as' button in the
toolbar of an interactive plot.</dd>
<dt><strong><code>save_scale</code></strong> :&ensp;<code>numeric</code>, default <code>1</code></dt>
<dd>Multiply title/legend/axis/canvas sizes by this factor when saving
the figure.</dd>
<dt><strong><code>interactive</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Return an interactive plot if True or a static plot if False.</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Return a plotly figure object? If True, a plot is not displayed as
it is generated.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_mineral_saturation(self, sample_name, title=None,
                            mineral_sat_type=&#34;affinity&#34;,
                            plot_width=4, plot_height=3, ppi=122,
                            colors=[&#34;blue&#34;, &#34;orange&#34;],
                            save_as=None, save_format=None, save_scale=1,
                            interactive=True, plot_out=False):
    &#34;&#34;&#34;
    Vizualize mineral saturation states in a sample as a bar plot.
    
    Parameters
    ----------
    sample_name : str
        Name of the sample to plot.
        
    title : str, optional
        Title of the plot.
    
    mineral_sat_type : str, default &#34;affinity&#34;
        Metric for mineral saturation state to plot. Can be &#34;affinity&#34; or
        &#34;logQoverK&#34;.
    
    colors : list of two str, default [&#34;blue&#34;, &#34;orange&#34;]
        Sets the color of the bars representing supersaturated
        and undersaturated states, respectively.
        
    save_as : str, optional
        Provide a filename to save this figure. Filetype of saved figure is
        determined by `save_format`.
        Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
        button in the plot&#39;s toolbar.

    save_format : str, default &#34;png&#34;
        Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
        &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
        an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
        and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
        toolbar of an interactive plot.

    save_scale : numeric, default 1
        Multiply title/legend/axis/canvas sizes by this factor when saving
        the figure.
    
    interactive : bool, default True
        Return an interactive plot if True or a static plot if False.
        
    plot_out : bool, default False
        Return a plotly figure object? If True, a plot is not displayed as
        it is generated.
    &#34;&#34;&#34;
    
    if sample_name not in self.report.index:
        msg = (&#34;Could not find &#39;{}&#39;&#34;.format(sample_name)+&#34; among sample &#34;
               &#34;names in the speciation report. Sample names include &#34;
               &#34;{}&#34;.format(list(self.report.index)))
        self.err_handler.raise_exception(msg)
    
    if isinstance(self.sample_data[sample_name].get(&#39;mineral_sat&#39;, None), pd.DataFrame):
        mineral_data = self.sample_data[sample_name][&#39;mineral_sat&#39;][mineral_sat_type].astype(float).sort_values(ascending=False)
        x = mineral_data.index
    else:
        msg = (&#34;This sample does not have mineral saturation state data.&#34;
               &#34;To generate this data, ensure get_mineral_sat=True when &#34;
               &#34;running speciate(), or ensure this sample has &#34;
               &#34;mineral-forming basis species.&#34;)
        self.err_handler.raise_exception(msg)
    
    color_list = [colors[0] if m &gt;= 0 else colors[1] for m in mineral_data]
        
    if mineral_sat_type == &#34;affinity&#34;:
        ylabel = &#39;affinity, kcal/mol&#39;
    if mineral_sat_type == &#34;logQoverK&#34;:
        ylabel = &#39;logQ/K&#39;
    
    if title==None:
        title = sample_name + &#34; mineral saturation index&#34;
    
    df = pd.DataFrame(mineral_data)

    fig = px.bar(df, x=df.index, y=&#34;affinity&#34;,
        height=plot_height*ppi, width=plot_width*ppi,
        labels={&#39;affinity&#39;: ylabel}, template=&#34;simple_white&#34;)
    
    fig.update_traces(hovertemplate = &#34;%{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&#34;,
                      marker_color=color_list)
    
    fig.update_layout(xaxis_tickangle=-45, xaxis_title=None,
                      title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                      margin={&#34;t&#34;:40},
                      xaxis={&#39;fixedrange&#39;:True},
                      yaxis={&#39;fixedrange&#39;:True, &#39;exponentformat&#39;:&#39;power&#39;})
    
    save_as, save_format = self._save_figure(fig, save_as, save_format,
                                              save_scale, plot_width,
                                              plot_height, ppi)

    config = {&#39;displaylogo&#39;: False,
              &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                         &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                         &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                         &#39;toggleSpikelines&#39;],
              &#39;toImageButtonOptions&#39;: {
                                         &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                         &#39;filename&#39;: save_as,
                                         &#39;height&#39;: plot_height*ppi,
                                         &#39;width&#39;: plot_width*ppi,
                                         &#39;scale&#39;: save_scale,
                                      },
             }
    if not interactive:
        config[&#39;staticPlot&#39;] = True

    if plot_out:
        return fig
    else:
        fig.show(config=config)</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation.plot_solid_solutions"><code class="name flex">
<span>def <span class="ident">plot_solid_solutions</span></span>(<span>self, sample, title=None, width=0.9, colormap='WORM', affinity_plot=True, affinity_plot_colors=['blue', 'orange'], plot_width=4, plot_height=4, ppi=122, save_as=None, save_format=None, save_scale=1, interactive=True, plot_out=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot fractions of minerals of hypothetical solid solutions in a sample.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sample</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the sample.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Title of the plot.</dd>
<dt><strong><code>width</code></strong> :&ensp;<code>float</code>, default <code>0.9</code></dt>
<dd>Width of bars. No space between bars if width=1.0.</dd>
<dt><strong><code>colormap</code></strong> :&ensp;<code>str</code>, default <code>"WORM"</code></dt>
<dd>Name of the colormap to color the scatterpoints. Accepts "WORM",
"colorblind", or matplotlib colormaps.
See <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">https://matplotlib.org/stable/tutorials/colors/colormaps.html</a>
The "colorblind" colormap is referenced from Wong, B. Points of view:
Color blindness. Nat Methods 8, 441 (2011).
<a href="https://doi.org/10.1038/nmeth.1618">https://doi.org/10.1038/nmeth.1618</a></dd>
<dt><strong><code>affinity_plot</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Include the affinity subplot?</dd>
<dt><strong><code>affinity_plot_colors</code></strong> :&ensp;<code>list</code> of <code>two str</code>, default <code>["blue", "orange"]</code></dt>
<dd>Colors indicating positive and negative values in the affinity
subplot, respectively.</dd>
<dt><strong><code>plot_width</code></strong>, <strong><code>plot_height</code></strong> :&ensp;<code>numeric</code>, default <code>4 by 3</code></dt>
<dd>Width and height of the plot, in inches. Size of interactive plots
is also determined by pixels per inch, set by the parameter <code>ppi</code>.</dd>
<dt><strong><code>ppi</code></strong> :&ensp;<code>numeric</code>, default <code>122</code></dt>
<dd>Pixels per inch. Along with <code>plot_width</code> and <code>plot_height</code>,
determines the size of interactive plots.</dd>
<dt><strong><code>save_as</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Provide a filename to save this figure. Filetype of saved figure is
determined by <code>save_format</code>.
Note: interactive plots can be saved by clicking the 'Download plot'
button in the plot's toolbar.</dd>
<dt><strong><code>save_format</code></strong> :&ensp;<code>str</code>, default <code>"png"</code></dt>
<dd>Desired format of saved or downloaded figure. Can be 'png', 'jpg',
'jpeg', 'webp', 'svg', 'pdf', 'eps', 'json', or 'html'. If 'html',
an interactive plot will be saved. Only 'png', 'svg', 'jpeg',
and 'webp' can be downloaded with the 'download as' button in the
toolbar of an interactive plot.</dd>
<dt><strong><code>save_scale</code></strong> :&ensp;<code>numeric</code>, default <code>1</code></dt>
<dd>Multiply title/legend/axis/canvas sizes by this factor when saving
the figure.</dd>
<dt><strong><code>interactive</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Return an interactive plot if True or a static plot if False.</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Return a plotly figure object? If True, a plot is not displayed as
it is generated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>Plotly figure object</code></dt>
<dd>A figure object is returned if <code>plot_out</code> is true. Otherwise, a
figure is simply displayed.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_solid_solutions(self, sample, title=None,
                               width=0.9, colormap=&#34;WORM&#34;,
                               affinity_plot=True,
                               affinity_plot_colors=[&#34;blue&#34;, &#34;orange&#34;],
                               plot_width=4, plot_height=4, ppi=122,
                               save_as=None, save_format=None,
                               save_scale=1, interactive=True,
                               plot_out=False):
    
    &#34;&#34;&#34;
    Plot fractions of minerals of hypothetical solid solutions in a sample.
    
    Parameters
    ----------
    sample : str
        Name of the sample.

    title : str, optional
        Title of the plot.
    
    width : float, default 0.9
        Width of bars. No space between bars if width=1.0.
    
    colormap : str, default &#34;WORM&#34;
        Name of the colormap to color the scatterpoints. Accepts &#34;WORM&#34;,
        &#34;colorblind&#34;, or matplotlib colormaps.
        See https://matplotlib.org/stable/tutorials/colors/colormaps.html
        The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
        Color blindness. Nat Methods 8, 441 (2011).
        https://doi.org/10.1038/nmeth.1618
        
    affinity_plot : bool, default True
        Include the affinity subplot?
    
    affinity_plot_colors : list of two str, default [&#34;blue&#34;, &#34;orange&#34;]
        Colors indicating positive and negative values in the affinity
        subplot, respectively.
        
    plot_width, plot_height : numeric, default 4 by 3
        Width and height of the plot, in inches. Size of interactive plots
        is also determined by pixels per inch, set by the parameter `ppi`.
        
    ppi : numeric, default 122
        Pixels per inch. Along with `plot_width` and `plot_height`,
        determines the size of interactive plots.
    
    save_as : str, optional
        Provide a filename to save this figure. Filetype of saved figure is
        determined by `save_format`.
        Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
        button in the plot&#39;s toolbar.

    save_format : str, default &#34;png&#34;
        Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
        &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
        an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
        and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
        toolbar of an interactive plot.

    save_scale : numeric, default 1
        Multiply title/legend/axis/canvas sizes by this factor when saving
        the figure.
    
    interactive : bool, default True
        Return an interactive plot if True or a static plot if False.
        
    plot_out : bool, default False
        Return a plotly figure object? If True, a plot is not displayed as
        it is generated.
        
    Returns
    -------
    fig : Plotly figure object
        A figure object is returned if `plot_out` is true. Otherwise, a
        figure is simply displayed.
    &#34;&#34;&#34;

    if sample not in self.sample_data.keys():
        msg = (&#34;The sample &#34;+sample+&#34; was not found in this speciation dataset.&#34;
               &#34; Samples with solid solutions in this dataset include:&#34;+str([s for s in self.sample_data.keys() if &#34;solid_solutions&#34; in self.sample_data[s].keys()]))
        self.err_handler.raise_exception(msg)
    
    try:
        self.sample_data[sample][&#34;solid_solutions&#34;]
    except:
        msg = (&#34;Results for solid solutions could not be found for this &#34;
               &#34;sample. Samples with solid solutions in this speciation &#34;
               &#34;dataset include:&#34;+str([s for s in self.sample_data.keys() if &#34;solid_solutions&#34; in self.sample_data[s].keys()]))
        self.err_handler.raise_exception(msg)
    
    if title == None:
        title = &#34;Hypothetical solid solutions in &#34; + sample
    
    df_full = copy.deepcopy(self.sample_data[sample][&#34;solid_solutions&#34;])

    df = copy.deepcopy(df_full.dropna(subset=[&#39;x&#39;]))
    df = df[df[&#39;x&#39;] != 0]

    unique_minerals = self.__unique(df[&#34;mineral&#34;])
    
    # get colormap
    colors = _get_colors(colormap, len(unique_minerals))
    
    # convert rgba to hex
    colors = [matplotlib.colors.rgb2hex(c) for c in colors]
    
    # map each species to its color, e.g.,
    # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
    dict_minerals_color = {sp:color for sp,color in zip(unique_minerals, colors)}

    solid_solutions = list(dict.fromkeys(df[&#34;solid solution&#34;]))
    
    df_ss_only = df_full[df_full[&#34;x&#34;].isnull()]
    
    mineral_dict = {m:[] for m in unique_minerals}
    for ss in solid_solutions:
        for m in unique_minerals:
            df_sub = df.loc[df[&#34;solid solution&#34;] == ss,]
            frac = df_sub.loc[df_sub[&#34;mineral&#34;] == m, &#34;x&#34;]
            if len(frac) &gt; 0:
                mineral_dict[m] = mineral_dict[m] + list(frac)
            else:
                mineral_dict[m].append(0)

    if affinity_plot:
        rows = 2
        specs = [[{&#34;type&#34;: &#34;bar&#34;}], [{&#34;type&#34;: &#34;bar&#34;}]]
    else:
        rows = 1
        specs = [[{&#34;type&#34;: &#34;bar&#34;}]]
                
    fig = make_subplots(
        rows=rows, cols=1,
        specs=specs,
        vertical_spacing = 0.05
    )

    # subplot 1
    for m in unique_minerals[::-1]:
        fig.add_trace(go.Bar(name=m, x=solid_solutions, y=mineral_dict[m], marker_color=dict_minerals_color[m]), row=1, col=1)
    
    # subplot 2
    if affinity_plot:
        fig.add_trace(go.Bar(name=&#34;ss&#34;, x=solid_solutions, y=df_ss_only[&#34;Aff, kcal&#34;],
                             marker_color=[affinity_plot_colors[0] if val &gt; 0 else affinity_plot_colors[1] for val in df_ss_only[&#34;Aff, kcal&#34;]],
                             showlegend=False),
                      row=2, col=1)

    fig.update_layout(barmode=&#39;stack&#39;, xaxis_tickangle=-45, xaxis_title=None, legend_title=None,
                      title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;}, autosize=False,
                      width=plot_width*ppi, height=plot_height*ppi,
                      margin={&#34;t&#34;: 40}, bargap=0, xaxis={&#39;fixedrange&#39;:True},
                      yaxis={&#39;fixedrange&#39;:True}, template=&#34;simple_white&#34;)


    fig.update_xaxes(tickangle=-45)
    fig[&#39;layout&#39;][&#39;yaxis&#39;][&#39;title&#39;]=&#39;Mole Fraction&#39;
    if affinity_plot:
        fig[&#39;layout&#39;][&#39;yaxis2&#39;][&#39;title&#39;]=&#39;Affinity, kcal/mol&#39;
        fig.update_xaxes(showticklabels=False) # hide all the xticks
        fig.update_xaxes(showticklabels=True, row=2, col=1)
        
    
    save_as, save_format = self._save_figure(fig, save_as, save_format,
                                              save_scale, plot_width,
                                              plot_height, ppi)
        
    config = {&#39;displaylogo&#39;: False,
              &#39;modeBarButtonsToRemove&#39;: [&#39;zoom2d&#39;, &#39;pan2d&#39;, &#39;select2d&#39;,
                                         &#39;lasso2d&#39;, &#39;zoomIn2d&#39;, &#39;zoomOut2d&#39;,
                                         &#39;autoScale2d&#39;, &#39;resetScale2d&#39;,
                                         &#39;toggleSpikelines&#39;],
              &#39;toImageButtonOptions&#39;: {
                                       &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                       &#39;filename&#39;: save_as,
                                       &#39;height&#39;: plot_height*ppi,
                                       &#39;width&#39;: plot_width*ppi,
                                       &#39;scale&#39;: save_scale,
                                       },
             }
    
    if not interactive:
        config[&#39;staticPlot&#39;] = True

    if plot_out:
        return fig
    else:
        fig.show(config=config)</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filename, messages=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the speciation as a '.speciation' file to your current working
directory. This file can be loaded with <code>AqEquil.load(filename)</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>The desired name of the file.</dd>
<dt><strong><code>messages</code></strong> :&ensp;<code>str</code></dt>
<dd>Print a message confirming the save?</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, filename, messages=True):
    &#34;&#34;&#34;
    Save the speciation as a &#39;.speciation&#39; file to your current working
    directory. This file can be loaded with `AqEquil.load(filename)`.
    
    Parameters
    ----------
    filename : str
        The desired name of the file.
        
    messages : str
        Print a message confirming the save?
    &#34;&#34;&#34;
    
    if filename[-11:] != &#39;.speciation&#39;:
        filename = filename + &#39;.speciation&#39;
    
    with open(filename, &#39;wb&#39;) as handle:
        dill.dump(self, handle, protocol=dill.HIGHEST_PROTOCOL)
        if messages:
            print(&#34;Saved as &#39;{}&#39;&#34;.format(filename))</code></pre>
</details>
</dd>
<dt id="AqEquil.AqSpeciation.Speciation.scatterplot"><code class="name flex">
<span>def <span class="ident">scatterplot</span></span>(<span>self, x='pH', y='Temperature', title=None, plot_width=4, plot_height=3, ppi=122, fill_alpha=0.7, point_size=10, ylab=None, lineplot=False, colormap='WORM', save_as=None, save_format=None, save_scale=1, interactive=True, plot_out=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Vizualize two or more sample variables with a scatterplot.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong>, <strong><code>y</code></strong> :&ensp;<code>str</code>, default <code>for x is "pH"</code>, default <code>for y is "Temperature"</code></dt>
<dd>Names of the variables to plot against each other. Valid variables
are columns in the speciation report. <code>y</code> can be a list of
of variable names for a multi-series scatterplot.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Title of the plot.</dd>
<dt><strong><code>plot_width</code></strong>, <strong><code>plot_height</code></strong> :&ensp;<code>numeric</code>, default <code>4 by 3</code></dt>
<dd>Width and height of the plot, in inches. Size of interactive plots
is also determined by pixels per inch, set by the parameter <code>ppi</code>.</dd>
<dt><strong><code>ppi</code></strong> :&ensp;<code>numeric</code>, default <code>122</code></dt>
<dd>Pixels per inch. Along with <code>plot_width</code> and <code>plot_height</code>,
determines the size of interactive plots.</dd>
<dt><strong><code>fill_alpha</code></strong> :&ensp;<code>numeric</code>, default <code>0.7</code></dt>
<dd>Transparency of scatterpoint area fill.</dd>
<dt><strong><code>point_size</code></strong> :&ensp;<code>numeric</code>, default <code>10</code></dt>
<dd>Size of scatterpoints.</dd>
<dt><strong><code>colormap</code></strong> :&ensp;<code>str</code>, default <code>"WORM"</code></dt>
<dd>Name of the colormap to color the plotted data. Accepts "WORM",
"colorblind", or matplotlib colormaps.
See <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">https://matplotlib.org/stable/tutorials/colors/colormaps.html</a>
The "colorblind" colormap is referenced from Wong, B. Points of view:
Color blindness. Nat Methods 8, 441 (2011).
<a href="https://doi.org/10.1038/nmeth.1618">https://doi.org/10.1038/nmeth.1618</a></dd>
<dt><strong><code>save_as</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Provide a filename to save this figure. Filetype of saved figure is
determined by <code>save_format</code>.
Note: interactive plots can be saved by clicking the 'Download plot'
button in the plot's toolbar.</dd>
<dt><strong><code>save_format</code></strong> :&ensp;<code>str</code>, default <code>"png"</code></dt>
<dd>Desired format of saved or downloaded figure. Can be 'png', 'jpg',
'jpeg', 'webp', 'svg', 'pdf', 'eps', 'json', or 'html'. If 'html',
an interactive plot will be saved. Only 'png', 'svg', 'jpeg',
and 'webp' can be downloaded with the 'download as' button in the
toolbar of an interactive plot.</dd>
<dt><strong><code>save_scale</code></strong> :&ensp;<code>numeric</code>, default <code>1</code></dt>
<dd>Multiply title/legend/axis/canvas sizes by this factor when saving
the figure.</dd>
<dt><strong><code>interactive</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Return an interactive plot if True or a static plot if False.</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Return a plotly figure object? If True, a plot is not displayed as
it is generated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>Plotly figure object</code></dt>
<dd>A figure object is returned if <code>plot_out</code> is true. Otherwise, a
figure is simply displayed.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scatterplot(self, x=&#34;pH&#34;, y=&#34;Temperature&#34;, title=None,
                      plot_width=4, plot_height=3, ppi=122,
                      fill_alpha=0.7, point_size=10,
                      ylab=None, lineplot=False,
                      colormap=&#34;WORM&#34;, save_as=None, save_format=None,
                      save_scale=1, interactive=True, plot_out=False):
    
    &#34;&#34;&#34;
    Vizualize two or more sample variables with a scatterplot.
    
    Parameters
    ----------
    x, y : str, default for x is &#34;pH&#34;, default for y is &#34;Temperature&#34;
        Names of the variables to plot against each other. Valid variables
        are columns in the speciation report. `y` can be a list of
        of variable names for a multi-series scatterplot.

    title : str, optional
        Title of the plot.
    
    plot_width, plot_height : numeric, default 4 by 3
        Width and height of the plot, in inches. Size of interactive plots
        is also determined by pixels per inch, set by the parameter `ppi`.
    
    ppi : numeric, default 122
        Pixels per inch. Along with `plot_width` and `plot_height`,
        determines the size of interactive plots.
    
    fill_alpha : numeric, default 0.7
        Transparency of scatterpoint area fill.
    
    point_size : numeric, default 10
        Size of scatterpoints.
    
    colormap : str, default &#34;WORM&#34;
        Name of the colormap to color the plotted data. Accepts &#34;WORM&#34;,
        &#34;colorblind&#34;, or matplotlib colormaps.
        See https://matplotlib.org/stable/tutorials/colors/colormaps.html
        The &#34;colorblind&#34; colormap is referenced from Wong, B. Points of view:
        Color blindness. Nat Methods 8, 441 (2011).
        https://doi.org/10.1038/nmeth.1618
        
    save_as : str, optional
        Provide a filename to save this figure. Filetype of saved figure is
        determined by `save_format`.
        Note: interactive plots can be saved by clicking the &#39;Download plot&#39;
        button in the plot&#39;s toolbar.

    save_format : str, default &#34;png&#34;
        Desired format of saved or downloaded figure. Can be &#39;png&#39;, &#39;jpg&#39;,
        &#39;jpeg&#39;, &#39;webp&#39;, &#39;svg&#39;, &#39;pdf&#39;, &#39;eps&#39;, &#39;json&#39;, or &#39;html&#39;. If &#39;html&#39;,
        an interactive plot will be saved. Only &#39;png&#39;, &#39;svg&#39;, &#39;jpeg&#39;,
        and &#39;webp&#39; can be downloaded with the &#39;download as&#39; button in the
        toolbar of an interactive plot.

    save_scale : numeric, default 1
        Multiply title/legend/axis/canvas sizes by this factor when saving
        the figure.
    
    interactive : bool, default True
        Return an interactive plot if True or a static plot if False.
        
    plot_out : bool, default False
        Return a plotly figure object? If True, a plot is not displayed as
        it is generated.
        
    Returns
    -------
    fig : Plotly figure object
        A figure object is returned if `plot_out` is true. Otherwise, a
        figure is simply displayed.
    &#34;&#34;&#34;

    if not isinstance(y, list):
        y = [y]
    
    if not isinstance(x, str):
        self.err_handler.raise_exception(&#34;x must be a string.&#34;)
    
    x_col = self.lookup(x)
    
    try:
        xsubheader = x_col.columns.get_level_values(1)[0]
    except:
        msg = (&#34;Could not find &#39;{}&#39; &#34;.format(x)+&#34;in the speciation &#34;
               &#34;report. Available variables include &#34;
               &#34;{}&#34;.format(list(set(self.report.columns.get_level_values(0)))))
        self.err_handler.raise_exception(msg)
        
    try:
        x_plot = [float(x0[0]) if x0[0] != &#39;NA&#39; else float(&#34;nan&#34;) for x0 in x_col.values.tolist()]
    except:
        msg = (&#34;One or more the values belonging to &#34;
               &#34;&#39;{}&#39; are non-numeric and cannot be plotted.&#34;.format(x_col.columns.get_level_values(0)[0]))
        self.err_handler.raise_exception(msg)
    
    try:
        xunit_type, xunit = self.__get_unit_info(xsubheader)
    except:
        xunit_type = &#34;&#34;
        xunit = &#34;&#34;

    colors = _get_colors(colormap, len(y), alpha=fill_alpha)
    
    for i, yi in enumerate(y):
        y_col = self.lookup(yi)
        
        try:
            subheader = y_col.columns.get_level_values(1)[0]
        except:
            msg = (&#34;Could not find &#39;{}&#39; &#34;.format(yi)+&#34;in the speciation &#34;
                   &#34;report. Available variables include &#34;
                  &#34;{}&#34;.format(list(set(self.report.columns.get_level_values(0)))))
            self.err_handler.raise_exception(msg)
        try:
            unit_type, unit = self.__get_unit_info(subheader)
        except:
            unit_type = &#34;&#34;
            unit = &#34;&#34;
        
        try:
            y_plot = [float(y0[0]) if y0[0] != &#39;NA&#39; else float(&#34;nan&#34;) for y0 in y_col.values.tolist()]
        except:
            msg = (&#34;One or more the values belonging to &#34;
                   &#34;&#39;{}&#39; are non-numeric and cannot be plotted.&#34;.format(y_col.columns.get_level_values(0)[0]))
            self.err_handler.raise_exception(msg)
            
        if i == 0:
            subheader_previous = subheader
            unit_type_previous = unit_type
        if unit_type != unit_type_previous and i != 0:
            msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                   &#34;({}) than {} ({}). &#34;.format(unit_type, yi_previous, unit_type_previous)+&#34;&#34;
                   &#34;Plotted variables must share units.&#34;)
            self.err_handler.raise_exception(msg)
        elif &#34;activity&#34; in subheader.lower() and &#34;molality&#34; in subheader_previous.lower():
            msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                   &#34;({}) than {} ({}). &#34;.format(&#34;activity&#34;, yi_previous, &#34;molality&#34;)+&#34;&#34;
                   &#34;Plotted variables must share units.&#34;)
            self.err_handler.raise_exception(msg)
        elif &#34;molality&#34; in subheader.lower() and &#34;activity&#34; in subheader_previous.lower():
            msg = (&#34;{} has a different unit of measurement &#34;.format(yi)+&#34;&#34;
                   &#34;({}) than {} ({}). &#34;.format(&#34;molality&#34;, yi_previous, &#34;activity&#34;)+&#34;&#34;
                   &#34;Plotted variables must share units.&#34;)
            self.err_handler.raise_exception(msg)
            
        yi_previous = copy.deepcopy(yi)
        unit_type_previous = copy.deepcopy(unit_type)
        subheader_previous = copy.deepcopy(subheader)

    if len(y) &gt; 1:
        if unit != &#34;&#34;:
            ylabel = &#34;{} [{}]&#34;.format(unit_type, unit)
        else:
            ylabel = unit_type
    else:
        if &#39;pH&#39; in y:
            ylabel = &#39;pH&#39;
        elif &#39;Temperature&#39; in y:
            ylabel = &#39;Temperature [C]&#39;
        else:
            y_formatted = chemlabel(y[0])
            if unit != &#34;&#34;:
                ylabel = &#34;{} {} [{}]&#34;.format(y_formatted, unit_type, unit)
            else:
                ylabel = &#34;{} {}&#34;.format(y_formatted, unit_type)
    
    if x == &#39;pH&#39;:
        xlabel = &#39;pH&#39;
    elif x == &#39;Temperature&#39;:
        xlabel = &#39;Temperature [C]&#39;
    else:
        x_formatted = chemlabel(x)
        if xunit != &#34;&#34;:
            xlabel = &#34;{} {} [{}]&#34;.format(x_formatted, xunit_type, xunit)
        else:
            xlabel = &#34;{} {}&#34;.format(x_formatted, xunit_type)

    # convert rgba to hex
    colors = [matplotlib.colors.rgb2hex(c) for c in colors]

    # map each species to its color, e.g.,
    # {&#39;CO2&#39;: &#39;#000000&#39;, &#39;HCO3-&#39;: &#39;#1699d3&#39;, &#39;Other&#39;: &#39;#736ca8&#39;}
    dict_species_color = {sp:color for sp,color in zip(y, colors)}
    
    # html format color dict key names
    dict_species_color = {chemlabel(k):v for k,v in dict_species_color.items()}
    
    df = self.lookup([&#34;name&#34;, x]+y).copy()
    df.loc[:, &#34;name&#34;] = df.index
    df.columns = df.columns.get_level_values(0)
    df = pd.melt(df, id_vars=[&#34;name&#34;, x], value_vars=y)
    df = df.rename(columns={&#34;Sample&#34;: &#34;y_variable&#34;, &#34;value&#34;: &#34;y_value&#34;})
    
    if (unit_type == &#34;energy supply&#34; or unit_type == &#34;affinity&#34;) and isinstance(self.reactions_for_plotting, pd.DataFrame):
        
        # get formatted reactions to display
        if not isinstance(self.reactions_for_plotting, pd.DataFrame):
            self.reactions_for_plotting = self.show_redox_reactions(formatted=True,
                                                                   charge_sign_at_end=False,
                                                                   show=False, simplify=True)
        
        y_find = [yi.replace(&#34;_energy&#34;, &#34;&#34;).replace(&#34;_affinity&#34;, &#34;&#34;) for yi in y]
        
        
        rxns = self.reactions_for_plotting.loc[y_find, :][&#34;reaction&#34;].tolist()
        rxn_dict = {rxn_name:rxn for rxn_name,rxn in zip(y, rxns)}

        if len(y) == 1:
            ylabel = &#34;{}&lt;br&gt;{} [{}]&#34;.format(chemlabel(y_find[0]), unit_type, unit)
        
        df[&#34;formatted_rxn&#34;] = df[&#34;y_variable&#34;].map(rxn_dict)
    else:
        df[&#34;formatted_rxn&#34;] = &#34;&#34;
    
    df[&#39;y_variable&#39;] = df[&#39;y_variable&#39;].apply(chemlabel)
    
    if ylab != None:
        ylabel=ylab
    
    if lineplot:
        fig = px.line(df, x=x, y=&#34;y_value&#34;, color=&#34;y_variable&#34;,
                         hover_data=[x, &#34;y_value&#34;, &#34;y_variable&#34;, &#34;name&#34;, &#34;formatted_rxn&#34;],
                         width=plot_width*ppi, height=plot_height*ppi,
                         labels={x: xlabel,  &#34;y_value&#34;: ylabel},
                         category_orders={&#34;species&#34;: y},
                         color_discrete_map=dict_species_color,
                         custom_data=[&#39;name&#39;, &#39;formatted_rxn&#39;],
                         template=&#34;simple_white&#34;)
    else:
        fig = px.scatter(df, x=x, y=&#34;y_value&#34;, color=&#34;y_variable&#34;,
                         hover_data=[x, &#34;y_value&#34;, &#34;y_variable&#34;, &#34;name&#34;, &#34;formatted_rxn&#34;],
                         width=plot_width*ppi, height=plot_height*ppi,
                         labels={x: xlabel,  &#34;y_value&#34;: ylabel},
                         category_orders={&#34;species&#34;: y},
                         color_discrete_map=dict_species_color,
                         opacity=fill_alpha,
                         custom_data=[&#39;name&#39;, &#39;formatted_rxn&#39;],
                         template=&#34;simple_white&#34;)
    
    
    fig.update_traces(marker=dict(size=point_size),
                      hovertemplate = &#34;%{customdata[0]}&lt;br&gt;&#34;+xlabel+&#34;: %{x} &lt;br&gt;&#34;+ylabel+&#34;: %{y}&lt;br&gt;%{customdata[1]}&#34;)
    fig.update_layout(legend_title=None,
                      title={&#39;text&#39;:title, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39;},
                      margin={&#34;t&#34;: 40},
                      yaxis={&#39;exponentformat&#39;:&#39;power&#39;})
    if len(y) == 1:
        fig.update_layout(showlegend=False)
        
    save_as, save_format = self._save_figure(fig, save_as, save_format,
                                              save_scale, plot_width,
                                              plot_height, ppi)

    config = {&#39;displaylogo&#39;: False, &#39;scrollZoom&#39;: True,
              &#39;modeBarButtonsToRemove&#39;: [&#39;select2d&#39;, &#39;lasso2d&#39;, &#39;toggleSpikelines&#39;, &#39;resetScale2d&#39;],
              &#39;toImageButtonOptions&#39;: {
                                       &#39;format&#39;: save_format, # one of png, svg, jpeg, webp
                                       &#39;filename&#39;: save_as,
                                       &#39;height&#39;: plot_height*ppi,
                                       &#39;width&#39;: plot_width*ppi,
                                       &#39;scale&#39;: save_scale,
                                       },
             }

    if not interactive:
        config[&#39;staticPlot&#39;] = True
    
    if plot_out:
        return fig
    else:
        fig.show(config=config)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="AqEquil" href="index.html">AqEquil</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="AqEquil.AqSpeciation.chemlabel" href="#AqEquil.AqSpeciation.chemlabel">chemlabel</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.compare" href="#AqEquil.AqSpeciation.compare">compare</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.load" href="#AqEquil.AqSpeciation.load">load</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="AqEquil.AqSpeciation.AqEquil" href="#AqEquil.AqSpeciation.AqEquil">AqEquil</a></code></h4>
<ul class="">
<li><code><a title="AqEquil.AqSpeciation.AqEquil.Thermodata" href="#AqEquil.AqSpeciation.AqEquil.Thermodata">Thermodata</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.AqEquil.create_data0" href="#AqEquil.AqSpeciation.AqEquil.create_data0">create_data0</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.AqEquil.make_redox_reactions" href="#AqEquil.AqSpeciation.AqEquil.make_redox_reactions">make_redox_reactions</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.AqEquil.plot_logK_fit" href="#AqEquil.AqSpeciation.AqEquil.plot_logK_fit">plot_logK_fit</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.AqEquil.runeq3" href="#AqEquil.AqSpeciation.AqEquil.runeq3">runeq3</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.AqEquil.runeq6" href="#AqEquil.AqSpeciation.AqEquil.runeq6">runeq6</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.AqEquil.runeqpt" href="#AqEquil.AqSpeciation.AqEquil.runeqpt">runeqpt</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.AqEquil.show_redox_reactions" href="#AqEquil.AqSpeciation.AqEquil.show_redox_reactions">show_redox_reactions</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.AqEquil.speciate" href="#AqEquil.AqSpeciation.AqEquil.speciate">speciate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="AqEquil.AqSpeciation.Error_Handler" href="#AqEquil.AqSpeciation.Error_Handler">Error_Handler</a></code></h4>
<ul class="">
<li><code><a title="AqEquil.AqSpeciation.Error_Handler.hide_traceback" href="#AqEquil.AqSpeciation.Error_Handler.hide_traceback">hide_traceback</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Error_Handler.raise_exception" href="#AqEquil.AqSpeciation.Error_Handler.raise_exception">raise_exception</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="AqEquil.AqSpeciation.Speciation" href="#AqEquil.AqSpeciation.Speciation">Speciation</a></code></h4>
<ul class="">
<li><code><a title="AqEquil.AqSpeciation.Speciation.barplot" href="#AqEquil.AqSpeciation.Speciation.barplot">barplot</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Speciation.join_6i_p" href="#AqEquil.AqSpeciation.Speciation.join_6i_p">join_6i_p</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Speciation.lookup" href="#AqEquil.AqSpeciation.Speciation.lookup">lookup</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Speciation.mt" href="#AqEquil.AqSpeciation.Speciation.mt">mt</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Speciation.plot_logK_fit" href="#AqEquil.AqSpeciation.Speciation.plot_logK_fit">plot_logK_fit</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Speciation.plot_mass_contribution" href="#AqEquil.AqSpeciation.Speciation.plot_mass_contribution">plot_mass_contribution</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Speciation.plot_mineral_saturation" href="#AqEquil.AqSpeciation.Speciation.plot_mineral_saturation">plot_mineral_saturation</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Speciation.plot_solid_solutions" href="#AqEquil.AqSpeciation.Speciation.plot_solid_solutions">plot_solid_solutions</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Speciation.save" href="#AqEquil.AqSpeciation.Speciation.save">save</a></code></li>
<li><code><a title="AqEquil.AqSpeciation.Speciation.scatterplot" href="#AqEquil.AqSpeciation.Speciation.scatterplot">scatterplot</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>